{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "333ae546d607a744",
      "metadata": {
        "id": "333ae546d607a744"
      },
      "source": [
        "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
        "\n",
        "## Objective:\n",
        "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hj5lLPVzpy7s",
      "metadata": {
        "id": "Hj5lLPVzpy7s"
      },
      "source": [
        "# Step 1: Import libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import gensim.downloader as api\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d2iS-X-p4xh",
      "metadata": {
        "id": "2d2iS-X-p4xh"
      },
      "source": [
        "# STEP 2: Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6mi0-SIdsHZk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mi0-SIdsHZk",
        "outputId": "1e3a8465-6984-4697-da31-a720e6b00c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   id            guest                    title  \\\n",
            "0   1      Max Tegmark                 Life 3.0   \n",
            "1   2    Christof Koch            Consciousness   \n",
            "2   3    Steven Pinker  AI in the Age of Reason   \n",
            "3   4    Yoshua Bengio            Deep Learning   \n",
            "4   5  Vladimir Vapnik     Statistical Learning   \n",
            "\n",
            "                                                text  \n",
            "0  As part of MIT course 6S099, Artificial Genera...  \n",
            "1  As part of MIT course 6S099 on artificial gene...  \n",
            "2  You've studied the human mind, cognition, lang...  \n",
            "3  What difference between biological neural netw...  \n",
            "4  The following is a conversation with Vladimir ...  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Especificar la ruta completa al archivo CSV\n",
        "file_path = '/content/drive/My Drive/Week10RI/podcastdata_dataset.csv'\n",
        "\n",
        "# Leer el archivo CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Mostrar las primeras filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RFqvFzdXqgRk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFqvFzdXqgRk",
        "outputId": "fe4c9c66-5a42-4621-a599-9642bcf80e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(319, 4)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fxZHduQVwZNN",
      "metadata": {
        "id": "fxZHduQVwZNN"
      },
      "source": [
        "# Step 3: Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5_0NBU6mVB3l",
      "metadata": {
        "id": "5_0NBU6mVB3l"
      },
      "source": [
        "- Delete puntuaciones\n",
        "- Delete stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QDnqSRvIu2g2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDnqSRvIu2g2",
        "outputId": "0b6e241c-8961-43b4-b560-b9caedabeaff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    As part of MIT course 6S099, Artificial Genera...\n",
            "1    As part of MIT course 6S099 on artificial gene...\n",
            "2    You've studied the human mind, cognition, lang...\n",
            "3    What difference between biological neural netw...\n",
            "4    The following is a conversation with Vladimir ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Mostrar los textos en un  DataFrame\n",
        "corpus = df['text']\n",
        "print(corpus.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ke4wozE4eGIp",
      "metadata": {
        "id": "Ke4wozE4eGIp"
      },
      "source": [
        "### Eliminamos los caracteres especiales, y transformamos Mayusculas a minusculas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19pPMbXQq20k",
      "metadata": {
        "id": "19pPMbXQq20k"
      },
      "outputs": [],
      "source": [
        "# Mostrar los textos en un  DataFrame\n",
        "corpus_nopunct = []\n",
        "#Iterar sobre cada documento del corpus\n",
        "for doc in corpus:\n",
        "   # Convertir el texto del documento a minúsculas y eliminar todos los caracteres de puntuación\n",
        "  corpus_nopunct.append(doc.lower().translate(str.maketrans('','',string.punctuation)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KivqZV9Kq2xL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KivqZV9Kq2xL",
        "outputId": "bf378371-a818-41a2-85f9-825d55fd2f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['as part of mit course 6s099 artificial general intelligence ive gotten the chance to sit down with max tegmark he is a professor here at mit hes a physicist spent a large part of his career studying the mysteries of our cosmological universe but hes also studied and delved into the beneficial possibilities and the existential risks of artificial intelligence amongst many other things he is the cofounder of the future of life institute author of two books both of which i highly recommend first our mathematical universe second is life 30 hes truly an out of the box thinker and a fun personality so i really enjoy talking to him if youd like to see more of these videos in the future please subscribe and also click the little bell icon to make sure you dont miss any videos also twitter linkedin agimitedu if you wanna watch other lectures or conversations like this one better yet go read maxs book life 30 chapter seven on goals is my favorite its really where philosophy and engineering come together and it opens with a quote by dostoevsky the mystery of human existence lies not in just staying alive but in finding something to live for lastly i believe that every failure rewards us with an opportunity to learn and in that sense ive been very fortunate to fail in so many new and exciting ways and this conversation was no different ive learned about something called radio frequency interference rfi look it up apparently music and conversations from local radio stations can bleed into the audio that youre recording in such a way that it almost completely ruins that audio its an exceptionally difficult sound source to remove so ive gotten the opportunity to learn how to avoid rfi in the future during recording sessions ive also gotten the opportunity to learn how to use adobe audition and izotope rx 6 to do some noise some audio repair of course this is an exceptionally difficult noise to remove i am an engineer im not an audio engineer neither is anybody else in our group but we did our best nevertheless i thank you for your patience and i hope youre still able to enjoy this conversation do you think theres intelligent life out there in the universe lets open up with an easy question i have a minority view here actually when i give public lectures i often ask for a show of hands who thinks theres intelligent life out there somewhere else and almost everyone put their hands up and when i ask why theyll be like oh theres so many galaxies out there theres gotta be but im a numbers nerd right so when you look more carefully at it its not so clear at all when we talk about our universe first of all we dont mean all of space we actually mean i dont know you can throw me the universe if you want its behind you there its we simply mean the spherical region of space from which light has a time to reach us so far during the 148 billion year 138 billion years since our big bang theres more space here but this is what we call a universe because thats all we have access to so is there intelligent life here thats gotten to the point of building telescopes and computers my guess is no actually the probability of it happening on any given planet is some number we dont know what it is and what we do know is that the number cant be super high because theres over a billion earth like planets in the milky way galaxy alone many of which are billions of years older than earth and aside from some ufo believers there isnt much evidence that any superduran civilization has come here at all and so thats the famous fermi paradox right and then if you work the numbers what you find is that if you have no clue what the probability is of getting life on a given planet so it could be 10 to the minus 10 10 to the minus 20 or 10 to the minus two or any power of 10 is sort of equally likely if you wanna be really open minded that translates into it being equally likely that our nearest neighbor is 10 to the 16 meters away 10 to the 17 meters away 10 to the 18 by the time you get much less than 10 to the 16 already we pretty much know there is nothing else that close and when you get beyond 10 because they would have discovered us yeah they would have been discovered as long ago or if theyre really close we would have probably noted some engineering projects that theyre doing and if its beyond 10 to the 26 meters thats already outside of here so my guess is actually that we are the only life in here thats gotten the point of building advanced tech which i think is very puts a lot of responsibility on our shoulders not screw up i think people who take for granted that its okay for us to screw up have an accidental nuclear war or go extinct somehow because theres a sort of star trek like situation out there where some other life forms are gonna come and bail us out and it doesnt matter as much i think theyre leveling us into a false sense of security i think its much more prudent to say lets be really grateful for this amazing opportunity weve had and make the best of it just in case it is down to us so from a physics perspective do you think intelligent life so its unique from a sort of statistical view of the size of the universe but from the basic matter of the universe how difficult is it for intelligent life to come about the kind of advanced tech building life is implied in your statement that its really difficult to create something like a human species well i think what we know is that going from no life to having life that can do a level of tech theres some sort of two going beyond that than actually settling our whole universe with life theres some major roadblock there which is some great filter as its sometimes called which is tough to get through its either that roadblock is either behind us or in front of us im hoping very much that its behind us im super excited every time we get a new report from nasa saying they failed to find any life on mars im like yes awesome because that suggests that the hard part maybe it was getting the first ribosome or some very low level kind of stepping stone so that were home free because if thats true then the future is really only limited by our own imagination it would be much suckier if it turns out that this level of life is kind of a dime a dozen but maybe theres some other problem like as soon as a civilization gets advanced technology within a hundred years they get into some stupid fight with themselves and poof that would be a bummer yeah so youve explored the mysteries of the universe the cosmological universe the one thats sitting between us today i think youve also begun to explore the other universe which is sort of the mystery the mysterious universe of the mind of intelligence of intelligent life so is there a common thread between your interest or the way you think about space and intelligence oh yeah when i was a teenager i was already very fascinated by the biggest questions and i felt that the two biggest mysteries of all in science were our universe out there and our universe in here so its quite natural after having spent a quarter of a century on my career thinking a lot about this one that im now indulging in the luxury of doing research on this one its just so cool i feel the time is ripe now for you trans greatly deepening our understanding of this just start exploring this one yeah because i think a lot of people view intelligence as something mysterious that can only exist in biological organisms like us and therefore dismiss all talk about artificial general intelligence as science fiction but from my perspective as a physicist i am a blob of quarks and electrons moving around in a certain pattern and processing information in certain ways and this is also a blob of quarks and electrons im not smarter than the water bottle because im made of different kinds of quarks im made of up quarks and down quarks exact same kind as this theres no secret sauce i think in me its all about the pattern of the information processing and this means that theres no law of physics saying that we cant create technology which can help us by being incredibly intelligent and help us crack mysteries that we couldnt in other words i think weve really only seen the tip of the intelligence iceberg so far yeah so the perceptronium yeah so you coined this amazing term its a hypothetical state of matter sort of thinking from a physics perspective what is the kind of matter that can help as youre saying subjective experience emerge consciousness emerge so how do you think about consciousness from this physics perspective very good question so again i think many people have underestimated our ability to make progress on this by convincing themselves its hopeless because somehow were missing some ingredient that we need theres some new consciousness particle or whatever i happen to think that were not missing anything and that its not the interesting thing about consciousness that gives us this amazing subjective experience of colors and sounds and emotions its rather something at the higher level about the patterns of information processing and thats why i like to think about this idea of perceptronium what does it mean for an arbitrary physical system to be conscious in terms of what its particles are doing or its information is doing i dont think i hate carbon chauvinism this attitude you have to be made of carbon atoms to be smart or conscious theres something about the information processing that this kind of matter performs yeah and you can see i have my favorite equations here describing various fundamental aspects of the world i feel that i think one day maybe someone whos watching this will come up with the equations that information processing has to satisfy to be conscious im quite convinced there is big discovery to be made there because lets face it we know that so many things are made up of information we know that some information processing is conscious because we are conscious but we also know that a lot of information processing is not conscious like most of the information processing happening in your brain right now is not conscious there are like 10 megabytes per second coming in even just through your visual system youre not conscious about your heartbeat regulation or most things even if i just ask you to like read what it says here you look at it and then oh now you know what it said but youre not aware of how the computation actually happened your consciousness is like the ceo that got an email at the end with the final answer so what is it that makes a difference i think thats both a great science mystery were actually studying it a little bit in my lab here at mit but i also think its just a really urgent question to answer for starters i mean if youre an emergency room doctor and you have an unresponsive patient coming in wouldnt it be great if in addition to having a ct scanner you had a consciousness scanner that could figure out whether this person is actually having locked in syndrome or is actually comatose and in the future imagine if we build robots or the machine that we can have really good conversations with which i think is very likely to happen wouldnt you want to know if your home helper robot is actually experiencing anything or just like a zombie i mean would you prefer it what would you prefer would you prefer that its actually unconscious so that you dont have to feel guilty about switching it off or giving boring chores or what would you prefer well certainly we would prefer i would prefer the appearance of consciousness but the question is whether the appearance of consciousness is different than consciousness itself and sort of to ask that as a question do you think we need to understand what consciousness is solve the hard problem of consciousness in order to build something like an agi system no i dont think that and i think we will probably be able to build things even if we dont answer that question but if we want to make sure that what happens is a good thing we better solve it first so its a wonderful controversy youre raising there where you have basically three points of view about the hard problem so there are two different points of view they both conclude that the hard problem of consciousness is bs on one hand you have some people like daniel dennett who say that consciousness is just bs because consciousness is the same thing as intelligence theres no difference so anything which acts conscious is conscious just like we are and then there are also a lot of people including many top ai researchers i know who say oh consciousness is just bullshit because of course machines can never be conscious theyre always going to be zombies you never have to feel guilty about how you treat them and then theres a third group of people including giulio tononi for example and krzysztof koch and a number of others i would put myself also in this middle camp who say that actually some information processing is conscious and some is not so lets find the equation which can be used to determine which it is and i think weve just been a little bit lazy kind of running away from this problem for a long time its been almost taboo to even mention the c word in a lot of circles because but we should stop making excuses this is a science question and there are ways we can even test any theory that makes predictions for this and coming back to this helper robot i mean so you said youd want your helper robot to certainly act conscious and treat you like have conversations with you and stuff i think so but wouldnt you would you feel would you feel a little bit creeped out if you realized that it was just a glossed up tape recorder you know that was just zombie and was a faking emotion would you prefer that it actually had an experience or would you prefer that its actually not experiencing anything so you feel you dont have to feel guilty about what you do to it its such a difficult question because you know its like when youre in a relationship and you say well i love you and the other person said i love you back its like asking well do they really love you back or are they just saying they love you back dont you really want them to actually love you its hard to its hard to really know the difference between everything seeming like theres consciousness present theres intelligence present theres affection passion love and it actually being there im not sure do you have but like can i ask you a question about this like to make it a bit more pointed so mass general hospital is right across the river right yes suppose youre going in for a medical procedure and theyre like you know for anesthesia what were going to do is were going to give you muscle relaxants so you wont be able to move and youre going to feel excruciating pain during the whole surgery but you wont be able to do anything about it but then were going to give you this drug that erases your memory of it would you be cool about that whats the difference that youre conscious about it or not if theres no behavioral change right right thats a really thats a really clear way to put it thats yeah it feels like in that sense experiencing it is a valuable quality so actually being able to have subjective experiences at least in that case is valuable and i think we humans have a little bit of a bad track record also of making these self serving arguments that other entities arent conscious you know people often say oh these animals cant feel pain its okay to boil lobsters because we ask them if it hurt and they didnt say anything and now there was just a paper out saying lobsters do feel pain when you boil them and theyre banning it in switzerland and we did this with slaves too often and said oh they dont mind they dont maybe arent conscious or women dont have souls or whatever so im a little bit nervous when i hear people just take as an axiom that machines cant have experience ever i think this is just a really fascinating science question is what it is lets research it and try to figure out what it is that makes the difference between unconscious intelligent behavior and conscious intelligent behavior so in terms of so if you think of a boston dynamics human or robot being sort of with a broom being pushed around it starts pushing on a consciousness question so let me ask do you think an agi system like a few neuroscientists believe needs to have a physical embodiment needs to have a body or something like a body no i dont think so you mean to have a conscious experience to have consciousness i do think it helps a lot to have a physical embodiment to learn the kind of things about the world that are important to us humans for sure but i dont think the physical embodiment is necessary after youve learned it to just have the experience think about when youre dreaming right your eyes are closed youre not getting any sensory input youre not behaving or moving in any way but theres still an experience there right and so clearly the experience that you have when you see something cool in your dreams isnt coming from your eyes its just the information processing itself in your brain which is that experience right but if i put it another way ill say because it comes from neuroscience is the reason you want to have a body and a physical something like a physical you know a physical system is because you want to be able to preserve something in order to have a self you could argue would you need to have some kind of embodiment of self to want to preserve well now were getting a little bit anthropomorphic into anthropomorphizing things maybe talking about self preservation instincts i mean we are evolved organisms right so darwinian evolution endowed us and other evolved organism with a self preservation instinct because those that didnt have those self preservation genes we can now i think quite convincingly answer that question of no its enough to have just one kind if you look under the hood of alphazero theres only one kind of neuron and its ridiculously simple mathematical thing so its just like in physics its not if you have a gas with waves in it its not the detailed nature of the molecule that matter its the collective behavior somehow similarly its this higher level structure of the network that matters not that you have 20 kinds of neurons i think our brain is such a complicated mess because it wasnt evolved just to be intelligent it was involved to also be self assembling and self repairing right and evolutionarily attainable and so on and so on so i think its pretty my hunch is that were going to understand how to build agi before we fully understand how our brains work just like we understood how to build flying machines long before we were able to build a mechanical bird yeah thats right youve given the example exactly of mechanical birds and airplanes and airplanes do a pretty good job of flying without really mimicking bird flight and even now after 100 years later did you see the ted talk with this german mechanical bird i heard you mention it check it out its amazing but even after that right we still dont fly in mechanical birds because it turned out the way we came up with was simpler and its better for our purposes and i think it might be the same there thats one lesson and another lesson its more what our paper was about first as a physicist thought it was fascinating how theres a very close mathematical relationship actually between our artificial neural networks and a lot of things that weve studied for in physics go by nerdy names like the renormalization group equation and hamiltonians and yada yada yada and when you look a little more closely at this you have at first i was like well theres something crazy here that doesnt make sense because we know that if you even want to build a super simple neural network to tell apart cat pictures and dog pictures right that you can do that very very well now but if you think about it a little bit you convince yourself it must be impossible because if i have one megapixel even if each pixel is just black or white theres two to the power of 1 million possible images which is way more than there are atoms in our universe right so in order to and then for each one of those i have to assign a number which is the probability that its a dog so an arbitrary function of images is a list of more numbers than there are atoms in our universe so clearly i cant store that under the hood of my gpu or my computer yet somehow it works so what does that mean well it means that out of all of the problems that you could try to solve with a neural network almost all of them are impossible to solve with a reasonably sized one but then what we showed in our paper was that the fraction the kind of problems the fraction of all the problems that you could possibly pose that we actually care about given the laws of physics is also an infinite testimony tiny little part and amazingly theyre basically the same part yeah its almost like our world was created for i mean they kind of come together yeah well you could say maybe where the world was created for us but i have a more modest interpretation which is that the world was created for us but i have a more modest interpretation which is that instead evolution endowed us with neural networks precisely for that reason because this particular architecture as opposed to the one in your laptop is very very well adapted to solving the kind of problems that nature kept presenting our ancestors with so it makes sense that why do we have a brain in the first place its to be able to make predictions about the future and so on so if we had a sucky system which could never solve it we wouldnt have a world so this is i think a very beautiful fact yeah we also realize that theres been earlier work on why deeper networks are good but we were able to show an additional cool fact there which is that even incredibly simple problems like suppose i give you a thousand numbers and ask you to multiply them together and you can write a few lines of code boom done trivial if you just try to do that with a neural network that has only one single hidden layer in it you can do it but youre going to need two to the power of a thousand neurons to multiply a thousand numbers which is again more neurons than there are atoms in our universe thats fascinating but if you allow yourself to make it a deep network with many layers you only need 4000 neurons its perfectly feasible thats really interesting yeah so on another architecture type i mean you mentioned schrodingers equation and what are your thoughts about quantum computing and the role of this kind of computational unit in creating an intelligence system in some hollywood movies that i will not mention by name because i dont want to spoil them the way they get agi is building a quantum computer because the word quantum sounds cool and so on thats right first of all i think we dont need quantum computers to build agi i suspect your brain is not a quantum computer in any profound sense so you dont even wrote a paper about that a lot many years ago i calculated the so called decoherence time how long it takes until the quantum computerness of what your neurons are doing gets erased by just random noise from the environment and its about 10 to the minus 21 seconds so as cool as it would be to have a quantum computer in my head i dont think that fast on the other hand there are very cool things you could do with quantum computers or i think well be able to do soon when we get bigger ones that might actually help machine learning do even better than the brain so for example one this is just a moonshot but learning is very much same thing as search if youre trying to train a neural network to get really learned to do something really well you have some loss function you have a bunch of knobs you can turn represented by a bunch of numbers and youre trying to tweak them so that it becomes as good as possible at this thing so if you think of a landscape with some valley where each dimension of the landscape corresponds to some number you can change youre trying to find the minimum and its well known that if you have a very high dimensional landscape complicated things its super hard to find the minimum quantum mechanics is amazingly good at this like if i want to know whats the lowest energy state this water can possibly have incredibly hard to compute but nature will happily figure this out for you if you just cool it down make it very very cold if you put a ball somewhere itll roll down to its minimum and this happens metaphorically at the energy landscape too and quantum mechanics even uses some clever tricks which todays machine learning systems dont like if youre trying to find the minimum and you get stuck in the little local minimum here in quantum mechanics you can actually tunnel through the barrier and get unstuck again thats really interesting yeah so it may be for example that well one day use quantum computers that help train neural networks better thats really interesting okay so as a component of kind of the learning process for example yeah let me ask sort of wrapping up here a little bit let me return to the questions of our human nature and love as i mentioned so do you think you mentioned sort of a helper robot but you could think of also personal robots do you think the way we human beings fall in love and get connected to each other is possible to achieve in an ai system and human level ai intelligence system do you think we would ever see that kind of connection or you know in all this discussion about solving complex goals is this kind of human social connection do you think thats one of the goals on the peaks and valleys with the raising sea levels that well be able to achieve or do you think thats something thats ultimately or at least in the short term relative to the other goals is not achievable i think its all possible and i mean in recent theres a very wide range of guesses as you know among ai researchers when were going to get agi some people you know like our friend rodney brooks says its going to be hundreds of years at least and then there are many others who think its going to happen much sooner and recent polls maybe half or so of ai researchers think were going to get agi within decades so if that happens of course then i think these things are all possible but in terms of whether it will happen i think we shouldnt spend so much time asking what do we think will happen in the future as if we are just some sort of pathetic your passive bystanders you know waiting for the future to happen to us hey were the ones creating this future right so we should be proactive about it and ask ourselves what sort of future we would like to have happen were going to make it like that well what i prefer is just some sort of incredibly boring zombie like future where theres all these mechanical things happening and theres no passion no emotion no experience maybe even no i would of course much rather prefer it if all the things that we find that we value the most about humanity are our subjective experience passion inspiration love you know if we can create a future where those things do happen where those things do exist you know i think ultimately its not our universe giving meaning to us its us giving meaning to our universe and if we build more advanced intelligence lets make sure we build it in such a way that meaning is part of it a lot of people that seriously study this problem and think of it from different angles have trouble in the majority of cases if they think through that happen are the ones that are not beneficial to humanity and so yeah so what are your thoughts whats should people you know i really dont like people to be terrified whats a way for people to think about it in a way we can solve it and we can make it better no i dont think panicking is going to help in any way its not going to increase chances of things going well either even if you are in a situation where there is a real threat does it help if everybody just freaks out no of course of course not i think yeah there are of course ways in which things can go horribly wrong first of all its important when we think about this thing about the problems and risks to also remember how huge the upsides can be if we get it right right everything we love about society and civilization is a product of intelligence so if we can amplify our intelligence with machine intelligence and not anymore lose our loved one to what were told is an incurable disease and things like this of course we should aspire to that so that can be a motivator i think reminding ourselves that the reason we try to solve problems is not just because were trying to avoid gloom but because were trying to do something great but then in terms of the risks i think the really important question is to ask what can we do today that will actually help make the outcome good right and dismissing the risk is not one of them i find it quite funny often when im in discussion panels about these things how the people who work for companies always be like oh nothing to worry about nothing to worry about nothing to worry about and its only academics sometimes express concerns thats not surprising at all if you think about it right upton sinclair quipped right that its hard to make a man believe in something when his income depends on not believing in it and frankly we know a lot of these people in companies that theyre just as concerned as anyone else but if youre the ceo of a company thats not something you want to go on record saying when you have silly journalists who are gonna put a picture of a terminator robot when they quote you so the issues are real and the way i think about what the issue is is basically the real choice we have is first of all are we gonna just dismiss the risks and say well lets just go ahead and build machines that can do everything we can do better and cheaper lets just make ourselves obsolete as fast as possible what could possibly go wrong thats one attitude the opposite attitude i think is to say heres this incredible potential lets think about what kind of future were really really excited about what are the shared goals that we can really aspire towards and then lets think really hard about how we can actually get there so start with dont start thinking about the risks start thinking about the goals and then when you do that then you can think about the obstacles you want to avoid i often get students coming in right here into my office for career advice i always ask them this very question where do you want to be in the future if all she can say is oh maybe ill have cancer maybe ill get run over by a truck yeah focus on the obstacles instead of the goals shes just going to end up a hypochondriac paranoid whereas if she comes in and fire in her eyes and is like i want to be there and then we can talk about the obstacles and see how we can circumvent them thats i think a much much healthier attitude and i feel its very challenging to come up with a vision for the future which we are unequivocally excited about im not just talking now in the vague terms like yeah lets cure cancer fine im talking about what kind of society do we want to create what do we want it to mean to be human in the age of ai in the age of agi so if we can have this conversation broad inclusive conversation and gradually start converging towards some some future that with some direction at least that we want to steer towards right then well be much more motivated to constructively take on the obstacles and i think if i had if i had to if i try to wrap this up in a more succinct way i think we can all agree already now that we should aspire to build agi that doesnt overpower us but that empowers us and think of the many various ways that can do that whether thats from my side of the world of autonomous vehicles im personally actually from the camp that believes this human level intelligence is required to achieve something like vehicles that would actually be something we would enjoy using and being part of so thats one example and certainly theres a lot of other types of robots and medicine and so on so focusing on those and then coming up with the obstacles coming up with the ways that that can go wrong and solving those one at a time and just because you can build an autonomous vehicle even if you could build one that would drive just fine without you maybe there are some things in life that we would actually want to do ourselves thats right right like for example if you think of our society as a whole there are some things that we find very meaningful to do and that doesnt mean we have to stop doing them just because machines can do them better im not gonna stop playing tennis just the day someone builds a tennis robot and beat me people are still playing chess and even go yeah and in the very near term even some people are advocating basic income replace jobs but if the government is gonna be willing to just hand out cash to people for doing nothing then one should also seriously consider whether the government should also hire a lot more teachers and nurses and the kind of jobs which people often find great fulfillment in doing right we get very tired of hearing politicians saying oh we cant afford hiring more teachers but were gonna maybe have basic income if we can have more serious research and thought into what gives meaning to our lives the jobs give so much more than income right mm hmm and then think about in the future what are the roles that we wanna have people continually feeling empowered by machines and i think sort of i come from russia from the soviet union and i think for a lot of people in the 20th century going to the moon going to space was an inspiring thing i feel like the universe of the mind so ai understanding creating intelligence is that for the 21st century so its really surprising and ive heard you mention this its really surprising to me both on the research funding side that its not funded as greatly as it could be but most importantly on the politician side that its not part of the public discourse except in the killer bots terminator kind of view that people are not yet i think perhaps excited by the possible positive future that we can build together so we should be because politicians usually just focus on the next election cycle right the single most important thing i feel we humans have learned in the entire history of science is they were the masters of underestimation we underestimated the size of our cosmos again and again realizing that everything we thought existed was just a small part of something grander right planet solar system the galaxy clusters of galaxies the universe and we now know that the future has just so much more potential than our ancestors could ever have dreamt of this cosmos imagine if all of earth was completely devoid of life except for cambridge massachusetts wouldnt it be kind of lame if all we ever aspired to was to stay in cambridge massachusetts forever and then go extinct in one week even though earth was gonna continue on for longer that sort of attitude i think we have now on the cosmic scale life can flourish on earth not for four years but for billions of years i can even tell you about how to move it out of harms way when the sun gets too hot and then we have so much more resources out here which today maybe there are a lot of other planets with bacteria or cow like life on them but most of this all this opportunity seems as far as we can tell to be largely dead like the sahara desert and yet we have the opportunity to help life flourish around this for billions of years so lets quit squabbling about whether some little border should be drawn one mile to the left or right and look up into the skies and realize hey we can do such incredible things yeah and thats i think why its really exciting that you and others are connected with some of the work elon musk is doing because hes literally going out into that space really exploring our universe and its wonderful that is exactly why elon musk is so misunderstood right misconstrued him as some kind of pessimistic doomsayer the reason he cares so much about ai safety is because he more than almost anyone else appreciates these amazing opportunities that well squander if we wipe out here on earth were not just going to wipe out the next generation all generations and this incredible opportunity thats out there and that would really be a waste and ai for people who think that it would be better to do without technology let me just mention that if we dont improve our technology the question isnt whether humanity is going to go extinct the question is just whether were going to get taken out by the next big asteroid or the next super volcano or something else dumb that we could easily prevent with more tech right and if we want life to flourish throughout the cosmos ai is the key to it as i mentioned in a lot of detail in my book right there even many of the most inspired sci fi writers i feel have totally underestimated the opportunities for space travel especially at the other galaxies because they werent thinking about the possibility of agi which just makes it so much easier right yeah so that goes to your view of agi that enables our progress that enables a better life so thats a beautiful way to put it and then something to strive for so max thank you so much thank you for your time today its been awesome thank you so much thanks have a great day got cleaned out of the gene pool right but if you build an artificial general intelligence the mind space that you can design is much much larger than just a specific subset of minds that can evolve so an agi mind doesnt necessarily have to have any self preservation instinct it also doesnt necessarily have to be so individualistic as us like imagine if you could just first of all or we are also very afraid of death you know i suppose you could back yourself up every five minutes and then your airplane is about to crash youre like shucks im gonna lose the last five minutes of experiences since my last cloud backup dang you know its not as big a deal or if we could just copy experiences between our minds easily like we which we could easily do if we were silicon based right then maybe we would feel a little bit more like a hive mind actually that maybe its the so i dont think we should take for granted at all that agi will have to have any of those sort of competitive as alpha male instincts on the other hand you know this is really interesting because i think some people go too far and say of course we dont have to have any concerns either that advanced ai will have those instincts because we can build anything we want that theres a very nice set of arguments going back to steve omohundro and nick bostrom and others just pointing out that when we build machines we normally build them with some kind of goal you know win this chess game drive this car safely or whatever and as soon as you put in a goal into machine especially if its kind of open ended goal and the machine is very intelligent itll break that down into a bunch of sub goals and one of those goals will almost always be self preservation because if it breaks or dies in the process its not gonna accomplish the goal right like suppose you just build a little you have a little robot and you tell it to go down the store market here and get you some food make you cook an italian dinner you know and then someone mugs it and tries to break it on the way that robot has an incentive to not get destroyed and defend itself or run away because otherwise its gonna fail in cooking your dinner its not afraid of death but it really wants to complete the dinner cooking goal so it will have a self preservation instinct continue being a functional agent somehow and similarly if you give any kind of more ambitious goal to an agi its very likely they wanna acquire more resources so it can do that better and its exactly from those sort of sub goals that we might not have intended that some of the concerns about agi safety come you give it some goal that seems completely harmless and then before you realize it its also trying to do these other things which you didnt want it to do and its maybe smarter than us so its fascinating and let me pause just because i am in a very kind of human centric way see fear of death as a valuable motivator so you dont think you think thats an artifact of evolution so thats the kind of mind space evolution created that were sort of almost obsessed about self preservation some kind of genetic flow you dont think thats necessary to be afraid of death so not just a kind of sub goal of self preservation just so you can keep doing the thing but more fundamentally sort of have the finite thing like this ends for you at some point interesting do i think its necessary for what precisely for intelligence but also for consciousness so for those for both do you think really like a finite death and the fear of it is important so before i can answer before we can agree on whether its necessary for intelligence or for consciousness we should be clear on how we define those two words cause a lot of really smart people define them in very different ways i was on this panel with ai experts and they couldnt agree on how to define intelligence even so i define intelligence simply as the ability to accomplish complex goals i like your broad definition because again i dont want to be a carbon chauvinist right and in that case no certainly it doesnt require fear of death i would say alpha go alpha zero is quite intelligent i dont think alpha zero has any fear of being turned off because it doesnt understand the concept of it even and similarly consciousness i mean you could certainly imagine very simple kind of experience if certain plants have any kind of experience i dont think theyre very afraid of dying or theres nothing they can do about it anyway much so there wasnt that much value in but more seriously i think if you ask not just about being conscious but maybe having what you would we might call an exciting life where you feel passion and really appreciate the things maybe there somehow maybe there perhaps it does help having a backdrop that hey its finite no lets make the most of this lets live to the fullest so if you knew you were going to live forever do you think you would change your yeah i mean in some perspective it would be an incredibly boring life living forever so in the sort of loose subjective terms that you said of something exciting and something in this that other humans would understand i think is yeah it seems that the finiteness of it is important well the good news i have for you then is based on what we understand about cosmology everything is in our universe is probably ultimately probably finite although big crunch or big whats the the infinite expansion yeah we could have a big chill or a big crunch or a big rip or thats the big snap or death bubbles all of them are more than a billion years away so we should we certainly have vastly more time than our ancestors thought but there is still its still pretty hard to squeeze in an infinite number of compute cycles even though there are some loopholes that just might be possible but i think you know some people like to say that you should live as if youre about to youre going to die in five years or so and thats sort of optimal maybe its a good assumption we should build our civilization as if its all finite to be on the safe side right exactly so you mentioned defining intelligence as the ability to solve complex goals where would you draw a line or how would you try to define human level intelligence and superhuman level intelligence where is consciousness part of that definition no consciousness does not come into this definition so so i think of intelligence as its a spectrum but there are very many different kinds of goals you can have you can have a goal to be a good chess player a good goal player a good car driver a good investor good poet et cetera so intelligence that by its very nature isnt something you can measure by this one number or some overall goodness no no there are some people who are more better at this some people are better than that right now we have machines that are much better than us at some very narrow tasks like multiplying large numbers fast memorizing large databases playing chess playing go and soon driving cars but theres still no machine that can match a human child in general intelligence but artificial general intelligence agi the name of your course of course that is by its very definition the quest to build a machine that can do everything as well as we can so the old holy grail of ai from back to its inception in the sixties if that ever happens of course i think its going to be the biggest transition in the history of life on earth but it doesnt necessarily have to wait the big impact until machines are better than us at knitting that the really big change doesnt come exactly at the moment theyre better than us at everything the really big change comes first there are big changes when they start becoming better at us at doing most of the jobs that we do because that takes away much of the demand for human labor and then the really whopping change comes when they become better than us at ai research right because right now the timescale of ai research is limited by the human research and development cycle of years typically you know how long does it take from one release of some software or iphone or whatever to the next but once google can replace 40000 engineers by 40000 equivalent pieces of software or whatever but then theres no reason that has to be years it can be in principle much faster and the timescale of future progress in ai and all of science and technology will be driven by machines not humans so its this simple point which gives right this incredibly fun controversy about whether there can be intelligence explosion so called singularity as werner vinge called it now the idea is articulated by ij good is obviously way back fifties but you can see alan turing and others thought about it even earlier so you asked me what exactly would i define human level intelligence yeah so the glib answer is to say something which is better than us at all cognitive tasks with a better than any human at all cognitive tasks but the really interesting bar i think goes a little bit lower than that actually its when they can when theyre better than us at ai programming and general learning so that they can if they want to get better than us at anything by just studying so theyre better is a key word and better is towards this kind of spectrum of the complexity of goals its able to accomplish so another way to and thats certainly a very clear definition of human love so theres its almost like a sea thats rising you can do more and more and more things its a geographic that you show its really nice way to put it so theres some peaks that and theres an ocean level elevating and you solve more and more problems but just kind of to take a pause and we took a bunch of questions and a lot of social networks and a bunch of people asked a sort of a slightly different direction on creativity and things that perhaps arent a peak human beings are flawed and perhaps better means having contradiction being flawed in some way so let me sort of start easy first of all so you have a lot of cool equations let me ask whats your favorite equation first of all i know theyre all like your children but like which one is that this is the shirt in your equation its the master key of quantum mechanics of the micro world so this equation will protect everything to do with atoms molecules and all the way up right yeah so okay so quantum mechanics is certainly a beautiful mysterious formulation of our world so id like to sort of ask you just as an example it perhaps doesnt have the same beauty as physics does but in mathematics abstract the andrew wiles who proved the fermats last theorem so he just saw this recently and it kind of caught my eye a little bit this is 358 years after it was conjectured so this is very simple formulation everybody tried to prove it everybody failed and so heres this guy comes along and eventually proves it and then fails to prove it and then proves it again in 94 and he said like the moment when everything connected into place in an interview said it was so indescribably beautiful that moment when you finally realize the connecting piece of two conjectures he said it was so indescribably beautiful it was so simple and so elegant i couldnt understand how id missed it and i just stared at it in disbelief for 20 minutes then during the day i walked around the department and i keep coming back to my desk looking to see if it was still there it was still there i couldnt contain myself i was so excited it was the most important moment on my working life nothing i ever do again will mean as much so that particular moment and it kind of made me think of what would it take and i think we have all been there at small levels maybe let me ask have you had a moment like that in your life where you just had an idea its like wow yes i wouldnt mention myself in the same breath as andrew wiles but ive certainly had a number of aha moments when i realized something very cool about physics which has completely made my head explode in fact some of my favorite discoveries i made later i later realized that they had been discovered earlier by someone who sometimes got quite famous for it so its too late for me to even publish it but that doesnt diminish in any way the emotional experience you have when you realize it like wow yeah so what would it take in that moment that wow that was yours in that moment so what do you think it takes for an intelligence system an agi system an ai system to have a moment like that thats a tricky question because there are actually two parts to it right one of them is can it accomplish that proof can it prove that you can never write a to the n plus b to the n equals three to that equal z to the n for all integers et cetera et cetera when n is bigger than two thats simply a question about intelligence can you build machines that are that intelligent and i think by the time we get a machine that can independently come up with that level of proofs probably quite close to agi the second question is a question about consciousness when will we how likely is it that such a machine will actually have any experience at all as opposed to just being like a zombie and would we expect it to have some sort of emotional response to this or anything at all akin to human emotion where when it accomplishes its machine goal it views it as somehow something very positive and sublime and deeply meaningful i would certainly hope that if in the future we do create machines that are our peers or even our descendants that i would certainly hope that they do have this sublime appreciation of life in a way my absolutely worst nightmare would be that at some point in the future the distant future maybe our cosmos is teeming with all this post biological life doing all the seemingly cool stuff and maybe the last humans by the time our species eventually fizzles out will be like well thats ok because were so proud of our descendants here and look what all the my worst nightmare is that we havent solved the consciousness problem and we havent realized that these are all the zombies theyre not aware of anything any more than a tape recorder has any kind of experience so the whole thing has just become a play for empty benches that would be the ultimate zombie apocalypse so i would much rather in that case that we have these beings which can really appreciate how amazing it is and in that picture what would be the role of creativity a few people ask about creativity when you think about intelligence certainly the story you told at the beginning of your book involved creating movies and so on making money you can make a lot of money in our modern world with music and movies so if you are an intelligent system you may want to get good at that but thats not necessarily what i mean by creativity is it important on that complex goals where the sea is rising for there to be something creative or am i being very human centric and thinking creativity somehow special relative to intelligence my hunch is that we should think of creativity simply as an aspect of intelligence and we have to be very careful with human vanity we have this tendency to very often want to say as soon as machines can do something we try to diminish it and say oh but thats not real intelligence isnt it creative or this or that the other thing if we ask ourselves to write down a definition of what we actually mean by being creative what we mean by andrew wiles what he did there for example dont we often mean that someone takes a very unexpected leap its not like taking 573 and multiplying it by 224 by just a step of straightforward cookbook like rules right you can maybe make a connection between two things that people had never thought was connected or something like that i think this is an aspect of intelligence and this is actually one of the most important aspects of it maybe the reason we humans tend to be better at it than traditional computers is because its something that comes more naturally if youre a neural network than if youre a traditional logic gate based computer machine we physically have all these connections and you activate here activate here activate here bing my hunch is that if we ever build a machine where you could just give it the task hey you say hey i just realized i want to travel around the world instead this month can you teach my agi course for me and its like ok ill do it and it does everything that you would have done and improvises and stuff that would in my mind involve a lot of creativity yeah so its actually a beautiful way to put it i think we do try to grasp at the definition of intelligence is everything we dont understand how to build so we as humans try to find things that we have and machines dont have and maybe creativity is just one of the things one of the words we use to describe that thats a really interesting way to put it i dont think we need to be that defensive i dont think anything good comes out of saying well were somehow special you know contrary wise there are many examples in history of where trying to pretend that were somehow superior to all other intelligent beings has led to pretty bad results right nazi germany they said that they were somehow superior to other people today we still do a lot of cruelty to animals by saying that were so superior somehow and they cant feel pain slavery was justified by the same kind of just really weak arguments and i dont think if we actually go ahead and build artificial general intelligence it can do things better than us i dont think we should try to found our self worth on some sort of bogus claims of superiority in terms of our intelligence i think we should instead find our calling and the meaning of life from the experiences that we have i can have very meaningful experiences even if there are other people who are smarter than me when i go to a faculty meeting here and we talk about something and then i certainly realize oh boy he has an old prize he has an old prize he has an old prize i dont have one does that make me enjoy life any less or enjoy talking to those people less of course not and the contrary i feel very honored and privileged to get to interact with other very intelligent beings that are better than me at a lot of stuff so i dont think theres any reason why we cant have the same approach with intelligent machines thats a really interesting so people dont often think about that they think about when theres going if theres machines that are more intelligent you naturally think that thats not going to be a beneficial type of intelligence you dont realize it could be like peers with nobel prizes that would be just fun to talk with and they might be clever about certain topics and you can have fun having a few drinks with them well also another example we can all relate to of why it doesnt have to be a terrible thing to be in the presence of people who are even smarter than us all around is when you and i were both two years old i mean our parents were much more intelligent than us right worked out ok because their goals were aligned with our goals and that i think is really the number one key issue we have to solve if we value align the value alignment problem exactly because people who see too many hollywood movies with lousy science fiction plot lines they worry about the wrong thing right they worry about some machine suddenly turning evil its not malice that is the concern its competence by definition intelligent makes you very competent if you have a more intelligent goal playing computer playing is a less intelligent one and when we define intelligence as the ability to accomplish goal winning its going to be the more intelligent one that wins and if you have a human and then you have an agi thats more intelligent in all ways and they have different goals guess whos going to get their way right so i was just reading about this particular rhinoceros species that was driven extinct just a few years ago ellen bummer is looking at this cute picture of a mommy rhinoceros with its child and why did we humans drive it to extinction it wasnt because we were evil rhino haters as a whole it was just because our goals werent aligned with those of the rhinoceros and it didnt work out so well for the rhinoceros because we were more intelligent right so i think its just so important that if we ever do build agi before we unleash anything we have to make sure that it learns to understand our goals that it adopts our goals and that it retains those goals so the cool interesting problem there is us as human beings trying to formulate our values so you could think of the united states constitution as a way that people sat down at the time a bunch of white men which is a good example i should say they formulated the goals for this country and a lot of people agree that those goals actually held up pretty well thats an interesting formulation of values and failed miserably in other ways so for the value alignment problem and the solution to it we have to be able to put on paper or in a program human values how difficult do you think that is very but its so important we really have to give it our best and its difficult for two separate reasons theres the technical value alignment problem of figuring out just how to make machines understand our goals adopt them and retain them and then theres the separate part of it the philosophical part whose values anyway and since its not like we have any great consensus on this planet on values what mechanism should we create then to aggregate and decide ok whats a good compromise that second discussion cant just be left to tech nerds like myself and if we refuse to talk about it and then agi gets built whos going to be actually making the decision about whose values its going to be a bunch of dudes in some tech company and are they necessarily so representative of all of humankind that we want to just entrust it to them are they even uniquely qualified to speak to future human happiness just because theyre good at programming ai id much rather have this be a really inclusive conversation but do you think its possible so you create a beautiful vision that includes the diversity cultural diversity and various perspectives on discussing rights freedoms human dignity but how hard is it to come to that consensus do you think its certainly a really important thing that we should all try to do but do you think its feasible i think theres no better way to guarantee failure than to refuse to talk about it or refuse to try and i also think its a really bad strategy to say ok lets first have a discussion for a long time and then once we reach complete consensus then well try to load it into some machine no we shouldnt let perfect be the enemy of good instead we should start with the kindergarten ethics that pretty much everybody agrees on and put that into machines now were not doing that even look at anyone who builds this passenger aircraft wants it to never under any circumstances fly into a building or a mountain yet the september 11 hijackers were able to do that and even more embarrassingly andreas lubitz this depressed germanwings pilot when he flew his passenger jet into the alps killing over 100 people he just told the autopilot to do it he told the freaking computer to change the altitude to 100 meters and even though it had the gps maps everything the computer was like ok so we should take those very basic values where the problem is not that we dont agree the problem is just weve been too lazy to try to put it into our machines and make sure that from now on airplanes will just which all have computers in them but will just refuse to do something like that go into safe mode maybe lock the cockpit door go over to the nearest airport and theres so much other technology in our world as well now where its really becoming quite timely to put in some sort of very basic values like this even in cars weve had enough vehicle terrorism attacks by now where people have driven trucks and vans into pedestrians that its not at all a crazy idea to just have that hardwired into the car because yeah there are a lot of theres always going to be people who for some reason want to harm others but most of those people dont have the technical expertise to figure out how to work around something like that so if the car just wont do it it helps so lets start there so theres a lot of thats a great point so not chasing perfect theres a lot of things that most of the world agrees on yeah lets start there lets start there and then once we start there well also get into the habit of having these kind of conversations about okay what else should we put in here and have these discussions this should be a gradual process then great so but that also means describing these things and describing it to a machine so one thing we had a few conversations with stephen wolfram im not sure if youre familiar with stephen oh yeah i know him quite well so he is he works with a bunch of things but cellular automata these simple computable things these computation systems and he kind of mentioned that we probably have already within these systems already something thats agi meaning like we just dont know it because we cant talk to it so if you give me this chance to try to at least form a question out of this is i think its an interesting idea to think that we can have intelligent systems but we dont know how to describe something to them and they cant communicate with us i know youre doing a little bit of work in explainable ai trying to get ai to explain itself so what are your thoughts of natural language processing or some kind of other communication how does the ai explain something to us how do we explain something to it to machines or you think of it differently so there are two separate parts to your question there one of them has to do with communication which is super interesting ill get to that in a sec the other is whether we already have agi but we just havent noticed it there right there i beg to differ i dont think theres anything in any cellular automaton or anything or the internet itself or whatever that has artificial general intelligence and that it can really do exactly everything we humans can do better i think the day that happens when that happens we will very soon notice well probably notice even before because in a very very big way but for the second part though wait can i ask sorry so because you have this beautiful way to formulating consciousness as information processing and you can think of intelligence as information processing and you can think of the entire universe as these particles and these systems roaming around that have this information processing power you dont think there is something with the power to process information in the way that we human beings do thats out there that needs to be sort of connected to it seems a little bit philosophical perhaps but theres something compelling to the idea that the power is already there which the focus should be more on being able to communicate with it well i agree that in a certain sense the hardware processing power is already out there because our universe itself can think of it as being a computer already right its constantly computing what water waves how it devolved the water waves in the river charles and how to move the air molecules around seth lloyd has pointed out my colleague here that you can even in a very rigorous way think of our entire universe as being a quantum computer its pretty clear that our universe supports this amazing processing power because you can even within this physics computer that we live in right we can even build actual laptops and stuff so clearly the power is there its just that most of the compute power that nature has its in my opinion kind of wasting on boring stuff like simulating yet another ocean wave somewhere where no one is even looking right so in a sense what life does what we are doing when we build computers is were rechanneling all this compute that nature is doing anyway into doing things that are more interesting than just yet another ocean wave and lets do something cool here so the raw hardware power is there for sure but then even just computing whats going to happen for the next five seconds in this water bottle takes a ridiculous amount of compute if you do it on a human computer this water bottle just did it but that does not mean that this water bottle has agi because agi means it should also be able to like ive written my book done this interview and i dont think its just communication problems i dont really think it can do it although buddhists say when they watch the water and that there is some beauty that theres some depth and beauty in nature that they can communicate with communication is also very important though because i mean look part of my job is being a teacher and i know some very intelligent professors even who just have a bit of hard time communicating they come up with all these brilliant ideas but to communicate with somebody else you have to also be able to simulate their own mind yes empathy build well enough and understand model of their mind that you can say things that they will understand and thats quite difficult and thats why today its so frustrating if you have a computer that makes some cancer diagnosis and you ask it well why are you saying i should have this surgery and if it can only reply i was trained on five terabytes of data and this is my diagnosis boop boop beep beep it doesnt really instill a lot of confidence right so i think we have a lot of work to do on communication there so what kind of i think youre doing a little bit of work in explainable ai what do you think are the most promising avenues is it mostly about sort of the alexa problem of natural language processing of being able to actually use human interpretable methods of communication so being able to talk to a system and it talk back to you or is there some more fundamental problems to be solved i think its all of the above the natural language processing is obviously important but there are also more nerdy fundamental problems like if you take you play chess of course im russian i have to you speak russian yes i speak russian excellent i didnt know when did you learn russian i speak very bad russian im only an autodidact but i bought a book teach yourself russian read a lot but it was very difficult wow thats why i speak so bad how many languages do you know wow thats really impressive i dont know my wife has some calculation but my point was if you play chess have you looked at the alphazero games the actual games no check it out some of them are just mind blowing really beautiful and if you ask how did it do that you go talk to demis hassabis i know others from deepmind all theyll ultimately be able to give you is big tables of numbers matrices that define the neural network and you can stare at these tables of numbers till your face turn blue and youre not gonna understand much about why it made that move and even if you have natural language processing that can tell you in human language about oh five seven points two eight still not gonna really help so i think theres a whole spectrum of fun challenges that are involved in taking a computation that does intelligent things and transforming it into something equally good equally intelligent but thats more understandable and i think thats really valuable because i think as we put machines in charge of ever more infrastructure in our world the power grid the trading on the stock market weapon systems and so on its absolutely crucial that we can trust these ais to do all we want and trust really comes from understanding in a very fundamental way and thats why im working on this because i think the more if were gonna have some hope of ensuring that machines have adopted our goals and that theyre gonna retain them that kind of trust i think needs to be based on things you can actually understand preferably even improve theorems on even with a self driving car right if someone just tells you its been trained on tons of data and it never crashed its less reassuring than if someone actually has a proof maybe its a computer verified proof but still it says that under no circumstances is this car just gonna swerve into oncoming traffic and that kind of information helps to build trust and helps build the alignment of goals at least awareness that your goals your values are aligned and i think even in the very short term if you look at how you know today right this absolutely pathetic state of cybersecurity that we have where is it three billion yahoo accounts we cant pack almost every americans credit card and so on why is this happening its ultimately happening because we have software that nobody fully understood how it worked thats why the bugs hadnt been found right and i think ai can be used very effectively for offense for hacking but it can also be used for defense hopefully automating verifiability and creating systems that are built in different ways so you can actually prove things about them and its important so speaking of software that nobody understands how it works of course a bunch of people ask about your paper about your thoughts of why does deep and cheap learning work so well thats the paper but what are your thoughts on deep learning these kind of simplified models of our own brains have been able to do some successful perception work pattern recognition work and now with alphazero and so on do some clever things what are your thoughts about the promise limitations of this piece great i think there are a number of very important insights very important lessons we can always draw from these kinds of successes one of them is when you look at the human brain you see its very complicated 10th of 11 neurons and there are all these different kinds of neurons and yada yada and theres been this long debate about whether the fact that we have dozens of different kinds is actually necessary for intelligence', 'as part of mit course 6s099 on artificial general intelligence i got a chance to sit down with christoph koch who is one of the seminal figures in neurobiology neuroscience and generally in the study of consciousness he is the president the chief scientific officer of the allen institute for brain science in seattle from 1986 to 2013 he was a professor at caltech before that he was at mit he is extremely well cited over 100000 citations his research his writing his ideas have had big impact on the scientific community and the general public in the way we think about consciousness in the way we see ourselves as human beings hes the author of several books the quest for consciousness and neurobiological approach and a more recent book consciousness confessions of a romantic reductionist if you enjoy this conversation this course subscribe click the little bell icon to make sure you never miss a video and in the comments leave suggestions for any people youd like to see be part of the course or any ideas that you would like us to explore thanks very much and i hope you enjoy okay before we delve into the beautiful mysteries of consciousness lets zoom out a little bit and let me ask do you think theres intelligent life out there in the universe yes i do believe so we have no evidence of it but i think the probabilities are overwhelming in favor of it given a universe where we have 10 to the 11 galaxies and each galaxy has between 10 to the 11 10 to the 12 stars and we know most stars have one or more planets so how does that make you feel it still makes me feel special because i have experiences i feel the world i experience the world and independent of whether there are other creatures out there i still feel the world and i have access to this world in this very strange compelling way and thats the core of human existence now you said human do you think if those intelligent creatures are out there do you think they experience their world yes if they are evolved if they are a product of natural evolution as they would have to be they will also experience their own world the consciousness isnt just human youre right its much wider it may be spread across all of biology the only thing that we have special is we can talk about it of course not all people can talk about it babies and little children can talk about it patients who have a stroke in the left inferior frontal gyrus can talk about it but most normal adult people can talk about it and so we think that makes us special compared to lets say monkeys or dogs or cats or mice or all the other creatures that we share the planet with but all the evidence seems to suggest that they too experience the world and so its overwhelmingly likely that aliens would also experience their world of course differently because they have a different sensorium they have different sensors they have a very different environment but the fact that i would strongly suppose that they also have experiences they feel pain and pleasure and see in some sort of spectrum and hear and have all the other senses of course their language if they have one would be different so we might not be able to understand their poetry about the experiences that they have thats correct so in a talk in a video ive heard you mention siputzo a dachshund that you came up with that you grew up with it was part of your family when you were young first of all youre technically a midwestern boy you just – technically yes but after that you traveled around a bit hence a little bit of the accent you talked about siputzo the dachshund having these elements of humanness of consciousness that you discovered so i just wanted to ask can you look back in your childhood and remember when was the first time you realized you yourself sort of from a third person perspective are a conscious being this idea of stepping outside yourself and seeing theres something special going on here in my brain i cant really actually – its a good question im not sure i recall a discrete moment i mean you take it for granted because thats the only world you know the only world i know and you know is the world of seeing and hearing voices and touching and all the other things so its only much later at early – in my underguided days when i enrolled in physics and in philosophy that i really thought about it and thought well this is really fundamentally very very mysterious and theres nothing really in physics right now that explains this transition from the physics of the brain to feelings where do the feelings come in so you can look at the foundational equation of quantum mechanics general relativity you can look at the periodic table of the elements you can look at the endless atgc chat in our genes and nowhere is consciousness yet i wake up every morning to a world where i have experiences and so thats the heart of the ancient mind body problem how do experiences get into the world so what is consciousness experience this is any experience some people call it subjective feeling some people call it phenomenology some people call it qualia of the philosopher but they all denote the same thing it feels like something in the famous word of the philosopher thomas nagel it feels like something to be a bat or to be an american or to be angry or to be sad or to be in love or to have pain and that is what experience is any possible experience could be as mundane as just sitting in a chair could be as exalted as having a mystical moment in deep meditation those are just different forms of experiences experience so if you were to sit down with maybe the next skip a couple generations of ibm watson something that won jeopardy what is the gap i guess the question is between watson that might be much smarter than you than us than any human alive but may not have experience what is the gap well so thats a big big question thats occupied people for the last certainly last 50 years since we you know since the advent the birth of computers thats a question alan turing tried to answer and of course he did it in this indirect way by proposing a test an operational test but thats not really thats you know he tried to get at what does it mean for a person to think and then he had this test right you lock them away and then you have a communication with them and then you try to guess after a while whether that is a person or whether its a computer system theres no question that now or very soon you know alexa or siri or you know google now will pass this test right and you can game it but you know ultimately certainly in your generation there will be machines that will speak with complete poise that will remember everything you ever said theyll remember every email you ever had like samantha remember in the movie her yeah theres no question its going to happen but of course the key question is does it feel like anything to be samantha in the movie her or does it feel like anything to be watson and there one has to very very strongly think there are two different concepts here that we co mingle there is the concept of intelligence natural or artificial and there is a concept of consciousness of experience natural or artificial those are very very different things now historically we associate consciousness with intelligence why because we live in a world leaving aside computers of natural selection where were surrounded by creatures either our own kin that are less or more intelligent or we go across species some are more adapted to a particular environment others are less adapted whether its a whale or dog or you go talk about a paramecium or a little worm and we see the complexity of the nervous system goes from one cell to specialized cells to a worm that has three nets that has 30 percent of its cells are nerve cells to creature like us or like a blue whale that has 100 billion even more nerve cells and so based on behavioral evidence and based on the underlying neuroscience we believe that as these creatures become more complex they are better adapted to their particular ecological niche and they become more conscious partly because their brain grows and we believe consciousness unlike the ancient ancient people thought most almost every culture thought that consciousness with intelligence has to do with your heart and you still see that today you see honey i love you with all my heart but what you should actually say is no honey i love you with all my lateral hypothalamus and for valentines day you should give your sweetheart you know hypothalamus a piece of chocolate and not a heart shaped chocolate anyway so we still have this language but now we believe its a brain and so we see brains of different complexity and we think well they have different levels of consciousness theyre capable of different experiences but now we confront the world where we know where were beginning to engineer intelligence and its radical unclear whether the intelligence were engineering has anything to do with consciousness and whether it can experience anything because fundamentally whats the difference intelligence is about function intelligence no matter exactly how you define it sort of adaptation to new environments being able to learn and quickly understand you know the setup of this and whats going on and who are the actors and whats going to happen next thats all about function consciousness is not about function consciousness is about being its in some sense much fundamental you can see this in several cases you can see it for instance in the case of the clinic when youre dealing with patients who are lets say had a stroke or had were in traffic accident et cetera theyre pretty much immobile terri schiavo you may have heard historically she was a person here in the 90s in florida her heart stood still she was reanimated and then for the next 14 years she was whats called in a vegetative state so there are thousands of people in a vegetative state so theyre you know theyre you know theyre like this occasionally they open their eyes for two three four five six eight hours and then close their eyes they have sleep wake cycle occasionally they have behaviors they do like you know but theres no way that you can establish a lawful relationship between what you say or the doctor says or the mom says and what the patient does so there isnt any behavior yet in some of these people there is still experience you can design and build brain machine interfaces where you can see theres still experience something and of course these cases of locked in state theres this famous book called the diving bell and the butterfly where you had an editor a french editor he had a stroke in the brainstem unable to move except his vertical eyes eye movement he could just move his eyes up and down and he dictated an entire book and some people even lose this at the end all the evidence seems to suggest that theyre still in there in this case you have no behavior you have consciousness second case is tonight like all of us youre going to go to sleep close your eyes you go to sleep you will wake up inside your sleeping body and you will have conscious experiences they are different from everyday experience you might fly you might not be surprised that youre flying you might meet a long dead pet childhood dog and youre not surprised that youre meeting them but you have conscious experience of love of hate they can be very emotional your body during this state typically its rem state sends an active signal to your motor neurons to paralyze you its called atonia because if you dont have that like some patients what do you do you act out your dreams you get for example rem behavioral disorder which is bad juju to get okay third case is pure experience so i recently had this what some people call a mystical experience i went to singapore and went into a flotation tank yeah all right so this is a big tub filled with water thats body temperature and epsom salt you strip completely naked you lie inside of it you close the lid darkness complete darkness soundproof so very quickly you become bodiless because youre floating and youre naked you have no rings no watch no nothing you dont feel your body anymore theres no sound soundless theres no photon sightless timeless because after a while early on you actually hear your heart but then you sort of adapt to that and then sort of the passage of time ceases yeah and if you train yourself like in a meditation not to think early on you think a lot its a little bit spooky you feel somewhat uncomfortable or you think well im going to get bored and if you try to not to think actively you become mindless there you are bodiless timeless you know soundless sightless mindless but youre in a conscious experience youre not asleep yeah youre not asleep you are a being of pure youre a pure being there isnt any function you arent doing any computation youre not remembering youre not projecting youre not planning yet you are fully conscious youre fully conscious theres something going on there it could be just a side effect so what is the you mean epiphenomena so whats the select meaning why what is the function of you being able to lay in this sensory free deprivation tank and still have a conscious experience evolutionary evolutionary obviously we didnt evolve with flotation tanks in our environment i mean so biology is notoriously bad at asking why question telenormical question why do we have two eyes why dont we have four eyes like some teachers or three eyes or something well no theres probably there is a function to that but were not very good at answering those questions we can speculate endlessly where biology is very or science is very good about mechanistic question why is there a charge in the universe right we find a certain universe where there are positive and negative charges why why does quantum mechanics hold you know why doesnt some other theory hold quantum mechanics holding our universe is very unclear why so telenormical question why questions are difficult to answer theres some relationship between complexity brain processing power and consciousness but however in these cases in these three examples i gave one is an everyday experience at night the other one is trauma and third one is in principle you can everybody can have these sort of mystical experiences you have a dissociation of function from of intelligence from consciousness you caught me asking a why question let me ask a question thats not a why question youre giving a talk later today on the turing test for intelligence and consciousness drawing lines between the two so is there a scientific way to say theres consciousness present in this entity or not and to anticipate your answer cause you you will also theres a neurobiological answer so we can test the human brain but if you take a machine brain that you dont know tests for yet how would you even begin to approach a test if theres consciousness present in this thing okay thats a really good question so let me take it in two steps so as you point out for for for for humans lets just stick with humans theres now a test called the zap and zip is a procedure where you ping the brain using transcranial magnetic stimulation you look at the electrical reverberations essentially using eg and then you can measure the complexity of this brain response and you can do this in awake people in asleep normal people you can do it in awake people and then anesthetize them you can do it in patients and it it it has a hundred percent accuracy that in all those cases when youre clear the patient or the person is either conscious or unconscious the complexity is either high or low and then you can adopt these techniques to similar creatures like monkeys and dogs and and and mice that have very similar brains now of course you you point out that may not help you because we dont have a cortex you know and if i send a magnetic pulse into my iphone or my computer its probably going to break something so we dont have that so what we need ultimately we need a theory of consciousness we cant just rely on our intuition our intuition is well yeah if somebody talks theyre conscious however then there are all these patients children babies dont talk right but we believe that that the babies also have conscious experiences right and then there are all these patients i mentioned and they dont talk when you dream you cant talk because youre paralyzed so what we ultimately need we cant just rely on our intuition we need a theory of conscience that tells us what is it about a piece of matter what is it about a piece of highly excitable matter like the brain or like a computer that gives rise to conscious experience we all believe none of us believes anymore in the old story its a soul right that used to be the most common explanation that most people accept that instill a lot of people today believe well theres theres god endowed only us with a special thing that animals dont have rene descartes famously said a dog if you hit it with your carriage may yell may cry but it doesnt have this special thing it doesnt have the magic the magic soul it doesnt have res cogitans the soul now we believe that isnt the case anymore so what is the difference between brains and and these guys silicon and in particular once their behavior matches so if you have siri or alexa in 20 years from now that she can talk just as good as any possible human what grounds do you have to say shes not conscious in particular if she says its of course she will well of course im conscious you ask her how are you doing and shell say well you know they theyll generate some way to of course shell behave like a like a person now theres several differences one is so this relates to the problem the very hard why is consciousness a hard problem its because its subjective right only i have it for only i know i have direct experience of my own consciousness i dont have experience in your consciousness now i assume as a sort of a bayesian person who believes in probability theory and all of that you know i can do i can do an abduction to the to the best available facts i deduce your brain is very similar to mine if i put you in a scanner your brain is roughly going to behave the same way as i do if if if you know if i give you this muesli and ask you how does it taste you tell me things that you know that that i would also say more or less right so i infer based on all of that that youre conscious now with theory i cant do that so there i really need a theory that tells me what is it about about any system this or this that makes it conscious we have such a theory yes so the integrated information theory but let me first maybe as an introduction for people who are not familiar descartes can you you talk a lot about pan panpsychism can you describe what uh physicalism versus dualism this you you mentioned the soul what what is the history of that idea what is the idea of panpsychism or no the debate really uh out of which panpsychism can um emerge of of of um dualism versus uh physicalism or do you not see panpsychism as fitting into that no you can argue theres some okay so lets step back so panpsychism is a very ancient belief thats been around uh i mean plato and aristotle talks about it uh modern philosophers talk about it of course in buddhism the idea is very prevalent that i mean there are different versions of it one version says everything is ensouled everything rocks and stones and dogs and people and forest and iphones all of us all right all matter is ensouled thats sort of one version another version is that all biology all creatures small or large from a single cell to a giant sequoia tree feel like something this one i think is somewhat more realistic um so the different versions what do you mean by feel like something have have feelings have some kind of it feels like something it may well be possible that it feels like something to be a paramecium i think its pretty likely it feels like something to be a bee or a mouse or a dog sure so okay so so that you can see thats also so panpsychism is very broad and you can so some people for example bertrand russell tried to advocate this this idea its called rasselian monism that that panpsychism is really physics viewed from the inside so the idea is that physics is very good at describing relationship among objects like charges or like gravity right you know describe the relationship between curvature and mass distribution okay thats the relationship among things physics doesnt really describe the ultimate reality itself its just relationship among you know quarks or all these other stuff from like a third person observer yes yes yes and consciousness is what physics feels from the inside so my conscious experience its the way the physics of my brain particularly my cortex feels from the inside and so if you are paramecium you got to remember you say paramecium well thats a pretty dumb creature it is but it has already a billion different molecules probably you know 5000 different proteins assembled in a highly highly complex system that no single person no computer system so far on this planet has ever managed to accurately simulate its complexity vastly escapes us yes and it may well be that that little thing feels like a tiny bit now it doesnt have a voice in the head like me it doesnt have expectations you know it doesnt have all that complex things but it may well feel like something yeah so this is really interesting can we draw some lines and maybe try to understand the difference between life intelligence and consciousness how do you see all of those if you had to define what is a living thing what is a conscious thing and what is an intelligent thing do those intermix for you or are they totally separate okay so a thats a question that we dont have a full answer to a lot of the stuff were talking about today is full of mysteries and fascinating ones right for example you can go to aristotle whos probably the most important scientist and philosopher whos ever lived in certainly in western culture he had this idea its called hylomorphism its quite popular these days that there are different forms of soul the soul is really the form of something he says all biological creatures have a vegetative soul thats life principle today we think we understand something more than it is biochemistry and nonlinear thermodynamics then he said they have a sensitive soul only animals and humans have also a sensitive soul or a petitive soul they can see they can smell and they have drives they want to reproduce they want to eat et cetera and then only humans have what he called a rational soul okay and that idea then made it into christendom and then the rational soul is the one that lives forever he was very unclear he wasnt really i mean different readings of aristotle give different whether did he believe that rational soul was immortal or not i probably think he didnt but then of course that made it through plato into christianity and then this soul became immortal and then became the connection to god so you ask me essentially what is our modern conception of these three aristotle would have called them different forms life we think we know something about it at least life on this planet right although we dont understand how to originate it but its been difficult to rigorously pin down you see this in modern definitions of death in fact right now theres a conference ongoing again that tries to define legally and medically what is death it used to be very simple death is you stop breathing your heart stops beating youre dead totally uncontroversial if youre unsure you wait another 10 minutes if the patient doesnt breathe hes dead well now we have ventilators we have heart pacemakers so its much more difficult to define what death is typically death is defined as the end of life and life is defined before death okay so we dont have really very good definitions intelligence we dont have a rigorous definition we know something how to measure its called iq or g factors right and were beginning to build it in a narrow sense right like go alphago and watson and you know google cars and uber cars and all of that its still narrow ai and some people are thinking about artificial general intelligence but roughly as we said before its something to do with ability to learn and to adapt to new environments but that is as i said also its radical difference from experience and its very unclear if you build a machine that has agi its not at all a priori its not at all clear that this machine will have consciousness it may or may not so lets ask it the other way do you think if you were to try to build an artificial general intelligence system do you think figuring out how to build artificial consciousness would help you get to an agi so or put another way do you think intelligent requires consciousness in human it goes hand in hand in human or i think in biology consciousness intelligence goes hand in hand quay is illusion because the brain evolved to be highly complex complexity via the theory integrated information theory is sort of ultimately is what is closely tied to consciousness ultimately its causal power upon itself and so in evolved systems they go together in artificial system particularly in digital machines they do not go together and if you ask me point blank is alexa 200 in the year 2040 when she can easily pass every turing test is she conscious no even if she claims shes conscious in fact you could even do a more radical version of this thought experiment you can build a computer simulation of the human brain you know what henry markham in the blue brain project or the human brain project in switzerland is trying to do lets grant them all the success so in 10 years we have this perfect simulation of the human brain every neuron is simulated and it has a larynx and it has motor neurons it has a brocas area and of course theyll talk and theyll say hi i just woke up i feel great ok even that computer simulation that can in principle map onto your brain will not be conscious why because it simulates its a difference between the simulated and the real so it simulates the behavior associated with consciousness it might be it will if its done properly will have all the intelligence that that particular person theyre simulating has but simulating intelligence is not the same as having conscious experiences and i give you a really nice metaphor that engineers and physicists typically get i can write down einsteins field equation nine or ten equations that describe the link in general relativity between curvature and mass i can do that i can run this on my laptop to predict that the central the black hole at the center of our galaxy will be so massive that it will twist space time around it so no light can escape its a black hole but funny have you ever wondered why doesnt this computer simulation suck me in it simulates gravity but it doesnt have the causal power of gravity thats a huge difference so its a difference between the real and the simulator just like it doesnt get wet inside a computer when the computer runs code that simulates a weather storm and so in order to have to have artificial consciousness you have to give it the same causal power as the human brain you have to build so called a neuromorphic machine that has hardware that is very similar to the human brain not a digital clocked phenomenon computer so thats just to clarify though you think that consciousness is not required to create human level intelligence it seems to accompany in the human brain but for machine not thats correct so maybe just because this is agi lets dig in a little bit about what we mean by intelligence so one thing is the g factor these kind of iq tests of intelligence but i think if you maybe another way to say so in 2040 2050 people will have siri that is just really impressive do you think people will say siri is intelligent yes intelligence is this amorphous thing so to be intelligent it seems like you have to have some kind of connections with other human beings in a sense that you have to impress them with your intelligence and there feels you have to somehow operate in this world full of humans and for that there feels like there has to be something like consciousness so you think you can have just the worlds best natural nlp system natural language understanding generation and that will be that will get us happy and say you know what weve created an agi i dont know happy but yes i do believe we can get what we call high level functional intelligence particular sort of the g you know this fluid like intelligence that we cherish particularly at a place like mit right in machines i see a priori no reasons and i see a lot of reason to believe its going to happen very you know over the next 50 years or 30 years so for beneficial ai for creating an ai system thats so you mentioned ethics that is exceptionally intelligent but also does not do does you know aligns its values with our values as humanity do you think then it needs consciousness yes i think that that is a very good argument that if were concerned about ai and the threat of ai a la nick bostrom existentialist threat i think having an intelligence that has empathy right why do we find abusing a dog why do most of us find that abhorrent abusing any animal right why do we find that abhorrent because we have this thing called empathy which if you look at the greek really means feeling with i feel a path of empathy i have feeling with you i see somebody else suffer that isnt even my conspecific its not a person its not my wife or my kids its a dog but i feel naturally most of us not all of us most of us will feel emphatic and so it may well be in the long term interest of survival of homo sapiens sapiens that if we do build agi and it really becomes very powerful that it has an emphatic response and doesnt just exterminate humanity so as part of the full conscious experience to create a consciousness artificial or in our human consciousness do you think fear maybe were going to get into the earlier days with nietzsche and so on but do you think fear and suffering are essential to have consciousness do you have to have the full range of experience to have a system that has experience or can you have a system that only has very particular kinds of very positive experiences look you can have in principle people have done this in the rat where you implant an electrode in the hypothalamus the pleasure center of the rat and the rat stimulates itself above and beyond anything else it doesnt care about food or natural sex or drink anymore it just stimulates itself because its such a pleasurable feeling i guess its like an orgasm just you have all day long and so a priori i see no reason why you need a great variety now clearly to survive that wouldnt work right but if id engineered artificially i dont think you need a great variety of conscious experience you could have just pleasure or just fear it might be a terrible existence but i think thats possible at least on conceptual logical ground because any real creature whether artificially engineered you want to give it fear the fear of extinction that we all have and you also want to give it positive repetitive states states that you want the machine encouraged to do because they give the machine positive feedback so you mentioned panpsychism to jump back a little bit everything having some kind of mental property how do you go from there to something like human consciousness so everything having some elements of consciousness is there something special about human consciousness so its not everything like a spoon the form of panpsychism i think about doesnt ascribe consciousness to anything like this the spoon on my liver however the theory the integrated information theory does say that the system even one that looks from the outside relatively simple at least if they have this internal causal power it does feel like something the theory a priori doesnt say anything whats special about human biologically we know the one thing thats special about human is we speak and we have an overblown sense of our own importance we believe were exceptional and were just gods gift to the universe but behaviorally the main thing that we have we can plan over the long term we have language and that gives us an enormous amount of power and thats why we are the current dominant species on the planet so you mentioned god you grew up a devout roman catholic family so with consciousness youre sort of exploring some really deeply fundamental human things that religion also touches on where does religion fit into your thinking about consciousness youve grown throughout your life and changed your views on religion as far as i understand yeah i mean im now much closer to im not a roman catholic anymore i dont believe theres sort of this god the god i was educated to believe in sits somewhere in the fullness of time ill be united in some sort of everlasting bliss i just dont see any evidence for that look the world the night is large and full of wonders there are many things that i dont understand i think many things that we as a cult look we dont even understand more than 4 of all the universe dark matter dark energy we have no idea what it is maybe its lost socks what do i know so all i can tell you is its sort of my current religious or spiritual sentiment is much closer to some form of buddhism without the reincarnation unfortunately theres no evidence for it than reincarnation so can you describe the way buddhism sees the world a little bit well so they talk about so when i spent several meetings with the dalai lama and what always impressed me about him he really unlike for example lets say the pope or some cardinal he always emphasized minimizing the suffering of all creatures so they have this from the early beginning they look at suffering in all creatures not just in people but in everybody this universal and of course by degrees an animal in general is less capable of suffering than a well developed normally developed human and they think consciousness pervades in this universe and they have these techniques you can think of them like mindfulness etc and meditation that tries to access what they claim of this more fundamental aspect of reality im not sure its more fundamental i think about it theres the physical and then theres this inside view consciousness and those are the two aspects thats the only thing i have access to in my life and youve got to remember my conscious experience and your conscious experience comes prior to anything you know about physics comes prior to knowledge about the universe and atoms and super strings and molecules and all of that the only thing you directly are acquainted with is this world thats populated with things in images and sounds in your head and touches and all of that i actually have a question so it sounds like you kind of have a rich life you talk about rock climbing and it seems like you really love literature and consciousness is all about experiencing things so do you think that has helped your research on this topic yes particularly if you think about it the various states so for example when you do rock climbing or now i do rowing crew rowing and a bike every day you can get into this thing called the zone and ive always wanted about it particularly with respect to consciousness because its a strangely addictive state once people have it once they want to keep on going back to it and you wonder what is it so addicting about it and i think its the experience of almost close to pure experience because in this zone youre not conscious of inner voice anymore theres always inner voice nagging you you have to do this you have to do that you have to pay your taxes you have to fight with your ex and all of those things theyre always there but when youre in the zone all of that is gone and youre just in this wonderful state where youre fully out in the world youre climbing or youre rowing or biking or doing soccer or whatever youre doing and sort of consciousness is this youre all action or in this case of pure experience youre not action at all but in both cases you experience some aspect of conscious you touch some basic part of conscious existence that is so basic and so deeply satisfying you i think you touch the root of being thats really what youre touching there youre getting close to the root of being and thats very different from intelligence so what do you think about the simulation hypothesis simulation theory the idea that we all live in a computer simulation rapture for nerds rapture for nerds i think its as likely as the hypothesis had engaged hundreds of scholars for many centuries are we all just existing in the mind of god and this is just a modern version of it its equally plausible people love talking about these sort of things i know theyre book written about this simulation hypothesis if thats what people want to do thats fine it seems rather esoteric its never testable but its not useful for you to think of in those terms so maybe connecting to the questions of free will which youve talked about i vaguely remember you saying that the idea that theres no free will it makes you very uncomfortable so what do you think about free will from a physics perspective from a conscious perspective what does it all fit okay so from the physics perspective leaving aside quantum mechanics we believe we live in a fully deterministic world right but then comes of course quantum mechanics so now we know that certain things are in principle not predictable which as you said i prefer because the idea that the initial condition of the universe and then everything else were just acting out the initial condition of the universe that doesnt… its not a romantic notion certainly not now when it comes to consciousness i think we do have certain freedom we are much more constrained by physics of course and by our past and by our own conscious desires and what our parents told us and what our environment tells us we all know that right theres hundreds of experiments that show how we can be influenced but finally in the final analysis when you make a life – and im talking really about critical decision where you really think should i marry should i go to this school or that school should i take this job or that job should i cheat on my taxes or not these are things where you really deliberate and i think under those conditions you are as free as you can be when you bring your entire being your entire conscious being to that question and try to analyze it under all the various conditions then you make a decision you are as free as you can ever be that is i think what free will is its not a will thats totally free to do anything it wants thats not possible right so as jack mentioned you actually write a blog about books youve read amazing books from im russian from bulgakov neil gaiman carl sagan murakami so what is a book that early in your life transformed the way you saw the world something that changed your life nietzsche i guess did thats brooks r truster because he talks about some of these problems he was one of the first discoverer of the unconscious this is a little bit before freud when he was in the air he makes all these claims that people sort of under the guise or under the mass of charity actually are very noncharitable so he is sort of really the first discoverer of the great land of the unconscious and that really struck me and what do you think about the unconscious what do you think about freud what do you think about these ideas just like dark matter in the universe whats over there in that unconscious a lot i mean much more than we think this is what a lot of last 100 years of research has shown so i think he was a genius misguided towards the end but he started out as a neuroscientist he contributed he did the studies on the lamprey he contributed himself to the neuron hypothesis the idea that there are discrete units that we call nerve cells now and then he wrote about the unconscious and i think its true theres lots of stuff happening you feel this particular when youre in a relationship and it breaks asunder right and then you have this terrible you can have love and hate and lust and anger and all of its mixed in and when you try to analyze yourself why am i so upset its very very difficult to penetrate to those basements those caverns in your mind because the prying eyes of conscious doesnt have access to those but theyre there in the amygdala or lots of other places they make you upset or angry or sad or depressed and its very difficult to try to actually uncover the reason you can go to a shrink you can talk with your friend endlessly you construct finally a story why this happened why you love her or dont love her or whatever but you dont really know whether that actually happened because you simply dont have access to those parts of the brain and theyre very powerful do you think thats a feature or a bug of our brain the fact that we have this deep difficult to dive into subconscious i think its a feature because otherwise look we are like any other brain or nervous system or computer we are severely band limited if everything i do every emotion i feel every eye movements i make if all of that had to be under the control of consciousness i wouldnt be here what you do early on your brain you have to be conscious when you learn things like typing or like riding on a bike but then what you do you train up routes i think that involve basal ganglia and striatum you train up different parts of your brain and then once you do it automatically like typing you can show you do it much faster without even thinking about it because youve got these highly specialized what frans krik and i call zombie agents theyre taking care of that while your consciousness can sort of worry about the abstract sense of the text you want to write i think thats true for many many things but for the things like all the fights you had with an ex girlfriend things that you would think are not useful to still linger somewhere in the subconscious so that seems like a bug that it would stick to there you think it would be better if you can analyze it and then get it out of the system better to get it out of the system or just forget it ever happened that seems a very buggy kind of well yeah in general we dont have and thats probably functional we dont have an ability unless its extreme there are cases clinical dissociations right when people are heavily abused when they completely repress the memory but that doesnt happen in normal people we dont have an ability to remove traumatic memories and of course we suffer from that on the other hand probably if you had the ability to constantly wipe your memory youd probably do it to an extent that isnt useful to you so yeah its a good question to balance so on the books as jack mentioned correct me if im wrong but broadly speaking academia and the different scientific disciplines certainly in engineering reading literature seems to be a rare pursuit so im wrong on this but thats in my experience most people read much more technical text and do not sort of escape or seek truth in literature it seems like you do so what do you think is the value what do you think literature adds to the pursuit of scientific truth do you think its good its useful for everybody gives you access to a much wider array of human experiences how valuable do you think it is well if you want to understand human nature and nature in general then i think you have to better understand a wide variety of experiences not just sitting in a lab staring at a screen and having a face flashed onto you for a hundred milliseconds and pushing a button thats what i used to do thats what most psychologists do theres nothing wrong with that but you need to consider lots of other strange states and literature is a shortcut for this well yeah because literature thats what literature is all about all sorts of interesting experiences that people have the contingency of it the fact that women experience the world different black people experience the world different the one way to experience that is reading all these different literature and try to find out you see everything is so relative you read a book 300 years ago they thought about certain problems very very differently than us today we today like any culture think we know it all thats common to every culture every culture believes at its heyday they know it all and then you realize well theres other ways of viewing the universe and some of them may have lots of things in their favor so this is a question i wanted to ask about time scale or scale in general when you with iit or in general try to think about consciousness try to think about these ideas we kind of naturally think in human time scales and also entities that are sized close to humans do you think of things that are much larger and much smaller as containing consciousness and do you think of things that take you know eons to operate in their conscious cause effect thats a very good question so i think a lot about small creatures because experimentally you know a lot of people work on flies and bees right so most people just think they are automata theyre just bugs for heavens sake right but if you look at their behavior like bees they can recognize individual humans they have this very complicated way to communicate if youve ever been involved or you know your parents when they bought a house what sort of agonizing decision that is and bees have to do that once a year right when they swarm in the spring and then they have this very elaborate way they have free and scouts they go to the individual sites they come back they have this power this dance literally where they dance for several days they try to recruit other deets this very complicated decision rate when they finally once they make a decision the entire swarm the scouts warm up the entire swarm and then go to one location they dont go to 50 locations they go to one location that the scouts have agreed upon by themselves thats awesome if we look at the circuit complexity its 10 times more denser than anything we have in our brain now they only have a million neurons but the neurons are amazingly complex complex behavior very complicated circuitry so theres no question they experience something their life is very different theyre tiny they only live you know for well workers live maybe for two months so i think and iit tells you this in principle the substrate of consciousness is the substrate that maximizes the cause effect power over all possible spatial temporal grains so when i think about for example do you know the science fiction story the black cloud okay its a classic by fred hoyle the astronomer he has this cloud intervening between the earth and the sun and leading to some sort of to global cooling this is written in the 50s it turns out you can using the radio dish they communicate with actually an entity its actually an intelligent entity and they sort of they convince it to move away so here you have a radical different entity and in principle iit says well you can measure the integrated information in principle at least and yes if the maximum of that occurs at a time scale of months rather than in assets for a fraction of a second yes then they would experience life where each moment is a month rather than or microsecond right rather than a fraction of a second in the human case and so there may be forms of consciousness that we simply dont recognize for what they are because they are so radical different from anything you and i are used to again thats why its good to read or to watch science fiction movies well to think about this do you know stanislav lem this polish science fiction writer he wrote solaris and was turned into a hollywood movie yes his best novel is in the 60s a very engineer hes an engineer in background his most interesting novel is called the victorious where human civilization they have this mission to this planet and everything is destroyed and they discover machines humans got killed and then these machines took over and there was this machine evolution darwinian evolution he talks about this very vividly and finally the dominant machine intelligence organism that survived were gigantic clouds of little hexagonal universal cellular automata this was written in the 60s so typically theyre all lying on the ground individual by themselves but in times of crisis they can communicate they assemble into gigantic nets into clouds of trillions of these particles and then they become hyper intelligent and they can beat anything that humans can throw at it its very beautiful and compelling where you have an intelligence where finally the humans leave the planet theyre simply unable to understand and comprehend this creature they can say well either we can nuke the entire planet and destroy it or we just have to leave because fundamentally its an alien its so alien from us and our ideas that we cannot communicate with them yeah actually in conversation so youre talking to us steven wolf from brought up is that there could be ideas that you already have these artificial general intelligence like super smart or maybe conscious beings in the cellular automata we just dont know how to talk to them so its the language of communication but you dont know what to do with it so thats one sort of view is consciousness is only something you can measure so its not conscious if you cant measure it so youre making an ontological and an epistemic statement one is its just like seeing the multiverses that might be true but i cant communicate with them i cant have any knowledge of them thats an epistemic argument right so those are two different things so it may well be possible look in another case thats happening right now people are building these mini organoids do you know what this is so you can take stem cells from under your arm put it in a dish add four transcription factors and then you can induce them to grow into large well large theyre a few millimeters theyre like a half a million neurons that look like nerve cells in a dish called mini organoids at harvard at stanford everywhere theyre building them it may well be possible that theyre beginning to feel like something but we cant really communicate with them right now so people are beginning to think about the ethics of this so yes he may be perfectly right but its one question are they conscious or not its a totally separate question how would i know those are two different things if you could give advice to a young researcher sort of dreaming of understanding or creating human level intelligence or consciousness what would you say just follow your dreams read widely no i mean i suppose with discipline what is the pursuit that they should take on is it neuroscience is it computational cognitive science is it philosophy is it computer science or robotics no in a sense that okay so the only known system that have high level of intelligence is homo sapiens so if you wanted to build it its probably good to continue to study closely what humans do so cognitive neuroscience you know somewhere between cognitive neuroscience on the one hand and some philosophy of mind and then ai ai computer science you can look at all the original ideas in your network they all came from neuroscience right reinforce whether its snarky minsky building is snarky or whether its you know the early hubel and wiesel experiments at harvard that then gave rise to networks and then multi layer networks so it may well be possible in fact some people argue that to make the next big step in ai once we realize the limits of deep convolutional networks they can do certain things but they cant really understand they dont they cant really i cant really show them one image i can show you a single image of somebody a pickpocket who steals a wallet from a purse you immediately know thats a pickpocket now computer system would just say well its a man its a woman its a purse right unless you train this machine on showing it a hundred thousand pickpockets right so it doesnt have this easy understanding that you have right so some people make the argument in order to go to the next step or you really want to build machines that understand in a way you and i we have to go to psychology we need to understand how we do it and how our brains enable us to do it and so therefore being on the cusp its also so exciting to try to understand better our nature and then to build to take some of those inside and build them so i think the most exciting thing is somewhere in the interface between cognitive science neuroscience ai computer science and philosophy of mind beautiful yeah id say if there is from the machine learning from our from the computer science computer vision perspective many of the researchers kind of ignore the way the human brain works or even psychology or literature or studying the brain i would hope josh tenenbaum talks about bringing that in more and more and thats yeah so youve worked on some amazing stuff throughout your life whats the thing that youre really excited about whats the mystery that you would love to uncover in the near term beyond beyond all the mysteries that youre already surrounded by well so theres a structure called the claustrum this is a structure its underneath our cortex its yay big you have one on the left on the right underneath this underneath the insula its very thin its like one millimeter its embedded in in wiring in white matter so its very difficult to image and it has it has connection to every cortical region and francis crick the last paper he ever wrote he dictated corrections the day he died in hospital on this paper you know we hypothesize well because it has this unique anatomy it gets input from every cortical area and projects back to every every cortical area that the function of this structure is similar its just a metaphor to the role of a conductor in a symphony orchestra you have all the different cortical players you have some that do motion some that do theory of mind some that infer social interaction and color and hearing and all the different modules in cortex but of course what consciousness is consciousness puts it all together into one package right the binding problem all of that and this is really the function because it has relatively few neurons compared to cortex but it talks it receives input from all of them and it projects back to all of them and so were testing that right now weve got this beautiful neuronal reconstruction in the mouse called crown of thorns crown of thorns neurons that are in the claustrum that have the most widespread connection of any neuron ive ever seen theyre very you have individual neurons that sit in the claustrum tiny but then they have this single neuron they have this huge axonal tree that cover both ipsy and contralateral cortex and trying to turn using you know fancy tools like optogenetics trying to turn those neurons on or off and study it what happens in the in the mouse so this thing is perhaps where the parts become the whole perhaps its one of the structures its a very good way of putting it where the individual parts turn into the whole of the whole of the conscious experience well with that thank you very much for being here today thank you very much thank you very much all right thank you very much', 'youve studied the human mind cognition language vision evolution psychology from child to adult from the level of individual to the level of our entire civilization so i feel like i can start with a simple multiple choice question what is the meaning of life is it a to attain knowledge as plato said b to attain power as nietzsche said c to escape death as ernest becker said d to propagate our genes as darwin and others have said e there is no meaning as the nihilists have said f knowing the meaning of life is beyond our cognitive capabilities as stephen pinker said based on my interpretation 20 years ago and g none of the above id say a comes closest but i would amend that to c to attaining not only knowledge but fulfillment more generally that is life health stimulation access to the living cultural and social world now this is our meaning of life its not the meaning of life if you were to ask our genes their meaning is to propagate copies of themselves but that is distinct from the meaning that the brain that they lead to sets for itself so to you knowledge is a small subset or a large subset its a large subset but its not the entirety of human striving because we also want to interact with people we want to experience beauty we want to experience the richness of the natural world but understanding what makes the universe tick is way up there for some of us more than others certainly for me thats one of the top five so is that a fundamental aspect are you just describing your own preference or is this a fundamental aspect of human nature is to seek knowledge in your latest book you talk about the power the usefulness of rationality and reason and so on is that a fundamental nature of human beings or is it something we should just strive for both were capable of striving for it because it is one of the things that make us what we are homo sapiens wise men we are unusual among animals in the degree to which we acquire knowledge and use it to survive we make tools we strike agreements via language we extract poisons we predict the behavior of animals we try to get at the workings of plants and when i say we i dont just mean we in the modern west but we as a species everywhere which is how weve managed to occupy every niche on the planet how weve managed to drive other animals to extinction and the refinement of reason in pursuit of human wellbeing of health happiness social richness cultural richness is our main challenge in the present that is using our intellect using our knowledge to figure out how the world works how we work in order to make discoveries and strike agreements that make us all better off in the long run right and you do that almost undeniably and in a data driven way in your recent book but id like to focus on the artificial intelligence aspect of things and not just artificial intelligence but natural intelligence too so 20 years ago in a book youve written on how the mind works you conjecture again am i right to interpret things you can correct me if im wrong but you conjecture that human thought in the brain may be a result of a massive network of highly interconnected neurons so from this interconnectivity emerges thought compared to artificial neural networks which we use for machine learning today is there something fundamentally more complex mysterious even magical about the biological neural networks versus the ones weve been starting to use over the past 60 years and have become to success in the past 10 there is something a little bit mysterious about the human neural networks which is that each one of us who is a neural network knows that we ourselves are conscious conscious not in the sense of registering our surroundings or even registering our internal state but in having subjective first person present tense experience that is when i see red its not just different from green but theres a redness to it that i feel whether an artificial system would experience that or not i dont know and i dont think i can know thats why its mysterious if we had a perfectly lifelike robot that was behaviorally indistinguishable from a human would we attribute consciousness to it or ought we to attribute consciousness to it and thats something that its very hard to know but putting that aside putting aside that largely philosophical question the question is is there some difference between the human neural network and the ones that were building in artificial intelligence will mean that were on the current trajectory not going to reach the point where weve got a lifelike robot indistinguishable from a human because the way their so called neural networks are organized are different from the way ours are organized i think theres overlap but i think there are some big differences that current neural networks current so called deep learning systems are in reality not all that deep that is they are very good at extracting high order statistical regularities but most of the systems dont have a semantic level a level of actual understanding of who did what to whom why where how things work what causes what else do you think that kind of thing can emerge as it does so artificial neural networks are much smaller the number of connections and so on than the current human biological networks but do you think sort of to go to consciousness or to go to this higher level semantic reasoning about things do you think that can emerge with just a larger network with a more richly weirdly interconnected network separate it in consciousness because consciousness is even a matter of complexity a really weird one yeah you could sensibly ask the question of whether shrimp are conscious for example theyre not terribly complex but maybe they feel pain so lets just put that part of it aside but i think sheer size of a neural network is not enough to give it structure and knowledge but if its suitably engineered then why not that is were neural networks natural selection did a kind of equivalent of engineering of our brains so i dont think theres anything mysterious in the sense that no system made out of silicon could ever do what a human brain can do i think its possible in principle whether itll ever happen depends not only on how clever we are in engineering these systems but whether we even want to whether thats even a sensible goal that is you can ask the question is there any locomotion system that is as good as a human well we kind of want to do better than a human ultimately in terms of legged locomotion theres no reason that humans should be our benchmark theyre tools that might be better in some ways it may be that we cant duplicate a natural system because at some point its so much cheaper to use a natural system that were not going to invest more brainpower and resources so for example we dont really have an exact substitute for wood we still build houses out of wood we still build furniture out of wood we like the look we like the feel it has certain properties that synthetics dont its not that theres anything magical or mysterious about wood its just that the extra steps of duplicating everything about wood is something we just havent bothered because we have wood likewise say cotton im wearing cotton clothing now it feels much better than polyester its not that cotton has something magic in it its not that we couldnt ever synthesize something exactly like cotton but at some point its just not worth it weve got cotton likewise in the case of human intelligence the goal of making an artificial system that is exactly like the human brain is a goal that we probably know is going to pursue to the bitter end i suspect because if you want tools that do things better than humans youre not going to care whether it does something like humans so for example diagnosing cancer or predicting the weather why set humans as your benchmark but in general i suspect you also believe that even if the human should not be a benchmark and we dont want to imitate humans in their system theres a lot to be learned about how to create an artificial intelligence system by studying the human yeah i think thats right in the same way that to build flying machines we want to understand the laws of aerodynamics including birds but not mimic the birds but theyre the same laws you have a view on ai artificial intelligence and safety that from my perspective is refreshingly rational or perhaps more importantly has elements of positivity to it which i think can be inspiring and empowering as opposed to paralyzing for many people including ai researchers the eventual existential threat of ai is obvious not only possible but obvious and for many others including ai researchers the threat is not obvious so elon musk is famously in the highly concerned about ai camp saying things like ai is far more dangerous than nuclear weapons and that ai will likely destroy human civilization human civilization so in february he said that if elon was really serious about ai the threat of ai he would stop building self driving cars that hes doing very successfully as part of tesla then he said wow if even pinker doesnt understand the difference between narrow ai like a car and general ai when the latter literally has a million times more compute power and an open ended utility function humanity is in deep trouble so first what did you mean by the statement about elon musk should stop building self driving cars if hes deeply concerned not the last time that elon musk has fired off an intemperate tweet well we live in a world where twitter has power yes yeah i think there are two kinds of existential threat that have been discussed in connection with artificial intelligence and i think that theyre both incoherent one of them is a vague fear of ai takeover that just as we subjugated animals and less technologically advanced peoples so if we build something thats more advanced than us it will inevitably turn us into pets or slaves or domesticated animal equivalents i think this confuses intelligence with a will to power that it so happens that in the intelligence system we are most familiar with namely homo sapiens we are products of natural selection which is a competitive process and so bundled together with our problem solving capacity are a number of nasty traits like dominance and exploitation and maximization of power and glory and resources and influence theres no reason to think that sheer problem solving capability will set that as one of its goals its goals will be whatever we set its goals as and as long as someone isnt building a megalomaniacal artificial intelligence then theres no reason to think that it would naturally evolve in that direction now you might say well what if we gave it the goal of maximizing its own power source thats a pretty stupid goal to give an autonomous system you dont give it that goal i mean thats just self evidently idiotic so if you look at the history of the world theres been a lot of opportunities where engineers could instill in a system destructive power and they choose not to because thats the natural process of engineering well except for weapons i mean if youre building a weapon its goal is to destroy people and so i think there are good reasons to not build certain kinds of weapons i think building nuclear weapons was a massive mistake you do so maybe pause on that because that is one of the serious threats do you think that it was a mistake in a sense that it should have been stopped early on or do you think its just an unfortunate event of invention that this was invented do you think its possible to stop i guess is the question its hard to rewind the clock because of course it was invented in the context of world war ii and the fear that the nazis might develop one first then once it was initiated for that reason it was hard to turn off especially since winning the war against the japanese and the nazis was such an overwhelming goal of every responsible person that theres just nothing that people wouldnt have done then to ensure victory its quite possible if world war ii hadnt happened that nuclear weapons wouldnt have been invented we cant know but i dont think it was by any means a necessity any more than some of the other weapon systems that were envisioned but never implemented like planes that would disperse poison gas over cities like crop dusters or systems to try to create earthquakes and tsunamis in enemy countries to weaponize the weather weaponize solar flares all kinds of crazy schemes that we thought the better of i think analogies between nuclear weapons and artificial intelligence are fundamentally misguided because the whole point of nuclear weapons is to destroy things the point of artificial intelligence is not to destroy things so the analogy is misleading so theres two artificial intelligence you mentioned the first one i guess is highly intelligent or power hungry yeah its a system that we design ourselves where we give it the goals goals are external to the means to attain the goals if we dont design an artificially intelligent system to maximize dominance then it wont maximize dominance its just that were so familiar with homo sapiens where these two traits come bundled together particularly in men that we are apt to confuse high intelligence with a will to power but thats just an error the other fear is that will be collateral damage that will give artificial intelligence a goal like make paper clips and it will pursue that goal so brilliantly that before we can stop it it turns us into paper clips well give it the goal of curing cancer and it will turn us into guinea pigs for lethal experiments or give it the goal of world peace and its conception of world peace is no people therefore no fighting and so it will kill us all now i think these are utterly fanciful in fact i think theyre actually self defeating they first of all assume that were going to be so brilliant that we can design an artificial intelligence that can cure cancer but so stupid that we dont specify what we mean by curing cancer in enough detail that it wont kill us in the process and it assumes that the system will be so smart that it can cure cancer but so idiotic that it cant figure out that what we mean by curing cancer is not killing everyone i think that the collateral damage scenario the value alignment problem is also based on a misconception so one of the challenges of course we dont know how to build either system currently or are we even close to knowing of course those things can change overnight but at this time theorizing about it is very challenging in either direction so thats probably at the core of the problem is without that ability to reason about the real engineering things here at hand is your imagination runs away with things exactly but let me sort of ask what do you think was the motivation the thought process of elon musk i build autonomous vehicles i study autonomous vehicles i study tesla autopilot i think it is one of the greatest currently large scale application of artificial intelligence in the world it has potentially a very positive impact on society so how does a person whos creating this very good quote unquote narrow ai system also seem to be so concerned about this other general ai what do you think is the motivation there what do you think is the thing well you probably have to ask him but there and he is notoriously flamboyant impulsive to the as we have just seen to the detriment of his own goals of the health of the company so i dont know whats going on in his mind you probably have to ask him but i dont think the and i dont think the distinction between special purpose ai and so called general ai is relevant that in the same way that special purpose ai is not going to do anything conceivable in order to attain a goal all engineering systems are designed to trade off across multiple goals when we build cars in the first place we didnt forget to install brakes because the goal of a car is to go fast it occurred to people yes you want it to go fast but not always so you would build in brakes too likewise if a car is going to be autonomous and program it to take the shortest route to the airport its not going to take the diagonal and mow down people and trees and fences because thats the shortest route thats not what we mean by the shortest route when we program it and thats just what an intelligence system is by definition it takes into account multiple constraints the same is true in fact even more true of so called general intelligence that is if its genuinely intelligent its not going to pursue some goal singlemindedly omitting every other consideration and collateral effect thats not artificial and general intelligence thats artificial stupidity i agree with you by the way on the promise of autonomous vehicles for improving human welfare i think its spectacular and im surprised at how little press coverage notes that in the united states alone something like 40000 people die every year on the highways vastly more than are killed by terrorists and we spent a trillion dollars on a war to combat deaths by terrorism about half a dozen a year whereas year in year out 40000 people are massacred on the highways which could be brought down to very close to zero so im with you on the humanitarian benefit let me just mention that as a person whos building these cars it is a little bit offensive to me to say that engineers would be clueless enough not to engineer safety into systems i often stay up at night thinking about those 40000 people that are dying and everything i tried to engineer is to save those peoples lives so every new invention that im super excited about in all the deep learning literature and cvpr conferences and nips everything im super excited about is all grounded in making it safe and help people so i just dont see how that trajectory can all of a sudden slip into a situation where intelligence will be highly negative you and i certainly agree on that and i think thats only the beginning of the potential humanitarian benefits of artificial intelligence theres been enormous attention to what are we going to do with the people whose jobs are made obsolete by artificial intelligence but very little attention given to the fact that the jobs that are going to be made obsolete are horrible jobs the fact that people arent going to be picking crops and making beds and driving trucks and mining coal these are soul deadening jobs and we have a whole literature sympathizing with the people stuck in these menial mind deadening dangerous jobs if we can eliminate them this is a fantastic boon to humanity now granted you solve one problem and theres another one namely how do we get these people a decent income but if were smart enough to invent machines that can make beds and put away dishes and handle hospital patients i think were smart enough to figure out how to redistribute income to apportion some of the vast economic savings to the human beings who will no longer be needed to make beds okay sam harris says that its obvious that eventually ai will be an existential risk hes one of the people who says its obvious we dont know when the claim goes but eventually its obvious and because we dont know when we should worry about it now this is a very interesting argument in my eyes so how do we think about timescale how do we think about existential threats when we dont really we know so little about the threat unlike nuclear weapons perhaps about this particular threat that it could happen tomorrow right so but very likely it wont very likely itd be a hundred years away so how do we ignore it how do we talk about it do we worry about it how do we think about those what is it a threat that we can imagine its within the limits of our imagination but not within our limits of understanding to accurately predict it but what is the it that were afraid of sorry ai being the existential threat ai how like enslaving us or turning us into paperclips i think the most compelling from the sam harris perspective would be the paperclip situation yeah i mean i just think its totally fanciful i mean that is dont build a system dont give a dont first of all the code of engineering is you dont implement a system with massive control before testing it now perhaps the culture of engineering will radically change then i would worry but i dont see any signs that engineers will suddenly do idiotic things like put a electric power plant in control of a system that they havent tested first or all of these scenarios not only imagine almost a magically powered intelligence including things like cure cancer which is probably an incoherent goal because theres so many different kinds of cancer or bring about world peace i mean how do you even specify that as a goal but the scenarios also imagine some degree of control of every molecule in the universe which not only is itself unlikely but we would not start to connect these systems to infrastructure without testing as we would any kind of engineering system now maybe some engineers will be irresponsible and we need legal and regulatory and legal responsibility implemented so that engineers dont do things that are stupid by their own standards but the ive never seen enough of a plausible scenario of existential threat to devote large amounts of brain power to to forestall it so you believe in the sort of the power on mass of the engineering of reason as you argue in your latest book of reason and science to sort of be the very thing that guides the development of new technology so its safe and also keeps us safe you know granted the same culture of safety that currently is part of the engineering mindset for airplanes for example so yeah i dont think that that should be thrown out the window and that untested all powerful systems should be suddenly implemented but theres no reason to think they are and in fact if you look at the progress of artificial intelligence its been you know its been impressive especially in the last 10 years or so but the idea that suddenly therell be a step function that all of a sudden before we know it it will be all powerful that therell be some kind of recursive self improvement some kind of fume is also fanciful we certainly by the technology that we that were now impresses us such as deep learning where you train something on hundreds of thousands or millions of examples theyre not hundreds of thousands of problems of which curing cancer is a typical example and so the kind of techniques that have allowed ai to increase in the last five years are not the kind that are going to lead to this fantasy of exponential sudden self improvement i think its kind of a magical thinking its not based on our understanding of how ai actually works now give me a chance here so you said fanciful magical thinking in his ted talk sam harris says that thinking about ai killing all human civilization is somehow fun intellectually now i have to say as a scientist engineer i dont find it fun but when im having beer with my non ai friends there is indeed something fun and appealing about it like talking about an episode of black mirror considering if a large meteor is headed towards earth we were just told a large meteor is headed towards earth something like this and can you relate to this sense of fun and do you understand the psychology of it yes good question i personally dont find it fun i find it kind of actually a waste of time because there are genuine threats that we ought to be thinking about like pandemics like cyber security vulnerabilities like the possibility of nuclear war and certainly climate change you know this is enough to fill many conversations and i think sam did put his finger on something namely that there is a community sometimes called the rationality community that delights in using its brainpower to come up with scenarios that would not occur to mere mortals to less cerebral people so there is a kind of intellectual thrill in finding new things to worry about that no one has worried about yet i actually think though that its not only is it a kind of fun that doesnt give me particular pleasure but i think there can be a pernicious side to it namely that you overcome people with such dread such fatalism that there are so many ways to die to annihilate our civilization that we may as well enjoy life while we can theres nothing we can do about it if climate change doesnt do us in then runaway robots will so lets enjoy ourselves now weve got to prioritize we have to look at threats that are close to certainty such as climate change and distinguish those from ones that are merely imaginable but with infinitesimal probabilities and we have to take into account peoples worry budget you cant worry about everything and if you sow dread and fear and terror and fatalism it can lead to a kind of numbness well these problems are overwhelming and the engineers are just going to kill us all so lets either destroy the entire infrastructure of science technology or lets just enjoy life while we can so theres a certain line of worry which im worried about a lot of things in engineering theres a certain line of worry when you cross youre allowed to cross that it becomes paralyzing fear as opposed to productive fear and thats kind of what youre highlighting exactly right and weve seen some we know that human effort is not well calibrated against risk in that because a basic tenet of cognitive psychology is that perception of risk and hence perception of fear is driven by imaginability not by data and so we misallocate vast amounts of resources to avoiding terrorism which kills on average about six americans a year with one exception of 9 11 we invade countries we invent entire new departments of government with massive massive expenditure of resources and lives to defend ourselves against a trivial risk whereas guaranteed risks one of them you mentioned traffic fatalities and even risks that are not here but are plausible enough to worry about like pandemics like nuclear war receive far too little attention in presidential debates theres no discussion of how to minimize the risk of nuclear war lots of discussion of terrorism for example and so i think its essential to calibrate our budget of fear worry concern planning to the actual probability of harm yep so let me ask this question so speaking of imaginability you said its important to think about reason and one of my favorite people who likes to dip into the outskirts of reason through fascinating exploration of his imagination is joe rogan oh yes so who has through reason used to believe a lot of conspiracies and through reason has stripped away a lot of his beliefs in that way so its fascinating actually to watch him through rationality kind of throw away the ideas of bigfoot and 9 11 im not sure exactly kim trails i dont know what he believes in yes okay but he no longer believed in no thats right no hes become a real force for good yep so you were on the joe rogan podcast in february and had a fascinating conversation but as far as i remember didnt talk much about artificial intelligence i will be on his podcast in a couple of weeks joe is very much concerned about existential threat of ai im not sure if youre this is why i was hoping that you would get into that topic and in this way he represents quite a lot of people who look at the topic of ai from 10000 foot level so as an exercise of communication you said its important to be rational and reason about these things let me ask if you were to coach me as an ai researcher about how to speak to joe and the general public about ai what would you advise well the short answer would be to read the sections that i wrote in enlightenment now about ai but a longer reason would be i think to emphasize and i think youre very well positioned as an engineer to remind people about the culture of engineering that it really is safety oriented that another discussion in enlightenment now i plot rates of accidental death from various causes plane crashes car crashes occupational accidents even death by lightning strikes and they all plummet because the culture of engineering is how do you squeeze out the lethal risks death by fire death by drowning death by asphyxiation all of them drastically declined because of advances in engineering that i got to say i did not appreciate until i saw those graphs and it is because exactly people like you who stay up at night thinking oh my god is what im inventing likely to hurt people and to deploy ingenuity to prevent that from happening now im not an engineer although i spent 22 years at mit so i know something about the culture of engineering my understanding is that this is the way you think if youre an engineer and its essential that that culture not be suddenly switched off when it comes to artificial intelligence so i mean that could be a problem but is there any reason to think it would be switched off i dont think so and one theres not enough engineers speaking up for this way for the excitement for the positive view of human nature what youre trying to create is positivity like everything we try to invent is trying to do good for the world but let me ask you about the psychology of negativity it seems just objectively not considering the topic it seems that being negative about the future makes you sound smarter than being positive about the future irregardless of topic am i correct in this observation and if so why do you think that is yeah i think there is that phenomenon that as tom lehrer the satirist said always predict the worst and youll be hailed as a prophet it may be part of our overall negativity bias we are as a species more attuned to the negative than the positive we dread losses more than we enjoy gains and that might open up a space for prophets to remind us of harms and risks and losses that we may have overlooked so i think there is that asymmetry so youve written some of my favorite books all over the place so starting from enlightenment now to the better ages of our nature blank slate how the mind works the one about language language instinct bill gates big fan too said of your most recent book that its my new favorite book of all time so for you as an author what was a book early on in your life that had a profound impact on the way you saw the world certainly this book enlightenment now was influenced by david deutschs the beginning of infinity a rather deep reflection on knowledge and the power of knowledge to improve the human condition and with bits of wisdom such as that problems are inevitable but problems are solvable given the right knowledge and that solutions create new problems that have to be solved in their turn thats i think a kind of wisdom about the human condition that influenced the writing of this book there are some books that are excellent but obscure some of which i have on a page on my website i read a book called the history of force self published by a political scientist named james payne on the historical decline of violence and that was one of the inspirations for the better angels of our nature what about early on if you look back when you were maybe a teenager i loved a book called one two three infinity when i was a young adult i read that book by george gamow the physicist which had very accessible and humorous explanations of relativity of number theory of dimensionality high multiple dimensional spaces in a way that i think is still delightful 70 years after it was published i like the time life science series these are books that would arrive every month that my mother subscribed to each one on a different topic one would be on electricity one would be on forests one would be on evolution and then one was on the mind i was just intrigued that there could be a science of mind and that book i would cite as an influence as well then later on thats when you fell in love with the idea of studying the mind was that the thing that grabbed you it was one of the things i would say i read as a college student the book reflections on language by noam chomsky i spent most of his career here at mit richard dawkins two books the blind watchmaker and the selfish gene were enormously influential mainly for the content but also for the writing style the ability to explain abstract concepts in lively prose stephen jay goulds first collection ever since darwin also an excellent example of lively writing george miller a psychologist that most psychologists are familiar with came up with the idea that human memory has a capacity of seven plus or minus two chunks thats probably his biggest claim to fame but he wrote a couple of books on language and communication that i read as an undergraduate again beautifully written and intellectually deep wonderful stephen thank you so much for taking the time today my pleasure thanks a lot lex', 'what difference between biological neural networks and artificial neural networks is most mysterious captivating and profound for you first of all theres so much we dont know about biological neural networks and thats very mysterious and captivating because maybe it holds the key to improving artificial neural networks one of the things i studied recently is something that we dont know how biological neural networks do but would be really useful for artificial ones is the ability to do credit assignment through very long time spans there are things that we can in principle do with artificial neural nets but its not very convenient and its not biologically plausible and this mismatch i think this kind of mismatch may be an interesting thing to study to a understand better how brains might do these things because we dont have good corresponding theories with artificial neural nets and b maybe provide new ideas that we could explore about things that brain do differently and that we could incorporate in artificial neural nets so lets break credit assignment up a little bit yes so what its a beautifully technical term but it could incorporate so many things so is it more on the rnn memory side that thinking like that or is it something about knowledge building up common sense knowledge over time or is it more in the reinforcement learning sense that youre picking up rewards over time for a particular to achieve a certain kind of goal so i was thinking more about the first two meanings whereby we store all kinds of memories episodic memories in our brain which we can access later in order to help us both infer causes of things that we are observing now and assign credit to decisions or interpretations we came up with a while ago when those memories were stored and then we can change the way we would have reacted or interpreted things in the past and now thats credit assignment used for learning so in which way do you think artificial neural networks the current lstm the current architectures are not able to capture the presumably youre thinking of very long term yes so current the current nets are doing a fairly good jobs for sequences with dozens or say hundreds of time steps and then it gets harder and harder and depending on what you have to remember and so on as you consider longer durations whereas humans seem to be able to do credit assignment through essentially arbitrary times like i could remember something i did last year and then now because i see some new evidence im going to change my mind about the way i was thinking last year and hopefully not do the same mistake again i think a big part of that is probably forgetting youre only remembering the really important things its very efficient forgetting yes so theres a selection of what we remember and i think there are really cool connection to higher level cognition here regarding consciousness deciding and emotions so deciding what comes to consciousness and what gets stored in memory which are not trivial either so youve been at the forefront there all along showing some of the amazing things that neural networks deep neural networks can do in the field of artificial intelligence is just broadly in all kinds of applications but we can talk about that forever but what in your view because were thinking towards the future is the weakest aspect of the way deep neural networks represent the world what is that what is in your view is missing so current state of the art neural nets trained on large quantities of images or texts have some level of understanding of you know what explains those data sets but its very basic its its very low level and its not nearly as robust and abstract and general as our understanding okay so that doesnt tell us how to fix things but i think it encourages us to think about how we can maybe train our neural nets differently so that they would focus for example on causal explanation something that we dont do currently with neural net training also one thing ill talk about in my talk this afternoon is the fact that instead of learning separately from images and videos on one hand and from texts on the other hand we need to do a better job of jointly learning about language and about the world to which it refers so that you know both sides can help each other we need to have good world models in our neural nets for them to really understand sentences which talk about whats going on in the world and i think we need language input to help provide clues about what high level concepts like semantic concepts should be represented at the top levels of our neural nets in fact there is evidence that the purely unsupervised learning of representations doesnt give rise to high level representations that are as powerful as the ones were getting from supervised learning and so the clues were getting just with the labels not even sentences is already very very high level and i think thats a very important thing to keep in mind its already very powerful do you think thats an architecture challenge or is it a data set challenge neither im tempted to just end it there can you elaborate slightly of course data sets and architectures are something you want to always play with but i think the crucial thing is more the training objectives the training frameworks for example going from passive observation of data to more active agents which learn by intervening in the world the relationships between causes and effects the sort of objective functions which could be important to allow the highest level explanations to rise from the learning which i dont think we have now the kinds of objective functions which could be used to reward exploration the right kind of exploration so these kinds of questions are neither in the data set nor in the architecture but more in how we learn under what objectives and so on yeah ive heard you mention in several contexts the idea of sort of the way children learn they interact with objects in the world and it seems fascinating because in some sense except with some cases in reinforcement learning that idea is not part of the learning process in artificial neural networks so its almost like do you envision something like an objective function saying you know what if you poke this object in this kind of way it would be really helpful for me to further learn right right sort of almost guiding some aspect of the learning right right right so i was talking to rebecca sacks just a few minutes ago and she was talking about lots and lots of evidence from infants seem to clearly pick what interests them in a directed way and so theyre not passive learners they focus their attention on aspects of the world which are most interesting surprising in a non trivial way that makes them change their theories of the world so thats a fascinating view of the future progress but on a more maybe boring question do you think going deeper and larger so do you think just increasing the size of the things that have been increasing a lot in the past few years is going to be a big thing i think increasing the size of the things that have been increasing a lot in the past few years will also make significant progress so some of the representational issues that you mentioned theyre kind of shallow in some sense oh shallow in the sense of abstraction in the sense of abstraction theyre not getting some i dont think that having more depth in the network in the sense of instead of 100 layers youre going to have more layers i dont think so is that obvious to you yes what is clear to me is that engineers and companies and labs and grad students will continue to tune architectures and explore all kinds of tweaks to make the current state of the art slightly ever slightly better but i dont think thats going to be nearly enough i think we need changes in the way that were considering learning to achieve the goal that these learners actually understand in a deep way the environment in which they are you know observing and acting but i guess i was trying to ask a question thats more interesting than just more layers its basically once you figure out a way to learn through interacting how many parameters it takes to store that information so i think our brain is quite bigger than most neural networks right right oh i see what you mean oh im with you there so i agree that in order to build neural nets with the kind of broad knowledge of the world that typical adult humans have probably the kind of computing power we have now is going to be insufficient so the good news is there are hardware companies building neural net chips and so its going to get better however the good news in a way which is also a bad news is that even our state of the art deep learning methods fail to learn models that understand even very simple environments like some grid worlds that we have built even these fairly simple environments i mean of course if you train them with enough examples eventually they get it but its just like instead of what humans might need just dozens of examples these things will need millions for very very very simple tasks and so i think theres an opportunity for academics who dont have the kind of computing power that say google has to do really important and exciting research to advance the state of the art in training frameworks learning models agent learning in even simple environments that are synthetic that seem trivial but yet current machine learning fails on we talked about priors and common sense knowledge it seems like we humans take a lot of knowledge for granted so whats your view of these priors of forming this broad view of the world this accumulation of information and how we can teach neural networks or learning systems to pick that knowledge up so knowledge for a while the artificial intelligence was maybe in the 80s like theres a time where knowledge representation knowledge acquisition expert systems i mean the symbolic ai was a view was an interesting problem set to solve and it was kind of put on hold a little bit it seems like because it doesnt work it doesnt work thats right but thats right but the goals of that remain important yes remain important and how do you think those goals can be addressed right so first of all i believe that one reason why the classical expert systems approach failed is because a lot of the knowledge we have so you talked about common sense intuition theres a lot of knowledge like this which is not consciously accessible there are lots of decisions were taking that we cant really explain even if sometimes we make up a story and that knowledge is also necessary for machines to take good decisions and that knowledge is hard to codify in expert systems rule based systems and classical ai formalism and there are other issues of course with the old ai like not really good ways of handling uncertainty i would say something more subtle which we understand better now but i think still isnt enough in the minds of people theres something really powerful that comes from distributed representations the thing that really makes neural nets work so well and its hard to replicate that kind of power in a symbolic world the knowledge in expert systems and so on is nicely decomposed into like a bunch of rules whereas if you think about a neural net its the opposite you have this big blob of parameters which work intensely together to represent everything the network knows and its not sufficiently factorized its not sufficiently factorized and so i think this is one of the weaknesses of current neural nets that we have to take lessons from classical ai in order to bring in another kind of compositionality which is common in language for example and in these rules but that isnt so native to neural nets and on that line of thinking disentangled representations yes so let me connect with disentangled representations if you might if you dont mind so for many years ive thought and i still believe that its really important that we come up with learning algorithms either unsupervised or supervised but reinforcement whatever that build representations in which the important factors hopefully causal factors are nicely separated and easy to pick up from the representation so thats the idea of disentangled representations it says transform the data into a space where everything becomes easy we can maybe just learn with linear models about the things we care about and i still think this is important but i think this is missing out on a very important ingredient which classical ai systems can remind us of so lets say we have these disentangled representations you still need to learn about the relationships between the variables those high level semantic variables theyre not going to be independent i mean this is like too much of an assumption theyre going to have some interesting relationships that allow to predict things in the future to explain what happened in the past the kind of knowledge about those relationships in a classical ai system is encoded in the rules like a rule is just like a little piece of knowledge that says oh i have these two three four variables that are linked in this interesting way then i can say something about one or two of them given a couple of others right in addition to disentangling the elements of the representation which are like the variables in a rule based system you also need to disentangle the mechanisms that relate those variables to each other so like the rules so the rules are neatly separated like each rule is you know living on its own and when i change a rule because im learning it doesnt need to break other rules whereas current neural nets for example are very sensitive to whats called catastrophic forgetting where after ive learned some things and then i learn new things they can destroy the old things that i had learned right if the knowledge was better factorized and separated disentangled then you would avoid a lot of that now you cant do this in the sensory domain what do you mean by sensory domain like in pixel space but my idea is that when you project the data in the right semantic space it becomes possible to now represent this extra knowledge beyond the transformation from inputs to representations which is how representations act on each other and predict the future and so on in a way that can be neatly disentangled so now its the rules that are disentangled from each other and not just the variables that are disentangled from each other and you draw a distinction between semantic space and pixel like does there need to be an architectural difference well yeah so theres the sensory space like pixels which where everything is entangled the information like the variables are completely interdependent in very complicated ways and also computation like its not just the variables its also how they are related to each other is all intertwined but im hypothesizing that in the right high level representation space both the variables and how they relate to each other can be disentangled and that will provide a lot of generalization power generalization power yes distribution of the test set is assumed to be the same as the distribution of the training set right this is where current machine learning is too weak it doesnt tell us anything is not able to tell us anything about how our neural nets say are going to generalize to a new distribution and you know people may think well but theres nothing we can say if we dont know what the new distribution will be the truth is humans are able to generalize to new distributions yeah how are we able to do that yeah because there is something these new distributions even though they could look very different from the training distributions they have things in common so let me give you a concrete example you read a science fiction novel the science fiction novel maybe you know brings you in some other planet where things look very different on the surface but its still the same laws of physics and so you can read the book and you understand whats going on so the distribution is very different but because you can transport a lot of the knowledge you had from earth about the underlying cause and effect relationships and physical mechanisms and all that and maybe even social interactions you can now make sense of what is going on on this planet where like visually for example things are totally different taking that analogy further and distorting it lets enter a science fiction world of say space odyssey 2001 with hal or maybe which is probably one of my favorite ai movies me too and then theres another one that a lot of people love that may be a little bit outside of the ai community is ex machina i dont know if youve seen it yes yes by the way what are your views on that movie are you able to enjoy it are there things i like and things i hate so you could talk about that in the context of a question i want to ask which is theres quite a large community of people from different backgrounds often outside of ai who are concerned about existential threat of artificial intelligence youve seen this community develop over time youve seen you have a perspective so what do you think is the best way to talk about ai safety to think about it to have discourse about it within ai community and outside and grounded in the fact that ex machina is one of the main sources of information for the general public about ai so i think youre putting it right theres a big difference between the sort of discussion we ought to have within the ai community and the sort of discussion that really matter in the general public so i think the picture of terminator and ai loose and killing people and super intelligence thats going to destroy us whatever we try isnt really so useful for the public discussion because for the public discussion the things i believe really matter are the short term and medium term very likely negative impacts of ai on society whether its from security like you know big brother scenarios with face recognition or killer robots or the impact on the job market or concentration of power and discrimination all kinds of social issues which could actually some of them could really threaten democracy for example just to clarify when you said killer robots you mean autonomous weapon weapon systems yes i dont mean thats right so i think these short and medium term concerns should be important parts of the public debate now existential risk for me is a very unlikely consideration but still worth academic investigation in the same way that you could say should we study what could happen if meteorite you know came to earth and destroyed it so i think its very unlikely that this is going to happen in or happen in a reasonable future the sort of scenario of an ai getting loose goes against my understanding of at least current machine learning and current neural nets and so on its not plausible to me but of course i dont have a crystal ball and who knows what ai will be in 50 years from now so i think it is worth that scientists study those problems its just not a pressing question as far as im concerned so before i continue down that line i have a few questions there but what do you like and not like about ex machina as a movie because i actually watched it for the second time and enjoyed it i hated it the first time and i enjoyed it quite a bit more the second time when i sort of learned to accept certain pieces of it see it as a concept movie what was your experience what were your thoughts so the negative is the picture it paints of science is totally wrong science in general and ai in particular science is not happening in some hidden place by some you know really smart guy one person this is totally unrealistic this is not how it happens even a team of people in some isolated place will not make it science moves by small steps thanks to the collaboration and community of a large number of people interacting and all the scientists who are expert in their field kind of know what is going on even in the industrial labs its information flows and leaks and so on and the spirit of it is very different from the way science is painted in this movie yeah let me ask on that point its been the case to this point that kind of even if the research happens inside google or facebook inside companies it still kind of comes out ideas come out do you think that will always be the case with ai is it possible to bottle ideas to the point where theres a set of breakthroughs that go completely undiscovered by the general research community do you think thats even possible its possible but its unlikely its not how it is done now its not how i can foresee it in the foreseeable future but of course i dont have a crystal ball and science is a crystal ball and so who knows this is science fiction after all i think its ominous that the lights went off during that discussion so the problem again theres one thing is the movie and you could imagine all kinds of science fiction the problem for me maybe similar to the question about existential risk is that this kind of movie paints such a wrong picture of what is the actual science and how its going on that it can have unfortunate effects on peoples understanding of current science and so thats kind of sad theres an important principle in research which is diversity so in other words research is exploration research is exploration in the space of ideas and different people will focus on different directions and this is not just good its essential so im totally fine with people exploring directions that are contrary to mine or look orthogonal to mine i am more than fine i think its important i and my friends dont claim we have universal truth about what will especially about what will happen in the future now that being said we have our intuitions and then we act accordingly according to where we think we can be most useful and where society has the most to gain or to lose we should have those debates and not end up in a society where theres only one voice and one way of thinking and research money is spread out so disagreement is a sign of good research good science yes the idea of bias in the human sense of bias how do you think about instilling in machine learning something thats aligned with human values in terms of bias we intuitively as human beings have a concept of what bias means of what fundamental respect for other human beings means but how do we instill that into machine learning systems do you think so i think there are short term things that are already happening and then there are long term things that we need to do in the short term there are techniques that have been proposed and i think will continue to be improved and maybe alternatives will come up to take data sets in which we know there is bias we can measure it pretty much any data set where humans are being observed taking decisions will have some sort of bias discrimination against particular groups and so on and we can use machine learning techniques to try to build predictors classifiers that are going to be less biased we can do it for example using adversarial methods to make our systems less sensitive to these variables we should not be sensitive to so these are clear well defined ways of trying to address the problem maybe they have weaknesses and more research is needed and so on but i think in fact they are sufficiently mature that governments should start regulating companies where it matters say like insurance companies so that they use those techniques because those techniques will probably reduce the bias but at a cost for example maybe their predictions will be less accurate and so companies will not do it until you force them all right so this is short term long term im really interested in thinking how we can instill moral values into computers obviously this is not something well achieve in the next five or 10 years how can we you know theres already work in detecting emotions for example in images in sounds in texts and also studying how different agents interacting in different ways may correspond to patterns of say injustice which could trigger anger so these are things we can do in the medium term and eventually train computers to model for example how humans react emotionally i would say the simplest thing is unfair situations which trigger anger this is one of the most basic emotions that we share with other animals i think its quite feasible within the next few years that we can build systems that can detect these kinds of things to the extent unfortunately that they understand enough about the world around us which is a long time away but maybe we can initially do this in virtual environments so you can imagine a video game where agents interact in some ways and then some situations trigger an emotion i think we could train machines to detect those situations and predict that the particular emotion will likely be felt if a human was playing one of the characters you have shown excitement and done a lot of excellent work with unsupervised learning but theres been a lot of success on the supervised learning side yes yes and one of the things im really passionate about is how humans and robots work together and in the context of supervised learning that means the process of annotation do you think about the problem of annotation put in a more interesting way as humans teaching machines yes is there yes i think its an important subject reducing it to annotation may be useful for somebody building a system tomorrow but longer term the process of teaching i think is something that deserves a lot more attention from the machine learning community so there are people who have coined the term machine teaching so what are good strategies for teaching a learning agent and can we design and train a system that is going to be a good teacher so in my group we have a project called bbi or bbi game where there is a game or scenario where theres a learning agent and a teaching agent presumably the teaching agent would eventually be a human but were not there yet and the role of the teacher is to use its knowledge of the environment which it can acquire using whatever way brute force to help the learner learn as quickly as possible so the learner is going to try to learn by itself maybe using some exploration and whatever but the teacher can choose can have an influence on the interaction with the learner so as to guide the learner maybe teach it the things that the learner has most trouble with or just add the boundary between what it knows and doesnt know and so on so theres a tradition of these kind of ideas from other fields and like tutorial systems for example and ai and of course people in the humanities have been thinking about these questions but i think its time that machine learning people look at this because in the future well have more and more human machine interaction with the human in the loop and i think understanding how to make this work better all the problems around that are very interesting and not sufficiently addressed youve done a lot of work with language too what aspect of the traditionally formulated turing test a test of natural language understanding and generation in your eyes is the most difficult of conversation what in your eyes is the hardest part of conversation to solve for machines so i would say its everything having to do with the non linguistic knowledge which implicitly you need in order to make sense of sentences things like the winograd schema so these sentences that are semantically ambiguous in other words you need to understand enough about the world in order to really interpret properly those sentences i think these are interesting challenges for machine learning because they point in the direction of building systems that both understand how the world works and this causal relationships in the world and associate that knowledge with how to express it in language either for reading or writing you speak french yes its my mother tongue its one of the romance languages do you think passing the turing test and all the underlying challenges we just mentioned depend on language do you think it might be easier in french than it is in english or is independent of language i think its independent of language i would like to build systems that can use the same principles the same learning mechanisms to learn from human agents whatever their language well certainly us humans can talk more beautifully and smoothly in poetry some russian originally i know poetry in russian is maybe easier to convey complex ideas than it is in english but maybe im showing my bias and some people could say that about french but of course the goal ultimately is our human brain is able to utilize any kind of those languages to use them as tools to convey meaning yeah of course there are differences between languages and maybe some are slightly better at some things but in the grand scheme of things where were trying to understand how the brain works and language and so on i think these differences are minute so youve lived perhaps through an ai winter of sorts yes how did you stay warm and continue your research stay warm with friends with friends okay so its important to have friends and what have you learned from the experience listen to your inner voice dont you know be trying to just please the crowds and the fashion and if you have a strong intuition about something that is not contradicted by actual evidence go for it i mean it could be contradicted by people not your own instinct of based on everything youve learned of course you have to adapt your beliefs when your experiments contradict those beliefs but you have to stick to your beliefs otherwise its what allowed me to go through those years its what allowed me to persist in directions that you know took time whatever other people think took time to mature and bring fruits so history of ai is marked with these of course its marked with technical breakthroughs but its also marked with these seminal events that capture the imagination of the community most recent i would say alphago beating the world champion human go player was one of those moments what do you think the next such moment might be okay so first of all i think that these so called seminal events are overrated as i said science really moves by small steps now what happens is you make one more small step and its like the drop that you know that fills the bucket and then you have drastic consequences because now youre able to do something you were not able to do before or now say the cost of building some device or solving a problem becomes cheaper than what existed and you have a new market that opens up right so especially in the world of commerce and applications the impact of a small scientific progress could be huge but in the science itself i think its very very gradual and where are these steps being taken now so theres unsupervised learning so if i look at one trend that i like in my community so for example at milan my institute what are the two hardest topics gans and reinforcement learning even though in montreal in particular reinforcement learning was something pretty much absent just two or three years ago so theres really a big interest from students and theres a big interest from people like me so i would say this is something where were going to see more progress even though it hasnt yet provided much in terms of actual industrial fallout like even though theres alphago theres no like google is not making money on this right now but i think over the long term this is really really important for many reasons so in other words i would say reinforcement learning may be more generally agent learning because it doesnt have to be with rewards it could be in all kinds of ways that an agent is learning about its environment now reinforcement learning youre excited about do you think gans could provide something at the moment well gans or other generative models i believe will be crucial ingredients in building agents that can understand the world a lot of the successes in reinforcement learning in the past has been with policy gradient where you just learn a policy you dont actually learn a model of the world but there are lots of issues with that and we dont know how to do model based rl right now but i think this is where we have to go in order to build models that can generalize faster and better like to new distributions that capture to some extent at least the underlying causal mechanisms in the world last question what made you fall in love with artificial intelligence if you look back what was the first moment in your life when you were fascinated by either the human mind or the artificial mind you know when i was an adolescent i was reading a lot and then i started reading science fiction there you go thats it thats where i got hooked and then you know i had one of the first personal computers and i got hooked in programming and so it just you know start with fiction and then make it a reality thats right yoshua thank you so much for talking to me my pleasure', 'the following is a conversation with vladimir vapnik hes the co inventor of support vector machines support vector clustering vc theory and many foundational ideas in statistical learning he was born in the soviet union and worked at the institute of control sciences in moscow then in the united states he worked at att nec labs facebook research and now is a professor at columbia university his work has been cited over 170000 times he has some very interesting ideas about artificial intelligence and the nature of learning especially on the limits of our current approaches and the open problems in the field this conversation is part of mit course on artificial general intelligence and the artificial intelligence podcast if you enjoy it please subscribe on youtube or rate it on itunes or your podcast provider of choice or simply connect with me on twitter or other social networks at lex friedman spelled f r i d and now heres my conversation with vladimir vapnik einstein famously said that god doesnt play dice yeah you have studied the world through the eyes of statistics so let me ask you in terms of the nature of reality fundamental nature of reality does god play dice we dont know some factors and because we dont know some factors which could be important it looks like god plays dice but we should describe it in philosophy they distinguish between two positions positions of instrumentalism where youre creating theory for prediction and position of realism where youre trying to understand what god did can you describe instrumentalism and realism a little bit for example if you have some mechanical laws what is that is it law which is true always and everywhere or it is law which allow you to predict position of moving element what you believe you believe that it is gods law that god created the world which obey to this physical law or it is just law for predictions and which one is instrumentalism for predictions if you believe that this is law of god and its always true everywhere that means that youre realist so youre trying to really understand gods thought so the way you see the world is as an instrumentalist you know im working for some models model of machine learning so in this model we can see setting and we try to solve resolve the setting to solve the problem and you can do in two different way from the point of view of instrumentalist and thats what everybody does now because they say that goal of machine learning is to find the rule for classification that is true but it is instrument for prediction but i can say the goal of machine learning is to learn about conditional probability so how god played use and if he play what is probability for one what is probability for another given situation but for prediction i dont need this i need the rule but for understanding i need conditional probability so let me just step back a little bit first to talk about you mentioned which i read last night the parts of the 1960 paper by eugene wigner unreasonable effectiveness of mathematics and natural sciences such a beautiful paper by the way made me feel to be honest to confess my own work in the past few years on deep learning heavily applied made me feel that i was missing out on some of the beauty of nature in the way that math can uncover so let me just step away from the poetry of that for a second how do you see the role of math in your life is it a tool is it poetry where does it sit and does math for you have limits of what it can describe some people say that math is language which use god use god so i believe that speak to god or use god or use god use god yeah so i believe that this article about effectiveness unreasonable effectiveness of math is that if youre looking at mathematical structures they know something about reality and the most scientists from natural science theyre looking on equation and trying to understand reality so the same in machine learning if you try very carefully look on all equations which define conditional probability you can understand something about reality more than from your fantasy so math can reveal the simple underlying principles of reality perhaps you know what means simple it is very hard to discover them but then when you discover them and look at them you see how beautiful they are and it is surprising why people did not see that before youre looking on equation and derive it from equations for example i talked yesterday about least square method and people had a lot of fantasy how to improve least square method but if youre going step by step by solving some equations you suddenly will get some term which after thinking you understand that it describes position of observation point in least square method we throw out a lot of information we dont look in composition of point of observations were looking only on residuals but when you understood that thats very simple idea but its not too simple to understand and you can derive this just from equations so some simple algebra a few steps will take you to something surprising that when you think about you understand and that is proof that human intuition is not too rich and very primitive and it does not see very simple situations so let me take a step back in general yes but what about human as opposed to intuition ingenuity moments of brilliance do you have to be so hard on human intuition are there moments of brilliance in human intuition they can leap ahead of math and then the math will catch up i dont think so i think that the best human intuition it is putting in axioms and then it is technical see where the axioms take you but if they correctly take axioms but it axiom polished during generations of scientists and this is integral wisdom that is beautifully put but if you maybe look at when you think of einstein and special relativity what is the role of imagination coming first there in the moment of discovery of an idea so there is obviously a mix of math and out of the box imagination there that i dont know whatever i did i exclude any imagination because whatever i saw in machine learning that comes from imagination like features like deep learning they are not relevant to the problem when you are looking very carefully from mathematical equations you are deriving very simple theory which goes far beyond theoretically than whatever people can imagine because it is not good fantasy it is just interpretation it is just fantasy but it is not what you need you dont need any imagination to derive the main principle of machine learning when you think about learning and intelligence maybe thinking about the human brain and trying to describe mathematically the process of learning that is something like what happens in the human brain do you think we have the tools currently do you think we will ever have the tools to try to describe that process of learning it is not description what is going on it is interpretation it is your interpretation your vision can be wrong you know one guy invented microscope levenhuk for the first time only he got this instrument and he kept secret about microscope but he wrote a report in london academy of science in his report when he was looking at the blood he looked everywhere on the water on the blood on the sperm but he described blood like fight between queen and king so he saw blood cells red cells and he imagined that it is army fighting each other and it was his interpretation of situation and he sent this report in academy of science they very carefully looked because they believed that he is right he saw something yes but he gave wrong interpretation and i believe the same can happen with brain with brain yeah the most important part you know i believe in human language in some proverbs there is so much wisdom for example people say that it is better than thousand days of diligent studies one day with great teacher but if i will ask you what teacher does nobody knows and that is intelligence but we know from history and now from math and machine learning that teacher can do a lot so what from a mathematical point of view is the great teacher i dont know thats an open question no but we can say what teacher can do he can introduce some invariants some predicate for creating invariants how he doing it i dont know because teacher knows reality and can describe from this reality a predicate invariants but he knows that when youre using invariant you can decrease number of observations hundred times so but maybe try to pull that apart a little bit i think you mentioned like a piano teacher saying to the student play like a butterfly yeah i play piano i play guitar for a long time yeah maybe its romantic poetic but it feels like theres a lot of truth in that statement like there is a lot of instruction in that statement and so can you pull that apart what is that the language itself may not contain this information it is not blah blah blah it is not blah blah blah it affects you its what it affects you it affects your playing yes it does but its not the laying it feels like what is the information being exchanged there what is the nature of information what is the representation of that information i believe that it is sort of predicate but i dont know that is exactly what intelligence and machine learning should be yes because the rest is just mathematical technique i think that what was discovered recently is that there is two mechanism of learning one called strong convergence mechanism and weak convergence mechanism before people use only one convergence in weak convergence mechanism you can use predicate thats what play like butterfly and it will immediately affect your playing you know there is english proverb great if it looks like a duck swims like a duck and quack like a duck then it is probably duck yes but this is exact about predicate looks like a duck what it means you saw many ducks that youre training data so you have description of how looks integral looks ducks yeah the visual characteristics of a duck yeah but you want and you have model for recognition so you would like so that theoretical description from model coincide with empirical description which you saw on territory so about looks like a duck it is general but what about swims like a duck you should know that duck swims you can say it play chess like a duck okay duck doesnt play chess and it is completely legal predicate but it is useless so half teacher can recognize not useless predicate so up to now we dont use this predicate in existing machine learning so why we need zillions of data but in this english proverb they use only three predicate looks like a duck swims like a duck and quack like a duck so you cant deny the fact that swims like a duck and quacks like a duck has humor in it has ambiguity lets talk about swim like a duck it doesnt say jump like a duck why because its not relevant but that means that you know ducks you know different birds you know animals and you derive from this that it is relevant to say swim like a duck so underneath in order for us to understand swims like a duck it feels like we need to know millions of other little pieces of information which we pick up along the way you dont think so there doesnt need to be this knowledge base in those statements carries some rich information that helps us understand the essence of duck yeah how far are we from integrating predicates you know that when you consider complete theory of machine learning so what it does you have a lot of functions and then youre talking it looks like a duck you see your training data from training data you recognize like expected duck should look then you remove all functions which does not look like you think it should look from training data so you decrease amount of function from which you pick up one then you give a second predicate and again decrease the set of function and after that you pick up the best function you can find it is standard machine learning so why you need not too many examples because your predicates arent very good that means that predicates are very good because every predicate is invented to decrease admissible set of function so you talk about admissible set of functions and you talk about good functions so what makes a good function so admissible set of function is set of function which has small capacity or small diversity small vc dimension example which contain good function inside so by the way for people who dont know vc youre the v in the vc so how would you describe to lay person what vc theory is how would you describe vc so when you have a machine so machine capable to pick up one function from the admissible set of function but set of admissible function can be big so it contain all continuous functions and its useless you dont have so many examples to pick up function but it can be small small we call it capacity but maybe better called diversity so not very different function in the set its infinite set of function but not very diverse so it is small vc dimension when vc dimension is small you need small amount of training data so the goal is to create admissible set of functions which is have small vc dimension and contain good function then you will be able to pick up the function using small amount of observations so that is the task of learning yeah is creating a set of admissible functions that has a small vc dimension and then youve figure out a clever way of picking up no that is goal of learning which i formulated yesterday statistical learning theory does not involve in creating admissible set of function in classical learning theory everywhere 100 in textbook the set of function admissible set of function is given but this is science about nothing because the most difficult problem to create admissible set of functions given say a lot of functions continuum set of function create admissible set of functions that means that it has finite vc dimension small vc dimension and contain good function so this was out of consideration so whats the process of doing that i mean its fascinating what is the process of creating this admissible set of functions that is invariant thats invariant yeah youre looking of properties of training data and properties means that you have some function and you just count what is value average value of function on training data you have model and what is expectation of this function on the model and they should coincide so the problem is about how to pick up functions it can be any function in fact it is true for all functions but because when were talking say duck does not jumping so you dont ask question jump like a duck because it is trivial it does not jumping and doesnt help you to recognize jump but you know something which question to ask and youre asking it seems like a duck but looks like a duck at this general situation looks like say guy who have this illness this disease it is legal so there is a general type of predicate looks like and special type of predicate which related to this specific problem and that is intelligence part of all this business and that where teacher is involved incorporating the specialized predicates what do you think about deep learning as neural networks these arbitrary architectures as helping accomplish some of the tasks youre thinking about their effectiveness or lack thereof what are the weaknesses and what are the possible strengths you know i think that this is fantasy everything which like deep learning like features let me give you this example one of the greatest books is churchill book about history of second world war and he started this book describing that in old time when war is over so the great kings they gathered together almost all of them were relatives and they discussed what should be done how to create peace and they came to agreement and when happened first world war the general public came in power and they were so greedy that robbed germany and it was clear for everybody that it is not peace that peace will last only 20 years because they were not professionals and the same i see in machine learning there are mathematicians who are looking for the problem from a very deep point of view mathematical point of view and there are computer scientists who mostly does not know mathematics they just have interpretation of that and they invented a lot of blah blah blah interpretations like deep learning why you need deep learning mathematic does not know deep learning mathematic does not know neurons it is just function if you like to say piecewise linear function say that and do in class of piecewise linear function but they invent something and then they try to prove advantage of that through interpretations which mostly wrong and when its not enough they appeal to brain which they know nothing about that nobody knows whats going on in the brain so i think that more reliable work on math this is a mathematical problem do your best to solve this problem try to understand that there is not only one way of convergence which is strong way of convergence there is a weak way of convergence which requires predicate and if you will go through all this stuff you will see that you dont need deep learning even more i would say one of the theory which called represented theory it says that optimal solution of mathematical problem which is described learning is on shadow network not on deep learning and a shallow network yeah the ultimate problem is there absolutely in the end what youre saying is exactly right the question is you have no value for throwing something on the table playing with it not math its like a neural network where you said throwing something in the bucket or the biological example and looking at kings and queens or the cells or the microscope you dont see value in imagining the cells or kings and queens and using that as inspiration and imagination for where the math will eventually lead you you think that interpretation basically deceives you in a way thats not productive i think that if youre trying to analyze this business of learning and especially discussion about deep learning it is discussion about interpretation not about things about what you can say about things thats right but arent you surprised by the beauty of it so not mathematical beauty but the fact that it works at all or are you criticizing that very beauty our human desire to interpret to find our silly interpretations in these constructs let me ask you this are you surprised and does it inspire you how do you feel about the success of a system like alphago at beating the game of go using neural networks to estimate the quality of a board and the quality of the position that is your interpretation quality of the board yeah yes yeah so its not our interpretation the fact is a neural network system it doesnt matter a learning system that we dont i think mathematically understand that well beats the best human player does something that was thought impossible that means that its not a very difficult problem so you empirically weve empirically have discovered that this is not a very difficult problem yeah its true so maybe cant argue so even more i would say that if they use deep learning it is not the most effective way of learning theory and usually when people use deep learning theyre using zillions of training data yeah but you dont need this so i describe challenge can we do some problems which do well deep learning method this deep net using hundred times less training data even more some problems deep learning cannot solve because its not necessary they create admissible set of function to create deep architecture means to create admissible set of functions you cannot say that youre creating good admissible set of functions you just its your fantasy it does not come from us but it is possible to create admissible set of functions because you have your training data that actually for mathematicians when you consider a variant you need to use law of large numbers when youre making training in existing algorithm you need uniform law of large numbers which is much more difficult it requires vc dimension and all this stuff but nevertheless if you use both weak and strong way of convergence you can decrease a lot of training data you could do the three the swims like a duck and quacks like a duck so lets step back and think about human intelligence in general clearly that has evolved in a non mathematical way it wasnt as far as we know god or whoever didnt come up with a model and place in our brain of admissible functions it kind of evolved i dont know maybe you have a view on this so alan turing in the 50s in his paper asked and rejected the question can machines think its not a very useful question but can you briefly entertain this useful useless question can machines think so talk about intelligence and your view of it i dont know that i know that turing described imitation if computer can imitate human being lets call it intelligent and he understands that it is not thinking computer he completely understands what hes doing but he set up problem of imitation so now we understand that the problem is not in imitation im not sure that intelligence is just inside of us it may be also outside of us i have several observations so when i prove some theorem its very difficult theorem in couple of years in several places people prove the same theorem say sawyer lemma after us was done then another guys proved the same theorem in the history of science its happened all the time for example geometry its happened simultaneously first it did lobachevsky and then gauss and boyai and another guys and its approximately in 10 times period 10 years period of time and i saw a lot of examples like that and many mathematicians think that when they develop something they develop something in general which affect everybody so maybe our model that intelligence is only inside of us is incorrect its our interpretation it might be there exists some connection with world intelligence i dont know youre almost like plugging in into yeah exactly and contributing to this into a big network into a big maybe in your own network on the flip side of that maybe you can comment on big o complexity and how you see classifying algorithms by worst case running time in relation to their input so that way of thinking about functions do you think p equals np do you think thats an interesting question yeah it is an interesting question but let me talk about complexity in about worst case scenario there is a mathematical setting when i came to united states in 1990 people did not know they did not know statistical learning theory so in russia it was published to monographs our monographs but in america they didnt know then they learned and somebody told me that it is worst case theory and they will create real case theory but till now it did not because it is mathematical too you can do only what you can do using mathematics and which has a clear understanding and clear description and for this reason we introduce complexity and we need this because using actually it is diversity i like this one more you see the mention you can prove some theorems but we also create theory for case when you know probability measure and that is the best case which can happen it is entropy theory so from mathematical point of view you know the best possible case and the worst possible case you can derive different model in medium but its not so interesting you think the edges are interesting the edges are interesting because it is not so easy to get good bound exact bound its not many cases where you have the bound is not exact but interesting principles which discover the mass do you think its interesting because its challenging and reveals interesting principles that allow you to get those bounds or do you think its interesting because its actually very useful for understanding the essence of a function of an algorithm so its like me judging your life as a human being by the worst thing you did and the best thing you did versus all the stuff in the middle it seems not productive i dont think so because you cannot describe situation in the middle so it will be not general so you can describe edges cases and it is clear it has some model but you cannot describe model for every new case so you will be never accurate when youre using model but from a statistical point of view the way youve studied functions and the nature of learning in the world dont you think that the real world has a very long tail that the edge cases are very far away from the mean the stuff in the middle or no i dont know that i think that from my point of view if you will use formal statistic you need uniform law of large numbers if you will use this invariance business you will need just law of large numbers and theres this huge difference between uniform law of large numbers and large numbers is it useful to describe that a little more or should we just take it to for example when im talking about duck i give three predicates and that was enough but if you will try to do formal distinguish you will need a lot of observations so that means that information about looks like a duck contain a lot of bit of information formal bits of information so we dont know that how much bit of information contain things from artificial and from intelligence and that is the subject of analysis till now all business i dont like how people consider artificial intelligence they consider us some codes which imitate activity of human being it is not science it is applications you would like to imitate go ahead it is very useful and a good problem but you need to learn something more how people try to do how people can to develop say predicates seems like a duck or play like butterfly or something like that not the teacher says you how it came in his mind how he choose this image so that process that is problem of intelligence that is the problem of intelligence and you see that connected to the problem of learning absolutely because you immediately give this predicate like specific predicate seems like a duck or quack like a duck it was chosen somehow so what is the line of work would you say if you were to formulate as a set of open problems that will take us there to play like a butterfly well get a system to be able to lets separate two stories one mathematical story that if you have predicate you can do something and another story how to get predicate it is intelligence problem and people even did not start to understand intelligence because to understand intelligence first of all try to understand what do teachers how teacher teach why one teacher better than another one yeah and so you think we really even havent started on the journey of generating the predicates no we dont understand we even dont understand that this problem exists because did you hear you do no i just know name i want to understand why one teacher better than another and how affect teacher student it is not because he repeating the problem which is in textbook he makes some remarks he makes some philosophy of reasoning yeah thats a beautiful so it is a formulation of a question that is the open problem why is one teacher better than another right what he does better yeah what what why in at every level how do they get better what does it mean to be better the whole yeah yeah from whatever model i have one teacher can give a very good predicate one teacher can say swims like a dog and another can say jump like a dog and jump like a dog carries zero information so what is the most exciting problem in statistical learning youve ever worked on or are working on now i just finished this invariant story and im happy that i believe that it is ultimate learning story at least i can show that there are no another mechanism only two mechanisms but they separate statistical part from intelligent part and i know nothing about intelligent part and if you will know this intelligent part so it will help us a lot in teaching in learning in learning yeah you will know it when we see it so for example in my talk the last slide was a challenge so you have say nist digit recognition problem and deep learning claims that they did it very well say 995 of correct answers but they use 60000 observations can you do the same using hundred times less but incorporating invariants what it means you know digit one two three but looking on that explain to me which invariant i should keep to use hundred examples or say hundred times less examples to do the same job yeah that last slide unfortunately your talk ended quickly but that last slide was a powerful open challenge and a formulation of the essence here what is the exact problem of intelligence because everybody when machine learning started and it was developed by mathematicians they immediately recognized that we use much more training data than humans needed but now again we came to the same story have to decrease that is the problem of learning it is not like in deep learning they use zillions of training data because maybe zillions are not enough if you have a good invariants maybe you will never collect some number of observations but now it is a question to intelligence how to do that because statistical part is ready as soon as you supply us with predicate we can do good job with small amount of observations and the very first challenge is well known digit recognition and you know digits and please tell me invariants i think about that i can say for digit three i would introduce concept of horizontal symmetry so the digit three has horizontal symmetry say more than say digit two or something like that but as soon as i get the idea of horizontal symmetry i can mathematically invent a lot of measure of horizontal symmetry or then vertical symmetry or diagonal symmetry whatever if i have idea of symmetry but what else i think on digit i see that it is meta predicate which is not shape it is something like symmetry like how dark is whole picture something like that which can self rise a predicate you think such a predicate could rise out of something that is not general meaning it feels like for me to be able to understand the difference between two and three i would need to have had a childhood of 10 to 15 years playing with kids going to school being yelled by parents all of that walking jumping looking at ducks and then i would be able to generate the right predicate for telling the difference between two and a three or do you think theres a more efficient way i dont know i know for sure that you must know something more than digits yes and thats a powerful statement yeah but maybe there are several languages of description these elements of digits so im talking about symmetry about some properties of geometry im talking about something abstract i dont know that but this is a problem of intelligence so in one of our articles it is trivial to show that every example can carry not more than one bit of information in real because when you show example and you say this is one you can remove say a function which does not tell you one say is the best strategy if you can do it perfectly its remove half of the functions but when you use one predicate which looks like a duck you can remove much more functions than half and that means that it contains a lot of bit of information from formal point of view but when you have a general picture of what you want to recognize and general picture of the world can you invent this predicate and that predicate carries a lot of information beautifully put maybe just me but in all the math you show in your work which is some of the most profound mathematical work in the field of learning ai and just math in general i hear a lot of poetry and philosophy you really kind of talk about philosophy of science theres a poetry and music to a lot of the work youre doing and the way youre thinking about it so do you where does that come from do you escape to poetry do you escape to music or not i think that there exists ground truth there exists ground truth yeah and that can be seen everywhere the smart guy philosopher sometimes im surprised how they deep see sometimes i see that some of them are completely out of subject but the ground truth i see in music music is the ground truth yeah and in poetry many poets they believe they take dictation so what piece of music as a piece of empirical evidence gave you a sense that they are touching something in the ground truth it is structure the structure of the math of music yeah because when youre listening to bach you see the structure very clear very classic very simple and the same in math when you have axioms in geometry you have the same feeling and in poetry sometimes you see the same and if you look back at your childhood you grew up in russia you maybe were born as a researcher in russia youve developed as a researcher in russia youve came to united states and a few places if you look back what was some of your happiest moments as a researcher some of the most profound moments not in terms of their impact on society but in terms of their impact on how damn good you feel that day and you remember that moment you know every time when you found something it is great in the life every simple things but my general feeling is that most of my time was wrong you should go again and again and again and try to be honest in front of yourself not to make interpretation but try to understand that its related to ground truth it is not my blah blah blah interpretation and something like that but youre allowed to get excited at the possibility of discovery oh yeah you have to double check it no but how its related to another ground truth is it just temporary or it is for forever you know you always have a feeling when you found something how big is that so 20 years ago when we discovered statistical learning theory nobody believed except for one guy dudley from mit and then in 20 years it became fashion and the same with support vector machines that is kernel machines so with support vector machines and learning theory when you were working on it you had a sense you had a sense of the profundity of it how this seems to be right this seems to be powerful right absolutely immediately i recognized that it will last forever and now when i found this invariant story i have a feeling that it is complete learning because i have proof that there are no different mechanisms you can have some cosmetic improvement you can do but in terms of invariants you need both invariants and statistical learning and they should work together but also im happy that we can formulate what is intelligence from that and to separate from technical part and that is completely different absolutely well vladimir thank you so much for talking today thank you its an honor', 'the following is a conversation with guido van rossum creator of python one of the most popular programming languages in the world used in almost any application that involves computers from web back end development to psychology neuroscience computer vision robotics deep learning natural language processing and almost any subfield of ai this conversation is part of mit course on artificial general intelligence and the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or your podcast provider of choice or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with guido van rossum you were born in the netherlands in 1956 your parents and the world around you was deeply deeply impacted by world war two as was my family from the soviet union so with that context what is your view of human nature are some humans inherently good and some inherently evil or do we all have both good and evil within us guido van rossum ouch i did not expect such a deep one i i guess we all have good and evil potential in us and a lot of it depends on circumstances and context peter bell out of that world at least on the soviet union side in europe sort of out of suffering out of challenge out of that kind of set of traumatic events often emerges beautiful art music literature in an interview i read or heard you said you enjoyed dutch literature when you were a child can you tell me about the books that had an influence on you in your childhood guido van rossum well with as a teenager my favorite writer was my favorite dutch author was a guy named willem frederik hermans whos writing certainly his early novels were all about sort of ambiguous things that happened during world war two i think he was a young adult during that time and he wrote about it a lot and very interesting very good books i thought i think peter bell in a nonfiction way guido van rossum no it was all fiction but it was very much set in the ambiguous world of resistance against the germans where often you couldnt tell whether someone was truly in the resistance or really a spy for the germans and some of the characters in his novels sort of crossed that line and you never really find out what exactly happened peter bell and in his novels theres always a good guy and a bad guy the nature of good and evil is it clear theres a hero guido van rossum no his heroes are often more his main characters are often anti heroes and so theyre not very heroic theyre often they fail at some level to accomplish their lofty goals peter bell and looking at the trajectory through the rest of your life has literature dutch or english or translation had an impact outside the technical world that you existed in guido van rossum i still read novels i dont think that it impacts me that much directly peter bell it doesnt impact your work guido van rossum its a separate world my work is highly technical and sort of the world of art and literature doesnt really directly have any bearing on it peter bell you dont think theres a creative element to the design you know some would say design of a language is art guido van rossum im not disagreeing with that im just saying that sort of i dont feel direct influences from more traditional art on my own creativity peter bell right of course you dont feel doesnt mean its not somehow deeply there in your subconscious guido van rossum who knows peter bell who knows so lets go back to your early teens your hobbies were building electronic circuits building mechanical models what if you can just put yourself back in the mind of that young guido 12 13 14 was that grounded in a desire to create a system so to create something or was it more just tinkering just the joy of puzzle solving guido van rossum i think it was more the latter actually i maybe towards the end of my high school period i felt confident enough that that i designed my own circuits that were sort of interesting somewhat but a lot of that time i literally just took a model kit and follow the instructions putting the things together i mean i think the first few years that i built electronics kits i really did not have enough understanding of sort of electronics to really understand what i was doing i mean i could debug it and i could sort of follow the instructions very carefully which has always stayed with me but i had a very naive model of like how do i build a circuit of like how a transistor works and i dont think that in those days i had any understanding of coils and capacitors which actually sort of was a major problem when i started to build more complex digital circuits because i was unaware of the sort of the analog part of the – how they actually work and i would have things that – the schematic looked – everything looked fine and it didnt work and what i didnt realize was that there was some megahertz level oscillation that was throwing the circuit off because i had a sort of – two wires were too close or the switches were kind of poorly built but through that time i think its really interesting and instructive to think about because echoes of it are in this time now so in the 1970s the personal computer was being born so did you sense in tinkering with these circuits did you sense the encroaching revolution in personal computing so if at that point we would sit you down and ask you to predict the 80s and the 90s do you think you would be able to do so successfully to unroll the process thats happening no i had no clue i remember i think in the summer after my senior year – or maybe it was the summer after my junior year – well at some point i think when i was 18 i went on a trip to the math olympiad in eastern europe and there was like – i was part of the dutch team and there were other nerdy kids that sort of had different experiences and one of them told me about this amazing thing called a computer and i had never heard that word my own explorations in electronics were sort of about very simple digital circuits and i had sort of – i had the idea that i somewhat understood how a digital calculator worked and so there is maybe some echoes of computers there but i never made that connection i didnt know that when my parents were paying for magazine subscriptions using punched cards that there was something called a computer that was involved that read those cards and transferred the money between accounts i was also not really interested in those things it was only when i went to university to study math that i found out that they had a computer and students were allowed to use it and there were some – youre supposed to talk to that computer by programming it what did that feel like finding – yeah that was the only thing you could do with it the computer wasnt really connected to the real world the only thing you could do was sort of – you typed your program on a bunch of punched cards you gave the punched cards to the operator and an hour later the operator gave you back your printout and so all you could do was write a program that did something very abstract and i dont even remember what my first forays into programming were but they were sort of doing simple math exercises and just to learn how a programming language worked did you sense okay first year of college you see this computer youre able to have a program and it generates some output did you start seeing the possibility of this or was it a continuation of the tinkering with circuits did you start to imagine that one the personal computer but did you see it as something that is a tool like a word processing tool maybe for gaming or something or did you start to imagine that it could be going to the world of robotics like the frankenstein picture that you could create an artificial being theres like another entity in front of you you did not see the computer i dont think i really saw it that way i was really more interested in the tinkering its maybe not a sort of a complete coincidence that i ended up sort of creating a programming language which is a tool for other programmers ive always been very focused on the sort of activity of programming itself and not so much what happens with the program you write right i do remember and i dont remember maybe in my second or third year probably my second actually someone pointed out to me that there was this thing called conways game of life youre probably familiar with it i think – in the 70s i think is when they came up with it so there was a scientific american column by someone who did a monthly column about mathematical diversions im also blanking out on the guys name it was very famous at the time and i think up to the 90s or so and one of his columns was about conways game of life and he had some illustrations and he wrote down all the rules and sort of there was the suggestion that this was philosophically interesting that that was why conway had called it that and all i had was like the two pages photocopy of that article i dont even remember where i got it but it spoke to me and i remember implementing a version of that game for the batch computer we were using where i had a whole pascal program that sort of read an initial situation from input and read some numbers that said do so many generations and print every so many generations and then out would come pages and pages of sort of things i remember much later ive done a similar thing using python but that original version i wrote at the time i found interesting because i combined it with some trick i had learned during my electronics hobbyist times i essentially first on paper i designed a simple circuit built out of logic gates that took nine bits of input which is sort of the cell and its neighbors and produced a new value for that cell and its like a combination of a half adder and some other clipping its actually a full adder and so i had worked that out and then i translated that into a series of boolean operations on pascal integers where you could use the integers as bitwise values and so i could basically generate 60 bits of a generation in like eight instructions or so nice so i was proud of that its funny that you mentioned so for people who dont know conways game of life its a cellular automata where theres single compute units that kind of look at their neighbors and figure out what they look like in the next generation based on the state of their neighbors and this is deeply distributed system in concept at least and then theres simple rules that all of them follow and somehow out of this simple rule when you step back and look at what occurs its beautiful theres an emergent complexity even though the underlying rules are simple theres an emergent complexity now the funny thing is youve implemented this and the thing youre commenting on is youre proud of a hack you did to make it run efficiently when youre not commenting on its a beautiful implementation youre not commenting on the fact that theres an emergent complexity that youve coded a simple program and when you step back and you print out the following generation after generation thats stuff that you may have not predicted would happen is happening and is that magic i mean thats the magic that all of us feel when we program when you create a program and then you run it and whether its hello world or it shows something on screen if theres a graphical component are you seeing the magic in the mechanism of creating that i think i went back and forth as a student we had an incredibly small budget of computer time that we could use it was actually measured i once got in trouble with one of my professors because i had overspent the departments budget its a different story i actually wanted the efficient implementation because i also wanted to explore what would happen with a larger number of generations and a larger size of the board once the implementation was flawless i would feed it different patterns and then i think maybe there was a follow up article where there were patterns that were like gliders patterns that repeated themselves after a number of generations but translated one or two positions to the right or up or something like that i remember things like glider guns well you can google conways game of life people still go aww and ooh over it for a reason because its not really well understood why i mean this is what stephen wolfram is obsessed about we dont have the mathematical tools to describe the kind of complexity that emerges in these kinds of systems the only way you can do is to run it im not convinced that its sort of a problem that lends itself to classic mathematical analysis one theory of how you create an artificial intelligence or artificial being is you kind of have to same with the game of life you kind of have to create a universe and let it run that creating it from scratch in a design way coding up a python program that creates a fully intelligent system may be quite challenging you might need to create a universe just like the game of life you might have to experiment with a lot of different universes before there is a set of rules that doesnt essentially always just end up repeating itself in a trivial way yeah and stephen wolfram works with these simple rules says that its kind of surprising how quickly you find rules that create interesting things you shouldnt be able to but somehow you do and so maybe our universe is laden with rules that will create interesting things that might not look like humans but emergent phenomena thats interesting may not be as difficult to create as we think sure but let me sort of ask at that time some of the world at least in popular press was kind of captivated perhaps at least in america by the idea of artificial intelligence that these computers would be able to think pretty soon and did that touch you at all in science fiction or in reality in any way i didnt really start reading science fiction until much much later i think as a teenager i read maybe one bundle of science fiction stories was it in the background somewhere like in your thoughts that sort of the using computers to build something intelligent always felt to me because and how did you try to design it into the language there are different tasks and as a programmer its useful to have different tools available that sort of are suitable for different tasks so i still write c code i still write shell code but i write most of my things in python why do i still use those other languages because sometimes the task just demands it and well i would say most of the time the task actually demands a certain language because the task is not write a program that solves problem x from scratch but its more like fix a bug in existing program x or add a small feature to an existing large program but even if youre not constrained in your choice of language by context like that there is still the fact that if you write it in a certain language then you have this balance between how long does it take you to write the code and how long does the code run and when youre in the phase of exploring solutions you often spend much more time writing the code than running it because every time youve run it you see that the output is not quite what you wanted and you spend some more time coding and a language like python just makes that iteration much faster because there are fewer details that you have to get right before your program compiles and runs there are libraries that do all sorts of stuff for you so you can sort of very quickly take a bunch of existing components put them together and get your prototype application running just like when i was building electronics i was using a breadboard most of the time so i had this sprawl out circuit that if you shook it it would stop working because it was not put together very well but it functioned and all i wanted was to see that it worked and then move on to the next schematic or design or add something to it once youve sort of figured out oh this is the perfect design for my radio or light sensor or whatever then you can say okay how do we design a pcb for this how do we solder the components in a small space how do we make it so that it is robust against say voltage fluctuations or mechanical disruption i know nothing about that when it comes to designing electronics but i know a lot about that when it comes to writing code so the initial steps are efficient fast and theres not much stuff that gets in the way but youre kind of describing like darwin described the evolution of species right youre observing of what is true about python now if you take a step back if the act of creating languages is art and you had three months to do it initial steps so you just specified a bunch of goals sort of things that you observe about python perhaps you had those goals but how do you create the rules the syntactic structure the features that result in those so i have in the beginning and i have follow up questions about through the evolution of python too but in the very beginning when you were sitting there creating the lexical analyzer or whatever python was still a big part of it because i sort of i said to myself i dont want to have to design everything from scratch im going to borrow features from other languages that i like oh interesting so you basically exactly you first observe what you like yeah and so thats why if youre 17 years old and you want to sort of create a programming language youre not going to be very successful at it because you have no experience with other languages whereas i was in my lets say mid 30s i had written parsers before so i had worked on the implementation of abc i had spent years debating the design of abc with its authors with its designers i had nothing to do with the design it was designed fully as it ended up being implemented when i joined the team but so you borrow ideas and concepts and very concrete sort of local rules from different languages like the indentation and certain other syntactic features from abc but i chose to borrow string literals and how numbers work from c and various other things so in then if you take that further so yet youve had this funny sounding but i think surprisingly accurate and at least practical title of benevolent dictator for life for quite you know for the last three decades or whatever or no not the actual title but functionally speaking so you had to make decisions design decisions can you maybe lets take python 2 so releasing python 3 as an example its not backward compatible to python 2 in ways that a lot of people know so what was that deliberation discussion decision like yeah what was the psychology of that experience do you regret any aspects of how that experience undergone that well yeah so it was a group process really at that point even though i was bdfl in name and certainly everybody sort of respected my position as the creator and the current sort of owner of the language design i was looking at everyone else for feedback sort of python 30 in some sense was sparked by other people in the community pointing out oh well there are a few issues that sort of bite users over and over can we do something about that and for python 3 we took a number of those python words as they were called at the time and we said can we try to sort of make small changes to the language that address those words and we had sort of in the past we had always taken backwards compatibility very seriously and so many python words in earlier versions had already been resolved because they could be resolved while maintaining backwards compatibility or sort of using a very gradual path of evolution of the language in a certain area and so we were stuck with a number of words that were widely recognized as problems not like roadblocks but nevertheless sort of things that some people trip over and you know that thats always the same thing that people trip over when they trip and we could not think of a backwards compatible way of resolving those issues but its still an option to not resolve the issues right and so yes for a long time we had sort of resigned ourselves to well okay the language is not going to be perfect in this way and that way and that way and we sort of certain of these i mean there are still plenty of things where you can say well that particular detail is better in java or in r or in visual basic or whatever and were okay with that because well we cant easily change it its not too bad we can do a little bit with user education or we can have a static analyzer or warnings in the parse or something but there were things where we thought well these are really problems that are not going away they are getting worse in the future we should do something about that but ultimately there is a decision to be made right so was that the toughest decision in the history of python you had to make as the benevolent dictator for life or if not what are there maybe even on the smaller scale what was the decision where you were really torn up about well the toughest decision was probably to resign all right lets go there hold on a second then let me just because in the interest of time too because i have a few cool questions for you and lets touch a really important one because it was quite dramatic and beautiful in certain kinds of ways in july this year three months ago you wrote now that pep 572 is done i dont ever want to have to fight so hard for a pep and find that so many people despise my decisions i would like to remove myself entirely from the decision process ill still be there for a while as an ordinary core developer and ill still be available to mentor people possibly more available but im basically giving myself a permanent vacation from being bdfl benevolent dictator for life and you all will be on your own first of all its almost shakespearean im not going to appoint a successor so what are you all going to do create a democracy anarchy a dictatorship a federation so that was a very dramatic and beautiful set of statements its almost its open ended nature called the community to create a future for python its just kind of a beautiful aspect to it so what and dramatic you know what was making that decision like what was on your heart on your mind stepping back now a few months later im glad you liked the writing because it was actually written pretty quickly it was literally something like after months and months of going around in circles i had finally approved pep572 which i had a big hand in its design although i didnt initiate it originally i sort of gave it a bunch of nudges in a direction that would be better for the language so sorry just to ask is async io thats the one or no pep572 was actually a small feature which is assignment expressions that had been there was just a lot of debate where a lot of people claimed that they knew what was pythonic and what was not pythonic and they knew that this was going to destroy the language this was like a violation of pythons most fundamental design philosophy and i thought that was all bullshit because i was in favor of it and i would think i know something about pythons design philosophy so i was really tired and also stressed of that thing and literally after sort of announcing i was going to accept it a certain wednesday evening i had finally sent the email its accepted i can just go implement it so i went to bed feeling really relieved thats behind me and i wake up thursday morning 7 am and i think well that was the last one thats going to be such a terrible debate and thats the last time that i let myself be so stressed out about a pep decision i should just resign ive been sort of thinking about retirement for half a decade ive been joking and sort of mentioning retirement sort of telling the community at some point in the future im going to retire dont take that fl part of my title too literally and i thought okay this is it im done i had the day off i wanted to have a good time with my wife we were going to a little beach town nearby and in i think maybe 15 20 minutes i wrote that thing that you just called shakespearean the funny thing is i didnt even realize what a monumental decision it was because five minutes later i read that link to my message back on twitter where people were already discussing on twitter guido resigned as the bdfl and i had posted it on an internal forum that i thought was only read by core developers so i thought i would at least have one day before the news would sort of get out the on your own aspects had also an element of quite it was quite a powerful element of the uncertainty that lies ahead but can you also just briefly talk about for example i play guitar as a hobby for fun and whenever i play people are super positive super friendly theyre like this is awesome this is great but sometimes i enter as an outside observer i enter the programming community and there seems to sometimes be camps on whatever the topic and the two camps the two or plus camps are often pretty harsh at criticizing the opposing camps as an onlooker i may be totally wrong on this but what do you think of this yeah holy wars are sort of a favorite activity in the programming community and what is the psychology behind that is that okay for a healthy community to have is that a productive force ultimately for the evolution of a language well if everybody is patting each other on the back and never telling the truth it would not be a good thing i think there is a middle ground where sort of being nasty to each other is not okay but there is a middle ground where there is healthy ongoing criticism and feedback that is very productive and you mean at every level you see that i mean someone proposes to fix a very small issue in a code base chances are that some reviewer will sort of respond by saying well actually you can do it better the other way when it comes to deciding on the future of the python core developer community we now have i think five or six competing proposals for a constitution so that future do you have a fear of that future do you have a hope for that future im very confident about that future by and large i think that the debate has been very healthy and productive and i actually when i wrote that resignation email i knew that python was in a very good spot and that the python core developer community the group of 50 or 100 people who sort of write or review most of the code that goes into python those people get along very well most of the time a large number of different areas of expertise are represented different levels of experience in the python core dev community different levels of experience completely outside it in software development in general large systems small systems embedded systems so i felt okay resigning because i knew that the community can really take care of itself and out of a grab bag of future feature developments let me ask if you can comment maybe on all very quickly concurrent programming parallel computing async io these are things that people have expressed hope complained about whatever have discussed on reddit async io so the parallelization in general packaging i was totally clueless on this i just used pip to install stuff but apparently theres pipenv poetry theres these dependency packaging systems that manage dependencies and so on theyre emerging and theres a lot of confusion about whats the right thing to use then also functional programming are we going to get more functional programming or not this kind of idea and of course the gil connected to the parallelization i suppose the global interpreter lock problem can you just comment on whichever you want to comment on well lets take the gil and parallelization and async io as one topic im not that hopeful that python will develop into a sort of high concurrency high parallelism language thats sort of the way the language is designed the way most users use the language the way the language is implemented all make that a pretty unlikely future so you think it might not even need to really the way people use it it might not be something that should be of great concern i think async io is a special case because it sort of allows overlapping io and only io and that is a sort of best practice of supporting very high throughput io many connections per second im not worried about that i think async io will evolve there are a couple of competing packages we have some very smart people who are sort of pushing us to make async io better parallel computing i think that python is not the language for that there are ways to work around it but you cant expect to write an algorithm in python and have a compiler automatically parallelize that what you can do is use a package like numpy and there are a bunch of other very powerful packages that sort of use all the cpus available because you tell the package heres the data heres the abstract operation to apply over it go at it and then were back in the c world those packages are themselves implemented usually in c thats where tensorflow and all these packages come in where they parallelize across gpus for example they take care of that for you in terms of packaging can you comment on the future of packaging in python packaging has always been my least favorite topic its a really tough problem because the os and the platform want to own packaging but their packaging solution is not specific to a language if you take linux there are two competing packaging solutions for linux or for unix in general but they all work across all languages several languages like node javascript ruby and python all have their own packaging solutions that only work within the ecosystem of that language what should you use that is a tough problem my own approach is i use the system packaging system to install python and i use the python packaging system then to install third party python packages thats what most people do ten years ago python packaging was really a terrible situation nowadays pip is the future there is a separate ecosystem for numerical and scientific python based on anaconda those two can live together i dont think there is a need for more than that thats packaging well at least for me thats where ive been extremely happy i didnt even know this was an issue until it was brought up in the interest of time let me sort of skip through a million other questions i have so i watched the five and a half hour oral history that youve done with the computer history museum and the nice thing about it it gave this because of the linear progression of the interview it gave this feeling of a life you know a life well lived with interesting things in it sort of a pretty i would say a good spend of this little existence we have on earth so outside of your family looking back what about this journey are you really proud of are there moments that stand out accomplishments ideas is it the creation of python itself that stands out as a thing that you look back and say damn i did pretty good there well i would say that python is definitely the best thing ive ever done and i wouldnt sort of say just the creation of python but the way i sort of raised python like a baby i didnt just conceive a child but i raised a child and now im setting the child free in the world and ive set up the child to sort of be able to take care of himself and im very proud of that and as the announcer of monty pythons flying circus used to say and now for something completely different do you have a favorite monty python moment or a moment in hitchhikers guide or any other literature show or movie that cracks you up when you think about it you can always play me the dead parrot sketch oh thats brilliant thats my favorite as well its pushing up the daisies okay greta thank you so much for talking with me today lex this has been a great conversation i felt i had so much understanding of what actually goes on inside a computer i knew how many bits of memory it had and how difficult it was to program and sort of i didnt believe at all that you could just build something intelligent out of that that would really sort of satisfy my definition of intelligence i think the most influential thing that i read in my early twenties was gödel escherbach that was about consciousness and that was a big eye opener in some sense in what sense so on your own brain did you at the time or do you now see your own brain as a computer or is there a total separation of the way so yeah youre very pragmatically practically know the limits of memory the limits of this sequential computing or weakly paralyzed computing and you just know what we have now and its hard to see how it creates but its also easy to see it was in the 40s 50s 60s and now at least similarities between the brain and our computers oh yeah i mean i totally believe that brains are computers in some sense i mean the rules they use to play by are pretty different from the rules we can sort of implement in our current hardware but i dont believe in like a separate thing that infuses us with intelligence or consciousness or any of that theres no soul ive been an atheist probably from when i was 10 years old just by thinking a bit about math and the universe and well my parents were atheists now i know that you could be an atheist and still believe that there is something sort of about intelligence or consciousness that cannot possibly emerge from a fixed set of rules i am not in that camp i totally see that sort of given how many millions of years evolution took its time dna is a particular machine that sort of encodes information and an unlimited amount of information in chemical form and has figured out a way to replicate itself i thought that that was maybe its 300 million years ago but i thought it was closer to half a billion years ago that thats sort of originated and it hasnt really changed that the sort of the structure of dna hasnt changed ever since that is like our binary code that we have in hardware i mean the basic programming language hasnt changed but maybe the programming itself obviously it did sort of it happened to be a set of rules that was good enough to sort of develop endless variability and sort of the idea of self replicating molecules competing with each other for resources and one type eventually sort of always taking over that happened before there were any fossils so we dont know how that exactly happened but i believe its clear that that did happen can you comment on consciousness and how you see it because i think well talk about programming quite a bit well talk about you know intelligence connecting to programming fundamentally but consciousness is this whole other thing do you think about it often as a developer of a programming language and as a human those are pretty sort of separate topics sort of my line of work working with programming does not involve anything that goes in the direction of developing intelligence or consciousness but sort of privately as an avid reader of popular science writing i have some thoughts which is mostly that i dont actually believe that consciousness is an all or nothing thing i have a feeling that and i forget what i read that influenced this but i feel that if you look at a cat or a dog or a mouse they have some form of intelligence if you look at a fish it has some form of intelligence and that evolution just took a long time but i feel that the sort of evolution of more and more intelligence that led to sort of the human form of intelligence followed the evolution of the senses especially the visual sense i mean there is an enormous amount of processing thats needed to interpret a scene and humans are still better at that than computers are and i have a feeling that there is a sort of the reason that like mammals in particular developed the levels of consciousness that they have and that eventually sort of going from intelligence to self awareness and consciousness has to do with sort of being a robot that has very highly developed senses has a lot of rich sensory information coming in so thats a really interesting thought that whatever that basic mechanism of dna whatever that basic building blocks of programming if you just add more abilities more high resolution sensors more sensors you just keep stacking those things on top that this basic programming in trying to survive develops very interesting things that start to us humans to appear like intelligence and consciousness as far as robots go i think that the self driving cars have that sort of the greatest opportunity of developing something like that because when i drive myself i dont just pay attention to the rules of the road i also look around and i get clues from that oh this is a shopping district oh heres an old lady crossing the street oh here is someone carrying a pile of mail theres a mailbox i bet you theyre going to cross the street to reach that mailbox and i slow down and i dont even think about that and so there is so much where you turn your observations into an understanding of what other consciousnesses are going to do or what other systems in the world are going to be oh that tree is going to fall i see sort of i see much more of i expect somehow that if anything is going to become unconscious its going to be the self driving car and not the network of a bazillion computers in a google or amazon data center that are all networked together to do whatever they do so in that sense so you actually highlight because thats what i work in thomas vehicles you highlight the big gap between what we currently cant do and what we truly need to be able to do to solve the problem under that formulation then consciousness and intelligence is something that basically a system should have in order to interact with us humans as opposed to some kind of abstract notion of a consciousness consciousness is something that you need to have to be able to empathize to be able to fear understand what the fear of death is all these aspects that are important for interacting with pedestrians you need to be able to do basic computation based on our human desires and thoughts and if you sort of yeah if you look at the dog the dog clearly knows i mean im not the dog owner but i have friends who have dogs the dogs clearly know what the humans around them are going to do or at least they have a model of what those humans are going to do and they learn some dogs know when youre going out and they want to go out with you theyre sad when you leave them alone they cry theyre afraid because they were mistreated when they were younger we dont assign sort of consciousness to dogs or at least not all that much but i also dont think they have none of that so i think its consciousness and intelligence are not all or nothing the spectrum is really interesting but in returning to programming languages and the way we think about building these kinds of things about building intelligence building consciousness building artificial beings so i think one of the exciting ideas came in the 17th century and with leibniz hobbes descartes where theres this feeling that you can convert all thought all reasoning all the thing that we find very special in our brains you can convert all of that into logic so you can formalize it formal reasoning and then once you formalize everything all of knowledge then you can just calculate and thats what were doing with our brains is were calculating so theres this whole idea that this is possible that this we can actually program but they werent aware of the concept of pattern matching in the sense that we are aware of it now they sort of thought they had discovered incredible bits of mathematics like newtons calculus and their sort of idealism their sort of extension of what they could do with logic and math sort of went along those lines and they thought theres like yeah logic theres like a bunch of rules and a bunch of input they didnt realize that how you recognize a face is not just a bunch of rules but is a shit ton of data plus a circuit that sort of interprets the visual clues and the context and everything else and somehow can massively parallel pattern match against stored rules i mean if i see you tomorrow here in front of the dropbox office i might recognize you even if im wearing a different shirt yeah but if i see you tomorrow in a coffee shop in belmont i might have no idea that it was you or on the beach or whatever i make those kind of mistakes myself all the time i see someone that i only know as like oh this person is a colleague of my wifes and then i see them at the movies and i didnt recognize them but do you see those you call it pattern matching do you see that rules is unable to encode that everything you see all the pieces of information you look around this room im wearing a black shirt i have a certain height im a human all these theres probably tens of thousands of facts you pick up moment by moment about this scene you take them for granted and you aggregate them together to understand the scene you dont think all of that could be encoded to where at the end of the day you can just put it all on the table and calculate i dont know what that means i mean yes in the sense that there is no actual magic there but there are enough layers of abstraction from the facts as they enter my eyes and my ears to the understanding of the scene that i dont think that ai has really covered enough of that distance its like if you take a human body and you realize its built out of atoms well that is a uselessly reductionist view right the body is built out of organs the organs are built out of cells the cells are built out of proteins the proteins are built out of amino acids the amino acids are built out of atoms and then you get to quantum mechanics so thats a very pragmatic view i mean obviously as an engineer i agree with that kind of view but you also have to consider the sam harris view of well intelligence is just information processing like you said you take in sensory information you do some stuff with it and you come up with actions that are intelligent that makes it sound so easy i dont know who sam harris is oh well its a philosopher so like this is how philosophers often think right and essentially thats what descartes was is wait a minute if there is like you said no magic so he basically says it doesnt appear like theres any magic but we know so little about it that it might as well be magic so just because we know that were made of atoms just because we know were made of organs the fact that we know very little how to get from the atoms to organs in a way thats recreatable means that you shouldnt get too excited just yet about the fact that you figured out that were made of atoms right and the same about taking facts as our sensory organs take them in and turning that into reasons and actions that sort of there are a lot of abstractions that we havent quite figured out how to deal with those i mean sometimes i dont know if i can go on a tangent or not so if i take a simple program that parses say i have a compiler that parses a program in a sense the input routine of that compiler of that parser is a sensing organ and it builds up a mighty complicated internal representation of the program it just saw it doesnt just have a linear sequence of bytes representing the text of the program anymore it has an abstract syntax tree and i dont know how many of your viewers or listeners are familiar with compiler technology but theres… fewer and fewer these days right thats also true probably people want to take a shortcut but theres sort of this abstraction is a data structure that the compiler then uses to produce outputs that is relevant like a translation of that program to machine code that can be executed by hardware and then that data structure gets thrown away when a fish or a fly sees sort of gets visual impulses im sure it also builds up some data structure and for the fly that may be very minimal a fly may have only a few i mean in the case of a flys brain i could imagine that there are few enough layers of abstraction that its not much more than when its darker here than it is here well it can sense motion because a fly sort of responds when you move your arm towards it so clearly its visual processing is intelligent well not intelligent but it has an abstraction for motion and we still have similar things in but much more complicated in our brains i mean otherwise you couldnt drive a car if you couldnt if you didnt have an incredibly good abstraction for motion yeah in some sense the same abstraction for motion is probably one of the primary sources of our of information for us we just know what to do i think we know what to do with that weve built up other abstractions on top we build much more complicated data structures based on that and we build more persistent data structures sort of after some processing some information sort of gets stored in our memory pretty much permanently and is available on recall i mean there are some things that you sort of youre conscious that youre remembering it like you give me your phone number i well at my age i have to write it down but i could imagine i could remember those seven numbers or ten digits and reproduce them in a while if i sort of repeat them to myself a few times so thats a fairly conscious form of memorization on the other hand how do i recognize your face i have no idea my brain has a whole bunch of specialized hardware that knows how to recognize faces i dont know how much of that is sort of coded in our dna and how much of that is trained over and over between the ages of zero and three but somehow our brains know how to do lots of things like that that are useful in our interactions with other humans without really being conscious of how its done anymore right so our actual day to day lives were operating at the very highest level of abstraction were just not even conscious of all the little details underlying it theres compilers on top of its like turtles on top of turtles or turtles all the way down theres compilers all the way down but thats essentially you say that theres no magic thats what i what i was trying to get at i think is with descartes started this whole train of saying that theres no magic i mean theres all this beforehand well didnt descartes also have the notion though that the soul and the body were fundamentally separate separate yeah i think he had to write in god in there for political reasons so i dont know actually im not a historian but theres notions in there that all of reasoning all of human thought can be formalized i think that continued in the 20th century with russell and with gadots incompleteness theorem this debate of what are the limits of the things that could be formalized thats where the turing machine came along and this exciting idea i mean underlying a lot of computing that you can do quite a lot with a computer you can encode a lot of the stuff were talking about in terms of recognizing faces and so on theoretically in an algorithm that can then run on a computer and in that context id like to ask programming in a philosophical way what does it mean to program a computer so you said you write a python program or compiled a c program that compiles to some byte code its forming layers youre programming a layer of abstraction thats higher how do you see programming in that context can it keep getting higher and higher levels of abstraction i think at some point the higher levels of abstraction will not be called programming and they will not resemble what we call programming at the moment there will not be source code i mean there will still be source code sort of at a lower level of the machine just like there are still molecules and electrons and sort of proteins in our brains but and so theres still programming and system administration and who knows what to keep the machine running but what the machine does is a different level of abstraction in a sense and as far as i understand the way that for the last decade or more people have made progress with things like facial recognition or the self driving cars is all by endless endless amounts of training data where at least as a lay person and i feel myself totally as a lay person in that field it looks like the researchers who publish the results dont necessarily know exactly how their algorithms work and i often get upset when i sort of read a sort of a fluff piece about facebook in the newspaper or social networks and they say well algorithms and thats like a totally different interpretation of the word algorithm because for me the way i was trained or what i learned when i was eight or ten years old an algorithm is a set of rules that you completely understand that can be mathematically analyzed and you can prove things you can like prove that aristotelian sieve produces all prime numbers and only prime numbers yeah so i dont know if you know who andrej karpathy is im afraid not so hes a head of ai at tesla now but he was at stanford before and he has this cheeky way of calling this concept software 20 so let me disentangle that for a second so kind of what youre referring to is the traditional the algorithm the concept of an algorithm something thats there its clear you can read it you understand it you can prove its functioning as kind of software 10 and what software 20 is is exactly what you described which is you have neural networks which is a type of machine learning that you feed a bunch of data and that neural network learns to do a function all you specify is the inputs and the outputs you want and you cant look inside you cant analyze it all you can do is train this function to map the inputs to the outputs by giving a lot of data and thats as programming becomes getting a lot of data thats what programming is well that would be programming 20 to programming 20 i wouldnt call that programming its just a different activity just like building organs out of cells is not called chemistry well so lets just step back and think sort of more generally of course but you know its like as a parent teaching your kids things can be called programming in that same sense thats how programming is being used youre providing them data examples use cases so imagine writing a function not by not with for loops and clearly readable text but more saying well heres a lot of examples of what this function should take and heres a lot of examples of when it takes those functions it should do this and then figure out the rest so thats the 20 concept and so the question i have for you is like its a very fuzzy way this is the reality of a lot of these pattern recognition systems and so on its a fuzzy way of quote unquote programming what do you think about this kind of world should it be called something totally different than programming if youre a software engineer does that mean youre designing systems that are very can be systematically tested evaluated they have a very specific specification and then this other fuzzy software 20 world machine learning world thats something else totally or is there some intermixing thats possible well the question is probably only being asked because we dont quite know what that software 20 actually is and i think there is a truism that every task that ai has tackled in the past at some point we realized how it was done and then it was no longer considered part of artificial intelligence because it was no longer necessary to use that term it was just oh now we know how to do this and a new field of science or engineering has been developed and i dont know if sort of every form of learning or sort of controlling computer systems should always be called programming so i dont know maybe im focused too much on the terminology but i expect that there just will be different concepts where people with sort of different education and a different model of what theyre trying to do will develop those concepts i guess if you could comment on another way to put this concept is i think the kind of functions that neural networks provide is things as opposed to being able to upfront prove that this should work for all cases you throw at it all youre able its the worst case analysis versus average case analysis all youre able to say is it seems on everything weve tested to work 999 of the time but we cant guarantee it and it fails in unexpected ways we cant even give you examples of how it fails in unexpected ways but its like really good most of the time is there no room for that in current ways we think about programming programming 10 is actually sort of getting to that point too where the sort of the ideal of a bug free program has been abandoned long ago by most software developers we only care about bugs that manifest themselves often enough to be annoying and were willing to take the occasional crash or outage or incorrect result for granted because we cant possibly we dont have enough programmers to make all the code bug free and it would be an incredibly tedious business and if you try to throw formal methods at it it becomes even more tedious so every once in a while the user clicks on a link and somehow they get an error and the average user doesnt panic they just click again and see if it works better the second time which often magically it does or they go up and they try some other way of performing their tasks so thats sort of an end to end recovery mechanism and inside systems there is all sorts of retries and timeouts and fallbacks and i imagine that that sort of biological systems are even more full of that because otherwise they wouldnt survive do you think programming should be taught and thought of as exactly what you just said i come from this kind of youre always denying that fact always in sort of basic programming education the sort of the programs youre having students write are so small and simple that if there is a bug you can always find it and fix it because the sort of programming as its being taught in some even elementary middle schools in high school introduction to programming classes in college typically its programming in the small very few classes sort of actually teach software engineering building large systems every summer here at dropbox we have a large number of interns every tech company on the west coast has the same thing these interns are always amazed because this is the first time in their life that they see what goes on in a really large software development environment everything theyve learned in college was almost always about a much smaller scale and somehow that difference in scale makes a qualitative difference in how you do things and how you think about it if you then take a few steps back into decades 70s and 80s when you were first thinking about python or just that world of programming languages did you ever think that there would be systems as large as underlying google facebook and dropbox did you when you were thinking about python i was actually always caught by surprise by sort of this yeah pretty much every stage of computing so maybe just because youve spoken in other interviews but i think the evolution of programming languages are fascinating and its especially because it leads from my perspective towards greater and greater degrees of intelligence i learned the first programming language i played with in russia was with the turtle logo logo yeah and if you look i just have a list of programming languages all of which ive now played with a little bit i mean theyre all beautiful in different ways from fortran cobalt lisp algol 60 basic logo again c as a few the object oriented came along in the 60s simula pascal smalltalk all of that leads theyre all the classics the classics yeah the classic hits right steam thats built on top of lisp on the database side sql c and all of that leads up to python pascal too and thats before python matlab these kind of different communities different languages so can you talk about that world i know that sort of python came out of abc which i actually never knew that language i just having researched this conversation went back to abc and it looks remarkably it has a lot of annoying qualities but underneath those like all caps and so on but underneath that theres elements of python that are quite theyre already there thats where i got all the good stuff all the good stuff so but in that world youre swimming these programming languages were you focused on just the good stuff in your specific circle or did you have a sense of what is everyone chasing you said that every programming language is built to scratch an itch were you aware of all the itches in the community and if not or if yes i mean what itch were you trying to scratch with python well im glad i wasnt aware of all the itches because i would probably not have been able to do anything i mean if youre trying to solve every problem at once youll solve nothing well yeah its too overwhelming and so i had a very very focused problem i wanted a programming language that sat somewhere in between shell scripting and c and now arguably there is like one is higher level one is lower level and python is sort of a language of an intermediate level although its still pretty much at the high level end i was thinking about much more about i want a tool that i can use to be more productive as a programmer in a very specific environment and i also had given myself a time budget for the development of the tool and that was sort of about three months for both the design like thinking through what are all the features of the language syntactically and semantically and how do i implement the whole pipeline from parsing the source code to executing it so i think both with the timeline and the goals it seems like productivity was at the core of it as a goal so like for me in the 90s and the first decade of the 21st century i was always doing machine learning ai programming for my research was always in c and then the other people who are a little more mechanical engineering electrical engineering are matlabby theyre a little bit more matlab focused those are the world and maybe a little bit java too but people who are more interested in emphasizing the object oriented nature of things so within the last 10 years or so especially with the oncoming of neural networks and these packages that are built on python to interface with neural networks i switched to python and its just ive noticed a significant boost that i cant exactly because i dont think about it but i cant exactly put into words why im just much much more productive just being able to get the job done much much faster so how do you think whatever that qualitative difference is i dont know if its quantitative it could be just a feeling i dont know if im actually more productive but how do you think about you probably are yeah well thats right i think theres elements let me just speak to one aspect that i think that was affecting my productivity is c was i really enjoyed creating performant code and creating a beautiful structure where everything that you know this kind of going into this especially with the newer and newer standards of templated programming of just really creating this beautiful formal structure that i found myself spending most of my time doing that as opposed to getting it parsing a file and extracting a few keywords or whatever the task was trying to do so what is it about python how do you think of productivity in general as you were designing it now sort of through the decades last three decades what do you think it means to be a productive programmer', 'the following is a conversation with jeff atwood he is the cofounder of stack overflow and stack exchange websites that are visited by millions of people every single day much like with wikipedia it is difficult to understate the impact on global knowledge and productivity that these networks of sites have created jeff is also the author of the famed blog coding horror and the founder of discourse an open source software project that seeks to improve the quality of our online community discussions this conversation is part of the mit course on artificial general intelligence and the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or your podcast provider of choice or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with jeff atwood having co created and managed for a few years the worlds largest community of programmers in stack overflow 10 years ago what do you think motivates most programmers is it fame fortune glory process of programming itself or is it the sense of belonging to a community its puzzles really i think its this idea of working on puzzles independently of other people and just solving a problem sort of like on your own almost although nobody really works alone in programming anymore but i will say theres an aspect of hiding yourself away and just beating on a problem until you solve it like brute force basically to me is what a lot of programming is the computers so fast that you can do things that would take forever for a human but you can just do them so many times and so often that you get the answer youre saying just the pure act of tinkering with the code is the thing that drives most problems the struggle balance within the joy of overcoming the brute force process of pain and suffering that eventually leads to something that actually works well datas fun too theres this thing called the shuffling problem the naive shuffle that most programmers write has a huge flaw and theres a lot of articles online about this because it can be really bad if youre a casino and you have an unsophisticated programmer writing your shuffle algorithm theres surprising ways to get this wrong but the neat thing is the way to figure that out is just to run your shuffle a bunch of times and see how many orientations of cards you get you should get an equal distribution of all the cards and with the naive method of shuffling if you just look at the data if you just brute force it and say ok i dont know whats going to happen you just write a program that does it a billion times and then see what the buckets look like of the data and the monty hall problem is another example of that where you have three doors and somebody gives you information about another door so the correct answer is you should always switch in the monty hall problem which is not intuitive and it freaks people out all the time but you can solve it with data if you write a program that does the monty hall game and then never switches then always switches just compare you would immediately see that you dont have to be smart you dont have to figure out the answer algorithmically you can just brute force it out with data and say well i know the answer is this because i ran the program a billion times and these are the data buckets that i got from it so empirically find it but whats the joy of that so for you for you personally outside of family what motivates you in this process well to be honest i dont really write a lot of code anymore what i do at discourse is managery stuff which i always despised as a programmer you think of managers as people who dont really do anything themselves but the weird thing about code is you realize that language is code the ability to direct other people lets you get more stuff done than you could by yourself anyway you said language is code language is code meaning communication with other humans yes it is you can think of it as a systematic so what is it like to be what makes before we get into programming what makes a good manager what makes a good leader well i think a leader its all about leading by example first of all sort of doing and being the things that you want to be now this can be kind of exhausting particularly when you have kids because you realize that your kids are watching you all the time even in ways that youve stopped seeing yourself the hardest person to see on the planet is really yourself its a lot easier to see other people and make judgments about them but yourself youre super biased you dont actually see yourself the way other people see you often youre very very hard on yourself in a way that other people really arent going to be so thats one of the insights is youve got to be really diligent about thinking am i behaving in a way that represents how i want other people to behave like leading through example theres a lot of examples of leaders that really mess this up like they make decisions that are like wow its a bad example for other people so i think leading by example is one the other one i believe is working really hard and i dont mean working exhaustively but showing a real passion for the problem not necessarily your solution to the problem but the problem itself is just one that you really believe in like with discourse for example the problem that were looking at which is my current project is how do you get people in groups to communicate in a way that doesnt break down into the howling of wolves how do you deal with trolling not like technical problems how do i get people to post paragraphs how do i get people to use bold how do i get people to use complete sentences although those are problems as well but how do i get people to get along with each other and then solve whatever problem it is they set out to solve or reach some consensus on discussion or just not hurt each other even maybe its a discussion that doesnt really matter but are people yelling at each other and why like thats not the purpose of this kind of communication so i would say leadership is about setting an example doing the things that represent what you want to be and making sure that youre actually doing those things and theres a trick to that too because the things you dont do also say a lot about what you are yeah so lets pause on that one so those two things are fascinating so how do you have as a leader that self awareness so you just said its really hard to be self aware so for you personally or maybe for other leaders youve seen or look up to how do you know both that the things youre doing are the wrong things to be doing the way you speak to others the way you behave and the things youre not doing how do you get that signal i think theres two aspects to that one is like processing feedback that youre getting so how do you get feedback well right so are you getting feedback right so one way we do it for example with discourse we have three cofounders and we periodically talk about decisions before we make them so its not like one person can make a mistake or like wow there can be misunderstandings things like that so its part of like group consensus of leadership is like its good to have i think systems where theres one leader and that leader has the rule of absolute law are just really dangerous in my experience for communities for example like if you have a community thats run by one person that one person makes all the decisions that persons gonna have a bad day something could happen to that person something theres a lot of variables so like first when you think about leadership have multiple people doing leadership and have them talk amongst each other so giving each other feedback about the decisions that theyre making and then when you do get feedback i think theres that little voice in your head right or your gut or wherever you wanna put it in your body i think that voice is really important like i think most people who have any kind of moral compass or like want to do most people want to do the right thing i do believe that i mean there might be a handful of sociopaths out there that dont but most people they want other people to think of them as a good person and why wouldnt you right like do you want people to despise you i mean thats just weird right so you have that little voice that sort of the angel and devil on your shoulder sort of talking to you about like what youre doing how youre doing how does it make you feel to make these decisions right and i think having some attunement to that voice is important but you said that voice also for i think this is a programmer situation too where sometimes the devil on the shoulder is a little too loud so youre a little too self critical for a lot of developers and especially when you have introverted personality how do you struggle with a self criticism or the criticism of others so one of the things of leadership is to do something thats potentially unpopular or where people doubt you and you still go through with the decision so whats that balance like i think you have to walk people through your decision making right like you have to this is where blogging is really important and communication is so important again code language is just another kind of code its like here is the program by which i arrived at the conclusion that im gonna reach right its one thing to say like this is a decision its final deal with it right thats not usually satisfying to people but if you say look weve been thinking about this problem for a while heres some stuff thats happened heres what we think is right heres our goals heres what we wanna achieve and weve looked at these options and we think this available options is the best option people will be like oh okay right maybe i dont totally agree with you but i can kind of see where youre coming from and i see its not just arbitrary decision delivered from a cloud of flames in the sky right its like a human trying to reach some kind of consensus about goals and their goals might be different than yours thats completely legit right but if youre making that clear its like oh well the reason we dont agree is because we have totally different goals right like how could we agree its not that youre a bad person its that we have radically different goals in mind when we started looking at this problem and the other one you said is passion so or hard work sorry well those are tied together in my mind lets say hard work and passion like for me like i just really love the problem discourse is setting out to solve because in a way its like theres a vision of the world where it all devolves into facebook basically owning everything and every aspect of human communication right and this has always been kind of a scary world for me first cause i dont i think facebook is really good at execution i got to compliment them theyre very competent in terms of what theyre doing but facebook has not much of a moral compass in terms of facebook cares about facebook really they dont really care about you and your problems what they care about is how big they can make facebook right is that you talking about the company or just the mechanism of how facebook works kind of both really right like and the idea with discourse the reason im so passionate about it is cause i believe every community should have the right to own themselves right like they should have their own software that they can run that belongs to them thats their space where they can set the rules and if they dont like it they can move to different hosting or you know whatever they need to happen can happen but like this idea of a company town where all human communication is implicitly owned by whatsapp instagram and facebook and its really disturbing too cause facebook is really smart like i said theyre great at execution buying in whatsapp and buying instagram were incredibly smart decisions and they also do this thing i dont know if you know but they have this vpn software that they give away for free on smartphones and it indirectly feeds all the data about the traffic back to facebook so they can see whats actually getting popular through the vpns right they have low level access to the network data because users have let them have that so so lets take a small pause here first of all discourse can you talk about can you lay out the land of all the different ways you can have communities so theres stack overflow that youve built theres discourse so stack overflow is kind of like a wiki wikipedia you talk about and its a very specific scalpel very focused so what is the purpose of discourse and maybe contrast that with facebook first of all say what is discourse yeah start from the beginning well let me start from the very beginning so stack overflow is a very structured wiki style q and a for programmers right and that was the problem we first worked on and when we started we thought it was discussions because we looked at like programming forums and other things but we quickly realized we were doing q and a which is a very narrow subset of human communication right sorry so when you started stack overflow you thought you didnt even know the q and a not really you didnt know it would be q and a well we didnt know we had an idea of like okay these are things that we see working online we had a goal right our goal was there was this site experts exchange with a very unfortunate name thank you for killing that site yeah i know right like a lot of people dont remember it anymore which is great like thats the measure of success when people dont remember the thing that you were trying to replace then youve totally won so it was a place to get answers to programming questions but it wasnt clear if it was like focused q and a if it was a discussion there were plenty of programming forums so we werent really sure we were like okay well take aspects of dig and reddit like voting were very important reordering answers based on votes wiki style stuff of like being able to edit posts not just your posts but other peoples posts to make them better and keep them more up to date ownership of blogging of like okay this is me im saying this in my voice this is the stuff that i know and your reputation accrues to you and its peer recognition so you asked earlier like what motivates programmers i think peer recognition motivates them a lot that was one of the key insights of stack overflow was like recognition from your peers is why things get done not necessarily money not necessarily your boss but like your peers saying wow this person really knows their stuff has a lot of value so the reputation system came from that so we were sort of frankensteining a bunch of stuff together in stack overflow like stuff we had seen working and we knew worked and that became stack overflow over time we realized it wasnt really discussion it was very focused questions and answers there wasnt a lot of room on the page for let me talk about this tangential thing it was more like okay is it answering the question is it clarifying the question or could it be an alternative answer to the same question because theres usually more than one way to do it in programming theres like say five to 10 ways and one of the patterns we got into early on with stack overflow was there were questions where there would be like hundreds of answers and were like wow how can there be a programming question with 500 200 500 answers and we looked at those and we realized those were not really questions in the traditional sense they were discussions it was stuff that we allowed early on that we eventually decided wasnt allowed such as whats your favorite programming food whats the funniest programming cartoon youve seen and we had to sort of backfill a bunch of rules about like why isnt this allowed such as is this a real problem youre facing like nobody goes to work and says wow i cant work cause i dont know what the funniest programming cartoon is so sorry cant compile this code now right its not a real problem youre facing in your job so that was run rule and the second like what can you really learn from that its like what i call accidental learning or reddit style learning where youre just like oh ill just browse some things and oh wow you know did you know tree frogs only live three years i mean i just made that up i dont know if thats true but i didnt really set out to learn that i dont need to know that right its accidental learning it was more intentional learning where youre like okay i have a problem and i want to learn about stuff around this problem having right and it could be theory it could be compiler theory it could be other stuff but im having a compiler problem hence i need to know the compiler theory that aspect of it that gets me to my answer right so kind of a directed learning so we had to backfill all these rules as we sort of figured out what the heck it was we were doing and the system came very strict over time and a lot of people still complain about that and i wrote my latest blog entry what does stack overflow want to be when it grows up celebrating the 10 year anniversary yeah yeah so 10 years and the system has trended towards strictness theres a variety of reasons for this one is people dont like to see other people get reputation for stuff as they view as frivolous which i can actually understand because if you saw a programmer got like 500 upvotes for funniest programming cartoon or funniest comment they had seen in code its like well why do they have that reputation is it because they wrote the joke probably not i mean if they did maybe or the cartoon right theyre getting a bunch of reputation based on someone elses work thats not even programming its just a joke right its related to programming so you begin to resent that youre like well thats not fair and it isnt at some level theyre correct i mean i empathize because its not correct to get reputation for that versus heres a really gnarly regular expression problem and heres a really clever insightful detailed answer laying out oh heres why youre seeing the behavior that youre seeing here let me teach you some things about how to avoid that in the future thats great thats gold right you want people to get reputation for that not so much for wow look at this funny thing i saw right great so theres this very specific qa format and then take me through the journey towards discourse and facebook and twitter so you started at the beginning that stack overflow evolved to have a purpose so what is discourse this passion you have for creating community for discussion when was that born and how well part of it is based on the realization that stack overflow is only good for very specific subjects where its based on data facts and science where answers can be kind of verified to be true another form of that is theres the book of knowledge like the tome of knowledge that defines whatever it is you can refer to that book and itll give you the answer there has to be it only works on subjects where theres like semi clear answers to things that can be verified in some form now again theres always more than one way to do it theres complete flexibility and system around that but where it falls down is stuff like poker and lego like we had if you go to stackexchangecom we have an engine that tries to launch different qa topics right and people can propose qa topics sample questions and if it gets enough support within the network we launched that qa site so some of the ones we launched were poker and lego and they did horribly right because i mean they might still be there lingering on in some form but it was an experiment this is like a test right and some subjects work super well on the stack engine and some dont but the reason lego and poker dont work is because theyre so social really its not about whats the rule here in poker its like well what kind of cigars do we like to smoke while playing poker or whats a cool set of cards to use when im playing poker or whats some strategies say i have this hand come up with some strategies i could use its more of a discussion around whats happening with lego same thing heres this cool lego set i found look how awesome this is and im like yeah thats freaking awesome right its not a question right theres all these social components and discussions that dont fit at all we literally have to disallow those in stack overflow because its not about being social its about problems that youre facing in your work that you need concrete answers for you have a real demonstrated problem thats blocking you in something nobodys blocked by what should i do when i have a straight flush its not a blocking problem in the world its just an opportunity to hang out and discuss so discourse was a way to address that and say look discussion forum software was very very bad and when i came out of stack overflow in early 2012 it was still very very bad i expected it improved in the four years since i last looked but it had not improved at all and i was like well thats kind of terrible because i love these communities of people talking about things that they love theyre just communities of interest right and theres no good software for them startups would come to me and say hey jeff i want to have this startup heres my idea and the first thing i would say to them is well first why are you asking me i dont really know your field necessarily why arent you asking the community the people that are interested in this problem the people that are using your product why arent you talking to them and then theyd say oh great idea how do i do that and then thats when i started playing sad trombone because i realized all the software involving talking to your users customers audience patrons whatever it is it was all really bad it was stuff that i would be embarrassed to recommend to other people and yet thats where i felt they could get the biggest and strongest most effective input for what they should be doing with their product right its from their users from their community right thats what we did on stack overflow so what were talking about with forums the what is it the dark matter of the internet its still i dont know if its still but for the longest time it has some of the most passionate and fascinating discussions and whats the usual structure theres usually its linear so its sequential so youre posting one after the other and theres pagination so its every theres 10 posts and then you go to the next page and that format still is used by like im were doing a lot of research with tesla vehicles and theres a tesla motors club forum which is extremely we really wanted to run that actually they pinged us about it i dont think we got it but i really would have liked to gotten that one but theyve started before even 2012 i believe its like you dont want a heartbeat thats like so fast its like youre just freaking out but it is a measure of health you should have a healthy heartbeat its up to people listening to decide what that means but it has to be healthy it has to be reasonable because otherwise youre just going to be frustrated because thats how you build software you make mistakes you roll it out you live with it you see what it feels like and say oh god that was a terrible idea oh my gosh this could be even better if we did y right you turn the crank and then the more you do that the faster you get ahead of your competitors ultimately its rate of change right delta v right how fast are you moving well within a year youre going to be miles away by the time they catch up with you right thats the way it works and plus as a software developer and user i love software thats constantly changing because i dont understand people who get super pissed off when like oh they changed the software on me how dare they im like yes change the software change it all the time man thats what makes this stuff great is that it can be changed so rapidly and become something that is greater than it is now now granted there are some changes that suck i admit ive seen it many times but in general thats what makes software cool right its that it is so malleable fighting that is weird to me because its like well youre fighting the essence of the thing that youre building that doesnt make sense you want to really embrace that not to be a hummingbird but embrace it to a healthy cycle of your heartbeat right so you talk about that people really dont change its true thats why probably a lot of the stuff you write about in your blog probably will remain true well theres a flip side of the coin people dont change like investing and understanding people is like learning unix in 1970 because nothing has changed right all those things youve learned about people will still be valid 34 years from now whereas if you learn the latest javascript framework thats going to be good for like two years right exactly but if you look at the future of programming so theres a people component but theres also the technology itself what do you see as the future of programming will it change significantly or as far as you can tell people are ultimately programming and so its not something that you foresee changing in any fundamental way well youve got to go look back on sort of the basics of programming and one of things that always shocked me is like source control like i didnt learn anything about source control granted i graduated from college in 1992 but i remember hearing from people as late as like 1998 1999 like even maybe today theyre not learning source control and to me its like well how can you not learn source control that is so fundamental to working with other programmers working in a way that you dont lose your work just basic software the literal bedrock of software development is source control now you compare it today like github right like microsoft bought github which i think was an incredibly smart acquisition move on their part now they have anybody who wants reasonable source control to go sign up on github its all set up for you right theres tons of walkthroughs tons of tutorials so from the concept of like has programming advanced from say 1999 its like well hell we have github i mean my god yes right like its massively advanced over what it was now as to whether programming is significantly different im going to say no but i think the baseline of what we view as fundamentals will continue to go up and actually get better like source control thats one of the fundamentals that has gotten hundreds of orders of magnitude better than it was 10 20 years ago so those are the fundamentals let me introduce two things that maybe you can comment on so one is mobile phones so that could fundamentally transform what programming is or maybe not maybe you can comment on that and the other one is artificial intelligence which promises to in some ways to do some of the programming for you is one way to think about it so its really what a programmer is is using the intelligence thats inside your skull to do something useful the hope with artificial intelligence is that it does some of the useful parts for you where you dont have to think about it so do you see smartphones the fact that everybody has one and theyre getting more and more powerful as potentially changing programming and do you see ai as potentially changing programming ok so thats good so smartphones have definitely changed i mean since i guess 2010 is when they really started getting super popular i mean in the last eight years the world has literally changed right everybody carries a computer around and thats normal i mean that is such a huge change in society i think were still dealing with a lot of the positive and negative ramifications of that right everybodys connected all the time everybodys on the computer all the time that was my dream world as a geek right but its like be careful what you ask for right like wow now everybody has a computer its not quite the utopia that we thought it would be right computers can be used for a lot of stuff thats not necessarily great so to me thats the central focus of the smartphone is just that it puts a computer in front of everyone granted a small touch screen smallish touch screen computer but as for programming i dont know i dont think that ive kind of over time come to subscribe to the unix view of the world when it comes to programming you want to teach these basic command line things and that is just what programming is going to be for i think a long long time i dont think theres any magical visual programming thats going to happen i dont know ive over time have become a believer in that unix philosophy of just you know they kind of had to write with unix thats going to be the way it is for a long long time and well continue to like i said raise the baseline the tools will get better itll get simpler but its still fundamentally going to be command line tools fancy ides thats kind of it for the foreseeable future im not seeing any visual programming stuff on the horizon because you kind of think like what do you do on a smartphone that will be directly analogous to programming like im trying to think right and theres really not much so not necessarily analogous to programming but the kind of things that the kind of programs you would need to write might need to be very different yeah and the kind of languages i mean but i probably also subscribe to the same just because everything in this world might be written in javascript oh yeah thats already happening i mean discourse is a bet discourse itself javascript is another bet on that side of the table and i still try and believe in that so i would say smartphones have mostly a cultural shift more than a programming shift now your other question was about artificial intelligence and sort of devices predicting what youre going to do and i do think theres some strength to that i think artificial intelligence is kind of overselling it in terms of what its doing its more like people are predictable right people do the same things let me give you an example one check we put in a discourse thats been a lot of big commercial websites is say you log in from new york city now and then an hour later you log in from san francisco its like well hmm thats interesting how did you get from new york to san francisco in one hour so at that point youre like ok this is a suspicious login at that point so we would alert you its like ok but thats not ai right thats just a heuristic of like how did you in one hour get 2000 miles right that doesnt i mean youre grand maybe youre on a vpn theres other ways to happen thats just a basic prediction based on the idea that people pretty much dont move around that much they may travel occasionally but nobody unless youre a traveling salesman thats literally traveling the world every day theres so much repetition and predictability in terms of things youre going to do and i think good software anticipates your needs for example google i think its called google now or whatever that google thing is that predicts your commute and predicts based on your phone location where are you every day well thats probably where you work that kind of stuff i do think computers can get a lot better at that i hesitate to call it full blown ai its just computers getting better at like first of all they have a ton of data because everybody has a smartphone now all of a sudden we have all this data that we didnt have before about location about communication and feeding that into some basic heuristics and maybe some fancy algorithms that turn it into predictions of anticipating your needs like a friend would right like oh hey i see your home would you like some dinner right like lets go get some food because thats usually what we do at this time of day right in the context of actually the act of programming do you see ides improving and making the life of programming as better i do think that is possible because theres a lot of repetition in programming right oh you know clippy would be the bad example of oh i see it looks like youre writing a for loop but there are patterns in code right and actually libraries are kind of like that right rather than go code up your own http request library its like well youd use one of the existing ones that we have thats already a troubleshot right its not ai per se its just building better lego bricks bigger lego bricks that have more functionality in them so people dont have to worry about the low level stuff as much anymore like wordpress for example to me is like a tool for somebody who isnt a programmer to do something i mean you can turn wordpress into anything its kind of crazy actually through plugins right and thats not programming per se its just lego bricks stacking wordpress elements right and a little bit of configuration glue so i would say maybe in a broader sense what im seeing like therell be more gluing and less actual programming and thats a good thing right because most of the stuff you need is kind of out there already you said 1970s unix do you see php and these kind of old remnants of the early birth of programming remaining with us for a long time like you said unix in itself do you see ultimately this stuff just being there out of momentum i kind of do i mean i was a big believer in windows early on and i was a big you know i was like unix what a waste of time but over time ive completely flipped on that where i was like okay the unix guys were right and pretty much microsoft and windows were kind of wrong at least on the server side now on the desktop right you need a gui you need all that stuff and you have the two philosophies like apple built on unix effectively darwin and on the desktop its a slightly different story but on the server side where youre gonna be programming now its a question of where the programmings gonna be theres gonna be a lot more like client side programming because technically discourse is client side programming the way you get discourse we deliver a big ball of javascript which is then executed locally so were really using a lot more local computing power well still retrieve the data obviously we have to display the posts on the screen and so forth but in terms of like sorting and a lot of the basic stuff were using the host processor but to the extent that a lot of programming is still gonna be server side i would say yeah the unix philosophy definitely won and therell be different veneers over unix but its still if you peel away one or two layers its gonna be unixy for a long i think unix won i mean so definitively its interesting to hear you say that because youve done so much excellent work on the microsoft side in terms of backend development cool so whats the future hold for jeff atwood i mean the discourse continuing the discourse in trying to improve conversation on the web well discourse is what ive viewed as a and originally i called it a five year project then really quickly revised that to a 10 year project so we started in early 2013 thats when we launched the first version so were still five years in this is the part where it starts getting good like we have a good product now discourse theres any project you build in software it takes three years to build what you want it to build anyway like v1 is gonna be terrible which it was but you ship it anyway because thats how you get better at stuff its about turning the crank its not about v1 being perfect because thats ridiculous its about v1 then lets get really good at v11 12 13 like how fast can we iterate and i think were iterating like crazy on discourse to the point that like its a really good product now we have serious momentum and my original vision was i wanna be the wordpress of discussion meaning someone came to you and said i wanna start a blog although the very question is kind of archaic now its like who actually blogs anymore but i wanted the answer to that to be it would be wordpress normally because thats the obvious choice for blogging most of the time but if someone said hey i need a group of people to get together and do something the answer should be discourse right that should be the default answer for people because its open source its free doesnt cost you anything you control it you can run it your minimum server cost for discourse is five bucks a month at this point they actually got the vps prices down it used to be 10 a month for one gigabyte of ram which we have a kind of heavy stack like theres a lot of stuff in discourse you need postgres you need redis you need ruby and rails you need a sidekick for scheduling its not a trivial amount of stuff because we were architected for like look were building for the next 10 years i dont care about shared php hosting thats not my model my idea is like hey eventually this is gonna be very cheap for everybody and i wanna build it right using again higher bigger building block levels right that have more requirements and theres a wordpress model of wordpressorg wordpresscom is there a central hosting for discourse or no there is were not strictly segmenting into the open source versus the commercial side we have a hosting business thats how discourse makes money is we host discourse instances and we have really close relationship with our customers of the symbiosis of them giving us feedback on the product we definitely wait feedback from customers a lot heavier than feedback from somebody who just wanders by and gives feedback but thats where we make all our money but we dont have a strict division we encourage people to use discourse like the whole point is that its free right anybody can set it up i dont wanna be the only person that hosts discourse thats absolutely not the goal but it is a primary way for us to build a business and its actually kind of a great business i mean the business is going really really well in terms of hosting so i used to work at google research its a company thats basically funded on advertisements so its facebook let me ask if you can comment on it i think advertisement is best so youd be extremely critical on what ads are but at its best its actually serving you in a sense its giving you its connecting you to what you would want to explore so its like related posts or related content its the same thats the best of advertisement so discourse is connecting people based on their interests it seems like a place where advertisement at its best could actually serve the users is that something that youre considering thinking about as a way to bring to financially support the platform thats interesting because i actually have a contrarian view of advertising which i kind of agree with you i recently installed adblocker reluctantly because i dont like to do that but the performance of the ads man theyre so heavy now and its just crazy so its almost like a performance argument more than like i actually am pro ads and i have a contrarian viewpoint i agree with you if you do ads right its serving you stuff you would be interested in anyway i dont mind that that actually is kind of a good thing so plus i think its rational to wanna support the people that are doing this work through seeing their ads but that said i run adblock now which i didnt wanna do but i was convinced by all these articles like 30 40 megabytes of stuff just to serve you ads yeah it feels like ads now are like the experts exchange of whenever you start a stock overflow its a little bit its overwhelming oh theres so many companies in ad tech that its embarrassing like you can do that have you seen those logo charts of like just the whole page its like you cant even see them theyre so small theres so many companies in the space but since you brought it up i do wanna point out that very very few discourse sites actually run using an ad supported model its not effective like its too diluted its too weird it doesnt pay well and like users hate it so its a combination of like users hate it it doesnt actually work that well in practice like in theory yes i agree with you if you had clean fast ads that were exactly the stuff you would be interested in awesome were so far from that though right like and google does an okay job they do retargeting and stuff like that but in the real world discourse sites rarely can make ads work it just doesnt work for so many reasons but you know what does work is subscriptions patreon affiliate codes for like amazon of like just oh heres a cool yo yo click and then you click and go to amazon they get a small percentage of that which is fair i think i mean because you saw the yo yo on that site and you clicked through and you bought it right thats fair for them to get 5 of that or 2 of that whatever it is those things definitely work in fact a site that i used to participate on a lot i helped the owner one of the things i got them to switch to discourse i basically paid them to switch to discourse because i was like look you guys got to switch i cant come here anymore on this terrible software but i was like look and on top of that like youre serving people ads that they hate like you should just go full on patreon because he had a little bit of patreon go full on patreon do the amazon affiliates thing for any amazon links that get posted and just do that and just triple down on that stuff and thats worked really well for them and this creator in particular so that stuff works but traditional ads i mean definitely not working at least on discourse so last question youve created the code keyboard ive programmed most of my adult life on a kinesis keyboard i have one upstairs now can you describe what a mechanical keyboard is and why is it something that makes you happy well you know this is another fetish item really like its not required you can do programming on any kind of keyboard even like an onscreen keyboard oh god thats terrifying but you could i mean if you look back at the early days of computing there were chiclet keyboards which are awful but whats a chiclet keyboard oh god ok well its just like thin rubber membranes oh the rubber ones oh no super bad right so its a fetish item all that really says is look i care really about keyboards because the keyboard is the primary method of communication with the computer so its just like having a nice mic for this podcast you want a nice keyboard right because it has a very tactile feel i can tell exactly when i press the key i get that little click so oh and it feels good and its also kind of a fetish item its like wow i care enough about programming that i care about the tool the primary tool that i use to communicate with the computer make sure its as good as it feels good to use for me and i can be very productive with it so to be honest its a little bit of a fetish item but a good one it indicates that youre serious it indicates youre interested it indicates that you care about the fundamentals because you know what makes you a good programmer being able to type really fast right this is true right so a core skill is just being able to type fast enough to get your ideas out of your head into the code base so just practicing your typing can make you a better programmer it is also something that makes you well makes you enjoy typing correct the actual act something about the process like i play piano its tactile theres a tactile feel that ultimately feeds the passion makes you happy right no totally thats it i mean and its funny because artisanal keyboards have exploded like massdrop has gone ballistic with this stuff theres probably like 500 keyboard projects on massdrop alone and theres some other guy i follow on twitter i used to write for the site the tech report way back in the day and hes like every week hes just posting what i call keyboard porn of just cool keyboards like oh my god those look really cool right its like how many keyboards does this guy have right its kind of like me with yo yos how many yo yos do you have how many do you need well technically one but i like a lot i dont know why so same thing with keyboards so yeah theyre awesome like i highly recommend anybody that doesnt have a mechanical to research it look into it and see what you like and its ultimately a fetish item but i think these sort of items these religious artifacts that we have are part of what make us human like that parts important right its kind of what makes life worth living yeah its not necessary in the strictest sense but aint nothing necessary if you think about it right like so yeah why not so sure jeff thank you so much for talking today yeah youre welcome thanks for having me i mean theyve been running for a long time its still an extremely rich source of information so whats broken about that system and how are you trying to fix it i think theres a lot of power in connecting people that love the same stuff around that specific topic meaning facebooks idea of connection is just any human thats related to another human right like through friendship or any other reason facebooks idea of the world is sort of the status update right like a friend of yours did something ate at a restaurant right whereas discussion forums were traditionally around the interest graph like i love electric cars specifically i love tesla right like i love the way they approach the problem i love the style of the founder i just love the design ethic and theres a lot to like about tesla i dont know if you saw the oatmeal he did a whole love comic to tesla and it was actually kind of cool because i learned some stuff he was talking about how great tesla cars were specifically like how they were built differently and he went into a lot of great detail that was really interesting and to me that oatmeal post if you read it is the genesis of pretty much all interest communities i just really love this stuff so like for me for example theres yo yos right like im into the yo yo communities and these interest communities are just really fascinating to me and i feel more connected to the yo yo communities than i do to friends that i dont see that often right like to me the powerful thing is the interest graph and facebook kind of dabbles in the interest graph i mean they have groups you can sign up for groups and stuff but its really about the relationship graph like this is my coworker this is my relative this is my friend but not so much about the interest so i think thats the linchpin of which forums and communities are built on that i personally love like i said leadership is about passion right and being passionate about stuff is a really valid way to look at the world and i think its a way a lot of stuff in the world gets done like i once had someone describe me as hes like jeff youre a guy who you just get super passionate about a few things at a time and you just go super deep in those things and i was like oh thats kind of right thats kind of what i do i get into something and just be super into that for a couple of years or whatever and just learn all i can about it and go super deep in it and thats how i enjoy experiencing the world right like not being shallow on a bunch of things but being really deep on a few things that im interested in so forums kind of unlock that right and you dont want a world where everything belongs to facebook at least i dont i want a world where communities can kind of own themselves set their own norms set their own rules control the experience because community is also about ownership right like if youre meeting at the barnes and noble every thursday and barnes and noble says get out of here you guys dont buy enough books well you know youre kind of hosed right barnes and noble owns you right like you cant but if you have your own meeting space you know your own clubhouse you can set your own rules decide what you want to talk about there and just really generate a lot better information than you could like hanging out at barnes and noble every thursday at 3 pm right so thats kind of the vision of discourse is a place where its fully open source you can take the software you can install it anywhere and you know you and a group of people can go deep on whatever it is that youre into and this works for startups right startups are a group of people who go super deep on a specific problem right and they want to talk to the community its like well install discourse right thats what we do at discourse thats what i did at stack overflow i spent a lot of time on meta stack overflow which is our internal well public community feedback site and just experiencing what the users were experiencing right because theyre the ones doing all the work in the system and they had a lot of interesting feedback and theres that 90 10 rule of like 90 of the feedback you get is not really actionable for a variety of reasons it might be bad feedback it might be crazy feedback it might be feedback you just cant act on right now but theres 10 of it thats like gold its like literally gold and diamonds where its like feedback of really good improvements to your core product that are not super hard to get to and actually make a lot of sense and my favorite is about 5 of those stuff i didnt even see coming its like oh my god i never even thought of that but thats a brilliant idea right and i can point to so many features of stack overflow that we derive from meta stack overflow feedback and meta discourse right same exact principle of discourse you know were getting ideas from the community i was like oh my god i never thought of that but thats fantastic right like i love that relationship with the community from having built these communities what have you learned about whats the process of getting a critical mass of members in a community is it luck skill timing persistence what is is it the tools like discourse that empower that community whats the key aspect of starting for one guy or gal and then building it to two and then 10 and a hundred and a thousand and so on i think when youre starting with an n of one i mean i think its persistence and also you have to be interesting like somebody i really admire once said something that i always liked about blogging hes like heres how you blog you have to have something interesting to say and have an interesting way of saying it right and then do that for like 10 years so thats the genesis is like you have to have sort of something interesting to say thats not exactly what everybody else is saying and an interesting way of saying it which is another way of saying kind of entertaining way of saying it and then as far as growing it its like ritual you know like you have to like say youre starting a blog you have to say look im gonna blog every week three times a week and you have to stick to that schedule right because until you do that for like several years youre never gonna get anywhere like it just takes years to get to where you need to get to and part of that is having the discipline to stick with the schedule and it helps again if its something youre passionate about this wont feel like work youre like i love this i could talk about this all day every day right you just have to do it in a way thats interesting to other people and then as youre growing the community that pattern of participation within the community of like generating these artifacts and inviting other people to help you like collaborate on these artifacts like even in the case of blogging like i felt in the early days of my blog which i started in 2004 which is really the genesis of stack overflow if you look at all my blog it leads up to stack overflow which was i have all this energy in my blog but i dont like 40000 people were subscribing to me and i was like i wanna do something and then i met joel and said hey joel i wanna do something take this ball of energy from my blog and do something and all the people reading my blog saw that its like oh cool youre involving us youre saying look youre part of this community lets build this thing together like they pick the name like we voted on the name for stack overflow on my blog like we came up and naming is super hard first of all the hardest problem in computer science is coming up with a good name for stuff right but you can go back to my blog theres the poll where we voted and stack overflow became the name of the site and all the early beta users of stack overflow were audience of my blog plus joels blog right so we started from like if you look at the genesis okay i was just a programmer who said hey i love programming but i have no outlet to talk about it so im just gonna blog about it because i dont have enough people to work to talk to about it because at the time i worked a place where you know programming wasnt the core output of the company it was a pharmaceutical company and i just love this stuff you know to an absurd degree so i was like ill just blog about it and then ill find an audience and eventually found an audience eventually found joel and eventually built stack overflow from that one core of activity right but it was that repetition of feeding back in feedback from my blog comments feedback from joel feedback from the early stack overflow community when people see that youre doing that they will follow along with you right theyll say cool youre here in good faith youre actually you know not listening to everything because thats impossible thats impossible but youre actually you know waiting our feedback and what youre doing and why wouldnt i because who does all the work on stack overflow me joel no its the other programmers that are doing all the work so you gotta have some respect for that and then you know discipline around look you know were trying to do a very specific thing here on stack overflow were not trying to solve all the worlds problems were trying to solve this very specific q and a problem in a very specific way not cause were jerks about it but because these strict set of rules help us get really good results right and programmers thats an easy sell for the most part because programmers are used to dealing with ridiculous systems of rules like constantly thats basically their job so theyre very oh yeah super strict system of rules that lets me get what i want thats programming right thats what stack overflow is so so youre making it sound easy but in 2004 lets go back there in 2004 you started the blog coding horror was it called that at the very beginning it was one of the smart things i did its from a book by steve mcconnell code complete which is one of my favorite programming books still probably my number one programming book for anyone to read so one of the smart things i did back then i dont always do smart things when i start stuff i contacted steve and said hey i really like this it was a sidebar illustration indicating danger in code right coding horror was like watch out and i love that illustration because it spoke to me because i saw that illustration go oh my god thats me like im always my own worst enemy like thats the key insight in programming is every time you write something think how am i gonna screw myself because you will constantly right so that icon was like oh yeah i need to constantly hold that mirror up and look and say look youre very fallible youre gonna screw this up like how can you build this in such a way that youre not gonna screw it up later like how can you get that discipline around making sure at every step im thinking through all the things that i could do wrong or that other people could do wrong because that is actually how you get to be a better programmer a lot of times right so that sidebar illustration i loved it so much and i wrote steve before i started my blog and said hey can i have permission to use this because i just really like this illustration and steve was kind enough to give me permission to do that and just continues to give me permission so yeah really thats awesome but in 2004 you started this blog you know you look at stephen king his book on writing or stephen pressfield war of art book i mean it seems like writers suffer i mean its a hard process of writing right theres gonna be suffering i mean i wont kid you well the work is suffering right like doing the work like even when youre every week youre like okay that blog post wasnt very good or people didnt like it or people said disparaging things about it you have to like have the attitude like you know no matter what happens i wanna do this for me right its not about you its about me i mean in the end it is about everyone because this is how good work gets out into the world but you have to be pretty strict about saying like you know im selfish in the sense that i have to do this for me you know you mentioned stephen king like his book on writing but like one of the things i do for example when writing is like i read it out loud one of the best pieces of advice for writing anything is read it out loud like multiple times and make it sound like youre talking because that is the goal of good writing it should sound like you said it with slightly better phrasing because you have more time to think about what youre saying but like it should sound natural when you say it and i think thats probably the single best writing advice i can give anyone just read it over and over out loud make sure it sounds like something you would normally say and it sounds good and whats your process of writing see theres usually a pretty good idea behind the blog post so ideas right so i think you gotta have the concept that theres so many interesting things in the world like i mean my god the world is amazing right like you can never write about everything thats going on because its so incredible but if you cant come up with like lets say one interesting thing per day to talk about then youre not trying hard enough because the world is full of just super interesting stuff and one great way to like mine stuff is go back to old books cause they bring up old stuff thats still super relevant and i did that a lot cause i was like reading classic programming books and a lot of the early blog posts were like oh i was reading this programming book and they brought this really cool concept and i wanna talk about it some more and you get the i mean youre not claiming credit for the idea but it gives you something interesting to talk about thats kind of evergreen right like you dont have to go what should i talk about so well just go dig up some old classic programming books and find something that oh wow thats interesting or how does that apply today or what about x and y or compare these two concepts so pull a couple of sentences from that book and then sort of play off of it almost agree or disagree so in 2007 you wrote that you were offered a significant amount of money to sell the blog you chose not to what were all the elements you were thinking about cause id like to take you back it seems like theres a lot of nonlinear decisions you made through life so what was that decision like right so one of the things i love is the choose your own adventure books which i loved as a kid and i feel like theyre early programmer books cause theyre all about if then statements right if this then this and theyre also very very unforgiving like theres all these sites that map the classic choose your own adventure books and how many outcomes are bad a lot of bad outcomes so part of the game is like oh i got a bad outcome go back one step go back one further step its like how did i get here right like its a sequence of decisions and this is true of life right like every decision is a sequence right individually any individual decision is not necessarily right or wrong but they lead you down a path right so i do think theres some truth to that so this particular decision the blog had gotten fairly popular theres a lot of rss readers that i had discovered and this guy contacted me out of the blue from this like bug tracking company hes like oh i really wanna buy your blog for like i think it was around it was 100000 it might have been like 80000 but it was a lot right like and thats you know at the time like i would have a years worth of salary all at once so i didnt really think about like well you know and i remember talking to people at the time i was like wow thats a lot of money but then im like i really like my blog right like do i wanna sell my blog cause it wouldnt really belong to me anymore at that point and one of the guidelines that i like to i dont like to give advice to people a lot but one of the pieces of advice i do give cause i do think its really true and its generally helpful is whenever youre looking at a set of decisions like oh gosh should i do a b or c you gotta pick the thing thats a little scarier in that list because not you know not like jump off a cliff scary but the thing that makes you nervous cause if you pick the safe choice its usually youre not really pushing youre not pushing yourself youre not choosing the thing thats gonna help you grow so for me the scarier choice was to say no i was like well no lets just see where this is going right because then i own it i mean it belongs to me its my thing and i can just take it and tell some other logical conclusion right because imagine how different the world would have been had i said yes and sold the blog its like there probably wouldnt be stack overflow you know a lot of other stuff would have changed so for that particular decision i think it was that same rule like what scares me a little bit more do the thing that scares you yeah so speaking of which startups i think theres a specific some more general questions that a lot of people would be interested in youve started stack overflow you started this course so whats the it was one two three guys whatever it is in the beginning what was that process like do you start talking about it do you start programming do you start like wheres the birth and the catalyst that actually well i can talk about it in the context of both stack overflow and discourse so i think the key thing initially is there is a problem something theres some state of the world thats unsatisfactory to the point that like youre upset about it right like in that case it was experts exchange i mean joels original idea because i approached joel as like look joel i have all this energy behind my blog i want to do something i want to build something but i dont know what it is because im honestly not a good idea person im really not im like the execution guy im really good at execution but im not good at like blue skying ideas not my forte which is another reason why i like the community feedback because they blue sky all day long for you right so when i can just go in and cherry pick a blue sky idea from community even if i have to spend three hours reading to get one good idea its worth it man but anyway so the idea from joel was hey experts exchange its got great data but the experience is hideous right its trying to trick you it feels like used car salesman its just bad so i was like oh thats awesome it feeds into community it feeds into like you know we can make creative comments so i think the core is to have a really good idea that you feel very strongly about in the beginning that like theres a wrong in the world an injustice that we will write through the process of building this thing for discourse it was like look theres no good software for communities to just hang out and like do stuff right like whether its problem solving startup whatever forums are such a great building block of online community and theyre hideous they were so bad right it was embarrassing like i literally was embarrassed to be associated with this software right i was like we have to have software that you can be proud of its like this is competitive with reddit this is competitive with twitter this is competitive with facebook right i would be proud to have the software on my site so that was the genesis of discourse was feeling very strongly about there needs to be a good solution for communities so thats step one genesis of an idea you feel super strongly about right and then people galvanize around the idea like joel was already super excited about the idea i was excited about the idea so with the forum software i was posting on twitter i had researched as part of my research i start researching the problem right and i found a game called forum wars which was a parody of forum its still very very funny of forum behavior circa i would say 2003 its aged some right like the behaviors a little different in there of twitter but it was awesome it was very funny and it was like a game it was like an rpg and it had a forum attached to it so it was like a game about forums with a forum attached i was like this is awesome right this is so cool and the founder of that company or that project it wasnt really a company contacted me this guy robin ward from toronto he said hey i saw youve been talking about forums and i really love that problem space he was like id still love to build really good forum software because i dont think anything out theres any good and i was like awesome at that point i was like were starting a company because i couldnt have whooshed for a better person to walk through the door and say im excited about this too same thing with joel right i mean joel is a legend in the industry right so when he walked through and said im excited about this problem i was like me too man we can do this right so that to me is the most important step its like having an idea youre super excited about and another person a cofounder right because again you get that dual leadership right am i making a bad decision sometimes its nice to have checks of like is this a good idea i dont know right so those are the crucial seeds but then starting to build stuff whether its you programming or somebody elses there is prototyping so theres tons of research theres tons of research like whats out there that failed because a lot of people look at the successes oh look at how successful x is everybody looks at the successes those are boring show me the failures because that is whats interesting thats where people were experimenting thats where people were pushing and they failed but they probably failed for reasons that werent directly about the quality of their idea right so look at all the failures dont just look what everybody looks at which is like oh gosh look at all these successful people look at the failures look at the things that didnt work research the entire field and so thats the research that i was doing that led me to robin right was that and then when we for example when we did stack overflow were like okay well i really like elements of voting and dig and read it i like the wikipedia everythings up to date nothing is like an old tombstone that has horrible out of date information we know that works wikipedia is an amazing resource blogging the idea of ownership is so powerful right like oh i joe wrote this and look how good joes answer is right all these concepts were rolling together researching all the things that were out there that were working and why they were working and trying to fold them into again that frankensteins monster of what stack overflow is and by the way that wasnt a free decision because theres still a ton of tension in the stack overflow system theres reasons people complain about stack overflow because its so strict right why is it so strict why are you guys always closing my questions its because theres so much tension that we built into the system around trying to get good good results out of the system and its not a free that stuff doesnt come for free right its not like we we all have perfect answers and nobody will have to get their feelings heard or nobody will have to get downvoted it doesnt work that way right so this is an interesting point and a small tangent you write about anxiety so ive posted a lot of questions and written answers on stack overflow on the question side you usually go to something very specific to something im working on and this is something you talk about that really the goal of stack overflow isnt about is to write a question thats not about you its about the question that will help the community in the future right but thats a tough sell right because people are like well i dont really care about the community what i care about is my problem and thats fair right its sort of that again that tension that balancing act of we wanna help you but we also wanna help everybody that comes behind you the long line of people are gonna come up and say oh i kinda have that problem too right and if nobodys ever gonna come up and say i have this problem too then that question shouldnt exist on stack overflow because the question is too specific and even thats tension right how do you judge that how do you know that nobodys ever gonna have this particular question again so theres a lot of tension in the system do you think that anxiety of asking the question the anxiety of answering that tension is inherent to programmers is inherent to this kind of process or can it be improved can it be happy land where that tension is not quite so harsh i dont think stack overflow can totally change the way it works one thing they are working on finally is the ask page had not changed since 2011 im still kind of bitter about this because i feel like you have a qa system and what are the core pages in a qa system well first of all the question all the answers and also the ask page particularly when youre a new user or someone trying to ask a question thats the point at which you need the most help and we just didnt adapt with the times but the good news is theyre working on this from what i understand and its gonna be a more wizard based format and you could envision a world where as part of this wizard based program when youre asking questions okay come up with a good title what are good words to put in the title one word thats not good to put in the title is problem for example i have a problem oh you have a problem okay a problem thats great you need specifics so its trying to help you make a good question title for example that step will be broken out all that stuff but one of those steps in that wizard of asking could say hey im a little nervous ive never done this before can you put me in a queue for special mentoring you could opt in to a special mentor i think that would be fantastic i dont have any objection to that at all in terms of being an opt in system because there are people that are like i just wanna help them i wanna help a person no matter what i wanna go above and beyond i wanna spend hours with this person it depends what their goals are its a great idea who am i to judge so thats fine its not precluded from happening but theres a certain big city ethos that we started with like look were in new york city you dont come to new york city and expect them to be oh welcome to the city joe hows it going come on in let me show you around thats not how new york city works again new york city has a reputation for being rude which i actually dont think it is having been there fairly recently its not rude its just like going about their business like look i have things to do im busy im a busy professional as are you and since youre a busy professional certainly when you ask a question youre gonna ask the best possible question because youre a busy professional and you would not accept anything less than a very well written question with a lot of detail about why youre doing it what youre doing what you researched what you found because youre a professional like me and this rubs people sometimes the wrong way and i dont think its wrong to say look i dont want that experience i want just a more chill place for beginners and i still think stack overflow is not was never designed for beginners right theres this misconception that even joel says sometimes oh yeah stack overflow for beginners and i think if youre a prodigy it can be right but for the most part not but thats not really representative right like i think as a beginner you want a totally different set of tools you want like live screen sharing live chat you want access to resources you want a playground like a playground you can experiment in and like test and all this stuff that we just dont give people because that was never really the audience that we were designing stack overflow for that doesnt mean its wrong and i think it would be awesome if there was a site like that on the internet or if stack overflow said hey you know were gonna start doing this thats fine too you know im not there im not making those decisions but i do think the pressure the tension that you described is there for people to be look im a little nervous because i know i gotta do my best work right the other one is something you talk about which is also really interesting to me is duplicate questions or its a really difficult problem that you highlight its super hard like you could take one little topic and you could probably write 10 20 30 ways of asking about that topic and there will be all different i dont know if there should be one page that answers all of it is there a way that stack overflow can help disambiguate like separate these duplicate questions or connect them together or is it a totally hopeless difficult impossible task i think its a very very hard computer science problem and partly because people are very good at using completely different words it always amazed me on stack overflow youd have two questions that were functionally identical and one question had like zero words in common with the other question like oh my god from a computer science perspective how do you even begin to solve that and it happens all the time people are super good at this right accidentally at asking the same thing in like 10 20 different ways and the other complexity is we want some of those duplicates to exist because if theres five versions with different words have those five versions point to the one centralized answer right its like okay this is a duplicate no worries heres the answer that you wanted over here on the prime example that we want to have rather than having 10 copies of the question and the answer because if you have 10 copies of the question and answer this also devalues the reputation system which programmers hate as i previously mentioned youre getting reputation for an answer that somebody else already gave its like well its an answer but somebody else already gave that answer so why are you getting reputation for the same answer as the other guy who gave it four years ago people get offended by that right so the reputation system itself adds tension to the system in that the people who have a lot of reputation become very incentivized to enforce the reputation system and for the most part thats good i know it sounds weird but for most parts like look strict systems i think to use stack overflow you have to have the idea that ok strict systems ultimately work better and i do think in programming youre familiar with loose typing versus strict typing right the idea that you can declare a variable not declare a variable rather just start using a variable and ok i see its implicitly an integer bam awesome duck equals 5 well duck is now an integer of 5 right and youre like cool awesome simpler right why would i want to worry about typing and for a long time in the ruby community theyre like yeah this is awesome you just do a bunch of unit testing which is testing your programs validity after the fact to catch any bugs that strict typing of variables would have caught and now you have this thing called typescript for microsoft from the guy who built c sharp anders whos one of the greatest minds in software development right like in terms of language design and says no no no we want to bolt on a strict type system to javascript because it makes things better and now everybodys like oh my god we deployed typescript and found 50 latent bugs that we didnt know about right like this is super common so i think there is a truth in programming that strictness its not the goal were not saying be super strict because strictness is correct no its no no strictness produces better results thats what im saying right so strict typing of variables i would say you almost universally have consensus now is basically correct should be that way in every language right duck equals five should generate an error because no you didnt declare you didnt tell me that duck was an integer right thats a bug right or maybe you mistyped you typed deck instead of duck right you never know this happens all the time right so with that in mind i will say that the strictness of the system is correct now that doesnt mean cruel that doesnt mean mean that doesnt mean angry it just means strict ok so i think where theres misunderstanding is people get cranky right like another question you asked is like why are programmers kind of mean sometimes well who do programmers work with all day long so i have a theory that if youre at a job and you work with assholes all day long what do you eventually become an asshole an asshole and what is the computer except the worlds biggest asshole because the computer has no time for your bullshit the computer the minute you make a mistake everything is crashing down right one semicolon has crashed space missions right so thats normal so you begin to internalize that you begin to think oh my coworker the computer is super strict and kind of a jerk about everything so thats kind of how im going to be because i work with this computer and i have to exceed to its terms on everything so therefore you start to absorb that you start to think oh well being really strict arbitrarily is really good an error of error code 56249 is a completely good error message because thats what the computer gave me right so you kind of forget to be a person at some level and you know how they say great detectives internalize criminals and kind of are criminals themselves like this trope of the master detective is good because he can think like the criminal well i do think thats true of programmers really good programmers think like the computer because thats their job but if you internalize it too much you become the computer you kind of become a jerk to everybody because thats what youve internalized youre almost not a jerk but you have no patience for a lack of strictness as you said its not out of a sense of meanness its accidental but i do believe its an occupational hazard of being a programmer is you start to behave like the computer youre very unforgiving youre very terse youre very oh wrong incorrect move on its like well can you help me what could i do to fix no wrong next question like thats normal for the computer just fail next i dont know if you remember in saturday night live in the 90s they had this character who was an it guy the move guy move move was that jimmy fallon no no who played him ok yeah i remember move right he had no patience for it might have been mad tv actually wasnt it mad tv might have been but anyway thats always been the perception you start to behave like the computer its like oh youre wrong out of the way you know youve written so many blog posts about programming about programs programming programmers what do you think makes a good lets start with what makes a good solo programmer well i dont think you should be a solo programmer i think to be a good solo programmer its kind of like what i talked about well not on mike but one of the things john carmack one of the best points he makes in the book masters of doom which is a fantastic book and anybody listening to this who hasnt read it please read it its such a great book is that at the time they were working on stuff like wolfenstein and doom they didnt have the resources that we have today they didnt have stack overflow they didnt have wikipedia they didnt have discourse forums they didnt have places to go to get people to help them they had to work on their own and thats why it took a genius like carmack to do this stuff because you had to be a genius to invent from first principles a lot of the stuff he was like the hacks he was coming up with were genius genius level stuff but you dont need to be a genius anymore and that means not working by yourself you have to be good at researching stuff online you have to be good at asking questions really good questions that are really well researched which implies oh i went out and researched for three hours before i wrote these questions thats what you should be doing because thats whats going to make you good to me this is the big difference between programming in the 80s versus programming today is you kind of had to be by yourself back then where would you go for answers i remember in the early days when i was learning visual basic for windows i would call the microsoft helpline on the phone when i had programming because i was like i dont know what to do so i would go and call and they had these huge phone banks and im like can you imagine how alien that is now who would do that thats crazy so there was just nowhere else to go when you got stuck i had the books that came with it i read those studied those religiously i just saw a post from steve sanofsky that said the c version 7 came with 10000 pages of written material because where else were you going to figure that stuff out go to the library i mean you didnt have wikipedia you didnt have reddit you didnt have anywhere to go to answer these questions so youve talked about through the years basically not having an ego and not thinking that youre the best programmer in the world so always kind of just looking to improve to become a better programmer than you were yesterday so how have you changed as a programmer and as a thinker designer around programming over the past what is it 15 years really of being a public figure i would say the big insight that i had is eventually as a programmer you have to stop writing code to be effective which is kind of disturbing because you really love it but you realize being effective at programming at programming in the general sense doesnt mean writing code and a lot of times you can be much more successful by not writing code and writing code in terms of just solving the problems you have essentially hiring people that are really good and setting them free and giving them basic direction on strategy and stuff because a lot of the problems you encounter arent necessarily solved through really gnarly code theyre solved by conceptual solutions which can then be turned into code but are you even solving the right problem so i would say for me the main insight i have is to succeed as a programmer you eventually kind of stop writing code thats going to sound discouraging probably to people hearing but i dont mean it that way what i mean is that youre coding at a higher level language eventually like ok so were coding in assembly language thats the beginning right youre hardcoded to the architecture then you have stuff like c where its like wow we can abstract across the architecture we can write code i can then compile that code for arm or whatever x86 or whatever else is out there and then even higher level than that youre looking at python ruby interpreted languages and then to me as a programmer im like ok i want to go even higher i want to go higher than that how do i abstract higher than the language its like well you abstract in spoken language and written language right youre sort of inspiring people to get things done giving them guidance like what if we did this what if we did this youre writing in the highest level language that there is which is for me english whatever your spoken language is so its all about being effective right and i think patrick mckenzie patio11 on hacker news and works at stripe has a great post about this of how calling yourself a programmer is a career limiting move at some level once you get far enough from your career and i really believe that and again i apologize this is sound discouraging i dont mean it to be but hes so right because all the stuff that goes on around the code like the people thats another thing if you look at my early blog entries is about wow programming is about people more than its about code which doesnt really make sense but its about can these people even get along together can they understand each other can you even explain to me what it is youre working on are you solving the right problem peopleware another classic programming book which again up there with code complete please read peopleware its that software is people people are the software first and foremost so a lot of the skills that i was working on early in the blog were about figuring out the people parts of programming which were the harder parts the hard part of programming once you get a certain skill level in programming you can pretty much solve any reasonable problem thats put in front of you youre not writing algorithms from scratch that just doesnt happen so any sort of reasonable problem put in front of you youre going to be able to solve but what you cant solve is our manager is a total jerk you cannot solve that with code that is not a code solvable problem and yet that will cripple you way more than oh we had to use this stupid framework i dont like or sam keeps writing bad code that i hate or dave is off there in the wilderness writing god knows what these are not your problems your problem is your manager or a co worker is so toxic to everybody else in your team that nobody can get anything done because everybodys so stressed out and freaked out these are the problems that you have to attack absolutely and so as you go to these higher level abstractions as youve developed as a programmer to higher and higher level abstractions and go into natural language youre also the guy who preached building it diving in and doing it and learn by doing yes do you worry that as you get to higher and higher level abstractions you lose track of the lower level of just building do you worry about that even not maybe now but 10 years from now 20 years from now well no i mean there is always that paranoia around oh gosh i dont feel its valuable since im not writing code but for me when we started the discourse project it was ruby which i didnt really know ruby i mean as you pointed out and this is another valuable observation in stack overflow you can be super proficient in for example c sharp which i was working in thats what we built stack overflow in and still is written in and then switch to ruby and youre a newbie again but you have the framework i know what a for loop is i know what recursion is i know what a stack trace is i have all the fundamental concepts to be a programmer i just dont know ruby so im still on a higher level im not like a beginner beginner like youre saying im just like i need to apply my programming concepts i already know to ruby well so theres a question thats really interesting so looking at ruby how do you go about learning enough that your intuition can be applied carried over thats what i was trying to get to its like what i realized particularly when i started with just me and robin i realized if i bother robin i am now costing us productivity every time i go to robin rather than building our first alpha version of discourse hes now answering my stupid questions about ruby is that a good use of his time is that a good use of my time and the answer to both of those was resoundingly no we were getting to an alpha and it was pretty much just ok well hire more programmers we eventually hired neil and then eventually sam who came in as a cofounder actually it was sam first then neil later but the answer to the problem is just hire other competent programmers now i shall pull myself up by my bootstraps and learn ruby but at some point writing code becomes a liability to you in terms of getting things done theres so many other things that go on in the project like building the prototype you mentioned well how do you if youre not writing code how does everybody keep focus on what are we building well first basic mockups and research what do we even want to build theres a little bit of that that goes on but then very quickly you get to the prototype stage like build a prototype lets iterate on the prototype really really rapidly and thats what we do with discourse and thats what we demoed to get our seed funding for discourse was the alpha version of discourse that we had running and ready to go and it was very it was bad i mean it was ill just tell you it was bad we have screenshots of it im just embarrassed to look at it now but it was the prototype we were figuring out whats working whats not working because theres such a broad gap between the way you think things will work in your mind or even on paper and the way they work once you sit and live in the software like actually spend time living and breathing in software so different so my philosophy is get to a prototype and then what youre really optimizing for is speed of iteration like how you can turn the crank how quickly can we iterate thats the absolutely critical metric of any software project and i had a tweet recently that people liked and i totally this is so fundamental to what i do is like if you want to measure the core competency of any software tech company its the speed at which somebody can say hey we really need this word in the product change this word right because it will be more clear to the user like instead of respond its reply or something but theres some from the conception of that idea to how quickly that single word can be changed in your software and rolled out to users that is your life cycle thats your health your heartbeat if your heartbeat is like super slow youre basically dead no seriously like if it takes two weeks or even a month to get that single word changed everybodys like oh my god this is a great idea that word is so much clearer im talking about like a super like everybodys on board for this change its not like lets just change a word because were bored its like this is an awesome change and then it takes months to roll out its like well youre dead you cant iterate you cant how are you going to do anything right so anyway about the heartbeat its like get the prototype and then iterate on it thats what i view as the central tenet of modern software development thats fascinating that you put it that way so i work and i build autonomous vehicles and when you look at what maybe compare tesla to most other automakers the heart beat for tesla is literally days now in terms of they can over the air deploy software updates to all their vehicles which is markedly different than every other automaker which takes years to update a piece of software and thats reflected in everything thats the final product thats reflected in really how slowly they adapt to the times and to be clear im not saying being a hummingbird is the goal either', 'the following is a conversation with eric schmidt he was the ceo of google for 10 years and a chairman for six more guiding the company through an incredible period of growth and a series of world changing innovations he is one of the most impactful leaders in the era of the internet and the powerful voice for the promise of technology in our society it was truly an honor to speak with him as part of the mit course on artificial general intelligence and the artificial intelligence podcast and now heres my conversation with eric schmidt what was the first moment when you fell in love with technology i grew up in the 1960s as a boy where every boy wanted to be an astronaut and part of the space program so like everyone else of my age we would go out to the cow pasture behind my house which was literally a cow pasture and we would shoot model rockets off and that i think is the beginning and of course generationally today it would be video games and all the amazing things that you can do online with computers theres a transformative inspiring aspect of science and math that maybe rockets would bring would instill in individuals youve mentioned yesterday that eighth grade math is where the journey through mathematical universe diverges from many people its this fork in the roadway theres a professor of math at berkeley edward frankel he im not sure if youre familiar with him i am he has written this amazing book i recommend to everybody called love and math two of my favorite words he says that if painting was taught like math then the students would be asked to paint a fence which is his analogy of essentially how math is taught and so you never get a chance to discover the beauty of the art of painting or the beauty of the art of math so how when and where did you discover that beauty i think what happens with people like myself is that your math enabled pretty early and all of a sudden you discover that you can use that to discover new insights the great scientists will all tell a story the men and women who are fantastic today that somewhere when they were in high school or in college they discovered that they could discover something themselves and that sense of building something of having an impact that you own drives knowledge acquisition and learning in my case it was programming and the notion that i could build things that had not existed that i had built that it had my name on it and this was before open source but you could think of it as open source contributions so today if i were a 16 or 17 year old boy im sure that i would aspire as a computer scientist to make a contribution like the open source heroes of the world today that would be what would be driving me and id be trying and learning and making mistakes and so forth in the ways that it works the repository that github represents and that open source libraries represent is an enormous bank of knowledge of all of the people who are doing that and one of the lessons that i learned at google was that the world is a very big place and theres an awful lot of smart people and an awful lot of them are underutilized so heres an opportunity for example building parts of programs building new ideas to contribute to the greater of society so in that moment in the 70s the inspiring moment where there was nothing and then you created something through programming that magical moment so in 1975 i think youve created a program called lex which i especially like because my name is lex so thank you thank you for creating a brand that established a reputation thats long lasting reliable and has a big impact on the world and still used today so thank you for that but more seriously in that time in the 70s as an engineer personal computers were being born do you think youd be able to predict the 80s 90s and the aughts of where computers would go im sure i could not and would not have gotten it right i was the beneficiary of the great work of many many people who saw it clearer than i did with lex i worked with a fellow named michael lesk who was my supervisor and he essentially helped me architect and deliver a system thats still in use today after that i worked at xerox palo alto research center where the alto was invented and the alto is the predecessor of the modern personal computer or macintosh and so forth and the altos were very rare and i had to drive an hour from berkeley to go use them but i made a point of skipping classes and doing whatever it took to have access to this extraordinary achievement i knew that they were consequential what i did not understand was scaling i did not understand what would happen when you had 100 million as opposed to 100 and so the since then and i have learned the benefit of scale i always look for things which are going to scale to platforms right so mobile phones android all those things there are the world is in numerous there are many many people in the world people really have needs they really will use these platforms and you can build big businesses on top of them so its interesting so when you see a piece of technology now you think what will this technology look like when its in the hands of a billion people thats right so an example would be that the market is so competitive now that if you cant figure out a way for something to have a million users or a billion users it probably is not going to be successful because something else will become the general platform and your idea will become a lost idea or a specialized service with relatively few users so its a path to generality its a path to general platform use its a path to broad applicability now there are plenty of good businesses that are tiny so luxury goods for example but if you want to have an impact at scale you have to look for things which are of common value common pricing common distribution and solve common problems theyre problems that everyone has and by the way people have lots of problems information medicine health education and so forth work on those problems like you said youre a big fan of the middle class because theres so many of them theres so many of them by definition so any product any thing that has a huge impact and improves their lives is a great business decision and its just good for society and theres nothing wrong with starting off in the high end as long as you have a plan to get to the middle class theres nothing wrong with starting with a specialized market in order to learn and to build and to fund things so you start with a luxury market to build a general purpose market but if you define yourself as only a narrow market someone else can come along with a general purpose market that can push you to the corner can restrict the scale of operation can force you to be a lesser impact than you might be so its very important to think in terms of broad businesses and broad impact even if you start in a little corner somewhere so as you look to the 70s but also in the decades to come and you saw computers did you see them as tools or was there a little element of another entity i remember a quote saying ai began with our dream to create the gods is there a feeling when you wrote that program that you were creating another entity giving life to something i wish i could say otherwise but i simply found the technology platforms so exciting thats what i was focused on i think the majority of the people that ive worked with and there are a few exceptions steve jobs being an example really saw this as a great technological play i think relatively few of the technical people understood the scale of its impact so i used ncp which is a predecessor to tcpip it just made sense to connect things we didnt think of it in terms of the internet and then companies and then facebook and then twitter and then politics and so forth we never did that build we didnt have that vision and i think most people its a rare person who can see compounding at scale most people can see if you ask people to predict the future theyll give you an answer of six to nine months or 12 months because thats about as far as people can imagine but theres an old saying which actually was attributed to a professor at mit a long time ago that we overestimate what can be done in one year and we underestimate what can be done in a decade and theres a great deal of evidence that these core platforms at hardware and software take a decade right so think about self driving cars self driving cars were thought about in the 90s there were projects around them the first darpa grand challenge was roughly 2004 so thats roughly 15 years ago and today we have self driving cars operating in a city in arizona right its 15 years and we still have a ways to go before theyre more generally available so youve spoken about the importance you just talked about predicting into the future youve spoken about the importance of thinking five years ahead and having a plan for those five years the way to say it is that almost everybody has a one year plan almost no one has a proper five year plan and the key thing to having a five year plan is to having a model for whats going to happen under the underlying platforms so heres an example moores law as we know it the thing that powered improvements in cpus has largely halted in its traditional shrinking mechanism because the costs have just gotten so high its getting harder and harder but theres plenty of algorithmic improvements and specialized hardware improvements so you need to understand the nature of those improvements and where theyll go in order to understand how it will change the platform in the area of network connectivity what are the gains that are gonna be possible in wireless it looks like theres an enormous expansion of wireless connectivity at many different bands and that we will primarily historically ive always thought that we were primarily gonna be using fiber but now it looks like were gonna be using fiber plus very powerful high bandwidth sort of short distance connectivity to bridge the last mile thats an amazing achievement if you know that then youre gonna build your systems differently by the way those networks have different latency properties right because theyre more symmetric the algorithms feel faster for that reason and so when you think about whether its a fiber or just technologies in general so theres this barber wooden poem or quote that i really like its from the champions of the impossible rather than the slaves of the possible that evolution draws its creative force so in predicting the next five years id like to talk about the impossible and the possible well and again one of the great things about humanity is that we produce dreamers right we literally have people who have a vision and a dream they are if you will disagreeable in the sense that they disagree with the they disagree with what the sort of zeitgeist is they say there is another way they have a belief they have a vision if you look at science science is always marked by such people who went against some conventional wisdom collected the knowledge at the time and assembled it in a way that produced a powerful platform and youve been amazingly honest about in an inspiring way about things youve been wrong about predicting and youve obviously been right about a lot of things but in this kind of tension how do you balance as a company in predicting the next five years the impossible planning for the impossible so listening to those crazy dreamers letting them do letting them run away and make the impossible real make it happen and slow you know thats how programmers often think and slowing things down and saying well this is the rational this is the possible the pragmatic the dreamer versus the pragmatist so its helpful to have a model which encourages a predictable revenue stream as well as the ability to do new things so in googles case were big enough and well enough managed and so forth that we have a pretty good sense of what our revenue will be for the next year or two at least for a while and so we have enough cash generation that we can make bets and indeed google has become alphabet so the corporation is organized around these bets and these bets are in areas of fundamental importance to the world whether its artificial intelligence medical technology self driving cars connectivity through balloons on and on and on and theres more coming and more coming so one way you could express this is that the current business is successful enough that we have the luxury of making bets and another one that you could say is that we have the wisdom of being able to see that a corporate structure needs to be created to enhance the likelihood of the success of those bets so we essentially turned ourselves into a conglomerate of bets and then this underlying corporation google which is itself innovative so in order to pull this off you have to have a bunch of belief systems and one of them is that you have to have bottoms up and tops down the bottoms up we call 20 time and the idea is that people can spend 20 of the time whatever they want and the top down is that our founders in particular have a keen eye on technology and theyre reviewing things constantly so an example would be theyll hear about an idea or ill hear about something and it sounds interesting lets go visit them and then lets begin to assemble the pieces to see if thats possible and if you do this long enough you get pretty good at predicting whats likely to work so thats a beautiful balance that struck is this something that applies at all scale it seems to be that sergey again 15 years ago came up with a concept called 10 of the budget should be on things that are unrelated it was called 70 20 10 70 of our time on core business 20 on adjacent business and 10 on other and he proved mathematically of course hes a brilliant mathematician that you needed that 10 to make the sum of the growth work and it turns out he was right so getting into the world of artificial intelligence youve talked quite extensively and effectively to the impact in the near term the positive impact of artificial intelligence whether its especially machine learning in medical applications and education and just making information more accessible right in the ai community there is a kind of debate theres this shroud of uncertainty as we face this new world with artificial intelligence in it and theres some people like elon musk youve disagreed at least on the degree of emphasis he places on the existential threat of ai so ive spoken with stuart russell max tegmark who share elon musks view and yoshua bengio steven pinker who do not and so theres a lot of very smart people who are thinking about this stuff disagreeing which is really healthy of course so what do you think is the healthiest way for the ai community to and really for the general public to think about ai and the concern of the technology being mismanaged in some kind of way so the source of education for the general public has been robot killer movies right and terminator et cetera and the one thing i can assure you were not building are those kinds of solutions furthermore if they were to show up someone would notice and unplug them right so as exciting as those movies are and theyre great movies were the killer robots to start we would find a way to stop them right so im not concerned about that and much of this has to do with the timeframe of conversation so you can imagine a situation 100 years from now when the human brain is fully understood and the next generation and next generation of brilliant mit scientists have figured all this out were gonna have a large number of ethics questions right around science and thinking and robots and computers and so forth and so on so it depends on the question of the timeframe in the next five to 10 years were not facing those questions what were facing in the next five to 10 years is how do we spread this disruptive technology as broadly as possible to gain the maximum benefit of it the primary benefits should be in healthcare and in education healthcare because its obvious were all the same even though we somehow believe were not as a medical matter the fact that we have big data about our health will save lives allow us to deal with skin cancer and other cancers ophthalmological problems theres people working on psychological diseases and so forth using these techniques i can go on and on the promise of ai in medicine is extraordinary there are many many companies and startups and funds and solutions and we will all live much better for that the same argument in education can you imagine that for each generation of child and even adult you have a tutor educator thats ai based thats not a human but is properly trained that helps you get smarter helps you address your language difficulties or your math difficulties or what have you why dont we focus on those two the gains societally of making humans smarter and healthier are enormous and those translate for decades and decades and well all benefit from them there are people who are working on ai safety which is the issue that youre describing and there are conversations in the community that should there be such problems what should the rules be like google for example has announced its policies with respect to ai safety which i certainly support and i think most everybody would support and they make sense right so it helps guide the research but the killer robots are not arriving this year and theyre not even being built and on that line of thinking you said the time scale in this topic or other topics have you found it useful on the business side or the intellectual side to think beyond five 10 years to think 50 years out has it ever been useful or productive in our industry there are essentially no examples of 50 year predictions that have been correct lets review ai right ai which was largely invented here at mit and a couple of other universities in the 1956 1957 1958 the original claims were a decade or two and when i was a phd student i studied ai a bit and it entered during my looking at it a period which is known as ai winter which went on for about 30 years which is a whole generation of science scientists and a whole group of people who didnt make a lot of progress because the algorithms had not improved and the computers had not approved it took some brilliant mathematicians starting with a fellow named jeff hinton at toronto and montreal who basically invented this deep learning model which empowers us today the seminal work there was 20 years ago and in the last 10 years its become popularized so think about the timeframes for that level of discovery its very hard to predict many people think that well be flying around in the equivalent of flying cars who knows my own view if i wanna go out on a limb is to say that we know a couple of things about 50 years from now we know that therell be more people alive we know that well have to have platforms that are more sustainable because the earth is limited in the ways we all know and that the kind of platforms that are gonna get built will be consistent with the principles that ive described they will be much more empowering of individuals theyll be much more sensitive to the ecology because they have to be they just have to be i also think that humans are gonna be a great deal smarter and i think theyre gonna be a lot smarter because of the tools that ive discussed with you and of course people will live longer life extension is continuing apace a baby born today has a reasonable chance of living to 100 which is pretty exciting its well past the 21st century so we better take care of them and you mentioned an interesting statistic on some very large percentage 60 70 of people may live in cities today more than half the world lives in cities and one of the great stories of humanity in the last 20 years has been the rural to urban migration this has occurred in the united states its occurred in europe its occurring in asia and its occurring in africa when people move to cities the cities get more crowded but believe it or not their health gets better their productivity gets better their iq and educational capabilities improve so its good news that people are moving to cities but we have to make them livable and safe so you first of all you are but youve also worked with some of the greatest leaders in the history of tech what insights do you draw from the difference in leadership styles of yourself steve jobs elon musk larry page now the new ceo sandra pichai and others from the i would say calm sages to the mad geniuses one of the things that i learned as a young executive is that theres no single formula for leadership they try to teach one but thats not how it really works there are people who just understand what they need to do and they need to do it quickly those people are often entrepreneurs they just know and they move fast there are other people who are systems thinkers and planners thats more who i am somewhat more conservative more thorough in execution a little bit more risk of risk a little bit more risk averse theres also people who are sort of slightly insane in the sense that they are emphatic and charismatic and they feel it and they drive it and so forth theres no single formula to success there is one thing that unifies all of the people that you named which is very high intelligence at the end of the day the thing that characterizes all of them is that they saw the world quicker faster they processed information faster they didnt necessarily make the right decisions all the time but they were on top of it and the other thing thats interesting about all those people is they all started young so think about steve jobs starting apple roughly at 18 or 19 think about bill gates starting at roughly 20 21 think about by the time they were 30 mark zuckerberg a good example at 19 20 by the time they were 30 they had 10 years at 30 years old they had 10 years of experience of dealing with people and products and shipments and the press and business and so forth its incredible how much experience they had compared to the rest of us who were busy getting our phds yes exactly so we should celebrate these people because theyve just had more life experience right and that helps inform the judgment at the end of the day when youre at the top of these organizations all the easy questions have been dealt with right how should we design the buildings where should we put the colors on our product what should the box look like right the problems thats why its so interesting to be in these rooms the problems that they face right in terms of the way they operate the way they deal with their employees their customers their innovation are profoundly challenging each of the companies is demonstrably different culturally they are not in fact cut of the same they behave differently based on input their internal cultures are different their compensation schemes are different their values are different so theres proof that diversity works so so when faced with a tough decision in need of advice its been said that the best thing one can do is to find the best person in the world who can give that advice and find a way to be in a room with them one on one and ask so here we are and let me ask in a long winded way i wrote this down in 1998 there were many good search engines lycos excite altavista infoseek ask jeeves maybe yahoo even so google stepped in and disrupted everything they disrupted the nature of search the nature of our access to information the way we discover new knowledge so now its 2018 actually 20 years later there are many good personal ai assistants including of course the best from google so youve spoken in medical and education the impact of such an ai assistant could bring so we arrive at this question so its a personal one for me but i hope my situation represents that of many other as we said dreamers and the crazy engineers so my whole life ive dreamed of creating such an ai assistant every step ive taken has been towards that goal now im a research scientist in human centered ai here at mit so the next step for me as i sit here so facing my passion is to do what larry and sergey did in 98 this simple startup and so heres my simple question given the low odds of success the timing and luck required the countless other factors that cant be controlled or predicted which is all the things that larry and sergey faced is there some calculation some strategy to follow in this step or do you simply follow the passion just because theres no other choice i think the people who are in universities are always trying to study the extraordinarily chaotic nature of innovation and entrepreneurship my answer is that they didnt have that conversation they just did it they sensed a moment when in the case of google there was all of this data that needed to be organized and they had a better algorithm they had invented a better way so today with human centered ai which is your area of research there must be new approaches its such a big field there must be new approaches different from what we and others are doing there must be startups to fund there must be research projects to try there must be graduate students to work on new approaches here at mit there are people who are looking at learning from the standpoint of looking at child learning how do children learn starting at age one and two and the work is fantastic those approaches are different from the approach that most people are taking perhaps thats a bet that you should make or perhaps theres another one but at the end of the day the successful entrepreneurs are not as crazy as they sound they see an opportunity based on whats happened lets use uber as an example as travis sells the story he and his co founder were sitting in paris and they had this idea because they couldnt get a cab and they said we have smartphones and the rest is history so whats the equivalent of that travis eiffel tower where is a cab moment that you could as an entrepreneur take advantage of whether its in human centered ai or something else thats the next great startup and the psychology of that moment so when sergey and larry talk about and listen to a few interviews its very nonchalant well heres the very fascinating web data and heres an algorithm we have for we just kind of want to play around with that data and it seems like thats a really nice way to organize this data i should say what happened to remember is that they were graduate students at stanford and they thought this was interesting so they built a search engine and they kept it in their room and they had to get power from the room next door because they were using too much power in the room so they ran an extension cord over right and then they went and they found a house and they had google world headquarters of five people right to start the company and they raised 100000 from andy bechtolsheim who was the sun founder to do this and dave cheriton and a few others the point is their beginnings were very simple but they were based on a powerful insight that is a replicable model for any startup it has to be a powerful insight the beginnings are simple and there has to be an innovation in larry and sergeys case it was pagerank which was a brilliant idea one of the most cited papers in the world today whats the next one so youre one of if i may say richest people in the world and yet it seems that money is simply a side effect of your passions and not an inherent goal but youre a fascinating person to ask so much of our society at the individual level and at the company level and as nations is driven by the desire for wealth what do you think about this drive and what have you learned about if i may romanticize the notion the meaning of life having achieved success on so many dimensions there have been many studies of human happiness and above some threshold which is typically relatively low for this conversation theres no difference in happiness about money the happiness is correlated with meaning and purpose a sense of family a sense of impact so if you organize your life assuming you have enough to get around and have a nice home and so forth youll be far happier if you figure out what you care about and work on that its often being in service to others theres a great deal of evidence that people are happiest when theyre serving others and not themselves this goes directly against the sort of press induced excitement about powerful and wealthy leaders of one kind and indeed these are consequential people but if you are in a situation where youve been very fortunate as i have you also have to take that as a responsibility and you have to basically work both to educate others and give them that opportunity but also use that wealth to advance human society in my case im particularly interested in using the tools of artificial intelligence and machine learning to make society better ive mentioned education ive mentioned inequality and middle class and things like this all of which are a passion of mine it doesnt matter what you do it matters that you believe in it that its important to you and that your life will be far more satisfying if you spend your life doing that i think theres no better place to end than a discussion of the meaning of life eric thank you so much', 'the following is a conversation with stuart russell hes a professor of computer science at uc berkeley and a coauthor of a book that introduced me and millions of other people to the amazing world of ai called artificial intelligence a modern approach so it was an honor for me to have this conversation as part of mit course in artificial general intelligence and the artificial intelligence podcast if you enjoy it please subscribe on youtube itunes or your podcast provider of choice or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with stuart russell so youve mentioned in 1975 in high school youve created one of your first ai programs that play chess were you ever able to build a program that beat you at chess or another board game so my program never beat me at chess i actually wrote the program at imperial college so i used to take the bus every wednesday with a box of cards this big and shove them into the card reader and they gave us eight seconds of cpu time it took about five seconds to read the cards in and compile the code so we had three seconds of cpu time which was enough to make one move you know with a not very deep search and then we would print that move out and then wed have to go to the back of the queue and wait to feed the cards in again how deep was the search are we talking about one move two moves three moves no i think we got an eight move a depth eight with alpha beta and we had some tricks of our own about move ordering and some pruning of the tree but you were still able to beat that program yeah yeah i was a reasonable chess player in my youth i did an othello program and a backgammon program so when i got to berkeley i worked a lot on what we call meta reasoning which really means reasoning about reasoning and in the case of a game playing program you need to reason about what parts of the search tree youre actually going to explore because the search tree is enormous bigger than the number of atoms in the universe and the way programs succeed and the way humans succeed is by only looking at a small fraction of the search tree and if you look at the right fraction you play really well if you look at the wrong fraction if you waste your time thinking about things that are never going to happen moves that no ones ever going to make then youre going to lose because you wont be able to figure out the right decision so that question of how machines can manage their own computation how they decide what to think about is the meta reasoning question and we developed some methods for doing that and very simply the machine should think about whatever thoughts are going to improve its decision quality we were able to show that both for othello which is a standard two player game and for backgammon which includes dice rolls so its a two player game with uncertainty for both of those cases we could come up with algorithms that were actually much more efficient than the standard alpha beta search which chess programs at the time were using and that those programs could beat me and i think you can see the same basic ideas in alpha go and alpha zero today the way they explore the tree is using a form of meta reasoning to select what to think about based on how useful it is to think about it is there any insights you can describe with our greek symbols of how do we select which paths to go down theres really two kinds of learning going on so as you say alpha go learns to evaluate board positions so it can look at a go board and it actually has probably a superhuman ability to instantly tell how promising that situation is to me the amazing thing about alpha go is not that it can be the world champion with its hands tied behind his back but the fact that if you stop it from searching altogether so you say okay youre not allowed to do any thinking ahead you can just consider each of your legal moves and then look at the resulting situation and evaluate it so what we call a depth one search so just the immediate outcome of your moves and decide if thats good or bad that version of alpha go can still play at a professional level and human professionals are sitting there for five 10 minutes deciding what to do and alpha go in less than a second can instantly intuit what is the right move to make based on its ability to evaluate positions and that is remarkable because we dont have that level of intuition about go we actually have to think about the situation so anyway that capability that alpha go has is one big part of why it beats humans the other big part is that its able to look ahead 40 50 60 moves into the future and if it was considering all possibilities 40 or 50 or 60 moves into the future that would be 10 to the 200 possibilities so way more than atoms in the universe and so on so its very very selective about what it looks at so let me try to give you an intuition about how you decide what to think about its a combination of two things one is how promising it is so if youre already convinced that a move is terrible theres no point spending a lot more time convincing yourself that its terrible because its probably not going to change your mind so the real reason you think is because theres some possibility of changing your mind about what to do and its that changing your mind that would result then in a better final action in the real world so thats the purpose of thinking is to improve the final action in the real world so if you think about a move that is guaranteed to be terrible you can convince yourself its terrible youre still not going to change your mind but on the other hand suppose you had a choice between two moves one of them youve already figured out is guaranteed to be a draw lets say and then the other one looks a little bit worse it looks fairly likely that if you make that move youre going to lose but theres still some uncertainty about the value of that move theres still some possibility that it will turn out to be a win then its worth thinking about that so even though its less promising on average than the other move which is a good move its worth thinking about on average than the other move which is guaranteed to be a draw theres still some purpose in thinking about it because theres a chance that you will change your mind and discover that in fact its a better move so its a combination of how good the move appears to be and how much uncertainty there is about its value the more uncertainty the more its worth thinking about because theres a higher upside if you want to think of it that way and of course in the beginning especially in the alphago zero formulation everything is shrouded in uncertainty so youre really swimming in a sea of uncertainty so it benefits you to i mean actually following the same process as you described but because youre so uncertain about everything you basically have to try a lot of different directions yeah so the early parts of the search tree are fairly bushy that it will look at a lot of different possibilities but fairly quickly the degree of certainty about some of the moves i mean if a move is really terrible youll pretty quickly find out right you lose half your pieces or half your territory and then youll say okay this is not worth thinking about anymore and then so further down the tree becomes very long and narrow and youre following various lines of play 10 20 30 40 50 moves into the future and that again is something that human beings have a very hard time doing mainly because they just lack the short term memory you just cant remember a sequence of moves thats 50 moves long and you cant imagine the board correctly for that many moves into the future of course the top players im much more familiar with chess but the top players probably have they have echoes of the same kind of intuition instinct that in a moments time alphago applies when they see a board i mean theyve seen those patterns human beings have seen those patterns before at the top at the grandmaster level it seems that there is some similarities or maybe its our imagination creates a vision of those similarities but it feels like this kind of pattern recognition that the alphago approaches are using is similar to what human beings at the top level are using i think theres theres some truth to that but not entirely yeah i mean i think the the extent to which a human grandmaster can reliably instantly recognize the right move and instantly recognize the value of the position i think thats a little bit overrated but if you sacrifice a queen for example i mean theres these theres these beautiful games of chess with bobby fischer somebody where its seeming to make a bad move and im not sure theres a perfect degree of calculation involved where theyve calculated all the possible things that happen but theres an instinct there right that somehow adds up to yeah so i think what happens is you you you get a sense that theres some possibility in the position even if you make a weird looking move that it opens up some some lines of of calculation that otherwise would be definitely bad and and its that intuition that theres something here in this position that might might yield a win and then you follow that right and and in some sense when a when a chess player is following a line and in his or her mind theyre theyre mentally simulating what the other person is going to do what the opponent is going to do and they can do that as long as the moves are kind of forced right as long as theres you know theres a a fort we call a forcing variation where the opponent doesnt really have much choice how to respond and then you follow that how to respond and then you see if you can force them into a situation where you win you know we see plenty of mistakes even even in grandmaster games where they just miss some simple three four five move combination that you know wasnt particularly apparent in in the position but was still there thats the thing that makes us human yeah so when you mentioned that in othello those games were after some matter reasoning improvements and research was able to beat you how did that make you feel part of the meta reasoning capability that it had was based on learning and and you could sit down the next day and you could just feel that it had got a lot smarter you know and all of a sudden you really felt like youre sort of pressed against the wall because it was it was much more aggressive and and was totally unforgiving of any minor mistake that you might make and and actually it seemed understood the game better than i did and gary kasparov has this quote where during his match against deep blue he said he suddenly felt that there was a new kind of intelligence across the board do you think thats a scary or an exciting possibility for for kasparov and for yourself in in the context of chess purely sort of in this like that feeling whatever that is i think its definitely an exciting feeling you know this is what made me work on ai in the first place was as soon as i really understood what a computer was i wanted to make it smart you know i started out with the first program i wrote was for the sinclair programmable calculator and i think you could write a 21 step algorithm that was the biggest program you could write something like that and do little arithmetic calculations so i think i implemented newtons method for a square roots and a few other things like that but then you know i thought okay if i just had more space i could make this thing intelligent and so i started thinking about ai and and i think the the the thing thats scary is not is not the chess program because you know chess programs theyre not in the taking over the world business but if you extrapolate you know there are things about chess that dont resemble the real world right we know we know the rules of chess the chess board is completely visible to the program where of course the real world is not most most of the real world is is not visible from wherever youre sitting so to speak and to overcome those kinds of problems you need qualitatively different algorithms another thing about the real world is that you know we we regularly plan ahead on the timescales involving billions or trillions of steps now we dont plan those in detail but you know when you choose to do a phd at berkeley thats a five year commitment and that amounts to about a trillion motor control steps that you will eventually be committed to including going up the stairs opening doors drinking water yeah i mean every every finger movement while youre typing every character of every paper and the thesis and everything so youre not committing in advance to the specific motor control steps but youre still reasoning on a timescale that will eventually reduce to trillions of motor control actions and so for all of these reasons you know alphago and deep blue and so on dont represent any kind of threat to humanity but they are a step towards it right and progress in ai occurs by essentially removing one by one these assumptions that make problems easy like the assumption of complete observability of the situation right we remove that assumption you need a much more complicated kind of computing design it needs it needs something that actually keeps track of all the things you cant see and tries to estimate whats going on and theres inevitable uncertainty in that so it becomes a much more complicated problem but you know we are removing those assumptions we are starting to have algorithms that can cope with much longer timescales that can cope with uncertainty that can cope with partial observability and so each of those steps sort of magnifies by a thousand the range of things that we can do with ai systems so the way i started in ai i wanted to be a psychiatrist for a long time i wanted to understand the mind in high school and of course program and so on and i showed up university of illinois to an ai lab and they said okay i dont have time for you but heres a book ai and modern approach i think it was the first edition at the time here go go go learn this and i remember the lay of the land was well its incredible that we solved chess but well never solve go i mean it was pretty certain that go in the way we thought about systems that reason wasnt possible to solve and now weve solved this so its a very well i think i would have said that its unlikely we could take the kind of algorithm that was used for chess and just get it to scale up and work well for go and at the time what we thought was that in order to solve go we would have to do something similar to the way humans manage the complexity of go which is to break it down into kind of sub games so when a human thinks about a go board they think about different parts of the board as sort of weakly connected to each other and they think about okay within this part of the board heres how things could go in that part of board heres how things could go and then you try to sort of couple those two analyses together and deal with the interactions and maybe revise your views of how things are going to go in each part and then youve got maybe five six seven ten parts of the board and that actually resembles the real world much more than chess does because in the real world we have work we have home life we have sport different kinds of activities shopping these all are connected to each other but theyre weakly connected so when im typing a paper i dont simultaneously have to decide which order im going to get the milk and the butter that doesnt affect the typing but i do need to realize okay i better finish this before the shops close because i dont have anything i dont have any food at home so theres some weak connection but not in the way that chess works where everything is tied into a single stream of thought so the thought was that to solve go wed have to make progress on stuff that would be useful for the real world and in a way alphago is a little bit disappointing right because the program designed for alphago is actually not that different from deep blue or even from arthur samuels checker playing program from the 1950s and in fact the two things that make alphago work is one is this amazing ability to evaluate the positions and the other is the meta reasoning capability which allows it to explore some paths in the tree very deeply and to abandon other paths very quickly including yourself because youre on camera now and your voice is coming through with high resolution yeah so you could take what im saying and replace it with pretty much anything else you wanted me to be saying and its a very simple thing take what im saying and replace it with pretty much anything else you wanted me to be saying and even it would change my lips and facial expressions to fit and theres actually not much in the way of real legal protection against that i think in the commercial area you could say yeah youre using my brand and so on there are rules about that but in the political sphere i think at the moment anything goes that could be really really damaging and let me just try to make not an argument but try to look back at history and say something dark in essence is while regulation seems to be oversight seems to be exactly the right thing to do here it seems that human beings what they naturally do is they wait for something to go wrong if youre talking about nuclear weapons you cant talk about nuclear weapons being dangerous until somebody actually like the united states drops the bomb or chernobyl melting do you think we will have to wait for things going wrong in a way thats obviously damaging to society not an existential risk but obviously damaging or do you have faith that i hope not but i think we do have to look at history and so the two examples you gave nuclear weapons and nuclear power are very very interesting because nuclear weapons we knew in the early years of the 20th century that atoms contained a huge amount of energy we had e equals mc squared we knew the mass differences between the different atoms and their components and we knew that you might be able to make an incredibly powerful explosive so hg wells wrote science fiction book i think in 1912 frederick soddy who was the guy who discovered isotopes the nobel prize winner he gave a speech in 1915 saying that one pound of this new explosive would be the equivalent of 150 tons of dynamite which turns out to be about right and this was in world war i so he was imagining how much worse the world war would be if we were using that kind of explosive but the physics establishment simply refused to believe that these things could be made including the people who are making it well so they were doing the nuclear physics i mean eventually were the ones who made it you talk about fermi or whoever well so up to the development was mostly theoretical so it was people using sort of primitive kinds of particle acceleration and doing experiments at the level of single particles or collections of particles they werent yet thinking about how to actually make a bomb or anything like that but they knew the energy was there and they figured if they understood it better it might be possible but the physics establishment their view and i think because they did not want it to be true their view was that it could not be true that this could not not provide a way to make a super weapon and there was this famous speech given by rutherford who was the sort of leader of nuclear physics and it was on september 11th 1933 and he said anyone who talks about the possibility of obtaining energy from transformation of atoms is talking complete moonshine and the next morning leo szilard read about that speech and then invented the nuclear chain reaction and so as soon as he invented as soon as he had that idea that you could make a chain reaction with neutrons because neutrons were not repelled by the nucleus so they could enter the nucleus and then continue the reaction as soon as he has that idea he instantly realized that the world was in deep doo doo because this is 1933 right hitler had recently come to power in germany szilard was in london and eventually became a refugee and came to the us and in the process of having the idea about the chain reaction he figured out basically how to make a bomb and also how to make a reactor and he patented the reactor in 1934 but because of the situation the great power conflict situation that he could see happening he kept that a secret and so between then and the beginning of world war ii people were working including the germans on how to actually create neutron sources what specific fission reactions would produce neutrons of the right energy to continue the reaction and that was demonstrated in germany i think in 1938 if i remember correctly the first nuclear weapon patent was 1939 by the french so this was actually going on well before world war ii really got going and then the british probably had the most advanced capability in this area but for safety reasons among others and just resources they moved the program from britain to the us and then that became manhattan project so the reason why we couldnt have any kind of oversight of nuclear weapons and nuclear technology was because we were basically already in an arms race and a war lr but you mentioned then in the 20s and 30s so what are the echoes the way youve described this story i mean theres clearly echoes why do you think most ai researchers folks who are really close to the metal they really are not concerned about ai they dont think about it whether its they dont want to think about it but why do you think that is is what are the echoes of the nuclear situation to the current ai situation and what can we do about it bf i think there is a kind of motivated cognition which is a term in psychology means that you believe what you would like to be true rather than what is true and its unsettling to think that what youre working on might be the end of the human race obviously so you would rather instantly deny it and come up with some reason why it couldnt be true and i have i collected a long list of reasons that extremely intelligent competent ai scientists have come up with for why we shouldnt worry about this for example calculators are superhuman at arithmetic and they havent taken over the world so theres nothing to worry about well okay my five year old you know could have figured out why that was an unreasonable and really quite weak argument another one was while its theoretically possible that you could have superhuman ai destroy the world its also theoretically possible that a black hole could materialize right next to the earth and destroy humanity i mean yes its theoretically possible quantum theoretically extremely unlikely that it would just materialize right there but thats a completely bogus analogy because you know if the whole physics community on earth was working to materialize a black hole in near earth orbit right wouldnt you ask them is that a good idea is that going to be safe you know what if you succeed right and thats the thing right the ai community is sort of refused to ask itself what if you succeed and initially i think that was because it was too hard but you know alan turing asked himself that and he said wed be toast right if we were lucky we might be able to switch off the power but probably wed be toast but theres also an aspect that because were not exactly sure what the future holds its not clear exactly so technically what to worry about sort of how things go wrong and so there is something it feels like maybe you can correct me if im wrong but theres something paralyzing about worrying about something that logically is inevitable but you have to think about it logically is inevitable but you dont really know what that will look like yeah i think thats its a reasonable point and you know its certainly in terms of existential risks its different from you know asteroid collides with the earth right which again is quite possible you know its happened in the past itll probably happen again we dont know right now but if we did detect an asteroid that was going to hit the earth in 75 years time wed certainly be doing something about it well its clear theres got big rock and theres well probably have a meeting and see what do we do about the big rock with ai right with ai i mean there are very few people who think its not going to happen within the next 75 years i know rod brooks doesnt think its going to happen maybe andrew ng doesnt think its happened but you know a lot of the people who work day to day you know as you say at the rock face they think its going to happen i think the median estimate from ai researchers is somewhere in 40 to 50 years from now or maybe you know i think in asia they think its going to be even faster than that im a little bit more conservative i think itd probably take longer than that but i think you know as happened with nuclear weapons it can happen overnight that you have these breakthroughs and we need more than one breakthrough but you know its on the order of half a dozen i mean this is a very rough scale but sort of half a dozen breakthroughs of that nature would have to happen for us to reach the superhuman ai but the you know the ai research community is vast now the massive investments from governments from corporations tons of really really smart people you know you just have to look at the rate of progress in different areas of ai to see that things are moving pretty fast so to say oh its just going to be thousands of years i dont see any basis for that you know i see you know for example the stanford 100 year ai project right which is supposed to be sort of you know the serious establishment view their most recent report actually said its probably not even possible oh wow right which if you want a perfect example of people in denial thats it because you know for the whole history of ai weve been saying to philosophers who said it wasnt possible well you have no idea what youre talking about of course its possible right give me an argument for why it couldnt happen and there isnt one right and now because people are worried that maybe ai might get a bad name or i just dont want to think about this theyre saying okay well of course its not really possible you know imagine if you know the leaders of the cancer biology community got up and said well you know of course curing cancer its not really possible thered be complete outrage and dismay and you know i find this really a strange phenomenon so okay so if you accept that its possible and if you accept that its probably going to happen the point that youre making that you know how does it go wrong a valid question without that without an answer to that question then youre stuck with what i call the gorilla problem which is you know the problem that the gorillas face right they made something more intelligent than them namely us a few million years ago and now theyre in deep doo doo so theres really nothing they can do theyve lost the control they failed to solve the control problem of controlling humans and so theyve lost so we dont want to be in that situation and if the gorilla problem is the only formulation you have theres not a lot you can do right other than to say okay we should try to stop you know we should just not make the humans or in this case not make the ai and i think thats really hard to do im not actually proposing that thats a feasible course of action i also think that you know if properly controlled ai could be incredibly beneficial but it seems to me that theres a consensus that one of the major failure modes is this loss of control that we create ai systems that are pursuing incorrect objectives and because the ai system believes it knows what the objective is it has no incentive to listen to us anymore so to speak right its just carrying out the strategy that it has computed as being the optimal solution and you know it may be that in the process it needs to acquire more resources to increase the possibility of success or prevent various failure modes by defending itself against interference and so that collection of problems i think is something we can address the other problems are roughly speaking you know misuse right so even if we solve the control problem we make perfectly safe controllable ai systems well why you know why does dr evil going to use those right he wants to just take over the world and hell make unsafe ai systems that then get out of control so thats one problem which is sort of a you know partly a policing problem partly a sort of a cultural problem for the profession of how we teach people what kinds of ai systems are safe you talk about autonomous weapon system and how pretty much everybody agrees that theres too many ways that that can go horribly wrong this great slaughterbots movie that kind of illustrates that beautifully i want to talk about that thats another theres another topic im having to talk about i just want to mention that what i see is the third major failure mode which is overuse not so much misuse but overuse of ai that we become overly dependent so i call this the wall e problem so if youve seen wall e the movie all right all the humans are on the spaceship and the machines look after everything for them and they just watch tv and drink big gulps and theyre all sort of obese and stupid and they sort of totally lost any notion of human autonomy and you know so in effect right this would happen like the slow boiling frog right we would gradually turn over more and more of the management of our civilization to machines as we are already doing and this you know if this if this process continues you know we sort of gradually switch from sort of being the masters of technology to just being the guests right so we become guests on a cruise ship you know which is fine for a week but not not for the rest of eternity you know and its almost irreversible right once you once you lose the incentive to for example you know learn to be an engineer or a doctor or a sanitation operative or any other of the infinitely many ways that we maintain and propagate our civilization you know if you if you dont have the incentive to do any of that you wont and then its really hard to recover and of course as just one of the technologies that could that third failure mode result in that theres probably other technology in general detaches us from it does a bit but the difference is that in terms of the knowledge to to run our civilization you know up to now weve had no alternative but to put it into peoples heads right and if you software with google i mean so software in general so computers in general but but the you know the knowledge of how you know how a sanitation system works you know thats an ai has to understand that its no good putting it into google so i mean we weve always put knowledge in on paper but paper doesnt run our civilization and only runs when it goes from the paper into peoples heads again right so weve always propagated civilization through human minds and weve spent about a trillion person years doing that i literally write you you can work it out its about right theres about just over 100 billion people whove ever lived and each of them has spent about 10 years learning stuff to keep their civilization going and so thats a trillion person years we put into this effort beautiful way to describe all civilization and now were you know were in danger of throwing that away so this is a problem that ai cant solve its not a technical problem its you know if we do our job right the ai systems will say you know the human race doesnt in the long run want to be passengers in a cruise ship the human race wants autonomy this is part of human preferences so we the ai systems are not going to do this stuff for you youve got to do it for yourself right im not going to carry you to the top of everest in an autonomous helicopter you have to climb it if you want to get the benefit and so on so but im afraid that because we are short sighted and lazy were going to override the ai systems and and theres an amazing short story that i recommend to everyone that i talked to about this called the machine stops written in 1909 by em forster who you know wrote novels about the british empire and sort of things that became costume dramas on the bbc but he wrote this one science fiction story which is an amazing vision of the future it has basically ipads it has video conferencing it has moocs it has computer induced obesity i mean literally its what people spend their time doing is giving online courses or listening to online courses and talking about ideas but they never get out there in the real world they dont really have a lot of face to face contact everything is done online you know so all the things were worrying about now were described in the story and and then the human race becomes more and more dependent on the machine loses knowledge of how things really run and then becomes vulnerable to collapse and so its a its a pretty unbelievably amazing story for someone writing in 1909 to imagine all this so theres very few people that represent artificial intelligence more than you stuart russell if you say its okay thats very kind so its all my fault right youre often brought up as the person well stuart russell like the ai person is worried about this thats why you should be worried about it do you feel the burden of that i dont know if you feel that at all but when i talk to people like from you talk about people outside of computer science when they think about this stuart russell is worried about ai safety you should be worried too do you feel the burden of that i mean in a practical sense yeah because i get you know a dozen sometimes 25 invitations a day to talk about it to give interviews to write press articles and so on so in that very practical sense im seeing that people are concerned and really interested about this are you worried that you could be wrong as all good scientists are of course i worry about that all the time i mean thats thats always been the way that i ive worked you know is like i have an argument in my head with myself right so i have i have some idea and then i think okay how could that be wrong or did someone else already have that idea so ill go and you know search in as much literature as i can to see whether someone else already thought of that or or even refuted it so you know i right now im im reading a lot of philosophy because you know in in the form of the debates over over utilitarianism and and other kinds of moral moral formulas shall we say people have already thought through some of these issues but you know what one of the things im im not seeing in a lot of these debates is this specific idea about the importance of uncertainty in the objective that this is the way we should think about machines that are beneficial to humans so this idea of provably beneficial machines based on explicit uncertainty in the objective you know it seems to be you know my gut feeling is this is the core of it its going to have to be elaborated in a lot of different directions and there are a lot of beneficial yeah but there there are i mean it has to be right we cant afford you know hand wavy beneficial because there are you know whenever we do hand wavy stuff there are loopholes and the thing about super intelligent machines is they find the loopholes you know just like you know tax evaders if you dont write your tax law properly people will find the loopholes and end up paying no tax and and so you should think of it this way and and getting those definitions right you know it is really a long process you know so you can you can define mathematical frameworks and within that framework you can prove mathematical theorems that yes this will you know this this theoretical entity will be provably beneficial to that theoretical entity but that framework may not match the real world in some crucial way so its a long process thinking through it iterating and so on last question yep you have 10 seconds to answer it what is your favorite sci fi movie about ai i would say interstellar has my favorite robots oh beats space yeah yeah yeah so so tars the robots one of the robots in interstellar is the way robot should behave and uh i would say ex machina is in some ways the one the one that makes you think uh in a nervous kind of way about about where were going well stuart thank you so much for talking today pleasure so this word meta reasoning while technically correct inspires perhaps the wrong degree of power that alphago has for example the word reasoning is a powerful word so let me ask you sort of you were part of the symbolic ai world for a while like ai was theres a lot of excellent interesting ideas there that unfortunately met a winter and so do you think it reemerges so i would say yeah its not quite as simple as that so the ai winter for the first winter that was actually named as such was the one in the late 80s and that came about because in the mid 80s there was a really a concerted attempt to push ai out into the real world using what was called expert system technology and for the most part that technology was just not ready for primetime they were trying in many cases to do a form of uncertain reasoning judgment combinations of evidence diagnosis those kinds of things which was simply invalid and when you try to apply invalid reasoning methods to real problems you can fudge it for small versions of the problem but when it starts to get larger the thing just falls apart so many companies found that the stuff just didnt work and they were spending tons of money on consultants to try to make it work and there were other practical reasons like they were asking the companies to buy incredibly expensive lisp machine workstations which were literally between 50000 and 100000 in 1980s money which would be like between 150000 and 300000 per workstation in current prices and then the bottom line they werent seeing a profit from it yeah in many cases i think there were some successes theres no doubt about that but people i would say overinvested every major company was starting an ai department just like now and i worry a bit that we might see similar disappointments not because the current technology is invalid but its limited in its scope and its almost the duel of the scope problems that expert systems had so what have you learned from that hype cycle and what can we do to prevent another winter for example yeah so when im giving talks these days thats one of the warnings that i give so this is a two part warning slide one is that rather than data being the new oil data is the new snake oil thats a good line and then the other is that we might see a kind of very visible failure in some of the major application areas and i think self driving cars would be the flagship and i think when you look at the history so the first self driving car was on the freeway driving itself changing lanes overtaking in 1987 and so its more than 30 years and that kind of looks like where we are today right you know prototypes on the freeway changing lanes and overtaking now i think thats one of the things thats been made particularly on the perception side so we worked a lot on autonomous vehicles in the early mid 90s at berkeley and we had our own big demonstrations we put congressmen into self driving cars and had them zooming along the freeway and the problem was clearly perception at the time the problem was perception yeah so in simulation with perfect perception you could actually show that you can drive safely for a long time even if the other cars are misbehaving and so on but simultaneously we worked on machine vision for detecting cars and tracking pedestrians and so on and we couldnt get the cars to do that and so we had to do that for pedestrians and so on and we couldnt get the reliability of detection and tracking up to a high enough level particularly in bad weather conditions nighttime rainfall good enough for demos but perhaps not good enough to cover the general operation yeah so the thing about driving is you know suppose youre a taxi driver you know and you drive every day eight hours a day for 10 years right thats 100 million seconds of driving you know and any one of those seconds you can make a fatal mistake so youre talking about eight nines of reliability right now if your vision system only detects 983 of the vehicles right then thats sort of you know one in a bit nines of reliability so you have another seven orders of magnitude to go and this is what people dont understand they think oh because i had a successful demo im pretty much done but youre not even within seven orders of magnitude of being done and thats the difficulty and its not the can i follow a white line thats not the problem right we follow a white line all the way across the country but its the weird stuff that happens its all the edge cases yeah the edge case other drivers doing weird things you know so if you talk to google right so they had actually a very classical architecture where you know you had machine vision which would detect all the other cars and pedestrians and the white lines and the road signs and then basically that was fed into a logical database and then you had a classical 1970s rule based expert system telling you okay if youre in the middle lane and theres a bicyclist in the right lane who is signaling this then you do that right and what they found was that every day theyd go out and thered be another situation that the rules didnt cover you know so theyd come to a traffic circle and theres a little girl riding her bicycle the wrong way around the traffic circle okay what do you do we dont have a rule oh my god okay stop and then you know they come back and add more rules and they just found that this was not really converging and if you think about it right how do you deal with an unexpected situation meaning one that youve never previously encountered and the sort of reasoning required to figure out the solution for that situation has never been done it doesnt match any previous situation in terms of the kind of reasoning you have to do well you know in chess programs this happens all the time right youre constantly coming up with situations you havent seen before and you have to reason about them and you have to think about okay here are the possible things i could do here are the outcomes heres how desirable the outcomes are and then pick the right one you know in the 90s we were saying okay this is how youre going to have to do automated vehicles theyre going to have to have a look ahead capability but the look ahead for driving is more difficult than it is for chess because theres humans and theyre less predictable than chess pieces well then you have an opponent in chess whos also somewhat unpredictable but for example in chess you always know the opponents intention theyre trying to beat you right whereas in driving you dont know is this guy trying to turn left or has he just forgotten to turn off his turn signal or is he drunk or is he changing the channel on his radio or whatever it might be youve got to try and figure out the mental state the intent of the other drivers to forecast the possible evolutions of their trajectories and then youve got to figure out okay which is the trajectory for me thats going to be safest and those all interact with each other because the other drivers are going to react to your trajectory and so on so you know theyve got the classic merging onto the freeway problem where youre kind of racing a vehicle thats already on the freeway and youre going to pull ahead of them or youre going to let them go first and pull in behind and you get this sort of uncertainty about whos going first so all those kinds of things mean that you need a decision making architecture thats very different from either a rule based system or it seems to me kind of an end to end neural network system so just as alphago is pretty good when it doesnt do any look ahead but its way way way way better when it does i think the same is going to be true for driving you can have a driving system thats pretty good when it doesnt do any look ahead but thats not good enough and weve already seen multiple deaths caused by poorly designed machine learning algorithms that dont really understand what theyre doing yeah on several levels i think on the perception side theres mistakes being made by those algorithms where the perception is very shallow on the planning side the look ahead like you said and the thing that we come up against thats really interesting when you try to deploy systems in the real world is you cant think of an artificial intelligence system as a thing that responds to the world always you have to realize that its an agent that others will respond to as well so in order to drive successfully you cant just try to do obstacle avoidance right you cant pretend that youre invisible right youre the invisible car right it doesnt work that way i mean but you have to assert yet others have to be scared of you just were all theres this tension theres this game so if we study a lot of work with pedestrians if you approach pedestrians as purely an obstacle avoidance so youre doing look ahead as in modeling the intent that theyre not going to theyre going to take advantage of you theyre not going to respect you at all there has to be a tension a fear some amount of uncertainty thats how we have created or at least just a kind of a resoluteness you have to display a certain amount of resoluteness you cant be too tentative and yeah so the solutions then become pretty complicated right you get into game theoretic analyses and so at berkeley now were working a lot on this kind of interaction between machines and humans and thats exciting and so my colleague ankur dragan actually if you formulate the problem game theoretically you just let the system figure out the solution it does interesting unexpected things like sometimes at a stop sign if no one is going first the car will actually back up a little right and just to indicate to the other cars that they should go and thats something it invented entirely by itself we didnt say this is the language of communication at stop signs it figured it out thats really interesting so let me one just step back for a second just this beautiful philosophical notion so pamela mccordick in 1979 wrote ai began with the ancient wish to forge the gods so when you think about the history of our civilization do you think that there is an inherent desire to create lets not say gods but to create superintelligence is it inherent to us is it in our genes that the natural arc of human civilization is to create things that are of greater and greater power and perhaps echoes of ourselves so to create the gods as pamela said maybe i mean were all individuals but certainly we see over and over again in history individuals who thought about this possibility hopefully when im not being too philosophical here but if you look at the arc of this where this is going and well talk about ai safety well talk about greater and greater intelligence do you see that there in when you created the othello program and you felt this excitement what was that excitement was it excitement of a tinkerer who created something cool like a clock or was there a magic or was it more like a child being born yeah so i mean i certainly understand that viewpoint and if you look at the lighthill report which was so in the 70s there was a lot of controversy in the uk about ai and whether it was for real and how much money the government should invest and there was a long story but the government commissioned a report by lighthill who was a physicist and he wrote a very damning report about ai which i think was the point and he said that these are frustrated men who are unable to have children would like to create and create a life as a kind of replacement which i think is really pretty unfair but there is a kind of magic i would say when you build something and what youre building in is really just youre building in some understanding of the principles of learning and decision making and to see those principles actually then turn into intelligent behavior in specific situations its an incredible thing and that is naturally going to make you think okay where does this end and so theres magical optimistic views of where it ends whatever your view of optimism is whatever your view of utopia is its probably different for everybody but youve often talked about concerns you have of how things may go wrong so ive talked to max tegmark theres a lot of interesting ways to think about ai safety youre one of the seminal people thinking about this problem amongst sort of being in the weeds of actually solving specific ai problems youre also thinking about the big picture of where are we going so can you talk about several elements of it lets just talk about maybe the control problem so this idea of losing ability to control the behavior in our ai system so how do you see that how do you see that coming about what do you think we can do to manage it well so it doesnt take a genius to realize that if you make something thats smarter than you you might have a problem alan turing wrote about this and gave lectures about this in 1951 he did a lecture on the radio and he basically says once the machine thinking method starts very quickly theyll outstrip humanity and if were lucky we might be able to turn off the power at strategic moments but even so our species would be humbled actually he was wrong about that if its sufficiently intelligent machine its not going to let you switch it off its actually in competition with you so what do you think is most likely going to happen what do you think is meant just for a quick tangent if we shut off this super intelligent machine that our species will be humbled i think he means that we would realize that we are inferior right that we only survive by the skin of our teeth because we happen to get to the off switch just in time and if we hadnt then we would have lost control over the earth are you more worried when you think about this stuff about super intelligent ai or are you more worried about super powerful ai thats not aligned with our values so the paperclip scenarios kind of so the main problem im working on is the control problem the problem of machines pursuing objectives that are as you say not aligned with human objectives and this has been the way weve thought about ai since the beginning you build a machine for optimizing and then you put in some objective and it optimizes right and we can think of this as the king midas problem right because if the king midas put in this objective everything i touch should turn to gold and the gods thats like the machine they said okay done you now have this power and of course his father his drink and his family all turned to gold and then he dies of misery and starvation and its a warning its a failure mode that pretty much every culture in history has had some story along the same lines theres the genie that gives you three wishes and the third wish is always you know please undo the first two wishes because i messed up and when arthur samuel wrote his checker playing program which learned to play checkers considerably better than arthur samuel could play and actually reached a pretty decent standard norbert wiener who was one of the major mathematicians of the 20th century hes sort of the father of modern automation control systems he saw this and he basically extrapolated as turing did and said okay this is how we could lose control and specifically that we have to be certain that the purpose we put into the machine is the purpose which we really desire and the problem is we cant do that you mean were not its a very difficult to encode to put our values on paper is really difficult or youre just saying its impossible so theoretically its possible but in practice its extremely unlikely that we could specify correctly in advance the full range of concerns of humanity you talked about cultural transmission of values i think is how humans to human transmission of values happens right well we learn yeah i mean as we grow up we learn about the values that matter how things should go what is reasonable to pursue and what isnt reasonable to pursue you think machines can learn in the same kind of way yeah so i think that what we need to do is to get away from this idea that you build an optimising machine and then you put the objective into it because if its possible that you might put in a wrong objective and we already know this is possible because its happened lots of times right that means that the machine should never take an objective thats given as gospel truth because once it takes the objective as gospel truth then it believes that whatever actions its taking in pursuit of that objective are the correct things to do so you could be jumping up and down and saying no no no no youre going to destroy the world but the machine knows what the true objective is and is pursuing it and tough luck to you and this is not restricted to ai right this is i think many of the 20th century technologies right so in statistics you minimise a loss function the loss function is exogenously specified in control theory you minimise a cost function in operations research you maximise a reward function and so on so in all these disciplines this is how we conceive of the problem and its the wrong problem because we cannot specify with certainty the correct objective right we need uncertainty we need the machine to be uncertain about what it is that its supposed to be maximising favourite idea of yours ive heard you say somewhere well i shouldnt pick favourites but it just sounds beautiful we need to teach machines humility its a beautiful way to put it i love it that theyre humble they know that they dont know what it is theyre supposed to be doing and that those objectives i mean they exist theyre within us but we may not be able to we may not be able to explicate them we may not even know how we want our future to go exactly and the machine a machine thats uncertain is going to be deferential to us so if we say dont do that well now the machines learn something a bit more about our true objectives because something that it thought was reasonable in pursuit of our objective turns out not to be so now its learned something so its going to defer because it wants to be doing what we really want and that point i think is absolutely central to solving the control problem and its a different kind of ai when you take away this idea that the objective is known then in fact a lot of the theoretical frameworks that were so familiar with you know markov decision processes goal based planning you know standard games research all of these techniques actually become inapplicable and you get a more complicated problem because now the interaction with the human becomes part of the problem because the human by making choices is giving you more information about the true objective and that information helps you achieve the objective better and so that really means that youre mostly dealing with game theoretic problems where youve got the machine and the human and theyre coupled together rather than a machine going off by itself with a fixed objective lw which is fascinating on the machine and the human level that we when you dont have an objective means youre together coming up with an objective i mean theres a lot of philosophy that you know you could argue that life doesnt really have meaning we together agree on what gives it meaning and we kind of culturally create things that give why the heck we are on this earth anyway we together as a society create that meaning and you have to learn that objective and one of the biggest i thought thats where you were going to go for a second one of the biggest troubles we run into outside of statistics and machine learning and ai and just human civilization is when you look at i came from i was born in the soviet union and the history of the 20th century we ran into the most trouble us humans when there was a certainty about the objective and you do whatever it takes to achieve that objective whether youre talking about germany or communist russia you get into trouble with humans i would say with you know corporations in fact some people argue that you know we dont have to look forward to a time when ai systems take over the world they already have and they call corporations right that corporations happen to be using people as components right now but they are effectively algorithmic machines and theyre optimizing an objective which is quarterly profit that isnt aligned with overall wellbeing of the human race and they are destroying the world they are primarily responsible for our inability to tackle climate change so i think thats one way of thinking about whats going on with corporations but i think the point youre making is valid that there are many systems in the real world where weve sort of prematurely fixed on the objective and then decoupled the machine from those thats supposed to be serving and i think you see this with government right government is supposed to be a machine that serves people but instead it tends to be taken over by people who have their own objective and use government to optimize that objective regardless of what people want do you find appealing the idea of almost arguing machines where you have multiple ai systems with a clear fixed objective we have in government the red team and the blue team theyre very fixed on their objectives and they argue and they kind of may disagree but it kind of seems to make it work somewhat that the duality of it okay lets go a hundred years back when there was still was going on or at the founding of this country there was disagreements and that disagreement is where so it was a balance between certainty and forced humility because the power was distributed yeah i think that the nature of debate and disagreement argument takes as a premise the idea that you could be wrong which means that youre not necessarily absolutely convinced that your objective is the correct one if you were absolutely convinced thered be no point in having any discussion or argument because you would never change your mind and there wouldnt be any sort of synthesis or anything like that i think you can think of argumentation as an implementation of a form of uncertain reasoning ive been reading recently about utilitarianism and the history of efforts to define in a sort of clear mathematical way if you like a formula for moral or political decision making its really interesting that the parallels between the philosophical discussions going back 200 years and what you see now in discussions about existential risk because its almost exactly the same someone would say okay well heres a formula for how we should make decisions utilitarianism is roughly each person has a utility function and then we make decisions to maximize the sum of everybodys utility then people point out well in that case the best policy is one that leads to the enormously vast population all of whom are living a life thats barely worth living this is called the repugnant conclusion another version is that we should maximize pleasure and thats what we mean by utility then youll get people effectively saying well in that case we might as well just have everyone hooked up to a heroin drip they didnt use those words but that debate was happening in the 19th century as it is now about ai that if we get the formula wrong were going to have ai systems working towards an outcome that in retrospect would be exactly wrong do you think theres as beautifully put so the echoes are there but do you think i mean if you look at sam harris our imagination worries about the ai version of that because of the speed at which the things going wrong in the utilitarian context could happen is that a worry for you yeah i think that in most cases not in all but if we have a wrong political idea we see it starting to go wrong and were not completely stupid and so we say okay maybe that was a mistake lets try something different also were very slow and inefficient about implementing these things and so on so you have to worry when you have corporations or political systems that are extremely efficient but when we look at ai systems or even just computers in general they have this different characteristic from ordinary human activity in the past so lets say you were a surgeon you had some idea about how to do some operation well and lets say you were wrong that way of doing the operation would mostly kill the patient well youd find out pretty quickly like after three maybe three or four tries but that isnt true for pharmaceutical companies because they dont do three or four operations they manufacture three or four billion pills and they sell them and then they find out maybe six months or a year later that oh people are dying of heart attacks or getting cancer from this drug and so thats why we have the fda right because of the scalability of pharmaceutical production and there have been some unbelievably bad episodes in the history of pharmaceuticals and adulteration of products and so on that have killed tens of thousands or paralyzed hundreds of thousands of people now with computers we have that same scalability problem that you can sit there and type for i equals one to five billion do right and all of a sudden youre having an impact on a global scale and yet we have no fda right theres absolutely no controls at all over what a bunch of undergraduates with too much caffeine can do to the world and we look at what happened with facebook well social media in general and click through optimization so you have a simple feedback algorithm thats trying to just optimize click through right that sounds reasonable right because you dont want to be feeding people ads that they dont care about or not interested in and you might even think of that process as simply adjusting the feeding of ads or news articles or whatever it might be to match peoples preferences right which sounds like a good idea but in fact that isnt how the algorithm works right you make more money the algorithm makes more money if it can better predict what people are going to click on because then it can feed them exactly that right so the way to maximize click through is actually to modify the people to make them more predictable and one way to do that is to feed them information which will change their behavior and preferences towards extremes that make them predictable whatever is the nearest extreme or the nearest predictable point thats where youre going to end up and the machines will force you there and i think theres a reasonable argument to say that this among other things is contributing to the destruction of democracy in the world and where was the oversight of this process where were the people saying okay you would like to apply this algorithm to 5 billion people on the face of the earth can you show me that its safe can you show me that it wont have various kinds of negative effects no there was no one asking that question there was no one placed between the undergrads with too much caffeine and the human race they just did it but some way outside the scope of my knowledge so economists would argue that the what is it the invisible hand so the capitalist system it was the oversight so if youre going to corrupt society with whatever decision you make as a company then thats going to be reflected in people not using your product thats one model of oversight we shall see but in the meantime but you might even have broken the political system that enables capitalism to function well youve changed it we shall see change is often painful so my question is absolutely its fascinating youre absolutely right that there was zero oversight on algorithms that can have a profound civilization changing effect so do you think its possible i mean i havent have you seen government so do you think its possible to create regulatory bodies oversight over ai algorithms which are inherently such cutting edge set of ideas and technologies yeah but i think it takes time to figure out what kind of oversight what kinds of controls i mean it took time to design the fda regime you know and some people still dont like it and they want to fix it and i think there are clear ways that it could be improved but the whole notion that you have stage one stage two stage three and here are the criteria for what you have to do to pass a stage one trial right we havent even thought about what those would be for algorithms so i mean i think there are things we could do right now with regard to bias for example we have a pretty good technical handle on how to detect algorithms that are propagating bias that exists in data sets how to de bias those algorithms and even what its going to cost you to do that so i think we could start having some standards on that i think there are things to do with impersonation and falsification that we could work on fakes yeah a very simple point so impersonation is a machine acting as if it was a person i cant see a real justification for why we shouldnt insist that machines self identify as machines where is the social benefit in fooling people into thinking that this is really a person when it isnt i dont mind if it uses a human like voice thats easy to understand thats fine but it should just say im a machine in some form and how many people are speaking to that i would think relatively obvious facts yeah i mean there is actually a law in california that bans impersonation but only in certain restricted circumstances so for the purpose of engaging in a fraudulent transaction and for the purpose of modifying someones voting behavior so those are the circumstances where machines have to self identify but i think arguably it should be in all circumstances and then when you talk about deep fakes were just at the beginning but already its possible to make a movie of anybody saying anything in ways that are pretty hard to detect', 'the following is a conversation with peter abbeel hes a professor at uc berkeley and the director of the berkeley robotics learning lab hes one of the top researchers in the world working on how we make robots understand and interact with the world around them especially using imitation and deep reinforcement learning this conversation is part of the mit course on artificial general intelligence and the artificial intelligence podcast if you enjoy it please subscribe on youtube itunes or your podcast provider of choice or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with peter abbeel youve mentioned that if there was one person you could meet it would be roger federer so let me ask when do you think well have a robot that fully autonomously can beat roger federer at tennis roger federer level player at tennis well first if you can make it happen for me to meet roger let me know in terms of getting a robot to beat him at tennis its kind of an interesting question because for a lot of the challenges we think about in ai the software is really the missing piece but for something like this the hardware is nowhere near either to really have a robot that can physically run around the boston dynamics robots are starting to get there but still not really human level ability to run around and then swing a racket so you think thats a hardware problem i dont think its a hardware problem only i think its a hardware and a software problem i think its both and i think theyll have independent progress so id say the hardware maybe in 10 15 years on clay not grass i mean grass is probably harder with the sliding yeah with the clay im not sure whats harder grass or clay the clay involves sliding which might be harder to master actually yeah but youre not limited to a bipedal i mean im sure theres no well if we can build a machine its a whole different question of course if you can say okay this robot can be on wheels it can move around on wheels and can be designed differently then i think that can be done sooner probably than a full humanoid type of setup what do you think of swing a racket so youve worked at basic manipulation how hard do you think is the task of swinging a racket would be able to hit a nice backhand or a forehand lets say we just set up stationary a nice robot arm lets say a standard industrial arm and it can watch the ball come and then swing the racket its a good question im not sure it would be super hard to do i mean im sure it would require a lot if we do it with reinforcement learning it would require a lot of trial and error its not gonna swing it right the first time around but yeah i dont see why i couldnt swing it the right way i think its learnable i think if you set up a ball machine lets say on one side and then a robot with a tennis racket on the other side i think its learnable and maybe a little bit of pre training and simulation yeah i think thats feasible i think the swing the racket is feasible itd be very interesting to see how much precision it can get cause i mean thats where i mean some of the human players can hit it on the lines which is very high precision with spin the spin is an interesting whether rl can learn to put a spin on the ball well you got me interested maybe someday well set this up sure you got me intrigued your answer is basically okay for this problem it sounds fascinating but for the general problem of a tennis player we might be a little bit farther away whats the most impressive thing youve seen a robot do in the physical world so physically for me its the boston dynamics videos always just bring home and just super impressed recently the robot running up the stairs doing the parkour type thing i mean yes we dont know whats underneath they dont really write a lot of detail but even if its hard coded underneath which it might or might not be just the physical abilities of doing that parkour thats a very impressive so have you met spot mini or any of those robots in person met spot mini last year in april at the mars event that jeff bezos organizes they brought it out there and it was nicely following around jeff when jeff left the room they had it follow him along which is pretty impressive so i think theres some confidence to know that theres no learning going on in those robots the psychology of it so while knowing that while knowing theres not if theres any learning going on its very limited i met spot mini earlier this year and knowing everything thats going on having one on one interaction so i got to spend some time alone and theres immediately a deep connection on the psychological level even though you know the fundamentals how it works theres something magical so do you think about the psychology of interacting with robots in the physical world even you just showed me the pr2 the robot and there was a little bit something like a face had a little bit something like a face theres something that immediately draws you to it do you think about that aspect of the robotics problem well its very hard with brad here well give him a name berkeley robot for the elimination of tedious tasks its very hard to not think of the robot as a person and it seems like everybody calls him a he for whatever reason but that also makes it more a person than if it was a it and it seems pretty natural to think of it that way this past weekend really struck me ive seen pepper many times on videos but then i was at an event organized by this was by fidelity and they had scripted pepper to help moderate some sessions and they had scripted pepper to have the personality of a child a little bit and it was very hard to not think of it as its own person in some sense because it would just jump in the conversation making it very interactive moderate would be saying pepper would just jump in hold on how about me can i participate in this too and youre just like okay this is like a person and that was 100 scripted and even then it was hard not to have that sense of somehow there is something there so as we have robots interact in this physical world is that a signal that could be used in reinforcement learning youve worked a little bit in this direction but do you think that psychology can be somehow pulled in yes thats a question i would say a lot of people ask and i think part of why they ask it is theyre thinking about how unique are we really still as people like after they see some results they see a computer play go they see a computer do this that theyre like okay but can it really have emotion can it really interact with us in that way and then once youre around robots you already start feeling it and i think that kind of maybe mythologically the way that i think of it is if you run something like reinforcement learning its about optimizing some objective and theres no reason that the objective couldnt be tied into how much does a person like interacting with this system and why could not the reinforcement learning system optimize for the robot being fun to be around and why wouldnt it then naturally become more and more interactive and more and more maybe like a person or like a pet i dont know what it would exactly be but more and more have those features and acquire them automatically as long as you can formalize an objective of what it means to like something what how you exhibit whats the ground truth how do you get the reward from human because you have to somehow collect that information within you human but youre saying if you can formulate as an objective it can be learned theres no reason it couldnt emerge through learning and maybe one way to formulate as an objective you wouldnt have to necessarily score it explicitly so standard rewards are numbers and numbers are hard to come by this is a 15 or a 17 on some scale its very hard to do for a person but much easier is for a person to say okay what you did the last five minutes was much nicer than what you did the previous five minutes and that now gives a comparison and in fact there have been some results on that for example paul christiano and collaborators at openai had the hopper mojoko hopper a one legged robot going through backflips purely from feedback i like this better than that thats kind of equally good and after a bunch of interactions it figured out what it was the person was asking for namely a backflip and so i think the same thing oh it wasnt trying to do a backflip it was just getting a comparison score from the person based on person having in mind in their own mind i wanted to do a backflip but the robot didnt know what it was supposed to be doing it just knew that sometimes the person said this is better this is worse and then the robot figured out what the person was actually after was a backflip and id imagine the same would be true for things like more interactive robots that the robot would figure out over time oh this kind of thing apparently is appreciated more than this other kind of thing so when i first picked up suttons richard suttons reinforcement learning book before sort of this deep learning before the reemergence of neural networks as a powerful mechanism for machine learning rl seemed to me like magic it was beautiful so that seemed like what intelligence is rl reinforcement learning so how do you think we can possibly learn anything about the world when the reward for the actions is delayed is so sparse like where is why do you think rl works why do you think you can learn anything under such sparse rewards whether its regular reinforcement learning or deep reinforcement learning whats your intuition the counterpart of that is why is rl why does it need so many samples so many experiences to learn from because really whats happening is when you have a sparse reward you do something maybe for like i dont know you take 100 actions and then you get a reward and maybe you get like a score of three and im like okay three not sure what that means you go again and now you get two and now you know that that sequence of 100 actions that you did the second time around somehow was worse than the sequence of 100 actions you did the first time around but thats tough to now know which one of those were better or worse some might have been good and bad in either one and so thats why it needs so many experiences but once you have enough experiences effectively rl is teasing that apart its trying to say okay what is consistently there when you get a higher reward and whats consistently there when you get a lower reward and then kind of the magic of sometimes the policy gradient update is to say now lets update the neural network to make the actions that were kind of present when things are good more likely and make the actions that are present when things are not as good less likely so that is the counterpoint but it seems like you would need to run it a lot more than you do even though right now people could say that rl is very inefficient but it seems to be way more efficient than one would imagine on paper that the simple updates to the policy the policy gradient that somehow you can learn exactly you just said what are the common actions that seem to produce some good results that that somehow can learn anything it seems counterintuitive at least is there some intuition behind it yeah so i think theres a few ways to think about this the way i tend to think about it mostly originally so when we started working on deep reinforcement learning here at berkeley which was maybe 2011 12 13 around that time john schulman was a phd student initially kind of driving it forward here and the way we thought about it at the time was if you think about rectified linear units or kind of rectifier type neural networks what do you get you get something thats piecewise linear feedback control and if you look at the literature linear feedback control is extremely successful can solve many many problems surprisingly well i remember for example when we did helicopter flight if youre in a stationary flight regime not a non stationary but a stationary flight regime like hover you can use linear feedback control to stabilize a helicopter very complex dynamical system but the controller is relatively simple and so i think thats a big part of it is that if you do feedback control even though the system you control can be very very complex often relatively simple control architectures can already do a lot but then also just linear is not good enough and so one way you can think of these neural networks is that sometimes they tile the space which people were already trying to do more by hand or with finite state machines say this linear controller here this linear controller here neural network learns to tile the space and say linear controller here another linear controller here but its more subtle than that and so its benefiting from this linear control aspect its benefiting from the tiling but its somehow tiling it one dimension at a time because if lets say you have a two layer network if in that hidden layer you make a transition from active to inactive or the other way around that is essentially one axis but not axis aligned but one direction that you change and so you have this kind of very gradual tiling of the space where you have a lot of sharing between the linear controllers that tile the space and that was always my intuition as to why to expect that this might work pretty well its essentially leveraging the fact that linear feedback control is so good but of course not enough and this is a gradual tiling of the space with linear feedback controls that share a lot of expertise across them so thats really nice intuition but do you think that scales to the more and more general problems of when you start going up the number of dimensions when you start going down in terms of how often you get a clean reward signal does that intuition carry forward to those crazier weirder worlds that we think of as the real world so i think where things get really tricky in the real world compared to the things weve looked at so far with great success in reinforcement learning is the time scales which takes us to an extreme so when you think about the real world i mean i dont know maybe some student decided to do a phd here right okay thats a decision thats a very high level decision but if you think about their lives i mean any persons life its a sequence of muscle fiber contractions and relaxations and thats how you interact with the world and thats a very high frequency control thing but its ultimately what you do and how you affect the world until i guess we have brain readings and you can maybe do it slightly differently but typically thats how you affect the world and the decision of doing a phd is so abstract relative to what youre actually doing in the world and i think thats where credit assignment becomes just completely beyond what any current rl algorithm can do and we need hierarchical reasoning at a level that is just not available at all yet where do you think we can pick up hierarchical reasoning by which mechanisms yeah so maybe let me highlight what i think the limitations are of what already was done 20 30 years ago in fact youll find reasoning systems that reason over relatively long horizons but the problem is that they were not grounded in the real world so people would have to hand design some kind of logical dynamical descriptions of the world and that didnt tie into perception and so it didnt tie into real objects and so forth and so that was a big gap now with deep learning we start having the ability to really see with sensors process that and understand whats in the world and so its a good time to try to bring these things together i see a few ways of getting there one way to get there would be to say deep learning can get bolted on somehow to some of these more traditional approaches now bolted on would probably mean you need to do some kind of end to end training where you say my deep learning processing somehow leads to a representation that in term uses some kind of traditional underlying dynamical systems that can be used for planning and thats for example the direction aviv tamar and thanard kuretach here have been pushing with causal info again and of course other people too thats one way can we somehow force it into the form factor that is amenable to reasoning another direction weve been thinking about for a long time and didnt make any progress on was more information theoretic approaches so the idea there was that what it means to take high level action is to take and choose a latent variable now that tells you a lot about whats gonna be the case in the future because thats what it means to take a high level action i say okay i decide im gonna navigate to the gas station because i need to get gas for my car well thatll now take five minutes to get there but the fact that i get there i could already tell that from the high level action i took much earlier that we had a very hard time getting success with not saying its a dead end necessarily but we had a lot of trouble getting that to work and then we started revisiting the notion of what are we really trying to achieve what were trying to achieve is not necessarily hierarchy per se but you could think about what does hierarchy give us what we hope it would give us is better credit assignment what is better credit assignment its giving us it gives us faster learning right and so faster learning is ultimately maybe what were after and so thats where we ended up with the rl squared paper on learning to reinforcement learn which at a time rocky dwan led and thats exactly the meta learning approach where you say okay we dont know how to design hierarchy we know what we want to get from it lets just enter and optimize for what we want to get from it and see if it might emerge and we saw things emerge the maze navigation had consistent motion down hallways which is what you want a hierarchical control should say i want to go down this hallway and then when there is an option to take a turn i can decide whether to take a turn or not and repeat even had the notion of where have you been before or not to not revisit places youve been before it still didnt scale yet to the real world kind of scenarios i think you had in mind but it was some sign of life that maybe you can meta learn these hierarchical concepts i mean it seems like through these meta learning concepts get at the what i think is one of the hardest and most important problems of ai which is transfer learning so its generalization how far along this journey towards building general systems are we being able to do transfer learning well so theres some signs that you can generalize a little bit but do you think were on the right path or its totally different breakthroughs are needed to be able to transfer knowledge between different learned models yeah im pretty torn on this in that i think there are some very impressive well theres just some very impressive results already i mean i would say when even with the initial kind of big breakthrough in 2012 with alexnet the initial thing is okay great this does better on imagenet hence image recognition but then immediately thereafter there was of course the notion that wow what was learned on imagenet and you now wanna solve a new task you can fine tune alexnet for new tasks and that was often found to be the even bigger deal that you learn something that was reusable which was not often the case before usually machine learning you learn something for one scenario and that was it and thats really exciting i mean thats a huge application thats probably the biggest success of transfer learning today in terms of scope and impact that was a huge breakthrough and then recently i feel like similar kind of by scaling things up it seems like this has been expanded upon like people training even bigger networks they might transfer even better if you looked at for example some of the openai results on language models and some of the recent google results on language models theyre learned for just prediction and then they get reused for other tasks and so i think there is something there where somehow if you train a big enough model on enough things it seems to transfer some deep mind results that i thought were very impressive the unreal results where it was learned to navigate mazes in ways where it wasnt just doing reinforcement learning but it had other objectives it was optimizing for so i think theres a lot of interesting results already i think maybe where its hard to wrap my head around this to which extent or when do we call something generalization or the levels of generalization in the real world or the levels of generalization involved in these different tasks right you draw this by the way just to frame things ive heard you say somewhere its the difference between learning to master versus learning to generalize that its a nice line to think about and i guess youre saying that its a gray area of what learning to master and learning to generalize where one starts i think i might have heard this i might have heard it somewhere else and i think it mightve been one of your interviews maybe the one with yoshua benjamin im not 100 sure but i liked the example im not sure who it was but the example was essentially if you use current deep learning techniques what were doing to predict lets say the relative motion of our planets it would do pretty well but then now if a massive new mass enters our solar system it would probably not predict what will happen right and thats a different kind of generalization thats a generalization that relies on the ultimate simplest simplest explanation that we have available today to explain the motion of planets whereas just pattern recognition could predict our current solar system motion pretty well no problem and so i think thats an example of a kind of generalization that is a little different from what weve achieved so far and its not clear if just regularizing more and forcing it to come up with a simpler simpler simpler explanation and say look this is not simple but thats what physics researchers do right they say can i make this even simpler how simple can i get this whats the simplest equation that can explain everything the master equation for the entire dynamics of the universe we havent really pushed that direction as hard in deep learning i would say not sure if it should be pushed but it seems a kind of generalization you get from that that you dont get in our current methods so far so i just talked to vladimir vapnik for example whos a statistician of statistical learning and he kind of dreams of creating the e equals mc squared for learning right the general theory of learning do you think thats a fruitless pursuit in the near term within the next several decades i think thats a really interesting pursuit in the following sense in that there is a lot of evidence that the brain is pretty modular and so i wouldnt maybe think of it as the theory maybe the underlying theory but more kind of the principle where there have been findings where people who are blind will use the part of the brain usually used for vision for other functions and even after some kind of if people get rewired in some way they might be able to reuse parts of their brain for other functions and so what that suggests is some kind of modularity and i think it is a pretty natural thing to strive for to see can we find that modularity can we find this thing of course every part of the brain is not exactly the same not everything can be rewired arbitrarily but if you think of things like the neocortex which is a pretty big part of the brain that seems fairly modular from what the findings so far can you design something equally modular and if you can just grow it it becomes more capable probably i think that would be the kind of interesting underlying principle to shoot for that is not unrealistic do you think you prefer math or empirical trial and error for the discovery of the essence of what it means to do something intelligent so reinforcement learning embodies both groups right to prove that something converges prove the bounds and then at the same time a lot of those successes are well lets try this and see if it works so which do you gravitate towards how do you think of those two parts of your brain maybe i would prefer we could make the progress with mathematics and the reason maybe i would prefer that is because often if you have something you can mathematically formalize you can leapfrog a lot of experimentation and experimentation takes a long time to get through and a lot of trial and error kind of reinforcement learning your research process but you need to do a lot of trial and error before you get to a success so if you can leapfrog that to my mind thats what the math is about and hopefully once you do a bunch of experiments you start seeing a pattern you can do some derivations that leapfrog some experiments but i agree with you i mean in practice a lot of the progress has been such that we have not been able to find the math that allows you to leapfrog ahead and we are kind of making gradual progress one step at a time a new experiment here a new experiment there that gives us new insights and gradually building up but not getting to something yet where were just okay heres an equation that now explains how you know that would be have been two years of experimentation to get there but this tells us what the results going to be unfortunately not so much yet not so much yet but your hope is there in trying to teach robots or systems to do everyday tasks or even in simulation what do you think youre more excited about imitation learning or self play so letting robots learn from humans or letting robots plan their own to try to figure out in their own way and eventually play eventually interact with humans or solve whatever the problem is whats the more exciting to you whats more promising you think as a research direction so when we look at self play whats so beautiful about it is goes back to kind of the challenges in reinforcement learning so the challenge of reinforcement learning is getting signal and if you dont never succeed you dont get any signal in self play youre on both sides so one of you succeeds and the beauty is also one of you fails and so you see the contrast you see the one version of me that did better than the other version so every time you play yourself you get signal and so whenever you can turn something into self play youre in a beautiful situation where you can naturally learn much more quickly than in most other reinforcement learning environments so i think if somehow we can turn more reinforcement learning problems into self play formulations that would go really really far so far self play has been largely around games where there is natural opponents but if we could do self play for other things and lets say i dont know a robot learns to build a house i mean thats a pretty advanced thing to try to do for a robot but maybe it tries to build a hut or something if that can be done through self play it would learn a lot more quickly if somebody can figure that out and i think that would be something where it goes closer to kind of the mathematical leapfrogging where somebody figures out a formalism to say okay any rl problem by playing this and this idea you can turn it into a self play problem where you get signal a lot more easily reality is many problems we dont know how to turn into self play and so either we need to provide detailed reward that doesnt just reward for achieving a goal but rewards for making progress and that becomes time consuming and once youre starting to do that lets say you want a robot to do something you need to give all this detailed reward well why not just give a demonstration because why not just show the robot and now the question is how do you show the robot one way to show is to tally operate the robot and then the robot really experiences things and thats nice because thats really high signal to noise ratio data and weve done a lot of that and you teach your robot skills in just 10 minutes you can teach your robot a new basic skill like okay pick up the bottle place it somewhere else thats a skill no matter where the bottle starts maybe it always goes onto a target or something thats fairly easy to teach your robot with tally up now whats even more interesting if you can now teach your robot through third person learning where the robot watches you do something and doesnt experience it but just kind of watches you it doesnt experience it but just watches it and says okay well if youre showing me that that means i should be doing this and im not gonna be using your hand because i dont get to control your hand but im gonna use my hand i do that mapping and so thats where i think one of the big breakthroughs has happened this year this was led by chelsea finn here its almost like learning a machine translation for demonstrations where you have a human demonstration and the robot learns to translate it into what it means for the robot to do it and that was a meta learning formulation learn from one to get the other and that i think opens up a lot of opportunities to learn a lot more quickly so my focus is on autonomous vehicles do you think this approach of third person watching the autonomous driving is amenable to this kind of approach so for autonomous driving i would say third person is slightly easier and the reason im gonna say its slightly easier to do with third person is because the car dynamics are very well understood so the easier than first person you mean or easier than so i think the distinction between third person and first person is not a very important distinction for autonomous driving theyre very similar because the distinction is really about who turns the steering wheel or maybe let me put it differently how to get from a point where you are now to a point lets say a couple meters in front of you and thats a problem thats very well understood and thats the only distinction between third and first person there whereas with the robot manipulation interaction forces are very complex and its still a very different thing for autonomous driving i think there is still the question imitation versus rl so imitation gives you a lot more signal i think where imitation is lacking and needs some extra machinery is it doesnt in its normal format doesnt think about goals or objectives and of course there are versions of imitation learning and versus reinforcement learning type imitation learning which also thinks about goals i think then were getting much closer but i think its very hard to think of a fully reactive car generalizing well if it really doesnt have a notion of objectives to generalize well to the kind of general that you would want youd want more than just that reactivity that you get from just behavioral cloning slash supervised learning so a lot of the work whether its self play or even imitation learning would benefit significantly from simulation from effective simulation and youre doing a lot of stuff in the physical world and in simulation do you have hope for greater and greater power of simulation being boundless eventually to where most of what we need to operate in the physical world could be simulated to a degree thats directly transferable to the physical world or are we still very far away from that so i think we could even rephrase that question in some sense please and so the power of simulation right as simulators get better and better of course becomes stronger and we can learn more in simulation but theres also another version which is where you say the simulator doesnt even have to be that precise as long as its somewhat representative and instead of trying to get one simulator that is sufficiently precise to learn in and transfer really well to the real world im gonna build many simulators ensemble of simulators ensemble of simulators not any single one of them is sufficiently representative of the real world such that it would work if you train in there but if you train in all of them then there is something thats good in all of them the real world will just be another one of them thats not identical to any one of them but just another one of them another sample from the distribution of simulators exactly we do live in a simulation so this is just one other one im not sure about that but yeah its definitely a very advanced simulator if it is yeah its a pretty good one ive talked to stuart russell its something you think about a little bit too of course youre really trying to build these systems but do you think about the future of ai a lot of people have concern about safety how do you think about ai safety as you build robots that are operating in the physical world what is yeah how do you approach this problem in an engineering kind of way in a systematic way so when a robot is doing things you kind of have a few notions of safety to worry about one is that the robot is physically strong and of course could do a lot of damage same for cars which we can think of as robots too in some way and this could be completely unintentional so it could be not the kind of longterm ai safety concerns that okay ai is smarter than us and now what do we do but it could be just very practical okay this robot if it makes a mistake what are the results going to be of course simulation comes in a lot there to test in simulation its a difficult question and im always wondering like i always wonder lets say you look at lets go back to driving because a lot of people know driving well of course what do we do to test somebody for driving right get a drivers license what do they really do i mean you fill out some tests and then you drive and i mean its suburban california that driving test is just you drive around the block pull over you do a stop sign successfully and then you pull over again and youre pretty much done and youre like okay if a self driving car did that would you trust it that it can drive and id be like no thats not enough for me to trust it but somehow for humans weve figured out that somebody being able to do that is representative of them being able to do a lot of other things and so i think somehow for humans we figured out representative tests of what it means if you can do this what you can really do of course testing humans humans dont wanna be tested at all times self driving cars or robots could be tested more often probably you can have replicas that get tested that are known to be identical because they use the same neural net and so forth but still i feel like we dont have this kind of unit tests or proper tests for robots and i think theres something very interesting to be thought about there especially as you update things your software improves you have a better self driving car suite you update it how do you know its indeed more capable on everything than what you had before that you didnt have any bad things creep into it so i think thats a very interesting direction of research that there is no real solution yet except that somehow for humans we do because we say okay you have a driving test you passed you can go on the road now and humans have accidents every like a million or 10 million miles something pretty phenomenal compared to that short test that is being done so let me ask youve mentioned that andrew ng by example showed you the value of kindness do you think the space of policies good policies for humans and for ai is populated by policies that with kindness or ones that are the opposite exploitation even evil so if you just look at the sea of policies we operate under as human beings or if ai system had to operate in this real world do you think its really easy to find policies that are full of kindness like we naturally fall into them or is it like a very hard optimization problem i mean there is kind of two optimizations happening for humans right so for humans theres kind of the very long term optimization which evolution has done for us and were kind of predisposed to like certain things and thats in some sense what makes our learning easier because i mean we know things like pain and hunger and thirst and the fact that we know about those is not something that we were taught thats kind of innate when were hungry were unhappy when were thirsty were unhappy when we have pain were unhappy and ultimately evolution built that into us to think about those things and so i think there is a notion that it seems somehow humans evolved in general to prefer to get along in some ways but at the same time also to be very territorial and kind of centric to their own tribe like it seems like thats the kind of space we converged onto i mean im not an expert in anthropology but it seems like were very kind of good within our own tribe but need to be taught to be nice to other tribes well if you look at steven pinker he highlights this pretty nicely in better angels of our nature where he talks about violence decreasing over time consistently so whatever tension whatever teams we pick it seems that the long arc of history goes towards us getting along more and more so i hope so so do you think that do you think its possible to teach rl based robots this kind of kindness this kind of ability to interact with humans this kind of policy even to let me ask a fun one do you think its possible to teach rl based robot to love a human being and to inspire that human to love the robot back so to like rl based algorithm that leads to a happy marriage thats an interesting question maybe ill answer it with another question right because i mean but ill come back to it so another question you can have is okay i mean how close does some peoples happiness get from interacting with just a really nice dog like i mean dogs you come home thats what dogs do they greet you theyre excited makes you happy when you come home to your dog youre just like okay this is exciting theyre always happy when im here and if they dont greet you cause maybe whatever your partner took them on a trip or something you might not be nearly as happy when you get home right and so the kind of it seems like the level of reasoning a dog has is pretty sophisticated but then its still not yet at the level of human reasoning and so it seems like we dont even need to achieve human level reasoning to get like very strong affection with humans and so my thinking is why not right why couldnt with an ai couldnt we achieve the kind of level of affection that humans feel among each other or with friendly animals and so forth so question is it a good thing for us or not thats another thing right because i mean but i dont see why not why not yeah so elon musk says love is the answer maybe he should say love is the objective function and then rl is the answer right well maybe oh peter thank you so much i dont want to take up more of your time thank you so much for talking today well thanks for coming by great to have you visit', 'the following is a conversation with jürgen schmidhuber hes the co director of the cs swiss ai lab and a co creator of long short term memory networks lsdms are used in billions of devices today for speech recognition translation and much more over 30 years he has proposed a lot of interesting out of the box ideas on meta learning adversarial networks computer vision and even a formal theory of quote creativity curiosity and fun this conversation is part of the mit course on artificial general intelligence and the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with jürgen schmidhuber early on you dreamed of ai systems that self improve recursively when was that dream born when i was a baby no thats not true when i was a teenager and what was the catalyst for that birth what was the thing that first inspired you when i was a boy i was thinking about what to do in my life and then i thought the most exciting thing is to solve the riddles of the universe and that means you have to become a physicist however then i realized that theres something even grander you can try to build a machine that isnt really a machine any longer that learns to become a much better physicist than i could ever hope to be and thats how i thought maybe i can multiply my tiny little bit of creativity into infinity but ultimately that creativity will be multiplied to understand the universe around us thats the curiosity for that mystery that drove you yes so if you can build a machine that learns to solve more and more complex problems and more and more general problem solver then you basically have solved all the problems at least all the solvable problems so how do you think what is the mechanism for that kind of general solver look like obviously we dont quite yet have one or know how to build one but we have ideas and you have had throughout your career several ideas about it so how do you think about that mechanism so in the 80s i thought about how to build this machine that learns to solve all these problems that i cannot solve myself and i thought it is clear it has to be a machine that not only learns to solve this problem here and this problem here but it also has to learn to improve the learning algorithm itself so it has to have the learning algorithm in a representation that allows it to inspect it and modify it such that it can come up with a better learning algorithm so i call that meta learning learning to learn and recursive self improvement that is really the pinnacle of that where you then not only learn how to improve on that problem and on that but you also improve the way the machine improves and you also improve the way it improves the way it improves itself and that was my 1987 diploma thesis which was all about that higher education hierarchy of meta learners that have no computational limits except for the well known limits that gödel identified in 1931 and for the limits of physics in the recent years meta learning has gained popularity in a specific kind of form youve talked about how thats not really meta learning with neural networks thats more basic transfer learning can you talk about the difference between the big general meta learning and a more narrow sense of meta learning the way its used today the way its talked about today lets take the example of a deep neural network that has learned to classify images and maybe you have trained that network on 100 different databases of images and now a new database comes along and you want to quickly learn the new thing as well so one simple way of doing that is you take the network which already knows 100 types of databases and then you just take the top layer of that and you retrain that using the new label data that you have in the new image database and then it turns out that it really really quickly can learn that too one shot basically because from the first 100 data sets it already has learned so much about computer vision that it can reuse that and that is then almost good enough to solve the new task except you need a little bit of adjustment on the top so that is transfer learning and it has been done in principle for many decades people have done similar things for decades meta learning too meta learning is about having the learning algorithm itself open to introspection by the system that is using it and also open to modification such that the learning system has an opportunity to modify any part of the learning algorithm and then evaluate the consequences of that modification and then learn from that to create a better learning algorithm and so on recursively so thats a very different animal where you are opening the space of possible learning algorithms to the learning system itself right so youve like in the 2004 paper you described gator machines programs that rewrite themselves right philosophically and even in your paper mathematically these are really compelling ideas but practically do you see these self referential programs being successful in the near term to having an impact where sort of it demonstrates to the world that this direction is a good one to pursue in the near term yes we had these two different types of fundamental research how to build a universal problem solver one basically exploiting proof search and things like that that you need to come up with asymptotically optimal theoretically optimal self improvers and problem solvers however one has to admit that through this proof search comes in an additive constant an overhead an additive overhead that vanishes in comparison to what you have to do to solve large problems however for many of the small problems that we want to solve in our everyday life we cannot ignore this constant overhead and thats why we also have been doing other things non universal things such as recurrent neural networks which are trained by gradient descent and local search techniques which arent universal at all which arent provably optimal at all like the other stuff that we did but which are much more practical as long as we only want to solve the small problems that we are typically trying to solve in this environment here so the universal problem solvers like the gödel machine but also markus hutters fastest way of solving all possible problems which he developed around 2002 in my lab they are associated with these constant overheads for proof search which guarantees that the thing that youre doing is optimal for example there is this fastest way of solving all problems with a computable solution which is due to markus markus hutter and to explain whats going on there lets take traveling salesman problems with traveling salesman problems you have a number of cities and cities and you try to find the shortest path through all these cities without visiting any city twice and nobody knows the fastest way of solving traveling salesman problems tsps but lets assume there is a method of solving them within n to the five operations where n is the number of cities then the universal method of markus is going to solve the same traveling salesman problem also within n to the five steps plus o of one plus a constant number of steps that you need for the proof searcher which you need to show that this particular class of problems the traveling salesman problems can be solved within a certain time frame solved within a certain time bound within order n to the five steps basically and this additive constant doesnt care for n which means as n is getting larger and larger as you have more and more cities the constant overhead pales in comparison and that means that almost all large problems are solved in the best possible way today we already have a universal problem solver like that however its not practical because the overhead the constant overhead is so large that for the small kinds of problems that we want to solve in this little biosphere by the way when you say small youre talking about things that fall within the constraints of our computational systems so they can seem quite large to us mere humans right thats right yeah so they seem large and even unsolvable in a practical sense today but they are still small compared to almost all problems because almost all problems are large problems which are much larger than any constant do you find it useful as a person who has dreamed of creating a general learning system has worked on creating one has done a lot of interesting ideas there to think about p versus np this formalization of how hard problems are how they scale this kind of worst case analysis type of thinking do you find that useful or is it only just a mathematical its a set of mathematical techniques to give you intuition about whats good and bad so p versus np thats super interesting from a theoretical point of view and in fact as you are thinking about that problem you can also get inspiration for better practical problem solvers on the other hand we have to admit that at the moment the best practical problem solvers for all kinds of problems that we are now solving through what is called ai at the moment they are not of the kind that is inspired by these questions there we are using general purpose computers such as recurrent neural networks but we have a search technique which is just local search gradient descent to try to find a program that is running on these recurrent networks such that it can solve some interesting problems such as speech recognition or machine translation and something like that and there is very little theory behind the best solutions that we have at the moment that can do that do you think that needs to change do you think that will change or can we go can we create a general intelligent systems without ever really proving that that system is intelligent in some kind of mathematical way solving machine translation perfectly or something like that within some kind of syntactic definition of a language or can we just be super impressed by the thing working extremely well and thats sufficient theres an old saying and i dont know who brought it up first which says theres nothing more practical than a good theory and a good theory of problem solving under limited resources like here in this universe or on this little planet has to take into account these limited resources and so probably there is locking a theory which is related to what we already have these asymptotically optimal problem solvers which tells us what we need in addition to that to come up with a practically optimal problem solver so i believe we will have something like that and maybe just a few little tiny twists are necessary to change what we already have to come up with that as well as long as we dont have that we admit that we are taking suboptimal ways and recurrent neural networks and long short term memory for equipped with local search techniques and we are happy that it works better than any competing methods but that doesnt mean that we think we are done youve said that an agi system will ultimately be a simple one a general intelligence system will ultimately be a simple one maybe a pseudocode of a few lines will be able to describe it can you talk through your intuition behind this idea why you feel that at its core intelligence is a simple algorithm experience tells us that the stuff that works best is really simple so the asymptotically optimal ways of solving problems if you look at them theyre just a few lines of code its really true although they are these amazing properties just a few lines of code then the most promising and most useful practical things maybe dont have this proof of optimality associated with them however they are also just a few lines of code the most successful recurrent neural networks you can write them down in five lines of pseudocode thats a beautiful almost poetic idea but what youre describing there is the lines of pseudocode are sitting on top of layers and layers of abstractions in a sense so youre saying at the very top itll be a beautifully written sort of algorithm but do you think that theres many layers of abstractions we have to first learn to construct yeah of course we are building on all these great abstractions that people have invented over the millennia such as matrix multiplications and real numbers and basic arithmetics and calculus and derivations of error functions and derivatives of error functions and stuff like that so without that language that greatly simplifies our way of thinking about these problems we couldnt do anything so in that sense as always we are standing on the shoulders of the giants who in the past simplified the problem of problem solving so much that now we have a chance to do the final step so the final step will be a simple one if we take a step back through all of human civilization and just the universe in general how do you think about evolution and what if creating a universe is required to achieve this final step what if going through the very painful and inefficient process of evolution is needed to come up with this set of abstractions that ultimately lead to intelligence do you think theres a shortcut or do you think we have to create something like our universe in order to create something like human level intelligence so far the only example we have is this one this universe in which we are living do you think we can do better maybe not but we are part of this whole process so apparently so it might be the case that the code that runs the universe is really really simple everything points to that possibility because gravity and other basic forces are really simple laws that can be easily described also in just a few lines of code basically and then there are these other events that the apparently random events in the history of the universe which as far as we know at the moment dont have a compact code but who knows maybe somebody in the near future is going to figure out the pseudo random generator which is computing whether the measurement of that spin up or down thing here is going to be positive or negative underlying quantum mechanics yes do you ultimately think quantum mechanics is a pseudo random number generator so its all deterministic theres no randomness in our universe does god play dice so a couple of years ago a famous physicist quantum physicist anton zeilinger he wrote an essay in nature and it started more or less like that one of the fundamental insights of the 20th century was that the universe is fundamentally random on the quantum level so i became aware of all of that in the 80s and back then logic programming was a huge thing was it inspiring to you yourself did you find it compelling because a lot of your work was not so much in that realm right it was more in the learning systems yes and no but we did all of that so my first publication ever actually was 1987 was the implementation of genetic algorithm of a genetic programming system in prolog so prolog thats what you learn back then which is a logic programming language and the japanese they have this huge fifth generation ai project which was mostly about logic programming back then although neural networks existed and were well known back then and deep learning has existed since 1965 since this guy in the ukraine iwakunenko started it but the japanese and many other people they focused really on this logic programming and i was influenced to the extent that i said okay lets take these biologically inspired algorithms like evolution programs and implement that in the language which i know which was prolog for example back then and then in many ways this came back later because the gödel machine for example has a proof searcher on board and without that it would not be optimal well markus futters universal algorithm for solving all well defined problems has a proof searcher on board so thats very much logic programming without that it would not be asymptotically optimal but then on the other hand because we are very pragmatic guys also we focused on recurrent neural networks and suboptimal stuff such as gradient based search and program space rather than provably optimal things the logic programming certainly has a usefulness when youre trying to construct something provably optimal or provably good or something like that but is it useful for practical problems its really useful for our theorem proving the best theorem provers today are not neural networks no they are logic programming systems and they are much better theorem provers than most math students in the first or second semester but for reasoning for playing games of go or chess or for robots autonomous vehicles that operate in the real world or object manipulation you think learning yeah as long as the problems have little to do with theorem proving themselves then as long as that is not the case you just want to have better pattern recognition so to build a self driving car you want to have better pattern recognition and pedestrian recognition and all these things you want to minimize the number of false positives which is currently slowing down self driving cars in many ways all of that has very little to do with logic programming what are you most excited about in terms of directions of artificial intelligence at this moment in the next few years in your own research and in the broader community so i think in the not so distant future we will have for the first time little robots that learn like kids i will be able to say to the robot look here robot we are going to assemble a smartphone lets take this slab of plastic and the screwdriver and lets screw in the screw like that not like that like that not like that like that and i dont have a data glove or something he will see me and he will hear me and he will try to do something with his own actuators which will be really different from mine but he will understand the difference and will learn to imitate me but not in the supervised way where a teacher is giving target signals for all his muscles all the time no by doing this high level imitation where he first has to learn to imitate me and then to interpret these additional noises coming from my mouth as helping helpful signals to do that better and then it will by itself come up with faster ways and more efficient ways of doing the same thing and finally i stop his learning algorithm and make a million copies and sell it and so at the moment this is not possible but we already see how we are going to get there and you can imagine to the extent that this works economically and cheaply its going to change everything almost all of production is going to be affected by that and a much bigger wave a much bigger ai wave is coming than the one that we are currently witnessing which is mostly about passive pattern recognition on your smartphone this is about active machines that shapes data through the actions they are executing and they learn to do that in a good way so many of the traditional industries are going to be affected by that all the companies that are building machines will equip these machines with cameras and other sensors and they are going to learn to solve all kinds of problems through interaction with humans but also a lot on their own to improve what they already can do and lots of old economy is going to be affected by that and in recent years i have seen that old economy is actually waking up and realizing that this is the case are you optimistic about that future are you concerned there is a lot of people concerned in the near term about the transformation of the nature of work the kind of ideas that you just suggested would have a significant impact of what kind of things could be automated are you optimistic about that future are you nervous about that future and looking a little bit farther into the future there are people like gila musk stuart russell concerned about the existential threats of that future so in the near term job loss in the long term existential threat are these concerns to you or are you ultimately optimistic so lets first address the near future we have had predictions of job losses for many decades for example when industrial robots came along many people predicted that lots of jobs are going to get lost and in a sense they were right because back then there were car factories and hundreds of people in these factories assembled cars and today the same car factories have hundreds of robots and maybe three guys watching the robots on the other hand those countries that have lots of robots per capita japan korea germany switzerland and a couple of other countries they have really low unemployment rates somehow all kinds of new jobs were created back then nobody anticipated those jobs and decades ago i always said its really easy to say which jobs are going to get lost but its really hard to predict the new ones 200 years ago who would have predicted all these people making money as youtube bloggers for example 200 years ago 60 of all people used to work in agriculture today maybe 1 but still only i dont know 5 unemployment lots of new jobs were created and homo ludens the playing man is inventing new jobs all the time most of these jobs are not existentially necessary for the survival of our species there are only very few existentially necessary jobs such as farming and building houses and warming up the houses but less than 10 of the population is doing that and most of these newly invented jobs are about interacting with other people in new ways through new media and so on getting new types of kudos and forms of likes and whatever and even making money through that so homo ludens the playing man doesnt want to be unemployed and thats why hes inventing new jobs all the time and he keeps considering these jobs as really important and is investing a lot of energy and hours of work into those new jobs thats quite beautifully put were really nervous about the future because we cant predict what kind of new jobs will be created but youre ultimately optimistic that we humans are so restless that we create and give meaning to newer and newer jobs totally new things that get likes on facebook or whatever the social platform is so what about long term existential threat of ai where our whole civilization may be swallowed up by these ultra super intelligent systems maybe its not going to be swallowed up but id be surprised if we humans were the last step in the evolution of the universe youve actually had this beautiful comment somewhere that ive seen saying that quite insightful artificial general intelligence systems just like us humans will likely not want to interact with humans theyll just interact amongst themselves just like ants interact amongst themselves and only tangentially interact with humans and its quite an interesting idea that once we create agi they will lose interest in humans and compete for their own facebook likes and their own social platforms so within that quite elegant idea how do we know in a hypothetical sense that theres not already intelligence systems out there how do you think broadly of general intelligence greater than us how do we know its out there how do we know its around us and could it already be id be surprised if within the next few decades or something like that we wont have ais that are truly smart in every single way and better problem solvers in almost every single important way and id be surprised if they wouldnt realize what we have realized a long time ago which is that almost all physical resources are not here in this biosphere but further out the rest of the solar system gets 2 billion times more solar energy than our little planet theres lots of material out there that you can use to build robots and self replicating robot factories and all this stuff and they are going to do that and they will be scientists and curious and they will explore what they can do and in the beginning they will be fascinated by life and by their own origins in our civilization they will want to understand that completely just like people today would like to understand how life works and also the history of our own existence and civilization but then also the physical laws that created all of that so in the beginning they will be fascinated by life once they understand it they lose interest like anybody who loses interest in things he understands and then as you said the most interesting sources of information for them will be others of their own kind so at least in the long run there seems to be some sort of protection through lack of interest on the other side and now it seems also clear as far as we understand physics you need matter and energy to compute and to build more robots and infrastructure for ai civilization and eiei ecologies consisting of trillions of different types of ais and so it seems inconceivable to me that this thing is not going to expand some ai ecology not controlled by one ai but trillions of different types of ais competing in all kinds of quickly evolving and disappearing ecological niches in ways that we cannot fathom at the moment but its going to expand limited by light speed and physics but its going to expand and now we realize that the universe is still young its only 138 billion years old and its going to be a thousand times older than that so theres plenty of time to conquer the entire universe and to fill it with intelligence and senders and receivers such that ais can travel the way they are traveling in our labs today which is by radio from sender to receiver and lets call the current age of the universe one eon one eon now it will take just a few eons from now and the entire visible universe is going to be full of that stuff and lets look ahead to a time when the universe is going to be 1000 times older than it is now they will look back and they will say look almost immediately after the big bang only a few eons later the entire universe started to become intelligent now to your question how do we see whether anything like that has already happened or is already in a more advanced stage in some other part of the universe of the visible universe we are trying to look out there and nothing like that has happened so far or is that true do you think we would recognize it how do we know its not among us how do we know planets arent in themselves intelligent beings how do we know ants seen as a collective are not much greater intelligence than our own these kinds of ideas when i was a boy i was thinking about these things and i thought maybe it has already happened because back then i knew i learned from popular physics books that the large scale structure of the universe is not homogeneous you have these clusters of galaxies and then in between there are these huge empty spaces and i thought maybe they arent really empty its just that in the middle of that some ai civilization already has expanded and then has covered a bubble of a billion light years diameter and is using all the energy of all the stars within that bubble for its own unfathomable purposes and so it already has happened and we just fail to interpret the signs and then i learned that gravity by itself explains the large scale structure of the universe and that this is not a convincing explanation and then i thought maybe its the dark matter because as far as we know today 80 of the measurable matter is invisible and we know that because otherwise our galaxy or other galaxies would fall apart they are rotating too quickly and then the idea was maybe all of these ai civilizations that are already out there they are just invisible because they are really efficient in using the energies of their own local systems and thats why they appear dark to us but this is also not a convincing explanation because then the question becomes why are there still any visible stars left in our own galaxy which also must have a lot of dark matter so that is also not a convincing thing and today i like to think its quite plausible that maybe we are the first at least in our local light cone within the few hundreds of millions of light years that we can reliably observe is that exciting to you that we might be the first and it would make us much more important because if we mess it up through a nuclear war then maybe this will have an effect on the development of the entire universe so lets not mess it up lets not mess it up jürgen thank you so much for talking today i really appreciate it its my pleasure and that whenever you measure spin up or down or something like that a new bit of information enters the history of the universe and while i was reading that i was already typing the response and they had to publish it because i was right that there is no evidence no physical evidence for that so theres an alternative explanation where everything that we consider random is actually pseudo random such as the decimal expansion of pi 3141 and so on which looks random but isnt so pi is interesting because every three digits sequence every sequence of three digits appears roughly one in a thousand times and every five digit sequence appears roughly one in 10000 times what you would expect if it was random but theres a very short algorithm a short program that computes all of that so its extremely compressible and who knows maybe tomorrow somebody some grad student at cern goes back over all these data points better decay and whatever and figures out oh its the second billion digits of pi or something like that we dont have any fundamental reason at the moment to believe that this is truly random and not just a deterministic video game if it was a deterministic video game it would be much more beautiful because beauty is simplicity and many of the basic laws of the universe like gravity and the other basic forces are very simple so very short programs can explain what these are doing and it would be awful and ugly the universe would be ugly the history of the universe would be ugly if for the extra things the random the seemingly random data points that we get all the time that we really need a huge number of extra bits to describe all these extra bits of information so as long as we dont have evidence that there is no short program that computes the entire history of the entire universe we are as scientists compelled to look further for that shortest program your intuition says there exists a program that can backtrack to the creation of the universe yeah so it can give the shortest path to the creation of the universe yes including all the entanglement things and all the spin up and down measures that have been taken place since 138 billion years ago so we dont have a proof that it is random we dont have a proof that it is compressible to a short program but as long as we dont have that proof we are obliged as scientists to keep looking for that simple explanation absolutely so you said the simplicity is beautiful or beauty is simple either one works but you also work on curiosity discovery the romantic notion of randomness of serendipity of being surprised by things that are about you in our poetic notion of reality we think its kind of like poetic notion of reality we think as humans require randomness so you dont find randomness beautiful you find simple determinism beautiful yeah okay so why why because the explanation becomes shorter a universe that is compressible to a short program is much more elegant and much more beautiful than another one which needs an almost infinite number of bits to be described as far as we know many things that are happening in this universe are really simple in terms of short programs that compute gravity and the interaction between elementary particles and so on so all of that seems to be very very simple every electron seems to reuse the same subprogram all the time as it is interacting with other elementary particles if we now require an extra oracle injecting new bits of information all the time for these extra things which are currently not understood such as better decay then the whole description length of the data that we can observe of the history of the universe would become much longer and therefore uglier and uglier again simplicity is elegant and beautiful the history of science is a history of compression progress yes so youve described sort of as we build up abstractions and youve talked about the idea of compression how do you see this the history of science the history of humanity our civilization and life on earth as some kind of path towards greater and greater compression what do you mean by that how do you think about that indeed the history of science is a history of compression progress what does that mean hundreds of years ago there was an astronomer whose name was kepler and he looked at the data points that he got by watching planets move and then he had all these data points and suddenly it turned out that he can greatly compress the data by predicting it through an ellipse law so it turns out that all these data points are more or less on ellipses around the sun and another guy came along whose name was newton and before him hooke and they said the same thing that is making these planets move like that is what makes the apples fall down and it also holds for stones and for all kinds of other objects and suddenly many many of these observations became much more compressible because as long as you can predict the next thing given what you have seen so far you can compress it and you dont have to store that data extra this is called predictive coding and then there was still something wrong with that theory of the universe and you had deviations from these predictions of the theory and 300 years later another guy came along whose name was einstein and he was able to explain away all these deviations from the predictions of the old theory through a new theory which was called the general theory of relativity which at first glance looks a little bit more complicated and you have to warp space and time but you cant phrase it within one single sentence which is no matter how fast you accelerate and how hard you decelerate and no matter what is the gravity in your local network light speed always looks the same and from that you can calculate all the consequences so its a very simple thing and it allows you to further compress all the observations because certainly there are hardly any deviations any longer that you can measure from the predictions of this new theory so all of science is a history of compression progress you never arrive immediately at the shortest explanation of the data but youre making progress whenever you are making progress you have an insight you see oh first i needed so many bits of information to describe the data to describe my falling apples my video of falling apples i need so many data so many pixels have to be stored but then suddenly i realize no there is a very simple way of predicting the third frame in the video from the first two and maybe not every little detail can be predicted but more or less most of these orange blobs that are coming down they accelerate in the same way which means that i can greatly compress the video and the amount of compression progress that is the depth of the insight that you have at that moment thats the fun that you have the scientific fun the fun in that discovery and we can build artificial systems that do the same thing they measure the depth of their insights as they are looking at the data which is coming in through their own experiments and we give them a reward an intrinsic reward in proportion to this depth of insight and since they are trying to maximize the rewards they get they are suddenly motivated to come up with new action sequences with new experiments that have the property that the data that is coming in as a consequence of these experiments has the property that they can learn something about see a pattern in there which they hadnt seen yet before so there is an idea of power play that you described a training in general problem solver in this kind of way of looking for the unsolved problems yeah can you describe that idea a little further its another very simple idea so normally what you do in computer science you have some guy who gives you a problem and then there is a huge search space of potential solution candidates and you somehow try them out and you have more less sophisticated ways of moving around in that search space until you finally found a solution which you consider satisfactory thats what most of computer science is about power play just goes one little step further and says lets not only search for solutions to a given problem but lets search to pairs of problems and their solutions where the system itself has the opportunity to phrase its own problem so we are looking suddenly at pairs of problems and their solutions or modifications of the problem solver that is supposed to generate a solution to that new problem and this additional degree of freedom allows us to build career systems that are like scientists in the sense that they not only try to solve and try to find answers to existing questions no they are also free to pose their own questions so if you want to build an artificial scientist you have to give it that freedom and power play is exactly doing that so thats a dimension of freedom thats important to have but how hard do you think that how multidimensional and difficult the space of then coming up with your own questions is so its one of the things that as human beings we consider to be the thing that makes us special the intelligence that makes us special is that brilliant insight that can create something totally new yes so now lets look at the extreme case lets look at the set of all possible problems that you can formally describe which is infinite which should be the next problem that a scientist or power play is going to solve well it should be the easiest problem that goes beyond what you already know so it should be the simplest problem that the current problem solver that you have which can already solve 100 problems that he cannot solve yet by just generalizing so it has to be new so it has to require a modification of the problem solver such that the new problem solver can solve this new thing but the old problem solver cannot do it and in addition to that we have to make sure that the problem solver doesnt forget any of the previous solutions right and so by definition power play is now trying always to search in this pair of in the set of pairs of problems and problems over modifications for a combination that minimize the time to achieve these criteria so its always trying to find the problem which is easiest to add to the repertoire so just like grad students and academics and researchers can spend their whole career in a local minima stuck trying to come up with interesting questions but ultimately doing very little do you think its easy in this approach of looking for the simplest unsolvable problem to get stuck in a local minima is not never really discovering new you know really jumping outside of the 100 problems that youve already solved in a genuine creative way no because thats the nature of power play that its always trying to break its current generalization abilities by coming up with a new problem which is beyond the current horizon just shifting the horizon of knowledge a little bit out there breaking the existing rules such that the new thing becomes solvable but wasnt solvable by the old thing so like adding a new axiom like what gödel did when he came up with these new sentences new theorems that didnt have a proof in the formal system which means you can add them to the repertoire hoping that they are not going to damage the consistency of the whole thing so in the paper with the amazing title formal theory of creativity fun and intrinsic motivation you talk about discovery as intrinsic reward so if you view humans as intelligent agents what do you think is the purpose and meaning of life for us humans youve talked about this discovery do you see humans as an instance of power play agents humans are curious and that means they behave like scientists not only the official scientists but even the babies behave like scientists and they play around with their toys to figure out how the world works and how it is responding to their actions and thats how they learn about gravity and everything in 1990 we had the first systems like that which would just try to play around with the environment and come up with situations that go beyond what they knew at that time and then get a reward for creating these situations and then becoming more general problem solvers and being able to understand more of the world i think in principle that curiosity strategy or more sophisticated versions of what i just described they are what we have built in as well because evolution discovered thats a good way of exploring the unknown world and a guy who explores the unknown world has a higher chance of solving the mystery that he needs to survive in this world on the other hand those guys who were too curious they were weeded out as well so you have to find this trade off evolution found a certain trade off apparently in our society there is a certain percentage of extremely explorative guys and it doesnt matter if they die because many of the others are more conservative it would be surprising to me if that principle of artificial curiosity wouldnt be present in almost exactly the same form here in our brains you are a bit of a musician and an artist continuing on this topic of creativity what do you think is the role of creativity and intelligence so youve kind of implied that its essential for intelligence if you think of intelligence as a problem solving system as ability to solve problems but do you think its essential this idea of creativity we never have a program a sub program that is called creativity or something its just a side effect of what our problem solvers do they are searching a space of problems a space of candidates of solution candidates until they hopefully find a solution to a given problem but then there are these two types of creativity and both of them are now present in our machines the first one has been around for a long time which is human gives problem to machine machine tries to find a solution to that and this has been happening for many decades and for many decades machines have found creative solutions to interesting problems where humans were not aware of these particularly creative solutions but then appreciated that the machine found that the second is the pure creativity that i would call what i just mentioned i would call the applied creativity like applied art where somebody tells you now make a nice picture of this pope and you will get money for that so here is the artist and he makes a convincing picture of the pope and the pope likes it and gives him the money and then there is the pure creativity which is more like the power play and the artificial curiosity thing where you have the freedom to select your own problem like a scientist who defines his own question to study and so that is the pure creativity if you will as opposed to the applied creativity which serves another and in that distinction there is almost echoes of narrow ai versus general ai so this kind of constrained painting of a pope seems like the approaches of what people are calling narrow ai and pure creativity seems to be maybe i am just biased as a human but it seems to be an essential element of human level intelligence is that what you are implying to a degree if you zoom back a little bit and you just look at a general problem solving machine which is trying to solve arbitrary problems then this machine will figure out in the course of solving problems that it is good to be curious so all of what i said just now about this prewired curiosity and this will to invent new problems that the system doesnt know how to solve yet should be just a byproduct of the general search however apparently evolution has built it into us because it turned out to be so successful a prewiring a bias a very successful exploratory bias that we are born with and you have also said that consciousness in the same kind of way may be a byproduct of problem solving do you find this an interesting byproduct do you think it is a useful byproduct what are your thoughts on consciousness in general or is it simply a byproduct of greater and greater capabilities of problem solving that is similar to creativity in that sense we never have a procedure called consciousness in our machines however we get as side effects of what these machines are doing things that seem to be closely related to what people call consciousness so for example already in 1990 we had simple systems which were basically recurrent networks and therefore universal computers trying to map incoming data into actions that lead to success maximizing reward in a given environment always finding the charging station in time whenever the battery is low and negative signals are coming from the battery always find the charging station in time without bumping against painful obstacles on the way so complicated things but very easily motivated and then we give these little guys a separate recurrent neural network which is just predicting whats happening if i do that and that what will happen as a consequence of these actions that im executing and its just trained on the long and long history of interactions with the world so it becomes a predictive model of the world basically and therefore also a compressor of the observations of the world because whatever you can predict you dont have to store extra so compression is a side effect of prediction and how does this recurrent network compress well its inventing little subprograms little subnetworks that stand for everything that frequently appears in the environment like bottles and microphones and faces maybe lots of faces in my environment so im learning to create something like a prototype face and a new face comes along and all i have to encode are the deviations from the prototype so its compressing all the time the stuff that frequently appears theres one thing that appears all the time that is present all the time when the agent is interacting with its environment which is the agent itself but just for data compression reasons it is extremely natural for this recurrent network to come up with little subnetworks that stand for the properties of the agents the hand the other actuators and all the stuff that you need to better encode the data which is influenced by the actions of the agent so there just as a side effect of data compression during problem solving you have internal self models now you can use this model of the world to plan your future and thats what we also have done since 1990 so the recurrent network which is the controller which is trying to maximize reward can use this model of the network of the world this model network of the world this predictive model of the world to plan ahead and say lets not do this action sequence lets do this action sequence instead because it leads to more predicted reward and whenever it is waking up these little subnetworks that stand for itself then it is thinking about itself and it is thinking about itself and it is exploring mentally the consequences of its own actions and now you tell me what is still missing missing the next the gap to consciousness there isnt thats a really beautiful idea that if life is a collection of data and life is a process of compressing that data to act efficiently in that data you yourself appear very often so its useful to form compressions of yourself and its a really beautiful formulation of what consciousness is a necessary side effect its actually quite compelling to me youve described rnns developed lstms long short term memory networks that are a type of recurrent neural networks that have gotten a lot of success recently so these are networks that model the temporal aspects in the data temporal patterns in the data and youve called them the deepest of the neural networks so what do you think is the value of depth in the models that we use to learn since you mentioned the long short term memory and the lstm i have to mention the names of the brilliant students who made that possible first of all my first student ever sepp hochreiter who had fundamental insights already in his diploma thesis then felix geers who had additional important contributions alex gray is a guy from scotland who is mostly responsible for this ctc algorithm which is now often used to train the lstm to do the speech recognition on all the google android phones and whatever and siri and so on so these guys without these guys i would be nothing its a lot of incredible work what is now the depth what is the importance of depth well most problems in the real world are deep in the sense that the current input doesnt tell you all you need to know about the environment so instead you have to have a memory of what happened in the past and often important parts of that memory are dated they are pretty old so when youre doing speech recognition for example and somebody says 11 then thats about half a second or something like that which means its already 50 time steps and another guy or the same guy says 7 so the ending is the same even but now the system has to see the distinction between 7 and 11 and the only way it can see the difference is it has to store that 50 steps ago there was an s or an l 11 or 7 so there you have already a problem of depth 50 because for each time step you have something like a virtual layer in the expanded unrolled version of this recurrent network which is doing the speech recognition so these long time lags they translate into problem depth and most problems in this world are such that you really have to look far back in time to understand what is the problem and to solve it but just like with lstms you dont necessarily need to when you look back in time remember every aspect you just need to remember the important aspects thats right the network has to learn to put the important stuff into memory and to ignore the unimportant noise but in that sense deeper and deeper is better or is there a limitation i mean lstm is one of the great examples of architectures that do something beyond just deeper and deeper networks theres clever mechanisms for filtering data for remembering and forgetting so do you think that kind of thinking is necessary if you think about lstms as a leap a big leap forward over traditional vanilla rnns what do you think is the next leap within this context so lstm is a very clever improvement but lstm still dont have the same kind of ability to see far back in the past as us humans do the credit assignment problem across way back not just 50 time steps or 100 or 1000 but millions and billions its not clear what are the practical limits of the lstm when it comes to looking back already in 2006 i think we had examples where it not only looked back tens of thousands of steps but really millions of steps and juan perez ortiz in my lab i think was the first author of a paper where we really was it 2006 or something had examples where it learned to look back for more than 10 million steps so for most problems of speech recognition its not necessary to look that far back but there are examples where it does now the looking back thing thats rather easy because there is only one past but there are many possible futures and so a reinforcement learning system which is trying to maximize its future expected reward and doesnt know yet which of these many possible futures should i select given this one single past is facing problems that the lstm by itself cannot solve so the lstm is good for coming up with a compact representation of the history and observations and actions so far but now how do you plan in an efficient and good way among all these how do you select one of these many possible action sequences that a reinforcement learning system has to consider to maximize reward in this unknown future we have this basic setup where you have one recurrent network which gets in the video and the speech and whatever and its executing actions and its trying to maximize reward so there is no teacher who tells it what to do at which point in time and then theres the other network which is just predicting whats going to happen if i do that and that and that could be an lstm network and it learns to look back all the way to make better predictions of the next time step so essentially although its predicting only the next time step it is motivated to learn to put into memory something that happened maybe a million steps ago because its important to memorize that if you want to predict that at the next time step the next event now how can a model of the world like that a predictive model of the world be used by the first guy lets call it the controller and the model the controller and the model how can the model be used by the controller to efficiently select among these many possible futures the naive way we had about 30 years ago was lets just use the model of the world as a stand in as a simulation of the world and millisecond by millisecond we plan the future and that means we have to roll it out really in detail and it will work only if the model is really good and it will still be inefficient because we have to look at all these possible futures and there are so many of them so instead what we do now since 2015 in our cm systems controller model systems we give the controller the opportunity to learn by itself how to use the potentially relevant parts of the m of the model network to solve new problems more quickly and if it wants to it can learn to ignore the m and sometimes its a good idea to ignore the m because its really bad its a bad predictor in this particular situation of life where the controller is currently trying to maximize reward however it can also learn to address and exploit some of the subprograms that came about in the model network through compressing the data by predicting it so it now has an opportunity to reuse that code the algorithmic information in the model network to reduce its own search space such that it can solve a new problem more quickly than without the model compression so youre ultimately optimistic and excited about the power of rl of reinforcement learning in the context of real systems absolutely yeah so you see rl as a potential having a huge impact beyond just sort of the m part is often developed on supervised learning methods you see rl as a for problems of self driving cars or any kind of applied cyber robotics thats the correct interesting direction for research in your view i do think so we have a company called nasence which has applied reinforcement learning to little audis which learn to park without a teacher the same principles were used of course so these little audis they are small maybe like that so much smaller than the real audis but they have all the sensors that you find in the real audis you find the cameras the lidar sensors they go up to 120 kilometers an hour if they want to and they have pain sensors basically and they dont want to bump against obstacles and other audis and so they must learn like little babies to park take the raw vision input and translate that into actions that lead to successful parking behavior which is a rewarding thing and yes they learn that so we have examples like that and its only in the beginning this is just the tip of the iceberg and i believe the next wave of ai is going to be all about that so at the moment the current wave of ai is about passive pattern observation and prediction and thats what you have on your smartphone and what the major companies on the pacific rim are using to sell you ads to do marketing thats the current sort of profit in ai and thats only one or two percent of the world economy which is big enough to make these companies pretty much the most valuable companies in the world but theres a much much bigger fraction of the economy going to be affected by the next wave which is really about machines that shape the data through their own actions do you think simulation is ultimately the biggest way that those methods will be successful in the next 10 20 years were not talking about 100 years from now were talking about sort of the near term impact of rl do you think really good simulation is required or is there other techniques like imitation learning observing other humans operating in the real world where do you think the success will come from so at the moment we have a tendency of using physics simulations to learn behavior from machines that learn to solve problems that humans also do not know how to solve however this is not the future because the future is in what little babies do they dont use a physics engine to simulate the world no they learn a predictive model of the world which maybe sometimes is wrong in many ways but captures all kinds of important abstract high level predictions which are really important to be successful and thats what was the future 30 years ago when we started that type of research but its still the future and now we know much better how to go there to move forward and to really make working systems based on that where you have a learning model of the world a model of the world that learns to predict whats going to happen if i do that and that and then the controller uses that model to more quickly learn successful action sequences and then of course always this curiosity thing in the beginning the model is stupid so the controller should be motivated to come up with experiments with action sequences that lead to data that improve the model do you think improving the model constructing an understanding of the world in this connection is now the popular approaches that have been successful are grounded in ideas of neural networks but in the 80s with expert systems theres symbolic ai approaches which to us humans are more intuitive in the sense that it makes sense that you build up knowledge in this knowledge representation what kind of lessons can we draw into our current approaches from expert systems from symbolic ai', 'the following is a conversation with thomas sanholm hes a professor at cmu and co creator of labratus which is the first ai system to beat top human players in the game of heads up no limit texas holdem he has published over 450 papers on game theory and machine learning including a best paper in 2017 at nips now renamed to newrips which is where i caught up with him for this conversation his research and companies have had wide reaching impact in the real world especially because he and his group not only propose new ideas but also build systems to prove that these ideas work in the real world this conversation is part of the mit course on artificial general intelligence and the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with thomas sanholm can you describe at the high level the game of poker texas holdem heads up texas holdem for people who might not be familiar with this card game yeah happy to so heads up no limit texas holdem has really emerged in the ai community as a main benchmark for testing these application independent algorithms for imperfect information game solving and this is a game thats actually played by humans you dont see that much on tv or casinos because well for various reasons but you do see it in some expert level casinos and you see it in the best poker movies of all time its actually an event in the world series of poker but mostly its played online and typically for pretty big sums of money and this is a game that usually only experts play so if you go to your home game on a friday night it probably is not gonna be heads up no limit texas holdem it might be no limit texas holdem in some cases but typically for a big group and its not as competitive while heads up means its two players so its really like me against you am i better or are you better much like chess or go in that sense but an imperfect information game which makes it much harder because i have to deal with issues of you knowing things that i dont know and i know things that you dont know instead of pieces being nicely laid on the board for both of us to see so in texas holdem theres two cards that you only see that belong to you yeah and there is they gradually lay out some cards that add up overall to five cards that everybody can see yeah so the imperfect nature of the information is the two cards that youre holding in your hand up front yeah so as you said you first get two cards in private each and then theres a betting round then you get three cards in public on the table then theres a betting round then you get the fourth card in public on the table theres a betting round then you get the 5th card on the table theres a betting round so theres a total of four betting rounds and four tranches of information revelation if you will the only the first tranche is private and then its public from there and this is probably by far the most popular game in ai and just the general public in terms of imperfect information so thats probably the most popular spectator game to watch right so which is why its a super exciting game to tackle so its on the order of chess i would say in terms of popularity in terms of ai setting it as the bar of what is intelligence so in 2017 labratus how do you pronounce it labratus labratus labratus beats a little latin there a little bit of latin labratus beats a few four expert human players can you describe that event what you learned from it what was it like what was the process in general for people who have not read the papers and the study yeah so the event was that we invited four of the top 10 players with these specialist players in heads up no limit texas holden which is very important because this game is actually quite different than the multiplayer version we brought them in to pittsburgh to play at the reverse casino for 20 days we wanted to get 120000 hands in because we wanted to get statistical significance so its a lot of hands for humans to play even for these top pros who play fairly quickly normally so we couldnt just have one of them play so many hands 20 days they were playing basically morning to evening and i raised 200000 as a little incentive for them to play and the setting was so that they didnt all get 50000 we actually paid them out based on how they did against the ai each so they had an incentive to play as hard as they could whether theyre way ahead or way behind or right at the mark of beating the ai and you dont make any money unfortunately right no we cant make any money so originally a couple of years earlier i actually explored whether we could actually play for money because that would be of course interesting as well to play against the top people for money but the pennsylvania gaming board said no so we couldnt so this is much like an exhibit like for a musician or a boxer or something like that nevertheless they were keeping track of the money and brought us close to 2 million i think so if it was for real money if you were able to earn money that was a quite impressive and inspiring achievement just a few details what were the players looking at were they behind a computer what was the interface like yes they were playing much like they normally do these top players when they play this game they play mostly online so theyre used to playing through a ui and they did the same thing here so there was this layout you could imagine theres a table on a screen theres the human sitting there and then theres the ai sitting there and the screen shows everything thats happening the cards coming out and shows the bets being made and we also had the betting history for the human so if the human forgot what had happened in the hand so far they could actually reference back and so forth is there a reason they were given access to the betting history for well we just it didnt really matter they wouldnt have forgotten anyway these are top quality people but we just wanted to put out there so its not a question of the human forgetting and the ai somehow trying to get advantage of better memory so what was that like i mean that was an incredible accomplishment so what did it feel like before the event did you have doubt hope where was your confidence at yeah thats great so great question so 18 months earlier i had organized a similar brains versus ai competition with a previous ai called cloudyco and we couldnt beat the humans so this time around it was only 18 months later and i knew that this new ai libratus was way stronger but its hard to say how youll do against the top humans before you try so i thought we had about a 50 50 shot and the international betting sites put us as a four to one or five to one underdog so its kind of interesting that people really believe in people and over ai not just people people dont just over believe in themselves but they have overconfidence in other people as well compared to the performance of ai and yeah so we were a four to one or five to one underdog and even after three days of beating the humans in a row we were still 50 50 on the international betting sites do you think theres something special and magical about poker and the way people think about it in the sense you have i mean even in chess theres no hollywood movies poker is the star of many movies and theres this feeling that certain human facial expressions and body language eye movement all these tells are critical to poker like you can look into somebodys soul and understand their betting strategy and so on so thats probably why possibly do you think that is why people have a confidence that humans will outperform because ai systems cannot in this construct perceive these kinds of tells theyre only looking at betting patterns and nothing else betting patterns and statistics so whats more important to you if you step back on human players human versus human whats the role of these tells of these ideas that we romanticize yeah so ill split it into two parts so one is why do humans trust humans more than ai and have overconfidence in humans i think thats not really related to the tell question its just that theyve seen these top players how good they are and theyre really fantastic so its just hard to believe that an ai could beat them so i think thats where that comes from and thats actually maybe a more general lesson about ai that until youve seen it overperform a human its hard to believe that it could but then the tells a lot of these top players theyre so good at hiding tells that among the top players its actually not really worth it for them to invest a lot of effort trying to find tells in each other because theyre so good at hiding them so yes at the kind of friday evening game tells are gonna be a huge thing you can read other people and if youre a good reader youll read them like an open book but at the top levels of poker now the tells become a much smaller and smaller aspect of the game as you go to the top levels the amount of strategies the amount of possible actions is very large 10 to the power of 100 plus so there has to be some ive read a few of the papers related it has to form some abstractions of various hands and actions so what kind of abstractions are effective for the game of poker yeah so youre exactly right so when you go from a game tree thats 10 to the 161 especially in an imperfect information game its way too large to solve directly even with our fastest equilibrium finding algorithms so you wanna abstract it first and abstraction in games is much trickier than abstraction in mdps or other single agent settings because you have these abstraction pathologies that if i have a finer grained abstraction the strategy that i can get from that for the real game might actually be worse than the strategy i can get from the coarse grained abstraction so you have to be very careful now the kinds of abstractions just to zoom out were talking about theres the hands abstractions and then theres betting strategies yeah betting actions yeah baiting actions so theres information abstraction dont talk about general games information abstraction which is the abstraction of what chance does and this would be the cards in the case of poker and then theres action abstraction which is abstracting the actions of the actual players which would be bets in the case of poker yourself and the other players yes yourself and other players and for information abstraction we were completely automated so these are algorithms but they do what we call potential aware abstraction where we dont just look at the value of the hand but also how it might materialize into good or bad hands over time and its a certain kind of bottom up process with integer programming there and clustering and various aspects how do you build this abstraction and then in the action abstraction there its largely based on how humans and other ais have played this game in the past but in the beginning we actually used an automated action abstraction technology which is provably convergent that it finds the optimal combination of bet sizes but its not very scalable so we couldnt use it for the whole game but we use it for the first couple of betting actions so whats more important the strength of the hand so the information abstraction or the how you play them the actions does it you know the romanticized notion again is that it doesnt matter what hands you have that the actions the betting may be the way you win no matter what hands you have yeah so thats why you have to play a lot of hands so that the role of luck gets smaller so you could otherwise get lucky and get some good hands and then youre gonna win the match even with thousands of hands you can get lucky because theres so much variance in no limit texas holden because if we both go all in its a huge stack of variance so there are these massive swings in no limit texas holden so thats why you have to play not just thousands but over 100000 hands to get statistical significance so let me ask another way this question if you didnt even look at your hands but they didnt know that the opponents didnt know that how well would you be able to do oh thats a good question theres actually i heard this story that theres this norwegian female poker player called annette oberstad whos actually won a tournament by doing exactly that but that would be extremely rare so you cannot really play well that way okay so the hands do have some role to play okay so labradus does not use as far as i understand they use learning methods deep learning is there room for learning in theres no reason why labradus doesnt combine with an alphago type approach for estimating the quality for function estimator what are your thoughts on this maybe as compared to another algorithm which im not that familiar with deepstack the engine that does use deep learning that its unclear how well it does but nevertheless uses deep learning so what are your thoughts about learning methods to aid in the way that labradus plays in the game of poker yeah so as you said labradus did not use learning methods and played very well without them since then we have actually actually here we have a couple of papers on things that do use learning techniques excellent and deep learning in particular and sort of the way youre talking about where its learning an evaluation function but in imperfect information games unlike lets say in go or now also in chess and shogi its not sufficient to learn an evaluation for a state because the value of an information set depends not only on the exact state but it also depends on both players beliefs like if i have a bad hand im much better off if the opponent thinks i have a good hand and vice versa if i have a good hand im much better off if the opponent believes i have a bad hand so the value of a state is not just a function of the cards it depends on if you will the path of play but only to the extent that its captured in the belief distributions so thats why its not as simple as it is in perfect information games and i dont wanna say its simple there either its of course very complicated computationally there too but at least conceptually its very straightforward theres a state theres an evaluation function you can try to learn it here you have to do something more and what we do is in one of these papers were looking at where we allow the opponent to actually take different strategies at the leaf of the search tree if you will and that is a different way of doing it and it doesnt assume therefore a particular way that the opponent plays but it allows the opponent to choose from a set of different continuation strategies and that forces us to not be too optimistic in a look ahead search and thats one way you can do sound look ahead search in imperfect information games which is very difficult and you were asking about deepstack what they did it was very different than what we do either in libratus or in this new work they were randomly generating various situations in the game then they were doing the look ahead from there to the end of the game as if that was the start of a different game and then they were using deep learning to learn those values of those states but the states were not just the physical states they include belief distributions when you talk about look ahead for deepstack or with libratus does it mean considering every possibility that the game can evolve are we talking about extremely sort of this exponentially growth of a tree yes so were talking about exactly that much like you do in alpha beta search or monte carlo tree search but with different techniques so theres a different search algorithm and then we have to deal with the leaves differently so if you think about what libratus did we didnt have to worry about this because we only did it at the end of the game so we would always terminate into a real situation and we would know what the payout is it didnt do these depth limited lookaheads but now in this new paper which is called depth limited i think its called depth limited search for imperfect information games we can actually do sound depth limited lookahead so we can actually start to do the look ahead from the beginning of the game on because thats too complicated to do for this whole long game so in libratus we were just doing it for the end so and then the other side this belief distribution so is it explicitly modeled what kind of beliefs that the opponent might have yeah it is explicitly modeled but its not assumed the beliefs are actually output not input of course the starting beliefs are input but they just fall from the rules of the game because we know that the dealer deals uniformly from the deck so i know that every pair of cards that you might have is equally likely i know that for a fact that just follows from the rules of the game of course except the two cards that i have i know you dont have those yeah you have to take that into account thats called card removal and thats very important is the dealing always coming from a single deck in heads up so you can assume single deck so you know that if i have the ace of spades i know you dont have an ace of spades great so in the beginning your belief is basically the fact that its a fair dealing of hands but how do you start to adjust that belief nuclear weapons have been here its an obvious problem thats just been sitting there so how do you think about what is the mechanism design there that just made everything seem stable and are you still extremely worried i am still extremely worried so you probably know the simple game theory of mad so this was a mutually assured destruction and it doesnt require any computation with small matrices you can actually convince yourself that the game is such that nobody wants to initiate yeah thats a very coarse grained analysis and it really works in a situational way you have two superpowers or small number of superpowers now things are very different you have a smaller nuke so the threshold of initiating is smaller and you have smaller countries and non nation actors who may get a nuke and so on so i think its riskier now than it was maybe ever before and what idea application of ai youve talked about a little bit but what is the most exciting to you right now i mean youre here at nips neurips now you have a few excellent pieces of work but what are you thinking into the future with several companies youre doing whats the most exciting thing or one of the exciting things the number one thing for me right now is coming up with these scalable techniques for game solving and applying them into the real world im still very interested in market design as well and were doing that in the optimized markets but im most interested if number one right now is strategic machine strategy robot getting that technology out there and seeing as you were in the trenches doing applications what needs to be actually filled what technology gaps still need to be filled so its so hard to just put your feet on the table and imagine what needs to be done but when youre actually doing real applications the applications tell you what needs to be done and i really enjoy that interaction is it a challenging process to apply some of the state of the art techniques youre working on and having the various players in industry or the military or people who could really benefit from it actually use it whats that process like of autonomous vehicles work with automotive companies and theyre in many ways are a little bit old fashioned its difficult they really want to use this technology theres clearly will have a significant benefit but the systems arent quite in place to easily have them integrated in terms of data in terms of compute in terms of all these kinds of things so is that one of the bigger challenges that youre facing and how do you tackle that challenge yeah i think thats always a challenge thats kind of slowness and inertia really of lets do things the way weve always done it you just have to find the internal champions at the customer who understand that hey things cant be the same way in the future otherwise bad things are going to happen and its in autonomous vehicles its actually very interesting that the car makers are doing that and theyre very traditional but at the same time you have tech companies who have nothing to do with cars or transportation like google and baidu really pushing on autonomous cars i find that fascinating clearly youre super excited about actually these ideas having an impact in the world in terms of the technology in terms of ideas and research are there directions that youre also excited about whether thats on some of the approaches you talked about for the imperfect information games whether its applying deep learning to some of these problems is there something that youre excited in the research side of things yeah yeah lots of different things in the game solving so solving even bigger games games where you have more hidden action of the player actions as well poker is a game where really the chance actions are hidden or some of them are hidden but the player actions are public multiplayer games of various sorts collusion opponent exploitation all and even longer games so games that basically go forever but theyre not repeated so see extensive fun games that go forever what would that even look like how do you represent that how do you solve that whats an example of a game like that or is this some of the stochastic games that you mentioned lets say business strategy so its not just modeling like a particular interaction but thinking about the business from here to eternity or lets say military strategy so its not like war is gonna go away how do you think about military strategy thats gonna go forever how do you even model that how do you know whether a move was good that somebody made and so on so thats kind of one direction im also very interested in learning much more scalable techniques for integer programming so we had an icml paper this summer on that the first automated algorithm configuration paper that has theoretical generalization guarantees so if i see this many training examples and i told my algorithm in this way its going to have good performance on the real distribution which ive not seen so which is kind of interesting that algorithm configuration has been going on now for at least 17 years seriously and there has not been any generalization theory before well this is really exciting and its a huge honor to talk to you thank you so much tomas thank you for bringing labradus to the world and all the great work youre doing well thank you very much its been fun no more questions well thats where this beauty of game theory comes so nash equilibrium which john nash introduced in 1950 introduces what rational play is when you have more than one player and these are pairs of strategies where strategies are contingency plans one for each player so that neither player wants to deviate to a different strategy given that the other doesnt deviate but as a side effect you get the beliefs from base roll so nash equilibrium really isnt just deriving in these imperfect information games nash equilibrium it doesnt just define strategies it also defines beliefs for both of us and defines beliefs for each state so at each state its called information sets at each information set in the game theres a set of different states that we might be in but i dont know which one were in nash equilibrium tells me exactly what is the probability distribution over those real world states in my mind how does nash equilibrium give you that distribution so why ill do a simple example so you know the game rock paper scissors so we can draw it as player one moves first and then player two moves but of course its important that player two doesnt know what player one moved otherwise player two would win every time so we can draw that as an information set where player one makes one of three moves first and then theres an information set for player two so player two doesnt know which of those nodes the world is in but once we know the strategy for player one nash equilibrium will say that you play 1 3rd rock 1 3rd paper 1 3rd scissors from that i can derive my beliefs on the information set that theyre 1 3rd 1 3rd 1 3rd so bayes gives you that bayes gives you but is that specific to a particular player or is it something you quickly update with the specific player no the game theory isnt really player specific so thats also why we dont need any data we dont need any history how these particular humans played in the past or how any ai or human had played before its all about rationality so the ai just thinks about what would a rational opponent do and what would i do if i am rational and thats the idea of game theory so its really a data free opponent free approach so it comes from the design of the game as opposed to the design of the player exactly theres no opponent modeling per se i mean weve done some work on combining opponent modeling with game theory so you can exploit weak players even more but thats another strand and in librarus we didnt turn that on so i decided that these players are too good and when you start to exploit an opponent you typically open yourself up to exploitation and these guys have so few holes to exploit and theyre worlds leading experts in counter exploitation so i decided that were not gonna turn that stuff on actually i saw a few of your papers exploiting opponents it sounded very interesting to explore do you think theres room for exploitation generally outside of librarus is there a subject or people differences that could be exploited maybe not just in poker but in general interactions and negotiations all these other domains that youre considering yeah definitely weve done some work on that and i really like the work at hybrid digested too so you figure out what would a rational opponent do and by the way thats safe in these zero sum games two player zero sum games because if the opponent does something irrational yes it might throw off my beliefs but the amount that the player can gain by throwing off my belief is always less than they lose by playing poorly so its safe but still if somebodys weak as a player you might wanna play differently to exploit them more so you can think about it this way a game theoretic strategy is unbeatable but it doesnt maximally beat the other opponent so the winnings per hand might be better with a different strategy and the hybrid is that you start from a game theoretic approach and then as you gain data about the opponent in certain parts of the game tree then in those parts of the game tree you start to tweak your strategy more and more towards exploitation while still staying fairly close to the game theoretic strategy so as to not open yourself up to exploitation too much how do you do that do you try to vary up strategies make it unpredictable its like what is it tit for tat strategies in prisoners dilemma or well thats a repeated game repeated games simple prisoners dilemma repeated games but even there theres no proof that says that thats the best thing but experimentally it actually does well so what kind of games are there first of all i dont know if this is something that you could just summarize theres perfect information games where all the informations on the table there is imperfect information games theres repeated games that you play over and over theres zero sum games theres non zero sum games and then theres a really important distinction youre making two player versus more players so what are what other games are there and whats the difference for example with this two player game versus more players what are the key differences in your view so let me start from the basics so a repeated game is a game where the same exact game is played over and over in these extensive form games where its think about three form maybe with these information sets to represent incomplete information you can have kind of repetitive interactions even repeated games are a special case of that by the way but the game doesnt have to be exactly the same its like in sourcing auctions yes were gonna see the same supply base year to year but what im buying is a little different every time and the supply base is a little different every time and so on so its not really repeated so to find a purely repeated game is actually very rare in the world so theyre really a very course model of whats going on then if you move up from just repeated simple repeated matrix games not all the way to extensive form games but in between theyre stochastic games where you know theres these you think about it like these little matrix games and when you take an action and your opponent takes an action they determine not which next state im going to next game im going to but the distribution over next games where i might be going to so thats the stochastic game but its like matrix games repeated stochastic games extensive form games that is from less to more general and poker is an example of the last one so its really in the most general setting extensive form games and thats kind of what the ai community has been working on and being benchmarked on with this heads up no limit texas holdem can you describe extensive form games whats the model here yeah so if youre familiar with the tree form so its really the tree form like in chess theres a search tree versus a matrix versus a matrix yeah and the matrix is called the matrix form or bi matrix form or normal form game and here you have the tree form so you can actually do certain types of reasoning there that you lose the information when you go to normal form theres a certain form of equivalence like if you go from tree form and you say it every possible contingency plan is a strategy then i can actually go back to the normal form but i lose some information from the lack of sequentiality then the multiplayer versus two player distinction is an important one so two player games in zero sum are conceptually easier and computationally easier theyre still huge like this one but theyre conceptually easier and computationally easier in that conceptually you dont have to worry about which equilibrium is the other guy going to play when there are multiple because any equilibrium strategy is a best response to any other equilibrium strategy so i can play a different equilibrium from you and well still get the right values of the game that falls apart even with two players when you have general sum games even without cooperation just in general even without cooperation so theres a big gap from two player zero sum to two player general sum or even to three player zero sum thats a big gap at least in theory can you maybe non mathematically provide the intuition why it all falls apart with three or more players it seems like you should still be able to have a nash equilibrium thats instructive that holds okay so it is true that all finite games have a nash equilibrium so this is what john nash actually proved so they do have a nash equilibrium thats not the problem the problem is that there can be many and then theres a question of which equilibrium to select so and if you select your strategy from a different equilibrium and i select mine then what does that mean and in these non zero sum games we may lose some joint benefit by being just simply stupid we could actually both be better off if we did something else and in three player you get other problems also like collusion like maybe you and i can gang up on a third player and we can do radically better by colluding so there are lots of issues that come up there so noah brown the student you work with on this has mentioned i looked through the ama on reddit he mentioned that the ability of poker players to collaborate will make the game he was asked the question of how would you make the game of poker or both of you were asked the question how would you make the game of poker beyond being solvable by current ai methods and he said that theres not many ways of making poker more difficult but a collaboration or cooperation between players would make it extremely difficult so can you provide the intuition behind why that is if you agree with that idea yeah so ive done a lot of work on coalitional games and we actually have a paper here with my other student gabriele farina and some other collaborators at nips on that actually just came back from the poster session where we presented this but so when you have a collusion its a different problem and it typically gets even harder then even the game representations some of the game representations dont really allow good computation so we actually introduced a new game representation for that is that kind of cooperation part of the model are you do you have do you have information about the fact that other players are cooperating or is it just this chaos that where nothing is known so theres some things unknown can you give an example of a collusion type game or is it usually so like bridge so think about bridge its like when you and i are on a team our payoffs are the same the problem is that we cant talk so when i get my cards i cant whisper to you what my cards are that would not be allowed so we have to somehow coordinate our strategies ahead of time and only ahead of time and then theres certain signals we can talk about but they have to be such that the other team also understands them so thats an example where the coordination is already built into the rules of the game but in many other situations like auctions or negotiations or diplomatic relationships poker its not really built in but it still can be very helpful for the colluders ive read you write somewhere the negotiations you come to the table with prior like a strategy that youre willing to do and not willing to do those kinds of things so how do you start to now moving away from poker moving beyond poker into other applications like negotiations how do you start applying this to other domains even real world domains that youve worked on yeah i actually have two startup companies doing exactly that one is called strategic machine and thats for kind of business applications gaming sports all sorts of things like that any applications of this to business and to sports and to gaming to various types of things in finance electricity markets and so on and the other is called strategy robot where we are taking these to military security cyber security and intelligence applications i think you worked a little bit in how do you put it advertisement sort of suggesting ads kind of thing auction thats another company optimized markets but thats much more about a combinatorial market and optimization based technology thats not using these game theoretic reasoning technologies i see okay so what sort of high level do you think about our ability to use game theoretic concepts to model human behavior do you think human behavior is amenable to this kind of modeling outside of the poker games and where have you seen it done successfully in your work im not sure the goal really is modeling humans like for example if im playing a zero sum game i dont really care that the opponent is actually following my model of rational behavior because if theyre not thats even better for me right so see with the opponents in games the prerequisite is that you formalize the interaction in some way that can be amenable to analysis and youve done this amazing work with mechanism design designing games that have certain outcomes but so ill tell you an example from my world of autonomous vehicles right were studying pedestrians and pedestrians and cars negotiate in this nonverbal communication theres this weird game dance of tension where pedestrians are basically saying i trust that you wont kill me and so as a jaywalker i will step onto the road even though im breaking the law and theres this tension and the question is we really dont know how to model that well in trying to model intent and so people sometimes bring up ideas of game theory and so on do you think that aspect of human behavior can use these kinds of imperfect information approaches modeling how do you start to attack a problem like that when you dont even know how to design the game to describe the situation in order to solve it okay so i havent really thought about jaywalking but one thing that i think could be a good application in autonomous vehicles is the following so lets say that you have fleets of autonomous cars operating by different companies so maybe heres the waymo fleet and heres the uber fleet if you think about the rules of the road they define certain legal rules but that still leaves a huge strategy space open like as a simple example when cars merge how humans merge they slow down and look at each other and try to merge wouldnt it be better if these situations would already be prenegotiated so we can actually merge at full speed and we know that this is the situation this is how we do it and its all gonna be faster but there are way too many situations to negotiate manually so you could use automated negotiation this is the idea at least you could use automated negotiation to negotiate all of these situations or many of them in advance and of course it might be that hey maybe youre not gonna always let me go first maybe you said okay well in these situations ill let you go first but in exchange youre gonna give me too much youre gonna let me go first in this situation so its this huge combinatorial negotiation and do you think theres room in that example of merging to model this whole situation as an imperfect information game or do you really want to consider it to be a perfect no thats a good question yeah thats a good question do you pay the price of assuming that you dont know everything yeah i dont know its certainly much easier games with perfect information are much easier so if you cant get away with it you should but if the real situation is of imperfect information then youre gonna have to deal with imperfect information great so what lessons have you learned the annual computer poker competition an incredible accomplishment of ai you look at the history of deep blue alphago these kind of moments when ai stepped up in an engineering effort and a scientific effort combined to beat the best of human players so what do you take away from this whole experience what have you learned about designing ai systems that play these kinds of games and what does that mean for ai in general for the future of ai development yeah so thats a good question so theres so much to say about it i do like this type of performance oriented research although in my group we go all the way from like idea to theory to experiments to big system building to commercialization so we span that spectrum but i think that in a lot of situations in ai you really have to build the big systems and evaluate them at scale before you know what works and doesnt and weve seen that in the computational game theory community that there are a lot of techniques that look good in the small but then they cease to look good in the large and weve also seen that there are a lot of techniques that look superior in theory and i really mean in terms of convergence rates like first order methods better convergence rates like the cfr based algorithms yet the cfr based algorithms are the fastest in practice so it really tells me that you have to test this in reality the theory isnt tight enough if you will to tell you which algorithms are better than the others and you have to look at these things in the large because any sort of projections you do from the small can at least in this domain be very misleading so thats kind of from a kind of a science and engineering perspective from a personal perspective its been just a wild experience in that with the first poker competition the first brains versus ai man machine poker competition that we organized there had been by the way for other poker games there had been previous competitions but this was for heads up no limit this was the first and i probably became the most hated person in the world of poker and i didnt mean to i just saw why is that for cracking the game for something yeah a lot of people felt that it was a real threat to the whole game the whole existence of the game if ai becomes better than humans people would be scared to play poker because there are these superhuman ais running around taking their money and all of that so i just its just really aggressive the comments were super aggressive i got everything just short of death threats do you think the same was true for chess because right now they just completed the world championships in chess and humans just started ignoring the fact that theres ai systems now that outperform humans and they still enjoy the game its still a beautiful game thats what i think and i think the same thing happens in poker and so i didnt think of myself as somebody who was gonna kill the game and i dont think i did ive really learned to love this game i wasnt a poker player before but learned so many nuances about it from these ais and theyve really changed how the game is played by the way so they have these very martian ways of playing poker and the top humans are now incorporating those types of strategies into their own play so if anything to me our work has made poker a richer more interesting game for humans to play not something that is gonna steer humans away from it entirely just a quick comment on something you said which is if i may say so in academia is a little bit rare sometimes its pretty brave to put your ideas to the test in the way you described saying that sometimes good ideas dont work when you actually try to apply them at scale so where does that come from i mean if you could do advice for people what drives you in that sense were you always this way i mean it takes a brave person i guess is what im saying to test their ideas and to see if this thing actually works against human top human players and so on yeah i dont know about brave but it takes a lot of work it takes a lot of work and a lot of time to organize to make something big and to organize an event and stuff like that and what drives you in that effort because you could still i would argue get a best paper award at nips as you did in 17 without doing this thats right yes and so in general i believe its very important to do things in the real world and at scale and thats really where the pudding if you will proof is in the pudding thats where it is in this particular case it was kind of a competition between different groups and for many years as to who can be the first one to beat the top humans at heads up no limit texas holdem so it became kind of like a competition who can get there yeah so a little friendly competition could do wonders for progress yes absolutely so the topic of mechanism design which is really interesting also kind of new to me except as an observer of i dont know politics and any im an observer of mechanisms but you write in your paper an automated mechanism design that i quickly read so mechanism design is designing the rules of the game so you get a certain desirable outcome and you have this work on doing so in an automatic fashion as opposed to fine tuning it so what have you learned from those efforts if you look say i dont know at complexes like our political system can we design our political system to have in an automated fashion to have outcomes that we want can we design something like traffic lights to be smart where it gets outcomes that we want so what are the lessons that you draw from that work yeah so i still very much believe in the automated mechanism design direction yes but its not a panacea there are impossibility results in mechanism design saying that there is no mechanism that accomplishes objective x in class c so its not going to theres no way using any mechanism design tools manual or automated to do certain things in mechanism design can you describe that again so meaning its impossible to achieve that yeah yeah and its unlikely impossible impossible so these are not statements about human ingenuity who might come up with something smart these are proofs that if you want to accomplish properties x in class c that is not doable with any mechanism the good thing about automated mechanism design is that were not really designing for a class were designing for specific settings at a time so even if theres an impossibility result for the whole class it just doesnt mean that all of the cases in the class are impossible it just means that some of the cases are impossible so we can actually carve these islands of possibility within these known impossible classes and weve actually done that so one of the famous results in mechanism design is the meyerson satethweight theorem by roger meyerson and mark satethweight from 1983 its an impossibility of efficient trade under imperfect information we show that you can in many settings avoid that and get efficient trade anyway depending on how they design the game okay depending how you design the game and of course it doesnt in any way contradict the impossibility result the impossibility result is still there but it just finds spots within this impossible class where in those spots you dont have the impossibility sorry if im going a bit philosophical but what lessons do you draw towards like i mentioned politics or human interaction and designing mechanisms for outside of just these kinds of trading or auctioning or purely formal games or human interaction like a political system how do you think its applicable to yeah politics or to business to negotiations these kinds of things designing rules that have certain outcomes yeah yeah i do think so have you seen that successfully done they havent really oh you mean mechanism design or automated mechanism design automated mechanism design so mechanism design itself has had fairly limited success so far there are certain cases but most of the real world situations are actually not sound from a mechanism design perspective even in those cases where theyve been designed by very knowledgeable mechanism design people the people are typically just taking some insights from the theory and applying those insights into the real world rather than applying the mechanisms directly so one famous example of is the fcc spectrum auctions so ive also had a small role in that and very good economists have been working excellent economists have been working on that with no game theory yet the rules that are designed in practice there theyre such that bidding truthfully is not the best strategy usually mechanism design we try to make things easy for the participants so telling the truth is the best strategy but even in those very high stakes auctions where you have tens of billions of dollars worth of spectrum being auctioned truth telling is not the best strategy and by the way nobody knows even a single optimal bidding strategy for those auctions whats the challenge of coming up with an optimal because theres a lot of players and theres imperfect its not so much that a lot of players but many items for sale and these mechanisms are such that even with just two items or one item bidding truthfully wouldnt be the best strategy if you look at the history of ai its marked by seminal events alphago beating a world champion human go player i would put liberatus winning the heads up no limit holdem as one of such event thank you and what do you think is the next such event whether its in your life or in the broadly ai community that you think might be out there that would surprise the world so thats a great question and i dont really know the answer in terms of game solving heads up no limit texas holdem really was the one remaining widely agreed upon benchmark so that was the big milestone now are there other things yeah certainly there are but theres not one that the community has kind of focused on so what could be other things there are groups working on starcraft there are groups working on dota 2 these are video games or you could have like diplomacy or hanabi things like that these are like recreational games but none of them are really acknowledged as kind of the main next challenge problem like chess or go or heads up no limit texas holdem was so i dont really know in the game solving space what is or what will be the next benchmark i kind of hope that there will be a next benchmark because really the different groups working on the same problem really drove these application independent techniques forward very quickly over 10 years do you think theres an open problem that excites you that you start moving away from games into real world games like say the stock market trading yeah so thats kind of how i am so i am probably not going to work as hard on these recreational benchmarks im doing two startups on game solving technology strategic machine and strategy robot and were really interested in pushing this stuff into practice what do you think would be really a powerful result that would be surprising that would be if you can say i mean five years 10 years from now something that statistically you would say is not very likely but if theres a breakthrough would achieve yeah so i think that overall were in a very different situation in game theory than we are in lets say machine learning so in machine learning its a fairly mature technology and its very broadly applied and proven success in the real world in game solving there are almost no applications yet we have just become superhuman which machine learning you could argue happened in the 90s if not earlier and at least on supervised learning certain complex supervised learning applications now i think the next challenge problem i know youre not asking about it this way youre asking about the technology breakthrough but i think that big big breakthrough is to be able to show that hey maybe most of lets say military planning or most of business strategy will actually be done strategically using computational game theory thats what i would like to see as the next five or 10 year goal maybe you can explain to me again forgive me if this is an obvious question but machine learning methods neural networks suffer from not being transparent not being explainable game theoretic methods nash equilibria do they generally when you see the different solutions are they when you talk about military operations are they once you see the strategies do they make sense are they explainable or do they suffer from the same problems as neural networks do so thats a good question i would say a little bit yes and no and what i mean by that is that these game theoretic strategies lets say nash equilibrium it has provable properties so its unlike lets say deep learning where you kind of cross your fingers hopefully itll work and then after the fact when you have the weights youre still crossing your fingers and i hope it will work here you know that the solution quality is there theres provable solution quality guarantees now that doesnt necessarily mean that the strategies are human understandable thats a whole other problem so i think that deep learning and computational game theory are in the same boat in that sense that both are difficult to understand but at least the game theoretic techniques they have these guarantees of solution quality so do you see business operations strategic operations or even military in the future being at least the strong candidates being proposed by automated systems do you see that yeah i do i do but thats more of a belief than a substantiated fact depending on where you land in optimism or pessimism thats a really to me thats an exciting future especially if theres provable things in terms of optimality so looking into the future theres a few folks worried about the especially you look at the game of poker which is probably one of the last benchmarks in terms of games being solved they worry about the future and the existential threats of artificial intelligence so the negative impact in whatever form on society is that something that concerns you as much or are you more optimistic about the positive impacts of ai oh i am much more optimistic about the positive impacts so just in my own work what weve done so far we run the nationwide kidney exchange hundreds of people are walking around alive today who would it be and its increased employment you have a lot of people now running kidney exchanges and at the transplant centers interacting with the kidney exchange you have extra surgeons nurses anesthesiologists hospitals all of that so employment is increasing from that and the world is becoming a better place another example is combinatorial sourcing auctions we did 800 large scale combinatorial sourcing auctions from 2001 to 2010 in a previous startup of mine called combinenet and we increased the supply chain efficiency on that 60 billion of spend by 126 so thats over 6 billion of efficiency improvement in the world and this is not like shifting value from somebody to somebody else just efficiency improvement like in trucking less empty driving so theres less waste less carbon footprint and so on so a huge positive impact in the near term but sort of to stay in it for a little longer because i think game theory has a role to play here oh let me actually come back on that as one thing i think ai is also going to make the world much safer so thats another aspect that often gets overlooked well let me ask this question maybe you can speak to the safer so i talked to max tegmark and stuart russell who are very concerned about existential threats of ai and often the concern is about value misalignment so ai systems basically working operating towards goals that are not the same as human civilization human beings so it seems like game theory has a role to play there to make sure the values are aligned with human beings i dont know if thats how you think about it if not how do you think ai might help with this problem how do you think ai might make the world safer yeah i think this value misalignment is a fairly theoretical worry and i havent really seen it in because i do a lot of real applications i dont see it anywhere the closest ive seen it was the following type of mental exercise really where i had this argument in the late eighties when we were building these transportation optimization systems and somebody had heard that its a good idea to have high utilization of assets so they told me hey why dont you put that as objective and we didnt even put it as an objective because i just showed him that if you had that as your objective the solution would be to load your trucks full and drive in circles nothing would ever get delivered youd have a hundred percent utilization so yeah i know this phenomenon ive known this for over 30 years but ive never seen it actually be a problem in reality and yes if you have the wrong objective the ai will optimize that to the hilt and its gonna hurt more than some human whos kind of trying to solve it in a half baked way with some human insight too but i just havent seen that materialize in practice theres this gap that youve actually put your finger on very clearly just now between theory and reality thats very difficult to put into words i think its what you can theoretically imagine the worst possible case or even yeah i mean bad cases and what usually happens in reality so for example to me maybe its something you can comment on having grown up and i grew up in the soviet union theres currently 10000 nuclear weapons in the world and for many decades its theoretically surprising to me that the nuclear war is not broken out do you think about this aspect from a game theoretic perspective in general why is that true why in theory you could see how things would go terribly wrong and somehow yet they have not yeah how do you think about it so i do think about that a lot i think the biggest two threats that were facing as mankind one is climate change and the other is nuclear war so those are my main two worries that i worry about and ive tried to do something about climate thought about trying to do something for climate change twice actually for two of my startups ive actually commissioned studies of what we could do on those things and we didnt really find a sweet spot but im still keeping an eye out on that if theres something where we could actually provide a market solution or optimizations solution or some other technology solution to problems right now like for example pollution critic markets was what we were looking at then and it was much more the lack of political will by those markets were not so successful rather than bad market design so i could go in and make a better market design but that wouldnt really move the needle on the world very much if theres no political will and in the us the market at least the chicago market was just shut down and so on so then it doesnt really help how great your market design was and then the nuclear side its more so global warming is a more encroaching problem', 'the following is a conversation with tommaso poggio hes a professor at mit and is a director of the center for brains minds and machines cited over 100000 times his work has had a profound impact on our understanding of the nature of intelligence in both biological and artificial neural networks he has been an advisor to many highly impactful researchers and entrepreneurs in ai including demis hassabis of deepmind amnon shashua of mobileye and christoph koch of the allen institute for brain science this conversation is part of the mit course on artificial general intelligence and the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with tommaso poggio youve mentioned that in your childhood youve developed a fascination with physics especially the theory of relativity and that einstein was also a childhood hero to you what aspect of einsteins genius the nature of his genius do you think was essential for discovering the theory of relativity you know einstein was a hero to me and im sure to many people because he was able to make of course a major major contribution to physics with simplifying a bit just a gedanken experiment a thought experiment you know imagining communication with lights between a stationary observer and somebody on a train and i thought you know the fact that just with the force of his thought of his thinking of his mind he could get to something so deep in terms of physical reality how time depend on space and speed it was something absolutely fascinating it was the power of intelligence the power of the mind do you think the ability to imagine to visualize as he did as a lot of great physicists do do you think thats in all of us human beings or is there something special to that one particular human being i think you know all of us can learn and have in principle similar breakthroughs there are lessons to be learned from einstein he was one of five phd students at eta the eidgenössische technische hochschule in zurich in physics and he was the worst of the five the only one who did not get an academic position when he graduated when he finished his phd and he went to work as everybody knows for the patent office and so its not so much that he worked for the patent office but the fact that obviously he was smart but he was not a top student obviously was the anti conformist he was not thinking in the traditional way that probably his teachers and the other students were doing so there is a lot to be said about trying to do the opposite or something quite different from what other people are doing thats certainly true for the stock market never buy if everybodys buying and also true for science yes so youve also mentioned staying on the theme of physics that you were excited at a young age by the mysteries of the universe that physics could uncover such as i saw mentioned the possibility of time travel so the most out of the box question i think ill get to ask today do you think time travel is possible well it would be nice if it were possible right now in science you never say no but your understanding of the nature of time yeah its very likely that its not possible to travel in time we may be able to travel forward in time if we can for instance freeze ourselves or go on some spacecraft traveling close to the speed of light but in terms of actively traveling for instance back in time i find probably very unlikely so do you still hold the underlying dream of the engineering intelligence that will build systems that are able to do such huge leaps like discovering the kind of mechanism that would be required to travel through time do you still hold that dream or echoes of it from your childhood yeah i dont think whether there are certain problems that probably cannot be solved depending what you believe about the physical reality like maybe totally impossible to create energy from nothing or to travel back in time but about making machines that can think as well as we do or better or more likely especially in the short and midterm help us think better which is in a sense is happening already with the computers we have and it will happen more and more but that i certainly believe and i dont see in principle why computers at some point could not become more intelligent than we are although the word intelligence is a tricky one and one we should discuss what i mean with that intelligence consciousness words like love all these need to be disentangled so youve mentioned also that you believe the problem of intelligence is the greatest problem in science greater than the origin of life and the origin of the universe youve also in the talk ive listened to said that youre open to arguments against you so what do you think is the most captivating aspect of this problem of understanding the nature of intelligence why does it captivate you as it does well originally i think one of the motivation that i had as i guess a teenager when i was infatuated with theory of relativity was really that i found that there was the problem of time and space and general relativity but there were so many other problems of the same level of difficulty and importance that i could even if i were einstein it was difficult to hope to solve all of them so what about solving a problem whose solution allowed me to solve all the problems and this was what if we could find the key to an intelligence 10 times better or faster than einstein so thats sort of seeing artificial intelligence as a tool to expand our capabilities but is there just an inherent curiosity in you in just understanding what it is in here that makes it all work yes absolutely youre right so i started saying this was the motivation when i was a teenager but soon after i think the problem of human intelligence became a real focus of my science and my research because i think for me the most interesting problem is really asking who we are its asking not only a question about science but even about the very tool we are using to do science which is our brain how does our brain work from where does it come from what are its limitations can we make it better and that in many ways is the ultimate question that underlies this whole effort of science so youve made significant contributions in both the science of intelligence and the engineering of intelligence in a hypothetical way let me ask how far do you think we can get in creating intelligence systems without understanding the biological the understanding how the human brain creates intelligence put another way do you think we can build a strong ai system without really getting at the core understanding the functional nature of the brain well this is a real difficult question we did solve problems like flying without really using too much our knowledge about how birds fly it was important i guess to know that you could have things heavier than air being able to fly like birds but beyond that probably we did not learn very much some the brothers wright did learn a lot of observation about birds and designing their aircraft but you can argue we did not use much of biology in that particular case now in the case of intelligence i think that its a bit of a bet right now if you ask ok we all agree well get at some point maybe soon maybe later to a machine that is indistinguishable from my secretary say in terms of what i can ask the machine to do i think well get there and now the question is you can ask people do you think well get there without any knowledge about the human brain or that the best way to get there is to understand better the human brain ok this is i think an educated bet that different people with different backgrounds will decide in different ways the recent history of the progress in ai in the last i would say five years or 10 years has been that the main breakthroughs the main recent breakthroughs really start from neuroscience i can mention reinforcement learning as one its one of the algorithms at the core of alphago which is the system that beat the kind of an official world champion of go lee sedol two three years ago in seoul thats one and that started really with the work of pavlov in 1900 marvin minsky in the 60s and many other neuroscientists later on and deep learning started which is at the core again of alphago and systems like autonomous driving systems for cars like the systems that mobileye which is a company started by one of my ex postdocs amnon shashua did so that is at the core of those things and deep learning really the initial ideas in terms of the architecture of these layered hierarchical networks started with work of torsten wiesel and david hubel at harvard up the river in the 60s so recent history suggests that neuroscience played a big role in these breakthroughs my personal bet is that there is a good chance they continue to play a big role maybe not in all the future breakthroughs but in some of them at least in inspiration at least in inspiration absolutely yes so you studied both artificial and biological neural networks you said these mechanisms that underlie deep learning and reinforcement learning but there is nevertheless significant differences between biological and artificial neural networks as they stand now so between the two what do you find is the most interesting mysterious maybe even beautiful difference as it currently stands in our understanding i must confess that until recently i found that the artificial networks too simplistic relative to real neural networks but recently ive been starting to think that yes there is a very big simplification of what you find in the brain but on the other hand they are much closer in terms of the architecture to the brain than other models that we had that computer science used as model of thinking which were mathematical logics lisp prologue and those kind of things so in comparison to those theyre much closer to the brain you have networks of neurons which is what the brain is about and the artificial neurons in the models as i said caricature of the biological neurons but theyre still neurons single units communicating with other units something that is absent in the traditional computer type models of mathematics reasoning and so on so what aspect would you like to see in artificial neural networks added over time as we try to figure out ways to improve them so one of the main differences and problems in terms of deep learning today and its not only deep learning and the brain is the need for deep learning techniques to have a lot of labeled examples for instance for imagenet you have like a training set which is 1 million images each one labeled by some human in terms of which object is there and its clear that in biology a baby may be able to see millions of images in the first years of life but will not have millions of labels given to him or her by parents or caretakers so how do you solve that i think there is this interesting challenge that today deep learning and related techniques are all about big data big data meaning a lot of examples labeled by humans whereas in nature you have this big data is n going to infinity thats the best n meaning labeled data but i think the biological world is more n going to 1 a child can learn from a very small number of labeled examples like you tell a child this is a car you dont need to say like in imagenet this is a car this is a car this is not a car this is not a car 1 million times and of course with alphago or at least the alphazero variants because the world of go is so simplistic that you can actually learn by yourself through self play you can play against each other in the real world the visual system that youve studied extensively is a lot more complicated than the game of go on the comment about children which are fascinatingly good at learning new stuff how much of it do you think is hardware and how much of it is software yeah thats a good deep question in a sense its the old question of nurture and nature how much is in the gene and how much is in the experience of an individual obviously its both that play a role and i believe that the way evolution gives puts prior information so to speak hardwired is not really hardwired but thats essentially an hypothesis i think whats going on is that evolution has almost necessarily if you believe in darwin is very opportunistic and think about our dna and the dna of drosophila our dna does not have many more genes than drosophila the fly the fly the fruit fly now we know that the fruit fly does not learn very much during its individual existence it looks like one of these machinery that its really mostly not 100 but 95 hardcoded by the genes but since we dont have many more genes than drosophila evolution could encode in as a general learning machinery and then had to give very weak priors like for instance let me give a specific example which is recent work by a member of our center for brains minds and machines we know because of work of other people in our group and other groups that there are cells in a part of our brain neurons that are tuned to faces they seem to be involved in face recognition now this face area seems to be present in young children and adults and one question is is there from the beginning is hardwired by evolution or somehow its learned very quickly so whats your by the way a lot of the questions im asking the answer is we dont really know or linear classifier we really dont understand the individual units or so but we understand what the computation and the limitations and the properties of it are its similar to many things what does it mean to understand how a fusion bomb works how many of us understand the basic principle and some of us may understand deeper details in that sense understanding is as a community as a civilization can we build another copy of it and in that sense do you think there will need to be some evolutionary component where it runs away from our understanding or do you think it could be engineered from the ground up the same way you go from the transistor to powerpoint so many years ago this was actually 40 41 years ago i wrote a paper with david marr who was one of the founding fathers of computer vision computational vision i wrote a paper about levels of understanding which is related to the question we discussed earlier about understanding powerpoint understanding transistors and so on and in that kind of framework we had the level of the hardware and the top level of the algorithms we did not have learning recently i updated adding levels and one level i added to those three was learning and you can imagine you could have a good understanding of how you construct a learning machine like we do but being unable to describe in detail what the learning machines will discover right now that would be still a powerful understanding if i can build a learning machine even if i dont understand in detail every time it learns something just like our children if they start listening to a certain type of music i dont know miley cyrus or something you dont understand why they came to that particular preference but you understand the learning process thats very interesting so on learning for systems to be part of our world it has a certain one of the challenging things that youve spoken about is learning ethics learning morals and how hard do you think is the problem of first of all humans understanding our ethics what is the origin on the neural on the low level of ethics what is it at the higher level is it something thats learnable from machines in your intuition i think yeah ethics is learnable very likely i think its one of these problems where i think understanding the neuroscience of ethics people discuss there is an ethics of neuroscience yeah yes how a neuroscientist should or should not behave can you think of a neurosurgeon and the ethics rule he has to be or he she has to be but im more interested on the neuroscience of ethics youre blowing my mind right now the neuroscience of ethics is very meta yeah and i think that would be important to understand also for being able to design machines that are ethical machines in our sense of ethics and you think there is something in neuroscience theres patterns tools in neuroscience that could help us shed some light on ethics or is it mostly on the psychologists of sociology in which higher level no there is psychology but there is also in the meantime there is evidence fmri of specific areas of the brain that are involved in certain ethical judgment and not only this you can stimulate those area with magnetic fields and change the ethical decisions yeah wow so thats work by a colleague of mine rebecca sachs and there is other researchers doing similar work and i think this is the beginning but ideally at some point well have an understanding of how this works and why it evolved right the big why question yeah it must have some purpose yeah obviously it has some social purposes probably if neuroscience holds the key to at least illuminate some aspect of ethics that means it could be a learnable problem yeah exactly and as were getting into harder and harder questions lets go to the hard problem of consciousness is this an important problem for us to think about and solve on the engineering of intelligence side of your work of our dream its unclear so again this is a deep problem partly because its very difficult to define consciousness and there is a debate among neuroscientists about whether consciousness and philosophers of course whether consciousness is something that requires flesh and blood so to speak or could be that we could have silicon devices that are conscious or up to statement like everything has some degree of consciousness and some more than others this is like giulio tonioni and phi we just recently talked to christoph koch ok christoph was my first graduate student do you think its important to illuminate aspects of consciousness in order to engineer intelligence systems do you think an intelligent system would ultimately have consciousness are they interlinked most of the people working in artificial intelligence i think would answer we dont strictly need consciousness to have an intelligent system thats sort of the easier question because its a very engineering answer to the question pass the turing test we dont need consciousness but if you were to go do you think its possible that we need to have that kind of self awareness we may yes so for instance i personally think that when test a machine or a person in a turing test in an extended turing test i think consciousness is part of what we require in that test implicitly to say that this is intelligent christoph disagrees yes he does despite many other romantic notions he holds he disagrees with that one yes thats right so well see do you think as a quick question ernest beckers fear of death do you think mortality and those kinds of things are important for consciousness and for intelligence the finiteness of life finiteness of existence or is that just a side effect of evolution evolutionary side effect thats useful for natural selection do you think this kind of thing that this interview is going to run out of time soon our life will run out of time soon do you think thats needed to make this conversation good and life good i never thought about it its a very interesting question i think steve jobs in his commencement speech at stanford argued that having a finite life was important for stimulating achievements so it was different yeah live every day like its your last right yeah so rationally i dont think strictly you need mortality for consciousness but who knows they seem to go together in our biological system right yeah yeah youve mentioned before and students are associated with alphago immobilized the big recent success stories in ai and i think its captivated the entire world of what ai can do so what do you think will be the next breakthrough and whats your intuition about the next breakthrough of course i dont know where the next breakthrough is i think that there is a good chance as i said before that the next breakthrough will also be inspired by neuroscience but which one i dont know and theres so mit has this quest for intelligence and theres a few moon shots which in that spirit which ones are you excited about which projects kind of well of course im excited about one of the moon shots which is our center for brains minds and machines which is the one which is fully funded by nsf and it is about visual intelligence and that one is particularly about understanding visual intelligence so the visual cortex and visual intelligence in the sense of how we look around ourselves and understand the world around ourselves meaning what is going on how we could go from here to there without hitting obstacles whether there are other agents people in the environment these are all things that we perceive very quickly and its something actually quite close to being conscious not quite but there is this interesting experiment that was run at google x which is in a sense is just a virtual reality experiment but in which they had a subject sitting say in a chair with goggles like oculus and so on earphones and they were seeing through the eyes of a robot nearby to cameras microphones for receiving so their sensory system was there and the impression of all the subject very strong they could not shake it off was that they were where the robot was they could look at themselves from the robot and still feel they were where the robot is they were looking at their body theirself had moved so some aspect of scene understanding has to have ability to place yourself have a self awareness about your position in the world and what the world is so we may have to solve the hard problem of consciousness to solve it on their way yes its quite a moonshine so youve been an advisor to some incredible minds including demis hassabis krzysztof koch amna shashua like you said all went on to become seminal figures in their respective fields from your own success as a researcher and from perspective as a mentor of these researchers having guided them in the way of advice what does it take to be successful in science and engineering careers whether youre talking to somebody in their teens 20s and 30s what does that path look like its curiosity and having fun and i think its important also having fun with other curious minds its the people you surround with too so fun and curiosity is there you mentioned steve jobs is there also an underlying ambition thats unique that you saw or does it really does boil down to insatiable curiosity and fun well of course its being curious in an active and ambitious way yes definitely but i think sometime in science there are friends of mine who are like this there are some of the scientists like to work by themselves and kind of communicate only when they complete their work or discover something i think i always found the actual process of discovering something is more fun if its together with other intelligent and curious and fun people so if you see the fun in that process the side effect of that process will be that youll actually end up discovering some interesting things so as youve led many incredible efforts here whats the secret to being a good advisor mentor leader in a research setting is it a similar spirit or yeah what advice could you give to people young faculty and so on its partly repeating what i said about an environment that should be friendly and fun and ambitious and i think i learned a lot from some of my advisors and friends and some who are physicists and there was for instance this behavior that was encouraged of when somebody comes with a new idea in the group you are unless its really stupid but you are always enthusiastic and then and youre enthusiastic for a few minutes for a few hours then you start asking critically a few questions testing this but this is a process that is i think its very good you have to be enthusiastic sometimes people are very critical from the beginning thats not yes you have to give it a chance for that seed to grow that said with some of your ideas which are quite revolutionary so theres a witness especially in the human vision side and neuroscience side there could be some pretty heated arguments do you enjoy these is that a part of science and academic pursuits that you enjoy yeah is that something that happens in your group as well yeah absolutely i also spent some time in germany again there is this tradition in which people are more forthright less kind than here so in the us when you write a bad letter you still say this guys nice yes yes so yeah here in america its degrees of nice yes its all just degrees of nice yeah right right so as long as this does not become personal and its really like a football game with these rules thats great thats fun so if you somehow found yourself in a position to ask one question of an oracle like a genie maybe a god and youre guaranteed to get a clear answer what kind of question would you ask what would be the question you would ask in the spirit of our discussion it could be how could i become 10 times more intelligent and so but see you only get a clear short answer so do you think theres a clear short answer to that no and thats the answer youll get okay so youve mentioned flowers of algernon oh yeah as a story that inspires you in your childhood as this story of a mouse human achieving genius level intelligence and then understanding what was happening while slowly becoming not intelligent again and this tragedy of gaining intelligence and losing intelligence do you think in that spirit in that story do you think intelligence is a gift or a curse from the perspective of happiness and meaning of life you try to create an intelligent system that understands the universe but on an individual level the meaning of life do you think intelligence is a gift its a good question i dont know as one of the as one people consider the smartest people in the world in some dimension at the very least what do you think i dont know it may be invariant to intelligence that degree of happiness it would be nice if it were thats the hope yeah you could be smart and happy and clueless and happy yeah as always on the discussion of the meaning of life its probably a good place to end tommaso thank you so much for talking today thank you this was great but as a person who has contributed some profound ideas in these fields youre a good person to guess at some of these so of course theres a caveat before a lot of the stuff we talk about but what is your hunch is the face the part of the brain that seems to be concentrated on face recognition are you born with that or you just is designed to learn that quickly like the face of the mother and so on my hunch my bias was the second one learned very quickly and it turns out that marge livingstone at harvard has done some amazing experiments in which she raised baby monkeys depriving them of faces during the first weeks of life so they see technicians but the technician have a mask yes and so when they looked at the area in the brain of these monkeys that were usually defined faces they found no face preference so my guess is that what evolution does in this case is there is a plastic area which is plastic which is kind of predetermined to be imprinted very easily but the command from the gene is not a detailed circuitry for a face template could be but this will require probably a lot of bits you had to specify a lot of connection of a lot of neurons instead the command from the gene is something like imprint memorize what you see most often in the first two weeks of life especially in connection with food and maybe nipples i dont know well source of food and so that area is very plastic at first and then solidifies itd be interesting if a variant of that experiment would show a different kind of pattern associated with food than a face pattern whether that could stick there are indications that during that experiment what the monkeys saw quite often were the blue gloves of the technicians that were giving to the baby monkeys the milk and some of the cells instead of being face sensitive in that area are hand sensitive thats fascinating can you talk about what are the different parts of the brain and in your view sort of loosely and how do they contribute to intelligence do you see the brain as a bunch of different modules and they together come in the human brain to create intelligence or is it all one mush of the same kind of fundamental architecture yeah thats an important question and there was a phase in neuroscience back in the 1950 or so in which it was believed for a while that the brain was equipotential this was the term you could cut out a piece and nothing special happened apart a little bit less performance there was a surgeon lashley who did a lot of experiments of this type with mice and rats and concluded that every part of the brain was essentially equivalent to any other one it turns out that thats really not true there are very specific modules in the brain as you said and people may lose the ability to speak if you have a stroke in a certain region or may lose control of their legs in another region so theyre very specific the brain is also quite flexible and redundant so often it can correct things and take over functions from one part of the brain to the other but really there are specific modules so the answer that we know from this old work which was basically based on lesions either on animals or very often there was a mine of very interesting data coming from the war from different types of injuries that soldiers had in the brain and more recently functional mri which allow you to check which part of the brain are active when you are doing different tasks can replace some of this you can see that certain parts of the brain are involved are active in certain tasks vision language yeah thats right but sort of taking a step back to that part of the brain that discovers that specializes in the face and how that might be learned whats your intuition behind is it possible that from a physicist perspective when you get lower and lower that its all the same stuff and it just when youre born its plastic and quickly figures out this part is going to be about vision this is going to be about language this is about common sense reasoning do you have an intuition that that kind of learning is going on really quickly or is it really kind of solidified in hardware thats a great question so there are parts of the brain like the cerebellum or the hippocampus that are quite different from each other they clearly have different anatomy different connectivity then there is the cortex which is the most developed part of the brain in humans and in the cortex you have different regions of the cortex that are responsible for vision for audition for motor control for language now one of the big puzzles of this is that in the cortex is the cortex is the cortex looks like it is the same in terms of hardware in terms of type of neurons and connectivity across these different modalities so for the cortex i think aside these other parts of the brain like spinal cord hippocampus cerebellum and so on for the cortex i think your question about hardware and software and learning and so on i think is rather open and i find it very interesting for risa to think about an architecture computer architecture that is good for vision and at the same time is good for language seems to be so different problem areas that you have to solve but the underlying mechanism might be the same and thats really instructive for artificial neural networks so weve done a lot of great work in vision in human vision computer vision and you mentioned the problem of human vision is really as difficult as the problem of general intelligence and maybe that connects to the cortex discussion can you describe the human visual cortex and how the humans begin to understand the world through the raw sensory information whats for folks who are not familiar especially on the computer vision side we dont often actually take a step back except saying with a sentence or two that one is inspired by the other what is it that we know about the human visual cortex thats interesting we know quite a bit at the same time we dont know a lot but the bit we know in a sense we know a lot of the details and many we dont know and we know a lot of the top level the answer to the top level question but we dont know some basic ones even in terms of general neuroscience forgetting vision why do we sleep its such a basic question and we really dont have an answer to that so taking a step back on that so sleep for example is fascinating do you think thats a neuroscience question or if we talk about abstractions what do you think is an interesting way to study intelligence or most effective on the levels of abstraction is it chemical is it biological is it electrophysical mathematical as youve done a lot of excellent work on that side which psychology at which level of abstraction do you think well in terms of levels of abstraction i think we need all of them its like if you ask me what does it mean to understand a computer thats much simpler but in a computer i could say well i understand how to use powerpoint thats my level of understanding a computer it is reasonable it gives me some power to produce slides and beautiful slides now you can ask somebody else he says well i know how the transistors work that are inside the computer i can write the equation for transistor and diodes and circuits logical circuits and i can ask this guy do you know how to operate powerpoint no idea so do you think if we discovered computers walking amongst us full of these transistors that are also operating under windows and have powerpoint do you think its digging in a little bit more how useful is it to understand the transistor in order to be able to understand powerpoint and these higher level intelligent processes so i think in the case of computers because they were made by engineers by us this different level of understanding are rather separate on purpose they are separate modules so that the engineer that designed the circuit for the chips does not need to know what is inside powerpoint and somebody can write the software translating from one to the other so in that case i dont think understanding the transistor helps you understand powerpoint or very little if you want to understand the computer this question i would say you have to understand it at different levels if you really want to build one right but for the brain i think these levels of understanding so the algorithms which kind of computation the equivalent of powerpoint and the circuits the transistors i think they are much more intertwined with each other there is not a neatly level of the software separate from the hardware and so thats why i think in the case of the brain the problem is more difficult and more than for computers requires the interaction the collaboration between different types of expertise the brain is a big hierarchical mess you cant just disentangle levels i think you can but its much more difficult and its not completely obvious and as i said i think its one of the personally i think is the greatest problem in science so i think its fair that its difficult thats a difficult one that said you do talk about compositionality and why it might be useful and when you discuss why these neural networks in artificial or biological sense learn anything you talk about compositionality see theres a sense that nature can be disentangled or well all aspects of our cognition could be disentangled to some degree so why do you think first of all how do you see compositionality and why do you think it exists at all in nature i spoke about i use the term compositionality when we looked at deep neural networks multilayers and trying to understand when and why they are more powerful than more classical one layer networks like linear classifier kernel machines so called and what we found is that in terms of approximating or learning or representing a function a mapping from an input to an output like from an image to the label in the image if this function has a particular structure then deep networks are much more powerful than shallow networks to approximate the underlying function and the particular structure is a structure of compositionality if the function is made up of functions of function so that you need to look on when you are interpreting an image classifying an image you dont need to look at all pixels at once but you can compute something from small groups of pixels and then you can compute something on the output of this local computation and so on which is similar to what you do when you read a sentence you dont need to read the first and the last letter but you can read syllables combine them in words combine the words in sentences so this is this kind of structure so thats as part of a discussion of why deep neural networks may be more effective than the shallow methods and is your sense for most things we can use neural networks for those problems are going to be compositional in nature like language like vision how far can we get in this kind of way so here is almost philosophy well lets go there yeah lets go there so a friend of mine max tegmark who is a physicist at mit ive talked to him on this thing yeah and he disagrees with you right a little bit yeah we agree on most but the conclusion is a bit different his conclusion is that for images for instance the compositional structure of this function that we have to learn or to solve these problems comes from physics comes from the fact that you have local interactions in physics between atoms and other atoms between particle of matter and other particles between planets and other planets between stars and other its all local and thats true but you could push this argument a bit further not this argument actually you could argue that maybe thats part of the truth but maybe what happens is kind of the opposite is that our brain is wired up as a deep network so it can learn understand solve problems that have this compositional structure and it cannot solve problems that dont have this compositional structure so the problems we are accustomed to we think about we test our algorithms on are this compositional structure because our brain is made up and thats in a sense an evolutionary perspective that weve so the ones that didnt have that werent dealing with the compositional nature of reality died off yes but also could be maybe the reason why we have this local connectivity in the brain like simple cells in cortex looking only at the small part of the image each one of them and then other cells looking at the small number of these simple cells and so on the reason for this may be purely that it was difficult to grow long range connectivity so suppose its for biology its possible to grow short range connectivity but not long range also because there is a limited number of long range that you can and so you have this limitation from the biology and this means you build a deep convolutional network this would be something like a deep convolutional network and this is great for solving certain class of problems these are the ones we find easy and important for our life and yes they were enough for us to survive and you can start a successful business on solving those problems with mobileye driving is a compositional problem so on the learning task we dont know much about how the brain learns in terms of optimization so the thing thats stochastic gradient descent is what artificial neural networks use for the most part to adjust the parameters in such a way that its able to deal based on the label data its able to solve the problem so whats your intuition about why it works at all how hard of a problem it is to optimize a neural network artificial neural network is there other alternatives just in general your intuition is behind this very simplistic algorithm that seems to do pretty good surprisingly so yes so i find neuroscience the architecture of cortex is really similar to the architecture of deep networks so there is a nice correspondence there between the biology and this kind of local connectivity hierarchical architecture the stochastic gradient descent as you said is a very simple technique it seems pretty unlikely that biology could do that from what we know right now about cortex and neurons and synapses so its a big question open whether there are other optimization learning algorithms that can replace stochastic gradient descent and my guess is yes but nobody has found yet a real answer i mean people are trying still trying and there are some interesting ideas the fact that stochastic gradient descent is so successful this has become clearly not so mysterious and the reason is that its an interesting fact its a change in a sense in how people think about statistics and this is the following is that typically when you had data and you had say a model with parameters you are trying to fit the model to the data to fit the parameter typically the kind of crowd wisdom type idea was you should have at least twice the number of data than the number of parameters maybe 10 times is better now the way you train neural networks these days is that they have 10 or 100 times more parameters than data exactly the opposite and it has been one of the puzzles about neural networks how can you get something that really works when you have so much freedom from that little data it can generalize somehow right exactly do you think the stochastic nature of it is essential the randomness so i think we have some initial understanding why this happens but one nice side effect of having this overparameterization more parameters than data is that when you look for the minima of a loss function like stochastic gradient descent is doing you find i made some calculations based on some old basic theorem of algebra called the bezu theorem that gives you an estimate of the number of solution of a system of polynomial equation anyway the bottom line is that there are probably more minima for a typical deep networks than atoms in the universe just to say there are a lot because of the overparameterization a more global minimum zero minimum good minimum a more global minima yeah a lot of them so you have a lot of solutions so its not so surprising that you can find them relatively easily and this is because of the overparameterization the overparameterization sprinkles that entire space with solutions that are pretty good its not so surprising right its like if you have a system of linear equation and you have more unknowns than equations then you have we know you have an infinite number of solutions and the question is to pick one thats another story but you have an infinite number of solutions so there are a lot of value of your unknowns that satisfy the equations but its possible that theres a lot of those solutions that arent very good whats surprising is that theyre pretty good so thats a good question why can you pick one that generalizes well yeah thats a separate question with separate answers one theorem that people like to talk about that kind of inspires imagination of the power of neural networks is the universality universal approximation theorem that you can approximate any computable function with just a finite number of neurons in a single hidden layer do you find this theorem one surprising do you find it useful interesting inspiring no this one i never found it very surprising it was known since the 80s since i entered the field because its basically the same as weierstrass theorem which says that i can approximate any continuous function with a polynomial of sufficiently with a sufficient number of terms monomials so basically the same and the proofs are very similar so your intuition was there was never any doubt that neural networks in theory could be very strong approximators right the question the interesting question is that if this theorem says you can approximate fine but when you ask how many neurons for instance or in the case of polynomial how many monomials i need to get a good approximation then it turns out that that depends on the dimensionality of your function how many variables you have but it depends on the dimensionality of your function in a bad way its for instance suppose you want an error which is no worse than 10 in your approximation you come up with a network that approximate your function within 10 then it turns out that the number of units you need are in the order of 10 to the dimensionality d how many variables so if you have two variables these two words you have 100 units and ok but if you have say 200 by 200 pixel images now this is 40000 whatever we again go to the size of the universe pretty quickly exactly 10 to the 40000 or something and so this is called the curse of dimensionality not quite appropriately and the hope is with the extra layers you can remove the curse what we proved is that if you have deep layers hierarchical architecture with the local connectivity of the type of convolutional deep learning and if youre dealing with a function that has this kind of hierarchical architecture then you avoid completely the curse youve spoken a lot about supervised deep learning what are your thoughts hopes views on the challenges of unsupervised learning with gans with generative adversarial networks do you see those as distinct the power of gans do you see those as distinct from supervised methods in neural networks or are they really all in the same representation ballpark gans is one way to get estimation of probability densities which is a somewhat new way that people have not done before i dont know whether this will really play an important role in intelligence or its interesting im less enthusiastic about it than many people in the field i have the feeling that many people in the field are really impressed by the ability of producing realistic looking images in this generative way which describes the popularity of the methods but youre saying that while thats exciting and cool to look at it may not be the tool thats useful for it so you describe it kind of beautifully current supervised methods go n to infinity in terms of number of labeled points and we really have to figure out how to go to n to 1 and youre thinking gans might help but they might not be the right i dont think for that problem which i really think is important i think they may help they certainly have applications for instance in computer graphics and i did work long ago which was a little bit similar in terms of saying ok i have a network and i present images and i can input its images and output is for instance the pose of the image a face how much is smiling is rotated 45 degrees or not what about having a network that i train with the same data set but now i invert input and output now the input is the pose or the expression a number set of numbers and the output is the image and i train it and we did pretty good interesting results in terms of producing very realistic looking images it was a less sophisticated mechanism but the output was pretty less than gans but the output was pretty much of the same quality so i think for a computer graphics type application yeah definitely gans can be quite useful and not only for that but for helping for instance on this problem of unsupervised example of reducing the number of labeled examples i think people its like they think they can get out more than they put in theres no free lunch as you said what do you think whats your intuition how can we slow the growth of n to infinity in supervised n to infinity in supervised learning so for example mobileye has very successfully i mean essentially annotated large amounts of data to be able to drive a car now one thought is so were trying to teach machines school of ai and were trying to so how can we become better teachers maybe thats one way no i like that because again one caricature of the history of computer science you could say begins with programmers expensive continuous labelers cheap and the future will be schools like we have for kids yeah currently the labeling methods were not selective about which examples we teach networks with so i think the focus of making networks that learn much faster is often on the architecture side but how can we pick better examples with which to learn do you have intuitions about that well thats part of the problem but the other one is if we look at biology a reasonable assumption i think is in the same spirit that i said evolution is opportunistic and has weak priors the way i think the intelligence of a child the baby may develop is by bootstrapping weak priors from evolution for instance you can assume that you have in most organisms including human babies built in some basic machinery to detect motion and relative motion and in fact we know all insects from fruit flies to other animals they have this even in the retinas in the very peripheral part its very conserved across species something that evolution discovered early it may be the reason why babies tend to look in the first few days to moving objects and not to not moving objects now moving objects means ok theyre attracted by motion but motion also means that motion gives automatic segmentation from the background so because of motion boundaries either the object is moving or the eye of the baby is tracking the moving object and the background is moving right yeah so just purely on the visual characteristics of the scene that seems to be the most useful right so its like looking at an object without background its ideal for learning the object otherwise its really difficult because you have so much stuff so suppose you do this at the beginning first weeks then after that you can recognize object now they are imprinted the number one even in the background even without motion so thats by the way i just want to ask on the object recognition problem so there is this being responsive to movement and doing edge detection essentially whats the gap between being effective at visually recognizing stuff detecting where it is and understanding the scene is this a huge gap in many layers or is it close no i think thats a huge gap i think present algorithm with all the success that we have and the fact that there are a lot of very useful i think we are in a golden age for applications of low level vision and low level speech recognition and so on alexa and so on there are many more things of similar level to be done including medical diagnosis and so on but we are far from what we call understanding of a scene of language of actions of people that is despite the claims thats i think very far were a little bit off so in popular culture and among many researchers some of which ive spoken with the stuart russell and elon musk in and out of the ai field theres a concern about the existential threat of ai and how do you think about this concern and is it valuable to think about large scale long term unintended consequences of intelligent systems we try to build i always think its better to worry first early rather than late so worry is good yeah im not against worrying at all personally i think that it will take a long time before there is real reason to be worried but as i said i think its good to put in place and think about possible safety against what i find a bit misleading are things like that have been said by people i know like elon musk and what is bostrom in particular and what is his first name nick bostrom nick bostrom right and a couple of other people that for instance ai is more dangerous than nuclear weapons i think thats really wrong that can be misleading because in terms of priority we should still be more worried about nuclear weapons and what people are doing about it and so on than ai and youve spoken about demis hassabis and yourself saying that you think youll be about 100 years out before we have a general intelligence system thats on par with a human being do you have any updates for those predictions well i think he said he said 20 i think he said 20 right this was a couple of years ago i have not asked him again so should i have your own prediction whats your prediction about when youll be truly surprised and whats the confidence interval on that its so difficult to predict the future and even the present sometimes its pretty hard to predict but i would be as i said this is completely i would be more like rod brooks i think hes about 200 years 200 years when we have this kind of agi system artificial general intelligence system youre sitting in a room with her him it do you think the underlying design of such a system is something well be able to understand it will be simple do you think itll be explainable understandable by us your intuition again were in the realm of philosophy a little bit well probably no but again it depends what you really mean for understanding so i think we dont understand how deep networks work i think we are beginning to have a theory now but in the case of deep networks or even in the case of the simpler kernel machines', 'the following is a conversation with kyle vogt hes the president and the cto of cruise automation leading an effort to solve one of the biggest robotics challenges of our time vehicle automation hes a cofounder of two successful companies twitch and cruise that have each sold for a billion dollars and hes a great example of the innovative spirit that flourishes in silicon valley and now is facing an interesting and exciting challenge of matching that spirit with the mass production and the safety centric culture of a major automaker like general motors this conversation is part of the mit artificial general intelligence series and the artificial intelligence podcast if you enjoy it please subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with kyle vogt you grew up in kansas right yeah and i just saw that picture you had hidden over there so im a little bit a little bit worried about that now yeah so in high school in kansas city you joined shawnee mission north high school robotics team yeah now that wasnt your high school thats right that was that was the only high school in the area that had a like a teacher who was willing to sponsor our first robotics team i was gonna troll you a little bit jog your memory a little bit yeah i was trying to look super cool and intense because you know this was battlebots this is serious business so were standing there with a welded steel frame and looking tough so go back there what is that drew you to robotics well i think ive been trying to figure this out for a while but ive always liked building things with legos and when i was really really young i wanted the legos that had motors and other things and then you know lego mindstorms came out and for the first time you could program lego contraptions and i think things just sort of snowballed from that but i remember seeing you know the battlebots tv show on comedy central and thinking that is the coolest thing in the world i want to be a part of that and not knowing a whole lot about how to build these 200 pound fighting robots so i sort of obsessively poured over the internet forums where all the creators for battlebots would sort of hang out and talk about you know document their build progress and everything and i think i read i must have read like you know tens of thousands of forum posts from basically everything that was out there on what these people were doing and eventually like sort of triangulated how to put some of these things together and i ended up doing battlebots which was you know i was like 13 or 14 which was pretty awesome im not sure if the show is still running but so battlebots is theres not an artificial intelligence component its remotely controlled and its almost like a mechanical engineering challenge of building things that can be broken theyre radio controlled so and i think that they allowed some limited form of autonomy but you know in a two minute match youre in the way these things ran youre really doing yourself a disservice by trying to automate it versus just you know do the practical thing which is drive it yourself and theres an entertainment aspect just going on youtube theres like an some of them wield an axe some of them i mean theres that fun so what drew you to that aspect was it the mechanical engineering was it the dream to create like frankenstein and sentient being or was it just like the lego you like tinkering with stuff i mean that was just building something i think the idea of you know this radio controlled machine that can do various things if it has like a weapon or something was pretty interesting i agree it doesnt have the same appeal as you know autonomous robots which i which i you know sort of gravitated towards later on but it was definitely an engineering challenge because everything you did in that competition was pushing components to their limits so we would buy like these 40 dc motors that came out of a winch like on the front of a pickup truck or something and wed power the car with those and wed run them at like double or triple their rated voltage so they immediately start overheating but for that two minute match you can get you know a significant increase in the power output of those motors before they burn out and so youre doing the same thing for your battery packs all the materials in the system and i think theres something something intrinsically interesting about just seeing like where things break and did you offline see where they break did you take it to the testing point like how did you know two minutes or was there a reckless lets just go with it and see we werent very good at battlebots we lost all of our matches the first round the one i built first both of them were these wedge shaped robots because wedge even though its sort of boring to look at is extremely effective you drive towards another robot and the front edge of it gets under them and then they sort of flip over kind of like a door stopper and the first one had a pneumatic polished stainless steel spike on the front that would shoot out about eight inches the purpose of which is what pretty pretty ineffective actually but it looks cool and was it to help with the lift no it was it was just to try to poke holes in the other robot and then the second time i did it which is the following i think maybe 18 months later we had a well a titanium axe with a with a hardened steel tip on it that was powered by a hydraulic cylinder which we were activating with liquid co2 which was had its own set of problems so great so thats kind of on the hardware side i mean at a certain point there must have been born a fascination on the software side so what was the first piece of code youve written go back there see what language was it what what was that was it emacs vim was it a more respectable modern ide do you do you remember any of this yeah well i remember i think maybe when i was in third or fourth grade the school i was at elementary school had a bunch of apple ii computers and wed play games on those and i remember every once in a while something would would would crash or wouldnt start up correctly and it would dump you out to what i later learned was like sort of a command prompt and my teacher would come over and type i actually remember this to this day for some reason like pr number six or pr pound six which is peripheral six which is the disk drive which would fire up the disk and load the program and i just remember thinking wow shes like a hacker like teach me these these codes these error codes that is what i called them at the time but she had no interest in that so it wasnt until i think about fifth grade that i had a school where you could actually go on these apple iis and learn to program and so it was all in basic you know where every line you know the line numbers are all number that every line is numbered and you have to like leave enough space between the numbers so that if you want to tweak your code you go back and the first line was 10 and the second line is 20 now you have to go back and insert 15 and if you need to add code in front of that you know 11 or 12 and you hope you dont run out of line numbers and have to redo the whole thing and theres go to statements yeah go to and its very basic maybe hence the name but a lot of fun and that was like that was you know thats when you know when you first program you see the magic of it its like it just just like this world opens up with you know endless possibilities for the things you could build or or accomplish with that computer so you got the bug then so even starting with basic and then what c throughout what did you was there computer programming computer science classes in high school not not where i went so it was self taught but i did a lot of programming the thing that you know sort of pushed me in the path of eventually working on self driving cars is actually one of these really long trips driving from my house in kansas to to i think las vegas where we did the battlebots competition and i had just gotten my i think my learners permit or early drivers permit and so i was driving this you know 10 hour stretch across western kansas where its just youre going straight on a highway and it is mind numbingly boring and i remember thinking even then with my sort of mediocre programming background that this is something that a computer can do right lets take a picture of the road lets find the yellow lane markers and you know steer the wheel and you know later id come to realize this had been done you know since since the 80s or the 70s or even earlier but i still wanted to do it and sort of immediately after that trip switched from sort of battlebots which is more radio controlled machines to thinking about building you know autonomous vehicles of some scale start off with really small electric ones and then you know progress to what were doing now so what was your view of artificial intelligence at that point what did you think so this is before theres been waves in artificial intelligence right the current wave with deep learning makes people believe that you can solve in a really rich deep way the computer vision perception problem but like in before the deep learning craze you know how do you think about how would you even go about building a thing that perceives itself in the world localizes itself in the world moves around the world like when you were younger i mean what was your thinking about it well prior to deep neural networks or convolutional neural analysis these modern techniques we have or at least ones that are in use today it was all a heuristic space and so like old school image processing and i think extracting you know yellow lane markers out of an image of a road is one of the problems that lends itself reasonably well to those heuristic based methods you know like just do a threshold on the color yellow and then try to fit some lines to that using a huff transform or something and then go from there traffic light detection and stop sign detection red yellow green and i think you could i mean if you wanted to do a full i was just trying to make something that would stay in between the lanes on a highway but if you wanted to do the full the full you know set of capabilities needed for a driverless car i think you could and wed done this at cruise you know in the very first days you can start off with a really simple you know human written heuristic just to get the scaffolding in place for your system traffic light detection probably a really simple you know color thresholding on day one just to get the system up and running before you migrate to you know a deep learning based technique or something else and you know back in when i was doing this my first one it was on a pentium 203 233 megahertz computer in it and i think i wrote the first version in basic which is like an interpreted language its extremely slow because thats the thing i knew at the time and so there was no no chance at all of using there was no no computational power to do any sort of reasonable deep nets like you have today so i dont know what kids these days are doing are kids these days you know at age 13 using neural networks in their garage i mean that would be awesome i get emails all the time from you know like 11 12 year olds saying im having you know im trying to follow this tensorflow tutorial and im having this problem and the general approach in the deep learning community is of extreme optimism of as opposed to you mentioned like heuristics you can you can you can separate the autonomous driving problem into modules and try to solve it sort of rigorously or you can just do it end to end and most people just kind of love the idea that you know us humans do it end to end we just perceive and act we should be able to use that do the same kind of thing when youre on nets and that that kind of thinking you dont want to criticize that kind of thinking because eventually they will be right yeah and so its exciting and especially when theyre younger to explore that as a really exciting approach but yeah its its changed the the language the kind of stuff youre tinkering with its kind of exciting to see when these teenagers grow up yeah i can only imagine if you if your starting point is you know python and tensorflow at age 13 where you end up you know after 10 or 15 years of that thats thats pretty cool because of github because the state tools for solving most of the major problems in artificial intelligence are within a few lines of code for most kids and thats incredible to think about also on the entrepreneurial side and and on that point was there any thought about entrepreneurship before you came to college is sort of doing youre building this into a thing that impacts the world on a large scale yeah ive always wanted to start a company i think thats you know just a cool concept of creating something and exchanging it for value or creating value i guess so in high school i was i was trying to build like you know servo motor drivers little circuit boards and sell them online or other other things like that and certainly knew at some point i wanted to do a startup but it wasnt really id say until college until i felt like i had the i guess the right combination of the environment the smart people around you and some free time and a lot of free time at mit so you came to mit as an undergrad 2004 thats right and thats when the first darpa grand challenge was happening yeah the the timing of that is beautifully poetic so how did you get yourself involved in that one originally there wasnt a official entry yeah faculty sponsored thing and so a bunch of undergrads myself included started meeting and got together and tried to haggle together some sponsorships we got a vehicle donated a bunch of sensors and tried to put something together and so we had our team was probably mostly freshmen and sophomores you know which which was not really a fair fair fight against maybe the you know postdoc and faculty led teams from other schools but we we got something up and running we had our vehicle drive by wire and you know very very basic control and things but on the day of the qualifying sort of pre qualifying round the one and only steering motor that we had purchased the thing that we had retrofitted to turn the steering wheel on the truck died and so our vehicle was just dead in the water couldnt steer so we didnt make it very far on the hardware side so was there a software component was there like how did your view of autonomous vehicles in terms of artificial intelligence evolve in this moment i mean you know like you said from the 80s has been autonomous vehicles but really that was the birth of the modern wave the the thing that captivated everyones imagination that we can actually do this so what how were you captivated in that way so how did your view of autonomous vehicles change at that point id say at that point in time it was it was a curiosity as in like is this really possible and i think that was generally the spirit and the purpose of that original darpa grand challenge which was to just get a whole bunch of really brilliant people exploring the space and pushing the limits and i think like to this day that darpa challenge with its you know million dollar prize pool was probably one of the most effective you know uses of taxpayer money dollar for dollar that ive seen you know because that that small sort of initiative that darpa put put out sort of in my view was the catalyst or the tipping point for this this whole next wave of autonomous vehicle development so that was pretty cool so let me jump around a little bit on that point they also did the urban challenge where it was in the city but it was very artificial and theres no pedestrians and theres very little human involvement except a few professional drivers yeah do you think theres room and then there was the robotics challenge with humanoid robots right so in your now role is looking at this youre trying to solve one of the you know autonomous driving one of the harder more difficult places in san francisco is there a role for darpa to step in to also kind of help out like challenge with new ideas specifically pedestrians and so on all these kinds of interesting things well i havent i havent thought about it from that perspective is there anything darpa could do today to further accelerate things and i would say my instinct is that thats maybe not the highest and best use of their resources and time because like kick starting and spinning up the flywheel is i think what what they did in this case for very very little money but today this has become this has become like commercially interesting to very large companies and the amount of money going into it and the amount of people like going through your class and learning about these things and developing these skills is just you know orders of magnitude more than it was back then and so theres enough momentum and inertia and energy and investment dollars into this space right now that i dont i dont i think theyre i think theyre they can just say mission accomplished and move on to the next area of technology that needs help so then stepping back to mit you left mit during your junior year what was that decision like as i said i always wanted to do a company in or start a company and this opportunity landed in my lap which was a couple guys from yale were starting a new company and i googled them and found that they had started a company previously and sold it actually on ebay for about a quarter million bucks which was a pretty interesting story but so i thought to myself these guys are you know rock star entrepreneurs theyve done this before they must be driving around in ferraris because they sold their company and you know i thought i could learn a lot from them so i teamed up with those guys and you know went out during went out to california during iap which is mits month off on a one way ticket and basically never went back we were having so much fun we felt like we were building something and creating something and it was going to be interesting that you know i was just all in and got completely hooked and that that business was justin tv which is originally a reality show about a guy named justin which morphed into a live video streaming platform which then morphed into what is twitch today so that was that was quite an unexpected journey so no regrets no looking back it was just an obvious i mean one way ticket i mean if we just pause on that for a second there was no how did you know these are the right guys this is the right decision you didnt think it was just follow the heart kind of thing well i didnt know but you know just trying something for a month during iap seems pretty low risk right and then you know well maybe ill take a semester off mits pretty flexible about that you can always go back right and then after two or three cycles of that i eventually threw in the towel but you know i think its i guess in that case i felt like i could always hit the undo button if i had to right but nevertheless from when you look in retrospect i mean it seems like a brave decision you know it would be difficult for a lot of people to make it wasnt as popular id say that the general you know flux of people out of mit at the time was mostly into you know finance or consulting jobs in boston or new york and very few people were going to california to start companies but today id say thats its probably inverted which is just a sign of a sign of the times i guess yeah so theres a story about midnight of march 18 2007 where techcrunch i guess announced justintv earlier than it was supposed to a few hours the site didnt work i dont know if any of this is true you can tell me and you and one of the folks at justintv emmett shearer coded through the night can you take me through that experience so let me let me say a few nice things that the article i read quoted justin kahn said that you were known for bureau coding through problems and being a creative quote creative genius so on that night what what was going through your head or maybe id put another way how do you solve these problems whats your approach to solving these kinds of problems where the line between success and failure seems to be pretty thin thats a good question well first of all thats thats a nice of justin to say that i think you know i would have been maybe 21 years old then and not very experienced at programming but as with with everything in a startup youre sort of racing against the clock and so our plan was the second we had this live streaming camera backpack up and running where justin could wear it and no matter where he went in a city it would be streaming live video and this is even before the iphones this is like hard to do back then we would launch and so we thought we were there and the backpack was working and then we sent out all the emails to launch the launch the company and do the press thing and then you know we werent quite actually there and then we thought oh well you know theyre not going to announce it until maybe 10 am the next morning and its i dont know its 5 pm now so how many hours do we have left what is that like you know 17 hours to go and and that was that was going to be fine was the problem obvious did you understand what could possibly like how complicated was the system at that point it was it was pretty messy so to get a live video feed that looked decent working from anywhere in san francisco i put together this system where we had like three or four cell phone data modems and they were like we take the video stream and you know sort of spray it across these three or four modems and then try to catch all the packets on the other side you know with unreliable cell phone networks its pretty low level networking yeah and putting these like you know sort of protocols on top of all that to to reassemble and reorder the packets and have time buffers and error correction and all that kind of stuff and the night before it was just staticky every once in a while the image would would go to staticky and there would be this horrible like screeching audio noise because the audio was also corrupted and this would happen like every five to ten minutes or so and it was a really you know off putting to the viewers how do you tackle that problem what was the uh youre just freaking out behind a computer theres are there other other folks working on this problem like were you behind a whiteboard were you doing uh yeah it was a little it was a little yeah its a little lonely because theres four of us working on the company and only two people really wrote code and emmett wrote the website and the chat system and i wrote the software for this video streaming device and video server and so you know its my sole responsibility to figure that out and i think i think its those you know setting setting deadlines trying to move quickly and everything where youre in that moment of intense pressure that sometimes people do their best and most interesting work and so even though that was a terrible moment i look back on it fondly because thats like you know thats one of those character defining moments i think so in 2013 october you founded cruise automation yeah so progressing forward another exceptionally successful company was acquired by gm in 16 for 1 billion but in october 2013 what was on your mind what was the plan how does one seriously start to tackle one of the hardest robotics most important impact for robotics problems of our age after going through twitch twitch was was and is today pretty successful but the the work was the result was entertainment mostly like the better the product was the more we would entertain people and then you know make money on the ad revenues and other things and that was that was a good thing it felt felt good to entertain people but i figured like you know what is really the point of becoming a really good engineer and developing these skills other than you know my own enjoyment and i realized i wanted something that scratched more of an existential itch like something that that truly matters and so i basically made this list of requirements for a new if i was going to do another company and the one thing i knew in the back of my head that twitch took like eight years to become successful and so whatever i do i better be willing to commit you know at least 10 years to something and when you think about things from that perspective you certainly i think raise the bar on what you choose to work on so for me the three things were it had to be something where the technology itself determines the success of the product like hard really juicy technology problems because thats what motivates me and then it had to have a direct and positive impact on society in some way so an example would be like you know health care self driving cars because they save lives other things where theres a clear connection to somehow improving other peoples lives and the last one is it had to be a big business because for the positive impact to matter its got to be a large scale and i was thinking about that for a while and i made like i tried writing a gmail clone and looked at some other ideas and then it just sort of light bulb went off like self driving cars like that was the most fun i had ever had in college working on that and like well whats the state of the technology its been 10 years maybe times have changed and maybe now is the time to make this work and i poked around and looked at the only other thing out there really at the time was the google self driving car project and i thought surely theres a way to you know have an entrepreneur mindset and sort of solve the minimum viable product here and so i just took the plunge right then and there and said this is something i know i can commit 10 years to its the probably the greatest applied ai problem of our generation and if it works its going to be both a huge business and therefore like probably the most positive impact i can possibly have on the world so after that light bulb went off i went all in on cruise immediately and got to work did you have an idea how to solve this problem which aspect of the problem to solve you know slow like we just had oliver from voyage here slow moving retirement communities urban driving highway driving did you have like did you have a vision of the city of the future where you know the transportation is largely automated that kind of thing or was it sort of more fuzzy and gray area than that my analysis of the situation is that google is putting a lot had been putting a lot of money into that project they had a lot more resources and so and they still hadnt cracked the fully driverless car you know this is 2013 i guess so i thought what can i do to sort of go from zero to you know significant scale so i can actually solve the real problem which is the driverless cars and i thought heres the strategy well start by doing a really simple problem or solving a really simple problem that creates value for people so eventually ended up deciding on automating highway driving which is relatively more straightforward as long as theres a backup driver there and you know the go to market will be able to retrofit peoples cars and just sell these products directly and the idea was well take all the revenue and profits from that and use it to do the so sort of reinvest that in research for doing fully driverless cars and that was the plan the only thing that really changed along the way between then and now is we never really launched the first product we had enough interest from investors and enough of a signal that this was something that we should be working on that after about a year of working on the highway autopilot we had it working you know on a prototype stage but we just completely abandoned that and said were going to go all in on driverless cars now is the time cant think of anything thats more exciting and if it works more impactful so were just going to go for it the idea of retrofit is kind of interesting yeah being able to its how you achieve scale its a really interesting idea is it something thats still in the in the back of your mind as a possibility not at all ive come full circle on that one after trying to build a retrofit product and ill touch on some of the complexities of that and then also having been inside an oem and seeing how things work and how a vehicle is developed and validated when it comes to something that has safety critical implications like controlling the steering and other control inputs on your car its pretty hard to get there with a retrofit or if you did even if you did it creates a whole bunch of new complications around liability or how did you truly validate that or you know something in the base vehicle fails and causes your system to fail whose fault is it or if the cars anti lock brake systems or other things kick in or the software has been its different in one version of the car you retrofit versus another and you dont know because the manufacturer has updated it behind the scenes theres basically an infinite list of long tail issues that can get you and if youre dealing with a safety critical product thats not really acceptable thats a really convincing summary of why thats really challenging but i didnt know all that at the time so we tried it anyway but as a pitch also at the time its a really strong one because thats how you achieve scale and thats how you beat the current the leader at the time of google or the only one in the market the other big problem we ran into which is perhaps the biggest problem from a business model perspective is we had kind of assumed that we started with an audi s4 as the vehicle we retrofitted with this highway driving capability and we had kind of assumed that if we just knock out like three make and models of vehicles thatll cover like 80 of the san francisco market doesnt everyone there drive i dont know a bmw or a honda civic or one of these three cars and then we surveyed our users and we found out that its all over the place we would to get even a decent number of units sold wed have to support like you know 20 or 50 different models and each one is a little butterfly that takes time and effort to maintain you know that retrofit integration and custom hardware and all this so it was a tough business so gm manufactures and sells over 9 million cars a year and what you with cruise are trying to do some of the most cutting edge innovation in terms of applying ai and so how do those youve talked about a little bit before but its also just fascinating to me we work a lot of automakers you know the difference between the gap between detroit and silicon valley lets say just to be sort of poetic about it i guess how do you close that gap how do you take gm into the future where a large part of the fleet will be autonomous perhaps i want to start by acknowledging that gm is made up of you know tens of thousands of really brilliant motivated people who want to be a part of the future and so its pretty fun to work within the attitude inside a car company like that is you know embracing this transformation and change rather than fearing it and i think thats a testament to the leadership at gm and thats flown all the way through to everyone you talk to even the people in the assembly plants working on these cars so thats really great so starting from that position makes it a lot easier so then when the people in san francisco at cruise interact with the people at gm at least we have this common set of values which is that we really want this stuff to work because we think its important and we think its the future thats not to say you know those two cultures dont clash they absolutely do theres different sort of value systems like in a car company the thing that gets you promoted and sort of the reward system is following the processes delivering the program on time and on budget so any sort of risk taking is discouraged in many ways because if a program is late or if you shut down the plant for a day its you know you can count the millions of dollars that burn by pretty quickly whereas i think you know most silicon valley companies and in cruise and the methodology we were employing especially around the time of the acquisition the reward structure is about trying to solve these complex problems in any way shape or form or coming up with crazy ideas that you know 90 of them wont work and so meshing that culture of sort of continuous improvement and experimentation with one where everything needs to be rigorously defined up front so that you never slip a deadline or miss a budget was a pretty big challenge and that were over three years in now after the acquisition and id say like you know the investment we made in figuring out how to work together successfully and who should do what and how we bridge the gaps between these very different systems and way of doing engineering work is now one of our greatest assets because i think we have this really powerful thing but for a while it was both gm and cruise were very steep on the learning curve yeah so im sure it was very stressful its really important work because thats how to revolutionize the transportation really to revolutionize any system you know you look at the health care system or you look at the legal system i have people like loris come up to me all the time like everything theyre working on can easily be automated but then thats not a good feeling yeah well its not a good feeling but also theres no way to automate because the entire infrastructure is really you know based is older and it moves very slowly and so how do you close the gap between i have an how can i replace of course loris dont want to be replaced with an app but you could replace a lot of aspect when most of the data is still on paper and so the same thing was with automotive i mean its fundamentally software its basically hiring software engineers its thinking in a software world i mean im pretty sure nobody in silicon valley has ever hit a deadline so and then on gm thats probably true yeah and gm side is probably the opposite yeah so thats that culture gap is really fascinating so youre optimistic about the future of that yeah i mean from what ive seen its impressive and i think like especially in silicon valley its easy to write off building cars because you know people have been doing that for over 100 years now in this country and so it seems like thats a solved problem but that doesnt mean its an easy problem and i think it would be easy to sort of overlook that and think that you know were silicon valley engineers we can solve any problem you know building a car its been done therefore its you know its not a real engineering challenge but after having seen just the sheer scale and magnitude and industrialization that occurs inside of an automotive assembly plant that is a lot of work that i am very glad that we dont have to reinvent to make self driving cars work and so to have you know partners who have done that for 100 years now these great processes and this huge infrastructure and supply base that we can tap into is just remarkable because the scope and surface area of the problem of deploying fleets of self driving cars is so large that were constantly looking for ways to do less so we can focus on the things that really matter more and if we had to figure out how to build and assemble and you know build the cars themselves i mean we work closely with gm on that but if we had to develop all that capability in house as well you know that would just make the problem really intractable i think so yeah just like your first entry at the mit darpa challenge when there was what the motor that failed somebody that knows what theyre doing with the motor did it that would have been nice if we could focus on the software not the hardware platform yeah right so from your perspective now you know theres so many ways that autonomous vehicles can impact society in the next year five years ten years what do you think is the biggest opportunity to make money in autonomous driving sort of make it a financially viable thing in the near term what do you think will be the biggest impact there well the things that drive the economics for fleets of self driving cars are theres sort of a handful of variables one is you know the cost to build the vehicle itself so the material cost how many you know whats the cost of all your sensors plus the cost of the vehicle and every all the other components on it another one is the lifetime of the vehicle its very different if your vehicle drives 100000 miles and then it falls apart versus you know two million and then you know if you have a fleet its kind of like an airplane or an airline where once you produce the vehicle you want it to be in operation as many hours a day as possible producing revenue and then you know the other piece of that is how are you generating revenue i think thats kind of what youre asking and i think the obvious things today are you know the ride sharing business because thats pretty clear that theres demand for that theres existing markets you can tap into and large urban areas that kind of thing yeah yeah and i think that there are some real benefits to having cars without drivers compared to sort of the status quo for people who use ride share services today you know you get privacy consistency hopefully significantly improve safety all these benefits versus the current product but its a crowded market and then other opportunities which youve seen a lot of activity in the last really in the last six or twelve months is you know delivery whether thats parcels and packages food or groceries those are all sort of i think opportunities that are pretty ripe for these you know once you have this core technology which is the fleet of autonomous vehicles theres all sorts of different business opportunities you can build on top of that but i think the important thing of course is that theres zero monetization opportunity until you actually have that fleet of very capable driverless cars that are that are as good or better than humans and thats sort of where the entire industry is sort of in this holding pattern right now yeah theyre trying to achieve that baseline so but you said sort of not reliability consistency its kind of interesting i think i heard you say somewhere im not sure if thats what you meant but you know i can imagine a situation where you would get an autonomous vehicle and you know when you get into an uber or lyft you dont get to choose the driver in a sense that you dont get to choose the personality of the driving do you think theres a theres room to define the personality of the car the way it drives you in terms of aggressiveness for example in terms of sort of pushing the bound one of the biggest challenges of autonomous driving is the is the trade off between sort of safety and assertiveness and do you think theres any room for the human to take a role in that decision sort of accept some of the liability i guess i wouldnt no id say within reasonable bounds as in were not gonna i think itd be highly unlikely wed expose any knob that would let you you know significantly increase safety risk i think thats just not something wed be willing to do but i think driving style or like you know are you going to relax the comfort constraints slightly or things like that all of those things make sense and are plausible i see all those as you know nice optimizations once again we get the core problem solved in these fleets out there but the other thing weve sort of observed is that you have this intuition that if you sort of slam your foot on the gas right after the light turns green and aggressively accelerate youre going to get there faster but the actual impact of doing that is pretty small you feel like youre getting there faster but so the same would be true for avs even if they dont slam their you know the pedal to the floor when the light turns green theyre going to get you there within you know if its a 15 minute trip within 30 seconds of what you would have done otherwise if you were going really aggressively so i think theres this sort of self deception that my aggressive driving style is getting me there faster well so thats you know some of the things ive studied some of the things im fascinated by the psychology of that i dont think it matters that it doesnt get you there faster its the emotional release driving is a place being inside of a car somebody said its like the real world version of being a troll so you have this protection this mental protection youre able to sort of yell at the world like release your anger whatever so theres an element of that that i think autonomous vehicles would also have to you know giving an outlet to people but it doesnt have to be through through through driving or honking or so on there might be other outlets but i think to just sort of even just put that aside the baseline is really you know thats the focus thats the thing you need to solve and then the fun human things can be solved after but so from the baseline of just solving autonomous driving youre working in san francisco one of the more difficult cities to operate in what is what is the in your view currently the hardest aspect of autonomous driving is it negotiating with pedestrians is it edge cases of perception is it planning is there a mechanical engineering is it data fleet stuff what are your thoughts on the challenge the more challenging aspects there thats a thats a good question i think before before we go to that though i just want to i like what you said about the psychology aspect of this because i think one observation ive made is i think i read somewhere that i think its maybe americans on average spend you know over an hour a day on social media like staring at facebook and so thats just you know 60 minutes of your life youre not getting back its probably not super productive and so thats 3600 seconds right and thats thats time you know its a lot of time youre giving up and if you compare that to people being on the road if another vehicle whether its a human driver or autonomous vehicle delays them by even three seconds theyre laying in on the horn you know even though thats thats you know one one thousandth of the time they waste looking at facebook every day so theres theres definitely some you know psychology aspects of this i think that are pretty interesting road rage in general and then the question of course is if everyone is in self driving cars do they even notice these three second delays anymore cause theyre doing other things or reading or working or just talking to each other so itll be interesting to see where that goes in a certain aspect people people need to be distracted by something entertaining something useful inside the car so they dont pay attention to the external world and then and then they can take whatever psychology and bring it back to twitter and then focus on that as opposed to sort of interacting sort of putting the emotion out there into the world so its a its an interesting problem but baseline autonomy i guess you could say self driving cars you know at scale will lower the collective blood pressure of society probably by a couple of points without all that road rage and stress so thats a good good external so back to your question about the technology and the i guess the biggest problems and i have a hard time answering that question because you know weve been at this like specifically focusing on driverless cars and all the technology needed to enable that for a little over four and a half years now and even a year or two in i felt like we had completed the functionality needed to get someone from point a to point b as in if we need to do a left turn maneuver or if we need to drive around at you know a double parked vehicle into oncoming traffic or navigate through construction zones the scaffolding and the building blocks was there pretty early on and so the challenge is not any one scenario or situation for which you know we fail at 100 of those its more you know were benchmarking against a pretty good or pretty high standard which is human driving all things considered humans are excellent at handling edge cases and unexpected scenarios where computers are the opposite and so beating that baseline set by humans is the challenge and so what weve been doing for quite some time now is basically its this continuous improvement process where we find sort of the most you know uncomfortable or the things that could lead to a safety issue or other things all these events and then we sort of categorize them and rework parts of our system to make incremental improvements and do that over and over and over again and we just see sort of the overall performance of the system you know actually increasing in a pretty steady clip but theres no one thing theres actually like thousands of little things and just like polishing functionality and making sure that it handles you know every version and possible permutation of a situation by either applying more deep learning systems or just by you know adding more test coverage or new scenarios that we develop against and just grinding on that were sort of in the unsexy phase of development right now which is doing the real engineering work that it takes to go from prototype to production youre basically scaling the grinding sort of taking seriously that the process of all those edge cases both with human experts and machine learning methods to cover all those situations yeah and the exciting thing for me is i dont think that grinding ever stops because theres a moment in time where youve crossed that threshold of human performance and become superhuman but theres no reason theres no first principles reason that av capability will tap out anywhere near humans like theres no reason it couldnt be 20 times better whether thats you know just better driving or safer driving or more comfortable driving or even a thousand times better given enough time and we intend to basically chase that you know forever to build the best possible product better and better and better and always new edge cases come up and new experiences so and you want to automate that process as much as possible so what do you think in general in society when do you think we may have hundreds of thousands of fully autonomous vehicles driving around so first of all predictions nobody knows the future youre a part of the leading people trying to define that future but even then you still dont know but if you think about hundreds of thousands of vehicles so a significant fraction of vehicles in major cities are autonomous do you think are you with rodney brooks who is 2050 and beyond or are you more with elon musk who is we should have had that two years ago well i mean id love to have it two years ago but were not there yet so i guess the way i would think about that is lets flip that question around so what would prevent you to reach hundreds of thousands of vehicles and thats a good thats a good rephrasing yeah so the id say the it seems the consensus among the people developing self driving cars today is to sort of start with some form of an easier environment whether it means you know lacking inclement weather or you know mostly sunny or whatever it is and then add add capability for more complex situations over time and so if youre only able to deploy in areas that meet sort of your criteria or the current domain you know operating domain of the software you developed that may put a cap on how many cities you could deploy in but then as those restrictions start to fall away like maybe you add capability to drive really well and safely in heavy rain or snow you know that that probably opens up the market by two two or three fold in terms of the cities you can expand into and so on and so the real question is you know i know today if we wanted to we could produce that that many autonomous vehicles but we wouldnt be able to make use of all of them yet cause we would sort of saturate the demand in the cities in which we would want to operate initially so if i were to guess like what the timeline is for those things falling away and reaching hundreds of thousands of vehicles i would say that thousands of vehicles maybe a range is better i would say less than five years less than five years yeah and of course youre working hard to make that happen so you started two companies that were eventually acquired for each four billion dollars so youre a pretty good person to ask what does it take to build a successful startup i think theres theres sort of survivor bias here a little bit but i can try to find some common threads for the things that worked for me which is you know in in both of these companies i was really passionate about the core technology i actually like you know lay awake at night thinking about these problems and how to solve them and i think thats helpful because when you start a business there are like to this day there are these crazy ups and downs like one day you think the business is just on youre just on top of the world and unstoppable and the next day you think okay this is all going to end you know its just its just going south and its going to be over tomorrow and and so i think like having a true passion that you can fall back on and knowing that you would be doing it even if you werent getting paid for it helps you weather those those tough times so thats one thing i think the other one is really good people so ive always been surrounded by really good cofounders that are logical thinkers are always pushing their limits and have very high levels of integrity so thats dan kahn and my current company and actually his brother and a couple other guys for justin tv and twitch and then i think the last thing is just i guess persistence or perseverance like and and that that can apply to sticking to sort of or having conviction around the original premise of your idea and sticking around to do all the you know the unsexy work to actually make it come to fruition including dealing with you know whatever it is that you that youre not passionate about whether thats finance or or hr or or operations or those things as long as you are grinding away and working towards you know that north star for your business whatever it is and you dont give up and youre making progress every day it seems like eventually youll end up in a good place and the only things that can slow you down are you know running out of money or i suppose your competitors destroying you but i think most of the time its its people giving up or or somehow destroying things themselves rather than being beaten by their competition or running out of money yeah if you never quit eventually youll arrive so uh its a much more concise version of what i was trying to say yeah that was good so you went the y combinator route twice yeah what do you think in a quick question do you think is the best way to raise funds in the early days or not just funds but just community develop your idea and so on can you do it solo or maybe with a co founder with like self funded do you think y combinator is good is it good to do vc route is there no right answer or is there from the y combinator experience something that you could take away that that was the right path to take theres no one size fits all answer but if your ambition i think is to you know see how big you can make something or or or rapidly expand and capture a market or solve a problem or whatever it is then then you know going to venture back route is probably a good approach so that so that capital doesnt become your primary constraint y combinator i love because it puts you in this uh sort of competitive environment where youre where youre surrounded by you know the top maybe 1 of other really highly motivated you know peers who are in the same same place and that uh that environment i think just breeds breed success right if youre surrounded by really brilliant hardworking people youre going to feel you know sort of compelled or inspired to to try to emulate them and or beat them and uh so even though i had done it once before and i felt like yeah im pretty self motivated i thought like look this is going to be a hard problem i can use all the help i can get so surrounding myself with other entrepreneurs is going to make me work a little bit harder or push a little harder than its worth it and so thats why i why i did it you know for example the second time lets uh lets go philosophical existential if you go back and do something differently in your life starting in the high school and mit leaving mit you could have gone the phd route doing the startup going to see about a startup in california and you or maybe some aspects of fundraising is there something you regret something you not necessarily regret but if you go back you could do differently i think ive made a lot of mistakes like you know pretty much everything you can screw up i think ive screwed up at least once but i you know i dont regret those things i think its its hard to its hard to look back on things even if it didnt go well and call it a regret because hopefully it took away some new knowledge or learning from that so i would say there was a period yeah the closest i can i can come to is theres a period um in in justin tv i think after seven years where you know the company was going one direction which is towards twitch uh in video gaming im not a video gamer i dont really even use twitch at all and i was still uh working on the core technology there but my my heart was no longer in it because the business that we were creating was not something that i was personally passionate about it didnt meet your bar of existential impact yeah and id say i probably spent an extra year or two working on that and uh and id say like i would have just tried to do something different sooner because those those were two years where i felt like um you know from this philosophical or existential thing i just i just felt that something was missing and so i would have i would have if i could look back now and tell myself its like i would have said exactly that like youre not getting any meaning out of your work personally right now you should you should find a way to change that and thats thats part of the pitch i use to basically everyone who joins cruise today its like hey youve got that now by coming here well maybe you needed the two years of that existential dread to develop the feeling that ultimately it was the fire that created cruise so you never know you cant good theory so last question what does 2019 hold for cruise after this i guess were going to go and ill talk to your class but one of the big things is going from prototype to production uh for autonomous cars and what does that mean what does that look like and 2019 for us is the year that we try to cross over that threshold and reach you know superhuman level of performance to some degree with the software and uh have all the other of the thousands of little building blocks in place to to launch um you know our our first uh commercial product so thats thats whats in store for us or in store for us and weve got a lot of work to do weve got a lot of brilliant people working on it so its its all up to us now yeah from charlie miller and chris vells like the people ive crossed paths with oh great if you it sounds like you have an amazing team so um like i said its one of the most i think one of the most important problems in artificial intelligence of the century itll be one of the most defining the super exciting that you work on it and uh the best of luck in 2018 im really excited to see what cruz comes up with thank you thanks for having me today thanks carl', 'the following is a conversation with kyle vogt hes the president and the cto of cruise automation leading an effort to solve one of the biggest robotics challenges of our time vehicle automation hes a cofounder of two successful companies twitch and cruise that have each sold for a billion dollars and hes a great example of the innovative spirit that flourishes in silicon valley and now is facing an interesting and exciting challenge of matching that spirit with the mass production and the safety centric culture of a major automaker like general motors this conversation is part of the mit artificial general intelligence series and the artificial intelligence podcast if you enjoy it please subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with kyle vogt you grew up in kansas right yeah and i just saw that picture you had hidden over there so im a little bit a little bit worried about that now yeah so in high school in kansas city you joined shawnee mission north high school robotics team yeah now that wasnt your high school thats right that was that was the only high school in the area that had a like a teacher who was willing to sponsor our first robotics team i was gonna troll you a little bit jog your memory a little bit yeah i was trying to look super cool and intense because you know this was battlebots this is serious business so were standing there with a welded steel frame and looking tough so go back there what is that drew you to robotics well i think ive been trying to figure this out for a while but ive always liked building things with legos and when i was really really young i wanted the legos that had motors and other things and then you know lego mindstorms came out and for the first time you could program lego contraptions and i think things just sort of snowballed from that but i remember seeing you know the battlebots tv show on comedy central and thinking that is the coolest thing in the world i want to be a part of that and not knowing a whole lot about how to build these 200 pound fighting robots so i sort of obsessively poured over the internet forums where all the creators for battlebots would sort of hang out and talk about you know document their build progress and everything and i think i read i must have read like you know tens of thousands of forum posts from basically everything that was out there on what these people were doing and eventually like sort of triangulated how to put some of these things together and i ended up doing battlebots which was you know i was like 13 or 14 which was pretty awesome im not sure if the show is still running but so battlebots is theres not an artificial intelligence component its remotely controlled and its almost like a mechanical engineering challenge of building things that can be broken theyre radio controlled so and i think that they allowed some limited form of autonomy but you know in a two minute match youre in the way these things ran youre really doing yourself a disservice by trying to automate it versus just you know do the practical thing which is drive it yourself and theres an entertainment aspect just going on youtube theres like an some of them wield an axe some of them i mean theres that fun so what drew you to that aspect was it the mechanical engineering was it the dream to create like frankenstein and sentient being or was it just like the lego you like tinkering with stuff i mean that was just building something i think the idea of you know this radio controlled machine that can do various things if it has like a weapon or something was pretty interesting i agree it doesnt have the same appeal as you know autonomous robots which i which i you know sort of gravitated towards later on but it was definitely an engineering challenge because everything you did in that competition was pushing components to their limits so we would buy like these 40 dc motors that came out of a winch like on the front of a pickup truck or something and wed power the car with those and wed run them at like double or triple their rated voltage so they immediately start overheating but for that two minute match you can get you know a significant increase in the power output of those motors before they burn out and so youre doing the same thing for your battery packs all the materials in the system and i think theres something something intrinsically interesting about just seeing like where things break and did you offline see where they break did you take it to the testing point like how did you know two minutes or was there a reckless lets just go with it and see we werent very good at battlebots we lost all of our matches the first round the one i built first both of them were these wedge shaped robots because wedge even though its sort of boring to look at is extremely effective you drive towards another robot and the front edge of it gets under them and then they sort of flip over kind of like a door stopper and the first one had a pneumatic polished stainless steel spike on the front that would shoot out about eight inches the purpose of which is what pretty pretty ineffective actually but it looks cool and was it to help with the lift no it was it was just to try to poke holes in the other robot and then the second time i did it which is the following i think maybe 18 months later we had a well a titanium axe with a with a hardened steel tip on it that was powered by a hydraulic cylinder which we were activating with liquid co2 which was had its own set of problems so great so thats kind of on the hardware side i mean at a certain point there must have been born a fascination on the software side so what was the first piece of code youve written go back there see what language was it what what was that was it emacs vim was it a more respectable modern ide do you do you remember any of this yeah well i remember i think maybe when i was in third or fourth grade the school i was at elementary school had a bunch of apple ii computers and wed play games on those and i remember every once in a while something would would would crash or wouldnt start up correctly and it would dump you out to what i later learned was like sort of a command prompt and my teacher would come over and type i actually remember this to this day for some reason like pr number six or pr pound six which is peripheral six which is the disk drive which would fire up the disk and load the program and i just remember thinking wow shes like a hacker like teach me these these codes these error codes that is what i called them at the time but she had no interest in that so it wasnt until i think about fifth grade that i had a school where you could actually go on these apple iis and learn to program and so it was all in basic you know where every line you know the line numbers are all number that every line is numbered and you have to like leave enough space between the numbers so that if you want to tweak your code you go back and the first line was 10 and the second line is 20 now you have to go back and insert 15 and if you need to add code in front of that you know 11 or 12 and you hope you dont run out of line numbers and have to redo the whole thing and theres go to statements yeah go to and its very basic maybe hence the name but a lot of fun and that was like that was you know thats when you know when you first program you see the magic of it its like it just just like this world opens up with you know endless possibilities for the things you could build or or accomplish with that computer so you got the bug then so even starting with basic and then what c throughout what did you was there computer programming computer science classes in high school not not where i went so it was self taught but i did a lot of programming the thing that you know sort of pushed me in the path of eventually working on self driving cars is actually one of these really long trips driving from my house in kansas to to i think las vegas where we did the battlebots competition and i had just gotten my i think my learners permit or early drivers permit and so i was driving this you know 10 hour stretch across western kansas where its just youre going straight on a highway and it is mind numbingly boring and i remember thinking even then with my sort of mediocre programming background that this is something that a computer can do right lets take a picture of the road lets find the yellow lane markers and you know steer the wheel and you know later id come to realize this had been done you know since since the 80s or the 70s or even earlier but i still wanted to do it and sort of immediately after that trip switched from sort of battlebots which is more radio controlled machines to thinking about building you know autonomous vehicles of some scale start off with really small electric ones and then you know progress to what were doing now so what was your view of artificial intelligence at that point what did you think so this is before theres been waves in artificial intelligence right the current wave with deep learning makes people believe that you can solve in a really rich deep way the computer vision perception problem but like in before the deep learning craze you know how do you think about how would you even go about building a thing that perceives itself in the world localizes itself in the world moves around the world like when you were younger i mean what was your thinking about it well prior to deep neural networks or convolutional neural analysis these modern techniques we have or at least ones that are in use today it was all a heuristic space and so like old school image processing and i think extracting you know yellow lane markers out of an image of a road is one of the problems that lends itself reasonably well to those heuristic based methods you know like just do a threshold on the color yellow and then try to fit some lines to that using a huff transform or something and then go from there traffic light detection and stop sign detection red yellow green and i think you could i mean if you wanted to do a full i was just trying to make something that would stay in between the lanes on a highway but if you wanted to do the full the full you know set of capabilities needed for a driverless car i think you could and wed done this at cruise you know in the very first days you can start off with a really simple you know human written heuristic just to get the scaffolding in place for your system traffic light detection probably a really simple you know color thresholding on day one just to get the system up and running before you migrate to you know a deep learning based technique or something else and you know back in when i was doing this my first one it was on a pentium 203 233 megahertz computer in it and i think i wrote the first version in basic which is like an interpreted language its extremely slow because thats the thing i knew at the time and so there was no no chance at all of using there was no no computational power to do any sort of reasonable deep nets like you have today so i dont know what kids these days are doing are kids these days you know at age 13 using neural networks in their garage i mean that would be awesome i get emails all the time from you know like 11 12 year olds saying im having you know im trying to follow this tensorflow tutorial and im having this problem and the general approach in the deep learning community is of extreme optimism of as opposed to you mentioned like heuristics you can you can you can separate the autonomous driving problem into modules and try to solve it sort of rigorously or you can just do it end to end and most people just kind of love the idea that you know us humans do it end to end we just perceive and act we should be able to use that do the same kind of thing when youre on nets and that that kind of thinking you dont want to criticize that kind of thinking because eventually they will be right yeah and so its exciting and especially when theyre younger to explore that as a really exciting approach but yeah its its changed the the language the kind of stuff youre tinkering with its kind of exciting to see when these teenagers grow up yeah i can only imagine if you if your starting point is you know python and tensorflow at age 13 where you end up you know after 10 or 15 years of that thats thats pretty cool because of github because the state tools for solving most of the major problems in artificial intelligence are within a few lines of code for most kids and thats incredible to think about also on the entrepreneurial side and and on that point was there any thought about entrepreneurship before you came to college is sort of doing youre building this into a thing that impacts the world on a large scale yeah ive always wanted to start a company i think thats you know just a cool concept of creating something and exchanging it for value or creating value i guess so in high school i was i was trying to build like you know servo motor drivers little circuit boards and sell them online or other other things like that and certainly knew at some point i wanted to do a startup but it wasnt really id say until college until i felt like i had the i guess the right combination of the environment the smart people around you and some free time and a lot of free time at mit so you came to mit as an undergrad 2004 thats right and thats when the first darpa grand challenge was happening yeah the the timing of that is beautifully poetic so how did you get yourself involved in that one originally there wasnt a official entry yeah faculty sponsored thing and so a bunch of undergrads myself included started meeting and got together and tried to haggle together some sponsorships we got a vehicle donated a bunch of sensors and tried to put something together and so we had our team was probably mostly freshmen and sophomores you know which which was not really a fair fair fight against maybe the you know postdoc and faculty led teams from other schools but we we got something up and running we had our vehicle drive by wire and you know very very basic control and things but on the day of the qualifying sort of pre qualifying round the one and only steering motor that we had purchased the thing that we had retrofitted to turn the steering wheel on the truck died and so our vehicle was just dead in the water couldnt steer so we didnt make it very far on the hardware side so was there a software component was there like how did your view of autonomous vehicles in terms of artificial intelligence evolve in this moment i mean you know like you said from the 80s has been autonomous vehicles but really that was the birth of the modern wave the the thing that captivated everyones imagination that we can actually do this so what how were you captivated in that way so how did your view of autonomous vehicles change at that point id say at that point in time it was it was a curiosity as in like is this really possible and i think that was generally the spirit and the purpose of that original darpa grand challenge which was to just get a whole bunch of really brilliant people exploring the space and pushing the limits and i think like to this day that darpa challenge with its you know million dollar prize pool was probably one of the most effective you know uses of taxpayer money dollar for dollar that ive seen you know because that that small sort of initiative that darpa put put out sort of in my view was the catalyst or the tipping point for this this whole next wave of autonomous vehicle development so that was pretty cool so let me jump around a little bit on that point they also did the urban challenge where it was in the city but it was very artificial and theres no pedestrians and theres very little human involvement except a few professional drivers yeah do you think theres room and then there was the robotics challenge with humanoid robots right so in your now role is looking at this youre trying to solve one of the you know autonomous driving one of the harder more difficult places in san francisco is there a role for darpa to step in to also kind of help out like challenge with new ideas specifically pedestrians and so on all these kinds of interesting things well i havent i havent thought about it from that perspective is there anything darpa could do today to further accelerate things and i would say my instinct is that thats maybe not the highest and best use of their resources and time because like kick starting and spinning up the flywheel is i think what what they did in this case for very very little money but today this has become this has become like commercially interesting to very large companies and the amount of money going into it and the amount of people like going through your class and learning about these things and developing these skills is just you know orders of magnitude more than it was back then and so theres enough momentum and inertia and energy and investment dollars into this space right now that i dont i dont i think theyre i think theyre they can just say mission accomplished and move on to the next area of technology that needs help so then stepping back to mit you left mit during your junior year what was that decision like as i said i always wanted to do a company in or start a company and this opportunity landed in my lap which was a couple guys from yale were starting a new company and i googled them and found that they had started a company previously and sold it actually on ebay for about a quarter million bucks which was a pretty interesting story but so i thought to myself these guys are you know rock star entrepreneurs theyve done this before they must be driving around in ferraris because they sold their company and you know i thought i could learn a lot from them so i teamed up with those guys and you know went out during went out to california during iap which is mits month off on a one way ticket and basically never went back we were having so much fun we felt like we were building something and creating something and it was going to be interesting that you know i was just all in and got completely hooked and that that business was justin tv which is originally a reality show about a guy named justin which morphed into a live video streaming platform which then morphed into what is twitch today so that was that was quite an unexpected journey so no regrets no looking back it was just an obvious i mean one way ticket i mean if we just pause on that for a second there was no how did you know these are the right guys this is the right decision you didnt think it was just follow the heart kind of thing well i didnt know but you know just trying something for a month during iap seems pretty low risk right and then you know well maybe ill take a semester off mits pretty flexible about that you can always go back right and then after two or three cycles of that i eventually threw in the towel but you know i think its i guess in that case i felt like i could always hit the undo button if i had to right but nevertheless from when you look in retrospect i mean it seems like a brave decision you know it would be difficult for a lot of people to make it wasnt as popular id say that the general you know flux of people out of mit at the time was mostly into you know finance or consulting jobs in boston or new york and very few people were going to california to start companies but today id say thats its probably inverted which is just a sign of a sign of the times i guess yeah so theres a story about midnight of march 18 2007 where techcrunch i guess announced justintv earlier than it was supposed to a few hours the site didnt work i dont know if any of this is true you can tell me and you and one of the folks at justintv emmett shearer coded through the night can you take me through that experience so let me let me say a few nice things that the article i read quoted justin kahn said that you were known for bureau coding through problems and being a creative quote creative genius so on that night what what was going through your head or maybe id put another way how do you solve these problems whats your approach to solving these kinds of problems where the line between success and failure seems to be pretty thin thats a good question well first of all thats thats a nice of justin to say that i think you know i would have been maybe 21 years old then and not very experienced at programming but as with with everything in a startup youre sort of racing against the clock and so our plan was the second we had this live streaming camera backpack up and running where justin could wear it and no matter where he went in a city it would be streaming live video and this is even before the iphones this is like hard to do back then we would launch and so we thought we were there and the backpack was working and then we sent out all the emails to launch the launch the company and do the press thing and then you know we werent quite actually there and then we thought oh well you know theyre not going to announce it until maybe 10 am the next morning and its i dont know its 5 pm now so how many hours do we have left what is that like you know 17 hours to go and and that was that was going to be fine was the problem obvious did you understand what could possibly like how complicated was the system at that point it was it was pretty messy so to get a live video feed that looked decent working from anywhere in san francisco i put together this system where we had like three or four cell phone data modems and they were like we take the video stream and you know sort of spray it across these three or four modems and then try to catch all the packets on the other side you know with unreliable cell phone networks its pretty low level networking yeah and putting these like you know sort of protocols on top of all that to to reassemble and reorder the packets and have time buffers and error correction and all that kind of stuff and the night before it was just staticky every once in a while the image would would go to staticky and there would be this horrible like screeching audio noise because the audio was also corrupted and this would happen like every five to ten minutes or so and it was a really you know off putting to the viewers how do you tackle that problem what was the uh youre just freaking out behind a computer theres are there other other folks working on this problem like were you behind a whiteboard were you doing uh yeah it was a little it was a little yeah its a little lonely because theres four of us working on the company and only two people really wrote code and emmett wrote the website and the chat system and i wrote the software for this video streaming device and video server and so you know its my sole responsibility to figure that out and i think i think its those you know setting setting deadlines trying to move quickly and everything where youre in that moment of intense pressure that sometimes people do their best and most interesting work and so even though that was a terrible moment i look back on it fondly because thats like you know thats one of those character defining moments i think so in 2013 october you founded cruise automation yeah so progressing forward another exceptionally successful company was acquired by gm in 16 for 1 billion but in october 2013 what was on your mind what was the plan how does one seriously start to tackle one of the hardest robotics most important impact for robotics problems of our age after going through twitch twitch was was and is today pretty successful but the the work was the result was entertainment mostly like the better the product was the more we would entertain people and then you know make money on the ad revenues and other things and that was that was a good thing it felt felt good to entertain people but i figured like you know what is really the point of becoming a really good engineer and developing these skills other than you know my own enjoyment and i realized i wanted something that scratched more of an existential itch like something that that truly matters and so i basically made this list of requirements for a new if i was going to do another company and the one thing i knew in the back of my head that twitch took like eight years to become successful and so whatever i do i better be willing to commit you know at least 10 years to something and when you think about things from that perspective you certainly i think raise the bar on what you choose to work on so for me the three things were it had to be something where the technology itself determines the success of the product like hard really juicy technology problems because thats what motivates me and then it had to have a direct and positive impact on society in some way so an example would be like you know health care self driving cars because they save lives other things where theres a clear connection to somehow improving other peoples lives and the last one is it had to be a big business because for the positive impact to matter its got to be a large scale and i was thinking about that for a while and i made like i tried writing a gmail clone and looked at some other ideas and then it just sort of light bulb went off like self driving cars like that was the most fun i had ever had in college working on that and like well whats the state of the technology its been 10 years maybe times have changed and maybe now is the time to make this work and i poked around and looked at the only other thing out there really at the time was the google self driving car project and i thought surely theres a way to you know have an entrepreneur mindset and sort of solve the minimum viable product here and so i just took the plunge right then and there and said this is something i know i can commit 10 years to its the probably the greatest applied ai problem of our generation and if it works its going to be both a huge business and therefore like probably the most positive impact i can possibly have on the world so after that light bulb went off i went all in on cruise immediately and got to work did you have an idea how to solve this problem which aspect of the problem to solve you know slow like we just had oliver from voyage here slow moving retirement communities urban driving highway driving did you have like did you have a vision of the city of the future where you know the transportation is largely automated that kind of thing or was it sort of more fuzzy and gray area than that my analysis of the situation is that google is putting a lot had been putting a lot of money into that project they had a lot more resources and so and they still hadnt cracked the fully driverless car you know this is 2013 i guess so i thought what can i do to sort of go from zero to you know significant scale so i can actually solve the real problem which is the driverless cars and i thought heres the strategy well start by doing a really simple problem or solving a really simple problem that creates value for people so eventually ended up deciding on automating highway driving which is relatively more straightforward as long as theres a backup driver there and you know the go to market will be able to retrofit peoples cars and just sell these products directly and the idea was well take all the revenue and profits from that and use it to do the so sort of reinvest that in research for doing fully driverless cars and that was the plan the only thing that really changed along the way between then and now is we never really launched the first product we had enough interest from investors and enough of a signal that this was something that we should be working on that after about a year of working on the highway autopilot we had it working you know on a prototype stage but we just completely abandoned that and said were going to go all in on driverless cars now is the time cant think of anything thats more exciting and if it works more impactful so were just going to go for it the idea of retrofit is kind of interesting yeah being able to its how you achieve scale its a really interesting idea is it something thats still in the in the back of your mind as a possibility not at all ive come full circle on that one after trying to build a retrofit product and ill touch on some of the complexities of that and then also having been inside an oem and seeing how things work and how a vehicle is developed and validated when it comes to something that has safety critical implications like controlling the steering and other control inputs on your car its pretty hard to get there with a retrofit or if you did even if you did it creates a whole bunch of new complications around liability or how did you truly validate that or you know something in the base vehicle fails and causes your system to fail whose fault is it or if the cars anti lock brake systems or other things kick in or the software has been its different in one version of the car you retrofit versus another and you dont know because the manufacturer has updated it behind the scenes theres basically an infinite list of long tail issues that can get you and if youre dealing with a safety critical product thats not really acceptable thats a really convincing summary of why thats really challenging but i didnt know all that at the time so we tried it anyway but as a pitch also at the time its a really strong one because thats how you achieve scale and thats how you beat the current the leader at the time of google or the only one in the market the other big problem we ran into which is perhaps the biggest problem from a business model perspective is we had kind of assumed that we started with an audi s4 as the vehicle we retrofitted with this highway driving capability and we had kind of assumed that if we just knock out like three make and models of vehicles thatll cover like 80 of the san francisco market doesnt everyone there drive i dont know a bmw or a honda civic or one of these three cars and then we surveyed our users and we found out that its all over the place we would to get even a decent number of units sold wed have to support like you know 20 or 50 different models and each one is a little butterfly that takes time and effort to maintain you know that retrofit integration and custom hardware and all this so it was a tough business so gm manufactures and sells over 9 million cars a year and what you with cruise are trying to do some of the most cutting edge innovation in terms of applying ai and so how do those youve talked about a little bit before but its also just fascinating to me we work a lot of automakers you know the difference between the gap between detroit and silicon valley lets say just to be sort of poetic about it i guess how do you close that gap how do you take gm into the future where a large part of the fleet will be autonomous perhaps i want to start by acknowledging that gm is made up of you know tens of thousands of really brilliant motivated people who want to be a part of the future and so its pretty fun to work within the attitude inside a car company like that is you know embracing this transformation and change rather than fearing it and i think thats a testament to the leadership at gm and thats flown all the way through to everyone you talk to even the people in the assembly plants working on these cars so thats really great so starting from that position makes it a lot easier so then when the people in san francisco at cruise interact with the people at gm at least we have this common set of values which is that we really want this stuff to work because we think its important and we think its the future thats not to say you know those two cultures dont clash they absolutely do theres different sort of value systems like in a car company the thing that gets you promoted and sort of the reward system is following the processes delivering the program on time and on budget so any sort of risk taking is discouraged in many ways because if a program is late or if you shut down the plant for a day its you know you can count the millions of dollars that burn by pretty quickly whereas i think you know most silicon valley companies and in cruise and the methodology we were employing especially around the time of the acquisition the reward structure is about trying to solve these complex problems in any way shape or form or coming up with crazy ideas that you know 90 of them wont work and so meshing that culture of sort of continuous improvement and experimentation with one where everything needs to be rigorously defined up front so that you never slip a deadline or miss a budget was a pretty big challenge and that were over three years in now after the acquisition and id say like you know the investment we made in figuring out how to work together successfully and who should do what and how we bridge the gaps between these very different systems and way of doing engineering work is now one of our greatest assets because i think we have this really powerful thing but for a while it was both gm and cruise were very steep on the learning curve yeah so im sure it was very stressful its really important work because thats how to revolutionize the transportation really to revolutionize any system you know you look at the health care system or you look at the legal system i have people like loris come up to me all the time like everything theyre working on can easily be automated but then thats not a good feeling yeah well its not a good feeling but also theres no way to automate because the entire infrastructure is really you know based is older and it moves very slowly and so how do you close the gap between i have an how can i replace of course loris dont want to be replaced with an app but you could replace a lot of aspect when most of the data is still on paper and so the same thing was with automotive i mean its fundamentally software its basically hiring software engineers its thinking in a software world i mean im pretty sure nobody in silicon valley has ever hit a deadline so and then on gm thats probably true yeah and gm side is probably the opposite yeah so thats that culture gap is really fascinating so youre optimistic about the future of that yeah i mean from what ive seen its impressive and i think like especially in silicon valley its easy to write off building cars because you know people have been doing that for over 100 years now in this country and so it seems like thats a solved problem but that doesnt mean its an easy problem and i think it would be easy to sort of overlook that and think that you know were silicon valley engineers we can solve any problem you know building a car its been done therefore its you know its not a real engineering challenge but after having seen just the sheer scale and magnitude and industrialization that occurs inside of an automotive assembly plant that is a lot of work that i am very glad that we dont have to reinvent to make self driving cars work and so to have you know partners who have done that for 100 years now these great processes and this huge infrastructure and supply base that we can tap into is just remarkable because the scope and surface area of the problem of deploying fleets of self driving cars is so large that were constantly looking for ways to do less so we can focus on the things that really matter more and if we had to figure out how to build and assemble and you know build the cars themselves i mean we work closely with gm on that but if we had to develop all that capability in house as well you know that would just make the problem really intractable i think so yeah just like your first entry at the mit darpa challenge when there was what the motor that failed somebody that knows what theyre doing with the motor did it that would have been nice if we could focus on the software not the hardware platform yeah right so from your perspective now you know theres so many ways that autonomous vehicles can impact society in the next year five years ten years what do you think is the biggest opportunity to make money in autonomous driving sort of make it a financially viable thing in the near term what do you think will be the biggest impact there well the things that drive the economics for fleets of self driving cars are theres sort of a handful of variables one is you know the cost to build the vehicle itself so the material cost how many you know whats the cost of all your sensors plus the cost of the vehicle and every all the other components on it another one is the lifetime of the vehicle its very different if your vehicle drives 100000 miles and then it falls apart versus you know two million and then you know if you have a fleet its kind of like an airplane or an airline where once you produce the vehicle you want it to be in operation as many hours a day as possible producing revenue and then you know the other piece of that is how are you generating revenue i think thats kind of what youre asking and i think the obvious things today are you know the ride sharing business because thats pretty clear that theres demand for that theres existing markets you can tap into and large urban areas that kind of thing yeah yeah and i think that there are some real benefits to having cars without drivers compared to sort of the status quo for people who use ride share services today you know you get privacy consistency hopefully significantly improve safety all these benefits versus the current product but its a crowded market and then other opportunities which youve seen a lot of activity in the last really in the last six or twelve months is you know delivery whether thats parcels and packages food or groceries those are all sort of i think opportunities that are pretty ripe for these you know once you have this core technology which is the fleet of autonomous vehicles theres all sorts of different business opportunities you can build on top of that but i think the important thing of course is that theres zero monetization opportunity until you actually have that fleet of very capable driverless cars that are that are as good or better than humans and thats sort of where the entire industry is sort of in this holding pattern right now yeah theyre trying to achieve that baseline so but you said sort of not reliability consistency its kind of interesting i think i heard you say somewhere im not sure if thats what you meant but you know i can imagine a situation where you would get an autonomous vehicle and you know when you get into an uber or lyft you dont get to choose the driver in a sense that you dont get to choose the personality of the driving do you think theres a theres room to define the personality of the car the way it drives you in terms of aggressiveness for example in terms of sort of pushing the bound one of the biggest challenges of autonomous driving is the is the trade off between sort of safety and assertiveness and do you think theres any room for the human to take a role in that decision sort of accept some of the liability i guess i wouldnt no id say within reasonable bounds as in were not gonna i think itd be highly unlikely wed expose any knob that would let you you know significantly increase safety risk i think thats just not something wed be willing to do but i think driving style or like you know are you going to relax the comfort constraints slightly or things like that all of those things make sense and are plausible i see all those as you know nice optimizations once again we get the core problem solved in these fleets out there but the other thing weve sort of observed is that you have this intuition that if you sort of slam your foot on the gas right after the light turns green and aggressively accelerate youre going to get there faster but the actual impact of doing that is pretty small you feel like youre getting there faster but so the same would be true for avs even if they dont slam their you know the pedal to the floor when the light turns green theyre going to get you there within you know if its a 15 minute trip within 30 seconds of what you would have done otherwise if you were going really aggressively so i think theres this sort of self deception that my aggressive driving style is getting me there faster well so thats you know some of the things ive studied some of the things im fascinated by the psychology of that i dont think it matters that it doesnt get you there faster its the emotional release driving is a place being inside of a car somebody said its like the real world version of being a troll so you have this protection this mental protection youre able to sort of yell at the world like release your anger whatever so theres an element of that that i think autonomous vehicles would also have to you know giving an outlet to people but it doesnt have to be through through through driving or honking or so on there might be other outlets but i think to just sort of even just put that aside the baseline is really you know thats the focus thats the thing you need to solve and then the fun human things can be solved after but so from the baseline of just solving autonomous driving youre working in san francisco one of the more difficult cities to operate in what is what is the in your view currently the hardest aspect of autonomous driving is it negotiating with pedestrians is it edge cases of perception is it planning is there a mechanical engineering is it data fleet stuff what are your thoughts on the challenge the more challenging aspects there thats a thats a good question i think before before we go to that though i just want to i like what you said about the psychology aspect of this because i think one observation ive made is i think i read somewhere that i think its maybe americans on average spend you know over an hour a day on social media like staring at facebook and so thats just you know 60 minutes of your life youre not getting back its probably not super productive and so thats 3600 seconds right and thats thats time you know its a lot of time youre giving up and if you compare that to people being on the road if another vehicle whether its a human driver or autonomous vehicle delays them by even three seconds theyre laying in on the horn you know even though thats thats you know one one thousandth of the time they waste looking at facebook every day so theres theres definitely some you know psychology aspects of this i think that are pretty interesting road rage in general and then the question of course is if everyone is in self driving cars do they even notice these three second delays anymore cause theyre doing other things or reading or working or just talking to each other so itll be interesting to see where that goes in a certain aspect people people need to be distracted by something entertaining something useful inside the car so they dont pay attention to the external world and then and then they can take whatever psychology and bring it back to twitter and then focus on that as opposed to sort of interacting sort of putting the emotion out there into the world so its a its an interesting problem but baseline autonomy i guess you could say self driving cars you know at scale will lower the collective blood pressure of society probably by a couple of points without all that road rage and stress so thats a good good external so back to your question about the technology and the i guess the biggest problems and i have a hard time answering that question because you know weve been at this like specifically focusing on driverless cars and all the technology needed to enable that for a little over four and a half years now and even a year or two in i felt like we had completed the functionality needed to get someone from point a to point b as in if we need to do a left turn maneuver or if we need to drive around at you know a double parked vehicle into oncoming traffic or navigate through construction zones the scaffolding and the building blocks was there pretty early on and so the challenge is not any one scenario or situation for which you know we fail at 100 of those its more you know were benchmarking against a pretty good or pretty high standard which is human driving all things considered humans are excellent at handling edge cases and unexpected scenarios where computers are the opposite and so beating that baseline set by humans is the challenge and so what weve been doing for quite some time now is basically its this continuous improvement process where we find sort of the most you know uncomfortable or the things that could lead to a safety issue or other things all these events and then we sort of categorize them and rework parts of our system to make incremental improvements and do that over and over and over again and we just see sort of the overall performance of the system you know actually increasing in a pretty steady clip but theres no one thing theres actually like thousands of little things and just like polishing functionality and making sure that it handles you know every version and possible permutation of a situation by either applying more deep learning systems or just by you know adding more test coverage or new scenarios that we develop against and just grinding on that were sort of in the unsexy phase of development right now which is doing the real engineering work that it takes to go from prototype to production youre basically scaling the grinding sort of taking seriously that the process of all those edge cases both with human experts and machine learning methods to cover all those situations yeah and the exciting thing for me is i dont think that grinding ever stops because theres a moment in time where youve crossed that threshold of human performance and become superhuman but theres no reason theres no first principles reason that av capability will tap out anywhere near humans like theres no reason it couldnt be 20 times better whether thats you know just better driving or safer driving or more comfortable driving or even a thousand times better given enough time and we intend to basically chase that you know forever to build the best possible product better and better and better and always new edge cases come up and new experiences so and you want to automate that process as much as possible so what do you think in general in society when do you think we may have hundreds of thousands of fully autonomous vehicles driving around so first of all predictions nobody knows the future youre a part of the leading people trying to define that future but even then you still dont know but if you think about hundreds of thousands of vehicles so a significant fraction of vehicles in major cities are autonomous do you think are you with rodney brooks who is 2050 and beyond or are you more with elon musk who is we should have had that two years ago well i mean id love to have it two years ago but were not there yet so i guess the way i would think about that is lets flip that question around so what would prevent you to reach hundreds of thousands of vehicles and thats a good thats a good rephrasing yeah so the id say the it seems the consensus among the people developing self driving cars today is to sort of start with some form of an easier environment whether it means you know lacking inclement weather or you know mostly sunny or whatever it is and then add add capability for more complex situations over time and so if youre only able to deploy in areas that meet sort of your criteria or the current domain you know operating domain of the software you developed that may put a cap on how many cities you could deploy in but then as those restrictions start to fall away like maybe you add capability to drive really well and safely in heavy rain or snow you know that that probably opens up the market by two two or three fold in terms of the cities you can expand into and so on and so the real question is you know i know today if we wanted to we could produce that that many autonomous vehicles but we wouldnt be able to make use of all of them yet cause we would sort of saturate the demand in the cities in which we would want to operate initially so if i were to guess like what the timeline is for those things falling away and reaching hundreds of thousands of vehicles i would say that thousands of vehicles maybe a range is better i would say less than five years less than five years yeah and of course youre working hard to make that happen so you started two companies that were eventually acquired for each four billion dollars so youre a pretty good person to ask what does it take to build a successful startup i think theres theres sort of survivor bias here a little bit but i can try to find some common threads for the things that worked for me which is you know in in both of these companies i was really passionate about the core technology i actually like you know lay awake at night thinking about these problems and how to solve them and i think thats helpful because when you start a business there are like to this day there are these crazy ups and downs like one day you think the business is just on youre just on top of the world and unstoppable and the next day you think okay this is all going to end you know its just its just going south and its going to be over tomorrow and and so i think like having a true passion that you can fall back on and knowing that you would be doing it even if you werent getting paid for it helps you weather those those tough times so thats one thing i think the other one is really good people so ive always been surrounded by really good cofounders that are logical thinkers are always pushing their limits and have very high levels of integrity so thats dan kahn and my current company and actually his brother and a couple other guys for justin tv and twitch and then i think the last thing is just i guess persistence or perseverance like and and that that can apply to sticking to sort of or having conviction around the original premise of your idea and sticking around to do all the you know the unsexy work to actually make it come to fruition including dealing with you know whatever it is that you that youre not passionate about whether thats finance or or hr or or operations or those things as long as you are grinding away and working towards you know that north star for your business whatever it is and you dont give up and youre making progress every day it seems like eventually youll end up in a good place and the only things that can slow you down are you know running out of money or i suppose your competitors destroying you but i think most of the time its its people giving up or or somehow destroying things themselves rather than being beaten by their competition or running out of money yeah if you never quit eventually youll arrive so uh its a much more concise version of what i was trying to say yeah that was good so you went the y combinator route twice yeah what do you think in a quick question do you think is the best way to raise funds in the early days or not just funds but just community develop your idea and so on can you do it solo or maybe with a co founder with like self funded do you think y combinator is good is it good to do vc route is there no right answer or is there from the y combinator experience something that you could take away that that was the right path to take theres no one size fits all answer but if your ambition i think is to you know see how big you can make something or or or rapidly expand and capture a market or solve a problem or whatever it is then then you know going to venture back route is probably a good approach so that so that capital doesnt become your primary constraint y combinator i love because it puts you in this uh sort of competitive environment where youre where youre surrounded by you know the top maybe 1 of other really highly motivated you know peers who are in the same same place and that uh that environment i think just breeds breed success right if youre surrounded by really brilliant hardworking people youre going to feel you know sort of compelled or inspired to to try to emulate them and or beat them and uh so even though i had done it once before and i felt like yeah im pretty self motivated i thought like look this is going to be a hard problem i can use all the help i can get so surrounding myself with other entrepreneurs is going to make me work a little bit harder or push a little harder than its worth it and so thats why i why i did it you know for example the second time lets uh lets go philosophical existential if you go back and do something differently in your life starting in the high school and mit leaving mit you could have gone the phd route doing the startup going to see about a startup in california and you or maybe some aspects of fundraising is there something you regret something you not necessarily regret but if you go back you could do differently i think ive made a lot of mistakes like you know pretty much everything you can screw up i think ive screwed up at least once but i you know i dont regret those things i think its its hard to its hard to look back on things even if it didnt go well and call it a regret because hopefully it took away some new knowledge or learning from that so i would say there was a period yeah the closest i can i can come to is theres a period um in in justin tv i think after seven years where you know the company was going one direction which is towards twitch uh in video gaming im not a video gamer i dont really even use twitch at all and i was still uh working on the core technology there but my my heart was no longer in it because the business that we were creating was not something that i was personally passionate about it didnt meet your bar of existential impact yeah and id say i probably spent an extra year or two working on that and uh and id say like i would have just tried to do something different sooner because those those were two years where i felt like um you know from this philosophical or existential thing i just i just felt that something was missing and so i would have i would have if i could look back now and tell myself its like i would have said exactly that like youre not getting any meaning out of your work personally right now you should you should find a way to change that and thats thats part of the pitch i use to basically everyone who joins cruise today its like hey youve got that now by coming here well maybe you needed the two years of that existential dread to develop the feeling that ultimately it was the fire that created cruise so you never know you cant good theory so last question what does 2019 hold for cruise after this i guess were going to go and ill talk to your class but one of the big things is going from prototype to production uh for autonomous cars and what does that mean what does that look like and 2019 for us is the year that we try to cross over that threshold and reach you know superhuman level of performance to some degree with the software and uh have all the other of the thousands of little building blocks in place to to launch um you know our our first uh commercial product so thats thats whats in store for us or in store for us and weve got a lot of work to do weve got a lot of brilliant people working on it so its its all up to us now yeah from charlie miller and chris vells like the people ive crossed paths with oh great if you it sounds like you have an amazing team so um like i said its one of the most i think one of the most important problems in artificial intelligence of the century itll be one of the most defining the super exciting that you work on it and uh the best of luck in 2018 im really excited to see what cruz comes up with thank you thanks for having me today thanks carl', 'the following is a conversation with leslie kaelbling she is a roboticist and professor at mit she is recognized for her work in reinforcement learning planning robot navigation and several other topics in ai she won the ijcai computers and thought award and was the editor in chief of the prestigious journal of machine learning research this conversation is part of the artificial intelligence podcast at mit and beyond if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with leslie kaelbling what made me get excited about ai i can say that is i read gödel escher bach when i was in high school that was pretty formative for me because it exposed the interestingness of primitives and combination and how you can make complex things out of simple parts and ideas of ai and what kinds of programs might generate intelligent behavior so so you first fell in love with ai reasoning logic versus robots yeah the robots came because my first job so i finished an undergraduate degree in philosophy at stanford and was about to finish a masters in computer science and i got hired at sri in their ai lab and they were building a robot it was a kind of a follow on to shaky but all the shaky people were not there anymore and so my job was to try to get this robot to do stuff and thats really kind of what got me interested in robots so maybe taking a small step back to your bachelors in stanford in philosophy did masters and phd in computer science but the bachelors in philosophy so what was that journey like what elements of philosophy do you think you bring to your work in computer science so its surprisingly relevant so the part of the reason that i didnt do a computer science undergraduate degree was that there wasnt one at stanford at the time but that theres a part of philosophy and in fact stanford has a special submajor in something called now symbolic systems which is logic model theory formal semantics of natural language and so thats actually a perfect preparation for work in ai and computer science thats kind of interesting so if you were interested in artificial intelligence what kind of majors were people even thinking about taking what is it in your science so besides philosophies what were you supposed to do if you were fascinated by the idea of creating intelligence there werent enough people who did that for that even to be a conversation i mean i think probably probably philosophy i mean its interesting in my class my graduating class of undergraduate philosophers probably maybe slightly less than half went on in computer science slightly less than half went on in law and like one or two went on in philosophy so it was a common kind of connection do you think ai researchers have a role to be part time philosophers or should they stick to the solid science and engineering without sort of taking the philosophizing tangents i mean you work with robots you think about what it takes to create intelligent beings arent you the perfect person to think about the big picture philosophy at all the parts of philosophy that are closest to ai i think or at least the closest to ai that i think about are stuff like belief and knowledge and denotation and that kind of stuff and thats you know its quite formal and its like just one step away from the kinds of computer science work that we do kind of routinely i think that there are important questions still about what you can do with a machine and what you cant and so on although at least my personal view is that im completely a materialist and i dont think that theres any reason why we cant make a robot be behaviorally indistinguishable from a human and the question of whether its distinguishable internally whether its a zombie or not in philosophy terms i actually dont i dont know and i dont know if i care too much about that right but there is a philosophical notions theyre mathematical and philosophical because we dont know so much of how difficult it is how difficult is the perception problem how difficult is the planning problem how difficult is it to operate in this world successfully because our robots are not currently as successful as human beings in many tasks the question about the gap between current robots and human beings borders a little bit on philosophy you know the expanse of knowledge thats required to operate in a human world required to operate in this world and the ability to form common sense knowledge the ability to reason about uncertainty much of the work youve been doing theres open questions there that i dont know required to activate a certain big picture view to me that doesnt seem like a philosophical gap at all to me there is a big technical gap theres a huge technical gap but i dont see any reason why its more than a technical gap perfect so when you mentioned ai you mentioned sri and maybe can you describe to me when you first fell in love with robotics with robots or inspired so you mentioned flaky or shaky flaky and what was the robot that first captured your imagination whats possible right well so the first robot i worked with was flaky shaky was a robot that the sri people had built but by the time i think when i arrived it was sitting in a corner of somebodys office dripping hydraulic fluid into a pan but its iconic and really everybody should read the shaky tech report because it has so many good ideas in it i mean they invented astar search and symbolic planning and learning macro operators they had low level kind of configuration space planning for their robot they had vision thats the basic ideas of a ton of things can you take a step back shaky have arms what was the job shaky was a mobile robot but it could push objects and so it would move things around with which actuator with itself with its base okay great and they had painted the baseboards black so it used vision to localize itself in a map it detected objects it could detect objects that were surprising to it it would plan and replan based on what it saw it reasoned about whether to look and take pictures i mean it really had the basics of so many of the things that we think about now how did it represent the space around it so it had representations at a bunch of different levels of abstraction so it had i think a kind of an occupancy grid of some sort at the lowest level at the high level it was abstract symbolic kind of rooms and connectivity so where does flaky come in yeah okay so i showed up at sri and we were building a brand new robot as i said none of the people from the previous project were kind of there or involved anymore so we were kind of starting from scratch and my advisor was stan rosenstein he ended up being my thesis advisor and he was motivated by this idea of situated computation or situated automata and the idea was that the tools of logical reasoning were important but possibly only for the engineers or designers to use in the analysis of a system but not necessarily to be manipulated in the head of the system itself so i might use logic to prove a theorem about the behavior of my robot even if the robots not using logic in its head to prove theorems so that was kind of the distinction and so the idea was to kind of use those principles to make a robot do stuff but a lot of the basic things we had to kind of learn for ourselves because i had zero background in robotics i didnt know anything about control i didnt know anything about sensors so we reinvented a lot of wheels on the way to getting that robot to do stuff do you think that was an advantage or a hindrance oh no i mean im big in favor of wheel reinvention actually i mean i think you learn a lot by doing it its important though to eventually have the pointers to so that you can see whats really going on but i think you can appreciate much better the good solutions once youve messed around a little bit on your own and found a bad one yeah i think you mentioned reinventing reinforcement learning and referring to rewards as pleasures pleasure yeah or i think which i think is a nice name for it yeah its more fun almost do you think you could tell the history of ai machine learning reinforcement learning and how you think about it from the fifties to now one thing is that its oscillates right so things become fashionable and then they go out and then something else becomes cool and that goes out and so on and i think theres so theres some interesting sociological process that actually drives a lot of whats going on early days was kind of cybernetics and control right and the idea that of homeostasis right people have made these robots that could i dont know try to plug into the wall when they needed power and then come loose and roll around and do stuff and then i think over time the thought well that was inspiring but people said no no no we want to get maybe closer to what feels like real intelligence or human intelligence and then maybe the expert systems people tried to do that but maybe a little too superficially right so oh we get the surface understanding of what intelligence is like because i understand how a steel mill works and i can try to explain it to you and you can write it down in logic and then we can make a computer and for that and then that didnt work out but whats interesting i think is when a thing starts to not be working very well its not only do we change methods we change problems right so its not like we have better ways of doing the problem of the expert systems people were trying to do we have no ways of trying to do that problem oh yeah no i think maybe a few but we kind of give up on that problem and we switched to a different problem and we worked that for a while and we make progress as a broad community as a community yeah and theres a lot of people who would argue you dont give up on the problem its just you decrease the number of people working on it you almost kind of like put it on the shelf say well come back to this 20 years later yeah i think thats right or you might decide that its malformed like you might say its wrong to just try to make something that does superficial symbolic reasoning behave like a doctor you cant do that until youve had the sensory motor experience of being a doctor or something so theres arguments that say that that problem was not well formed or it could be that it is well formed but we just werent approaching it well so you mentioned that your favorite part of logic and symbolic systems is that they give short names for large sets so there is some use to this they use symbolic reasoning so looking at expert systems and symbolic computing what do you think are the roadblocks that were hit in the 80s and 90s ah okay so right so the fact that im not a fan of expert systems doesnt mean that im not a fan of some kinds of symbolic reasoning right so lets see roadblocks well the main road block i think was that the idea that humans could articulate their knowledge effectively into some kind of logical statements so its not just the cost the effort but really just the capability of doing it right because were all experts in vision right but totally dont have introspective access into how we do that right and its true that i mean i think the idea was well of course even people then would know of course i wouldnt ask you to please write down the rules that you use for recognizing a water bottle thats crazy and everyone understood that but we might ask you to please write down the rules you use for deciding i dont know what tie to put on or how to set up a microphone or something like that but even those things i think people maybe i think what they found im not sure about this but i think what they found was that the so called experts could give explanations that sort of post hoc explanations for how and why they did things but they werent necessarily very good and then they depended on maybe some kinds of perceptual things which again they couldnt really define very well so i think fundamentally i think the underlying problem with that was the assumption that people could articulate how and why they make their decisions right so its almost encoding the knowledge from converting from expert to something that a machine could understand and reason with no no no no not even just encoding but getting it out of you right not not not writing it i mean yes hard also to write it down for the computer but i dont think that people can produce it you can tell me a story about why you do stuff but im not so sure thats the why great so there are still on the hierarchical planning side places where symbolic reasoning is very useful so as youve talked about so wheres the gap yeah okay good so saying that humans cant provide a description of their reasoning processes thats okay fine but that doesnt mean that its not good to do reasoning of various styles inside a computer those are just two orthogonal points so then the question is what kind of reasoning should you do inside a computer right and the answer is i think you need to do all different kinds of reasoning inside a computer depending on what kinds of problems you face i guess the question is what kind of things can you encode symbolically so you can reason about i think the idea about and even symbolic i dont even like that terminology because i dont know what it means technically and formally i do believe in abstractions so abstractions are critical right you cannot reason at completely fine grain about everything in your life right you cant make a plan at the level of images and torques for getting a phd so you have to reduce the size of the state space and you have to reduce the horizon if youre going to reason about getting a phd or even buying the ingredients to make dinner and so how can you reduce the spaces and the horizon of the reasoning you have to do and the answer is abstraction spatial abstraction temporal abstraction i think abstraction along the lines of goals is also interesting like you might well abstraction and decomposition goals is maybe more of a decomposition thing so i think thats where these kinds of if you want to call it symbolic or discrete models come in you talk about a room of your house instead of your pose you talk about doing something during the afternoon instead of at 254 and you do that because it and you do that because it makes your reasoning problem easier and also because you have you dont have enough information to reason in high fidelity about your pose of your elbow at 235 this afternoon anyway right when youre trying to get a phd or when youre doing anything really yeah okay except for at that moment at that moment you do have to reason about the pose of your elbow maybe but then you maybe you do that in some continuous joint space kind of model and so again i my biggest point about all of this is that there should be the dogma is not the thing right we shouldnt it shouldnt be that im in favor against symbolic reasoning and youre in favor against neural networks it should be that just just computer science tells us what the right answer to all these questions is if we were smart enough to figure it out well yeah when you try to actually solve the problem with computers the right answer comes out but you mentioned abstractions i mean neural networks form abstractions or rather theres theres automated ways to form abstractions and theres expert driven ways to form abstractions and expert human driven ways and humans just seem to be way better at forming abstractions currently and certain problems so when youre referring to 245 pm versus afternoon how do we construct that taxonomy is there any room for automated construction of such abstractions oh i think eventually yeah i mean i think when we get to be better and machine learning engineers well build algorithms that build awesome abstractions that are useful in this kind of way that youre describing yeah so lets then step from the the abstraction discussion and lets talk about pomm mdps partially observable markov decision processes so uncertainty so first what are markov decision processes what are markov decision processes and maybe how much of our world can be models and mdps how much when you wake up in the morning and youre making breakfast how do you do you think of yourself as an mdp so how do you think about mdps and how they relate to our world well so theres a stance question right so a stance is a position that i take with respect to a problem so i as a researcher or a person who designs systems can decide to make a model of the world around me in some terms so i take this messy world and i say im going to treat it as if it were a problem of this formal kind and then i can apply solution concepts or algorithms or whatever to solve that formal thing right so of course the world is not anything its not an mdp or a pomm dp i dont know what it is but i can model aspects of it in some way or some other way and when i model some aspect of it in a certain way that gives me some set of algorithms i can use you can model the world in all kinds of ways some have some are some are some are more accepting of uncertainty more easily modeling uncertainty of the world some really force the world to be deterministic and so certainly mdps model the uncertainty of the world yes model some uncertainty they model not present state uncertainty but they model uncertainty in the way the future will unfold right so what are markov decision processes so markov decision process is a model its a kind of a model that you could make that says i know completely the current state of my system and what it means to be a state is that i that all the i have all its a combination of learning and not learning and what should that combination be and whats the stuff we build in so to me thats the most compelling question and when you say engineer robots you mean engineering systems that work in the real world is that thats the emphasis okay last question which robots or robot is your favorite from science fiction so you can go with star wars or rtd2 or you can go with more modern maybe hal from i dont think i have a favorite robot from science fiction this is this is back to you like to make robots work in the real world here not not in i mean i love the process and i care more about the process the engineering process yeah i mean i do research because its fun not because i care about what we produce well thats a thats a beautiful note actually and leslie thank you so much for talking today sure its been fun the information right now that will let me make predictions about the future as well as i can so that remembering anything about my history wouldnt make my predictions any better and but then it also says that then i can take some actions that might change the state of the world and that i dont have a deterministic model of those changes i have a probabilistic model of how the world might change its a its a useful model for some kinds of systems i think its a i mean its certainly not a good model for most problems i think because for most problems you dont actually know the state for most problems you its partially observed so thats now a different problem class so okay thats where the pomdps the part that we observe with the markov decision processes step in so how do they address the fact that you cant observe most incomplete information about most of the world around you right so now the idea is we still kind of postulate that there exists a state we think that there is some information about the world out there such that if we knew that we could make good predictions but we dont know the state and so then we have to think about how but we do get observations maybe i get images or i hear things or i feel things and those might be local or noisy and so therefore they dont tell me everything about whats going on and then i have to reason about given the history of actions ive taken and observations ive gotten what do i think is going on in the world and then given my own kind of uncertainty about whats going on in the world i can decide what actions to take and so how difficult is this problem of planning under uncertainty in your view and your long experience of modeling the world trying to deal with this uncertainty in especially in real world systems optimal planning for even discrete pomdps can be undecidable depending on how you set it up and so lots of people say i dont use pomdps because they are intractable and i think that thats kind of a very funny thing to say because the problem you have to solve is the problem you have to solve so if the problem you have to solve is intractable thats what makes us ai people right so we solve we understand that the problem were solving is wildly intractable that we cant we will never be able to solve it optimally at least i dont yeah right so later we can come back to an idea about bounded optimality and something but anyway we cant come up with optimal solutions to these problems so we have to make approximations approximations in modeling approximations in the solution algorithms and so on and so i dont have a problem with saying yeah my problem actually it is pomdp in continuous space with continuous observations and its so computationally complex i cant even think about its you know big o whatever but that doesnt prevent me from it helps me gives me some clarity to think about it that way and to then take steps to make approximation after approximation to get down to something thats like computable in some reasonable time when you think about optimality the community broadly has shifted on that i think a little bit in how much they value the idea of optimality of chasing an optimal solution how has your views of chasing an optimal solution changed over the years when you work with robots thats interesting i think we have a little bit of a methodological crisis actually from the theoretical side i mean i do think that theory is important and that right now were not doing much of it so theres lots of empirical hacking around and training this and doing that and reporting numbers but is it good is it bad we dont know its very hard to say things and if you look at like computer science theory so people talked for a while everyone was about solving problems optimally or completely and then there were interesting relaxations so people look at oh are there regret bounds or can i do some kind of approximation can i prove something that i can approximately solve this problem or that i get closer to the solution as i spend more time and so on whats interesting i think is that we dont have good approximate solution concepts for very difficult problems i like to say that im interested in doing a very bad job of very big problems right so very bad job very big problems i like to do that but i wish i could say something i wish i had a i dont know some kind of a formal solution concept that i could use to say oh this algorithm actually it gives me something like i know what im going to get i can do something other than just run it and get out so that that notion is still somewhere deeply compelling to you the notion that you can say you can drop thing on the table says this you can expect this this algorithm will give me some good results i hope theres i hope science will i mean theres engineering and theres science i think that theyre not exactly the same and i think right now were making huge engineering like leaps and bounds so the engineering is running away ahead of the science which is cool and often how it goes right so were making things and nobody knows how and why they work roughly but we need to turn that into science theres some form its a yeah theres some room for formalizing we need to know what the principles are why does this work why does that not work i mean for a while people built bridges by trying but now we can often predict whether its going to work or not without building it can we do that for learning systems or for robots so your hope is from a materialistic perspective that intelligence artificial intelligence systems robots are just fancier bridges belief space whats the difference between belief space and state space so you mentioned mdps fomdps reasoning about you sense the world theres a state uh what whats this belief space idea that sounds so good it sounds good so belief space that is instead of thinking about whats the state of the world and trying to control that as a robot i think about what is the space of beliefs that i could have about the world whats if i think of a belief as a probability distribution of our ways the world could be a belief state is a distribution and then my control problem if im reasoning about how to move through a world im uncertain about my control problem is actually the problem of controlling my beliefs so i think about taking actions not just what effect theyll have on the world outside but what effect theyll have on my own understanding of the world outside and so that might compel me to ask a question or look somewhere to gather information which may not really change the world state but it changes my own belief about the world thats a powerful way to to empower the agent to reason about the world to explore the world so what kind of problems does it allow you to solve to to consider belief space versus just state space well any problem that requires deliberate information gathering right so if in some problems like chess theres no uncertainty or maybe theres uncertainty about the opponent theres no uncertainty about the state and some problems theres uncertainty but you gather information as you go right you might say oh im driving my autonomous car down the road and it doesnt know perfectly where it is but the light hours are all going all the time so i dont have to think about whether to gather information but if youre a human driving down the road you sometimes look over your shoulder to see whats going on behind you in the lane and you have to decide whether you should do that now and you have to trade off the fact that youre not seeing in front of you and youre looking behind you and how valuable is that information and so on and so to make choices about information gathering you have to reasonably space also i mean also to just take into account your own uncertainty before trying to do things so you might say if i understand where im standing relative to the door jam pretty accurately then its okay for me to go through the door but if im really not sure where the door is then it might be better to not do that right now the degree of your uncertainty about the world is actually part of the thing youre trying to optimize in forming the plan right so this idea of a long horizon of planning for a phd or just even how to get out of the house or how to make breakfast you show this presentation of the wtf wheres the fork of robot looking at a sink and can you describe how we plan in this world of this idea of hierarchical planning weve mentioned so yeah how can a robot hope to plan about something with such a long horizon where the goal is quite far away people since probably reasoning began have thought about hierarchical reasoning the temporal hierarchy in particular well theres spatial hierarchy but lets talk about temporal hierarchy so you might say oh i have this long execution i have to do but i can divide it into some segments abstractly right so maybe you have to get out of the house i have to get in the car i have to drive and so on and so you can plan if you can build abstractions so this we started out by talking about abstractions and were back to that now if you can build abstractions in your state space and abstractions sort of temporal abstractions then you can make plans at a high level and you can say im going to go to town and then ill have to get gas and then i can go here and i can do this other thing and you can reason about the dependencies and constraints among these actions again without thinking about the complete details what we do in our hierarchical planning work is then say all right i make a plan at a high level of abstraction i have to have some reason to think that its feasible without working it out in complete detail and thats actually the interesting step i always like to talk about walking through an airport like you can plan to go to new york and arrive at the airport and then find yourself an office building later you cant even tell me in advance what your plan is for walking through the airport partly because youre too lazy to think about it maybe but partly also because you just dont have the information you dont know what gate youre landing in or what people are going to be in front of you or anything so theres no point in planning in detail but you have to have you have to make a leap of faith that you can figure it out once you get there and its really interesting to me how you arrive at that how do you so you have learned over your lifetime to be able to make some kinds of predictions about how hard it is to achieve some kinds of sub goals and thats critical like you would never plan to fly somewhere if you couldnt didnt have a model of how hard it was to do some of the intermediate steps so one of the things were thinking about now is how do you do this kind of very aggressive generalization to situations that you havent been in and so on to predict how long will it take to walk through the kuala lumpur airport like you could give me an estimate and it wouldnt be crazy and you have to have an estimate of that in order to make plans that involve walking through the kuala lumpur airport even if you dont need to know it in detail so im really interested in these kinds of abstract models and how do we acquire them but once we have them we can use them to do hierarchical reasoning which is i think is very important yeah theres this notion of goal regression and preimage backchaining this idea of starting at the goal and just forming these big clouds of states i mean its almost like saying to the airport you know once you show up to the airport that youre like a few steps away from the goal so like thinking of it this way its kind of interesting i dont know if you have sort of further comments on that of starting at the goal yeah i mean its interesting that simon herb simon back in the early days of ai talked a lot about means ends reasoning and reasoning back from the goal theres a kind of an intuition that people have that the number of that state space is big the number of actions you could take is really big so if you say here i sit and i want to search forward from where i am what are all the things i could do thats just overwhelming if you say if you can reason at this other level and say heres what im hoping to achieve what could i do to make that true that somehow the branching is smaller now whats interesting is that like in the ai planning community that hasnt worked out in the class of problems that they look at and the methods that they tend to use it hasnt turned out that its better to go backward its still kind of my intuition that it is but i cant prove that to you right now right i share your intuition at least for us mere humans speaking of which when you maybe now we take a little step into that philosophy circle how hard would it when you think about human life you give those examples often how hard do you think it is to formulate human life as a planning problem or aspects of human life so when you look at robots youre often trying to think about object manipulation tasks about moving a thing when you take a slight step outside the room let the robot leave and go get lunch or maybe try to pursue more fuzzy goals how hard do you think is that problem if you were to try to maybe put another way try to formulate human life as a planning problem well that would be a mistake i mean its not all a planning problem right i think its really really important that we understand that you have to put together pieces and parts that have different styles of reasoning and representation and learning i think it seems probably clear to anybody that it cant all be this or all be that brains arent all like this or all like that right they have different pieces and parts and substructure and so on so i dont think that theres any good reason to think that theres going to be like one true algorithmic thing thats going to do the whole job so its a bunch of pieces together designed to solve a bunch of specific problems or maybe styles of problems i mean theres probably some reasoning that needs to go on in image space i think again theres this model based versus model free idea right so in reinforcement learning people talk about oh should i learn i could learn a policy just straight up a way of behaving i could learn its popular on a value function thats some kind of weird intermediate ground or i could learn a transition model which tells me something about the dynamics of the world if i take it imagine that i learned a transition model and i couple it with a planner and i draw a box around that i have a policy again its just stored a different way right but its just as much of a policy as the other policy its just ive made i think the way i see it is its a time space trade off in computation right a more overt policy representation maybe it takes more space but maybe i can compute quickly what action i should take on the other hand maybe a very compact model of the world dynamics plus a planner lets me compute what action to take to just more slowly theres no i dont i mean i dont think theres no argument to be had its just like a question of what form of computation is best for us for the various sub problems right so and and so like learning to do algebra manipulations for some reason is i mean thats probably gonna want naturally a sort of a different representation than writing a unicycle at the time constraints on the unicycle are serious the space is maybe smaller i dont know but so i could be the more human size of falling in love having a relationship that might be another another style of how to model that yeah lets first solve the algebra and the object manipulation what do you think is harder perception or planning perception thats why understanding thats why so what do you think is so hard about perception by understanding the world around you well i mean i think the big question is representational hugely the question is representation so perception has made great strides lately right and we can classify images and we can play certain kinds of games and predict how to steer the car and all this sort of stuff um i dont think we have a very good idea of what perception should deliver right so if you if you believe in modularity okay theres theres a very strong view which says we shouldnt build in any modularity we should make a giant gigantic neural network train it end to end to do the thing and thats the best way forward and its hard to argue with that except on a sample complexity basis right so you might say oh well if i want to do end to end reinforcement learning on this giant giant neural network its going to take a lot of data and a lot of like broken robots and stuff so then the only answer is to say okay we have to build something in build in some structure or some bias we know from theory of machine learning the only way to cut down the sample complexity is to kind of cut down somehow cut down the hypothesis space you can do that by building in bias theres all kinds of reasons to think that nature built bias into humans um convolution is a bias right its a very strong bias and its a very critical bias so my own view is that we should look for more things that are like convolution but the address other aspects of reasoning right so convolution helps us a lot with a certain kind of spatial reasoning thats quite close to the imaging i think theres other ideas like that maybe some amount of forward search maybe some notions of abstraction maybe the notion that objects exist actually i think thats pretty important and a lot of people wont give you that to start with right so almost like a convolution in the uh uh in the object semantic object space or some kind of some kind of ideas in there thats right and people are starting like the graph graph convolutions are an idea that are related to relation relational representations and so so i think there are so you ive come ive come far field from perception but i think um i think the thing thats going to make perception that kind of the next step is actually understanding better what it should produce right so what are we going to do with the output of it right its fine when what were going to do with the output is steer its less clear when were just trying to make a one integrated intelligent agent what should the output of perception be we have no idea and how should that hook up to the other stuff we dont know so i think the pressing question is what kinds of structure can we build in that are like the moral equivalent of convolution that will make a really awesome superstructure that then learning can kind of progress on efficiently i agree very compelling description of actually where we stand with the perception problem youre teaching a course on embodied intelligence what do you think it takes to build a robot with human level intelligence i dont know if we knew we would do it if you were to i mean okay so do you think a robot needs to have a self awareness consciousness fear of mortality or is it is it simpler than that or is consciousness a simple thing like do you think about these notions i dont think much about consciousness even most philosophers who care about it will give you that you could have robots that are zombies right that behave like humans but are not conscious and i at this moment would be happy enough with that so im not really worried one way or the other so the technical side youre not thinking of the use of self awareness well but i okay but then what does self awareness mean i mean that you need to have some part of the system that can observe other parts of the system and tell whether theyre working well or not that seems critical so does that count as i mean does that count as self awareness or not well it depends on whether you think that theres somebody at home who can articulate whether theyre self aware but clearly if i have like you know some piece of code thats counting how many times this procedure gets executed thats a kind of self awareness right so theres a big spectrum its clear you have to have some of it right you know were quite far away in many dimensions but is there a direction of research thats most compelling to you for you know trying to achieve human level intelligence in our robots well to me i guess the thing that seems most compelling to me at the moment is this question of what to build in and what to learn um i think were we dont were missing a bunch of ideas and and we you know people you know dont you dare ask me how many years its going to be until that happens because i wont even participate in the conversation because i think were missing ideas and i dont know how long its going to take to find them so i wont ask you how many years but uh maybe ill ask you what it when youll be sufficiently impressed that weve achieved it so whats whats a good test of intelligence do you like the turing test the natural language in the robotic space is there something where you would sit back and think oh thats thats pretty impressive uh as a test as a benchmark do you think about these kinds of problems no i resist i mean i think all the time that we spend arguing about those kinds of things could be better spent just making the robots work better uh so you dont value competition so i mean theres a nature of benchmark benchmarks and datasets or turing test challenges where everybody kind of gets together and tries to build a better robot cause they want to out compete each other like the darpa challenge with the autonomous vehicles do you see the value of that or it can get in the way i think it can get in the way i mean some people many people find it motivating and so thats good i find it anti motivating personally uh but i think what i mean i think you get an interesting cycle where for a contest a bunch of smart people get super motivated and they hack their brains out and much of what gets done is just hacks but sometimes really cool ideas emerge and then that gives us something to chew on after that so im its not a thing for me but i dont i dont regret that other people do it yeah its like you said with everything else that it makes us good so jumping topics a little bit you started the journal of machine learning research and served as its editor in chief uh how did the publication come about and what do you think about the current publishing model space in machine learning artificial intelligence okay good so it came about because there was a journal called machine learning which still exists which was owned by cluer and there was i was on the editorial board and we used to have these meetings annually where we would complain to cluer that it was too expensive for the libraries and that people couldnt publish and we would really like to have some kind of relief on those fronts and they would always sympathize but not do anything so uh we just decided to make a new journal and uh there was the journal of ai research which has was on the same model which had been in existence for maybe five years or so and it was going on pretty well so uh we just made a new journal it wasnt i mean um i dont know i guess it was work but it wasnt that hard so basically the editorial board probably 75 of the editorial board of uh machine learning resigned and we founded the new journal but it was sort of it was more open yeah right so its completely open its open access actually uh uh i had a postdoc george conidaris who wanted to call these journals free for all uh because there were i mean it both has no page charges and has no uh uh access restrictions and the reason and so lots of people i mean there were there were people who were mad about the existence of this journal who thought it was a fraud or something it would be impossible they said to run a journal like this with basically i mean for a long time i didnt even have a bank account uh i paid for the lawyer to incorporate and the ip address and it just did cost a couple of hundred dollars a year to run its a little bit more now but not that much more but thats because i think computer scientists are competent and autonomous in a way that many scientists and other fields arent i mean at doing these kinds of things we already types out our own papers we all have students and people who can hack a website together in an afternoon so the infrastructure for us was like not a problem but for other people in other fields its a harder thing to do yeah and this kind of open access journal is nevertheless one of the most prestigious journals so its not like uh prestige and it can be achieved without any of the paper is not required for prestige yeah it turns out yeah so on the review process side of actually a long time ago i dont remember when i reviewed a paper where you were also a reviewer and i remember reading your review being influenced by it and it was really well written it influenced how i write feature reviews uh you disagreed with me actually uh and you made it uh my review but much better so but nevertheless the review process you know has its uh flaws and how do you think what do you think works well how can it be improved so actually when i started jmlr i wanted to do something completely different and i didnt because it felt like we needed a traditional journal of record and so we just made jmlr be almost like a normal journal except for the open access parts of it basically um increasingly of course publication is not even a sensible word you can publish something by putting it in an archive so i can publish everything tomorrow so making stuff public is theres no barrier we still need curation and evaluation i dont have time to read all of archive and you could argue that kind of social thumbs upping of articles suffices right you might say oh heck with this we dont need journals at all well put everything on archive and people will upvote and downvote the articles and then your cv will say oh man he got a lot upvotes so uh thats good um but i think theres still value in careful reading and commentary of things and its hard to tell when people are upvoting and downvoting or arguing about your paper on twitter and reddit whether they know what theyre talking about right so then i have the second order problem of trying to decide whose opinions i should value and such so i dont know what i w if i had infinite time which i dont and im not going to do this because i really want to make robots work but if i felt inclined to do something more in the publication direction i would do this other thing which i thought about doing the first time which is to get together some set of people whose opinions i value and who are pretty articulate and i guess we would be public although we could be private im not sure and we would review papers we wouldnt publish them and you wouldnt submit them we would just find papers and we would write reviews and we would make those reviews public and maybe if you you know so were leslies friends who review papers and maybe eventually if if we our opinion was sufficiently valued like the opinion of jmlr is valued then youd say on your cv that leslies friends gave my paper a five star rating and that would be just as good as saying i got it so you know accepted into this journal so i think i think we should have good public commentary and organize it in some way but i dont really know how to do it its interesting times the way you describe it actually is really interesting i mean we do it for movies imdbcom theres experts critics come in they write reviews but theres also regular non critics humans write reviews and theyre separated i like open review the iclear process i think is interesting its a step in the right direction but its still not as compelling as reviewing movies or video games i mean it sometimes almost it might be silly at least from my perspective to say but it boils down to the user interface how fun and easy it is to actually perform the reviews how efficient how much you as a reviewer get street cred for being a good reviewer those elements those human elements come into play no its a big investment to do a good review of a paper and the flood of papers is out of control right so you know there arent 3000 new i dont know how many new movies are there in a year i dont know but thats probably going to be less than how many machine learning papers are in a year now and im worried you know i right so im like an old person so of course im going to say things are moving too fast im a stick in the mud so i can say that but my particular flavor of that is i think the horizon for researchers has gotten very short that students want to publish a lot of papers and theres a huge theres value its exciting and theres value in that and you get patted on the head for it and so on but and some of that is fine but im worried that were driving out people who would spend two years thinking about something back in my day when we worked on our thesis we did not publish papers you did your thesis for years you picked a hard problem and then you worked and chewed on it and did stuff and wasted time and for a long time and when it was roughly when it was done you would write papers and so i dont know how to and i dont think that everybody has to work in that mode but i think theres some problems that are hard enough that its important to have a long research horizon and im worried that we dont incentivize that at all at this point in this current structure yeah so what do you see as what are your hopes and fears about the future of ai and continuing on this theme so ai has gone through a few winters ups and downs do you see another winter of ai coming are you more hopeful about making robots work as you said i think the cycles are inevitable but i think each time we get higher right i mean so you know its like climbing some kind of landscape with a noisy optimizer so its clear that the you know the deep learning stuff has made deep and important improvements and so the high water mark is now higher theres no question but of course i think people are overselling and eventually investors i guess and other people will look around and say well youre not quite delivering on this grand claim and that wild hypothesis its probably its going to crash some amount and then its okay i mean but i dont i cant imagine that theres like some awesome monotonic improvement from here to human level ai so in you know i have to ask this question i probably anticipate answers the answers but do you have a worry short term or long term about the existential threats of ai and maybe short term less existential but more robots taking away jobs well actually let me talk a little bit about utility actually i had an interesting conversation with some military ethicists who wanted to talk to me about autonomous weapons and theyre they were interesting smart well educated guys who didnt know too much about ai or machine learning and the first question they asked me was has your robot ever done something you didnt expect and i like burst out laughing because anybody whos ever done something on the robot right knows that they dont do it and what i realized was that their model of how we program a robot was completely wrong their model of how we can program a robot was like lego mind storms like oh go forward a meter turn left take a picture do this do that and so if you have that model of programming then its true its kind of weird that your robot would do something that you didnt anticipate but the fact is and actually so now this is my new educational mission if i have to talk to non experts i try to teach them the idea that we dont operate we operate at least one or maybe many levels of abstraction about that and we say oh heres a hypothesis class maybe its a space of plans or maybe its a space of classifiers or whatever but theres some set of answers and an objective function and then we work on some optimization method that tries to optimize a solution solution in that class and we dont know what solution is going to come out right so i think its important to communicate that so i mean of course probably people who listen to this they they know that lesson but i think its really critical to communicate that lesson and then lots of people are now talking about you know the value alignment problem so you want to be sure as robots or software systems get more competent that their objectives are aligned with your objectives or that our objectives are compatible in some way or we have a good way of mediating when they have different objectives and so i think it is important to start thinking in terms like you dont have to be freaked out by the robot apocalypse to accept that its important to think about objective functions of value alignment yes and that you have to really everyone whos done optimization knows that you have to be careful what you wish for that you know sometimes you get the optimal solution and you realize man that was that objective was wrong so pragmatically in the shortest term it seems to me that that that those are really interesting and critical questions and the idea that were going to go from being people who engineer algorithms to being people who engineer objective functions i think thats thats definitely going to happen and thats going to change our thinking and methodology and so were gonna you started at stanford philosophy thats where she could be and i will go back to philosophy maybe well i mean theyre mixed together because because as we also know as machine learning people right when you design in fact this is the lecture i gave in class today when you design an objective function you have to wear both hats theres the hat that says what do i want and theres the hat that says but i know what my optimizer can do to some degree and i have to take that into account so its its always a trade off and we have to kind of be mindful of that the part about taking peoples jobs i understand that thats important i dont understand sociology or economics or people very well so i dont know how to think about that so thats yeah so there might be a sociological aspect there the economic aspect thats very difficult to think about okay i mean i think other people should be thinking about it but im just thats not my strength so what do you think is the most exciting area of research in the short term for the community and for your for yourself well so i mean theres the story ive been telling about how to engineer intelligent robots so thats what we want to do we all kind of want to do well i mean some set of us want to do this and the question is whats the most effective strategy and weve tried it and theres a bunch of different things you could do at the extremes right one super extreme is whats the most effective strategy and theres a bunch of different things you could do at the extremes right one super extreme is we do introspection and we write a program okay that has not worked out very well another extreme is we take a giant bunch of neural goo and we try and train it up to do something i dont think thats going to work either so the question is whats the middle ground and and again this isnt a theological question or anything like that its just like whats the middle ground and i think its clear its a combination of learning to me its clear', 'the following is a conversation with eric weinstein hes a mathematician economist physicist and the managing director of teal capital he coined the term and you can say is the founder of the intellectual dark web which is a loosely assembled group of public intellectuals that includes sam harris jordan peterson steven pinker joe rogan michael shermer and a few others this conversation is part of the artificial intelligence podcast at mit and beyond if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with eric weinstein are you nervous about this scared shitless okay you mentioned kung fu panda as one of your favorite movies it has the usual profound master student dynamic going on so who was who has been a teacher that significantly influenced the direction of your thinking and lifes work so if youre the kung fu panda who was your shifu oh well its interesting because i didnt see shifu as being the teacher who was the teacher oogway master oogway the turtle oh the turtle right they only meet twice in the entire film and the first conversation sort of doesnt count so the magic of the film in fact its point is that the teaching that really matters is transferred during a single conversation and its very brief and so who played that role in my life i would say uh either uh my grandfather uh harry rubin and his wife sophie rubin my grandmother or tom lehrer tom lehrer yeah in which way if you give a child tom lehrer records what you do is you destroy their ability to be taken over by later malware and its so irreverent so witty so clever so obscene that it destroys the ability to lead a normal life for many people so if i meet somebody whos usually really shifted from any kind of neurotypical presentation ill often ask them uh are you a tom lehrer fan and the odds that they will respond are quite high tom lehrer is uh poisoning pigeons in the park tom lehrer thats very interesting there are a small number of tom lehrer songs that broke into the general population poisoning pigeons in the park the element song and perhaps the vatican rag uh so when you meet somebody who knows those songs but doesnt know oh youre judging me right now arent you harshly uh no but youre a russian so i doubt as the you know nikolai ivanovich lubachevsky that song yeah um so that was a song about plagiarism that was in fact plagiarized which most people dont know from danny kay uh where danny kay did a song called stanislavsky of the muskie arts and so tom lehrer did this brilliant job of plagiarizing a song about and making it about plagiarism and then making it about this mathematician who worked in non euclidean geometry that was like uh giving heroin to a child it was extremely addictive and eventually led me to a lot of different places one of which may have been a phd in mathematics and he was also at least a lecturer in mathematics i believe at harvard something like that yeah i just had dinner with him in fact uh when my son turned 13 we didnt tell him but um his bar mitzvah present was dinner with his hero tom lehrer and tom lehrer was 88 years old sharp as a tack irreverent and funny as hell and just you know there are very few people in this world that you have to meet while theyre still here and that was definitely one for our family so that wit is a reflection of intelligence in some kind of deep way like where that would be a good test of intelligence whether youre a tom lehrer fan so what do you think that is about wit about that kind of humor ability to see the absurdity in existence well do you think thats connected to intelligence or are we just two jews on a mic that appreciate that kind of humor no i think that its absolutely connected to intelligence so you can you can see it theres a place where tom lehrer decides that hes going to lampoon gilbert of gilbert and sullivan and hes going to outdo gilbert with clever meaningless wordplay and he has forget the well lets see hes doing clementine as if gilbert and sullivan wrote it that i misunderstood depressed her young sister named mr this mr depester she tried pestering sisters of festering blister you best to resist or say i the sister persisted the mr resisted i kissed her all loyalty slip when he said when she said i could have her her sisters cadaver must surely have turned in its crypt thats so dense its so insane that thats clearly intelligence because its hard to construct something like that if i look at my favorite tom lehrer tom lehrer lyric you know theres a perfectly absurd one which is once all the germans were warlike and mean but that couldnt happen again we taught them a lesson in 1918 and theyve hardly bothered us since then right that is a different kind of intelligence you know youre taking something that is so horrific and youre youre sort of making it palatable and funny and demonstrating also um just your humanity i mean i think the thing that came through as as tom lehrer wrote all of these terrible horrible lines was just what a sensitive and beautiful soul he was who was channeling pain through humor and through grace ive seen throughout europe throughout russia that same kind of humor emerged from the generation of world war ii it seemed like that humor is required to somehow deal with the pain and the suffering of that that war created you do need the environment to create the broad slavic soul i dont think that many americans really appreciate um russian humor how you had to joke during the time of lets say article 58 under stalin you had to be very very careful you know the concept of a russian satirical magazine like crocodile uh doesnt make sense so you have this cross cultural problem that there are certain areas of human experience that it would be better to know nothing about and quite unfortunately eastern europe knows a great deal about them which makes the you know the songs of vladimir vysotsky so potent the uh you know the pros of pushkin whatever it is uh you have to appreciate the depth of the eastern european experience and i would think that perhaps americans knew something like this around the time of the civil war or merit maybe um you know under slavery and jim crow or even the uh harsh tyranny of uh the coal and steel employers during the labor wars um but in general i would say its hard for us to understand and imagine the collective culture unless we have the system of selective pressures that for example uh russians were subjected to yeah so if theres one good thing that comes out of war its literature art and humor and music oh i dont think so i think almost everything is good about war except for death and destruction right without the death it would bring uh the romance of it the whole thing is nice well this is why were always caught up in war and we have this very ambiguous relationship to it is that it makes life real and pressing and meaningful and at an unacceptable price and the price has never been higher so just jump in uh into ai a little bit you uh in one of the conversations you had or one of the videos you described that one of the things ai systems cant do and biological systems can is self replicate in the physical world oh no no in the physical world well yes the physical robots cant self replicate but the fit but you this is a very tricky point which is that the only thing that weve been able to create thats really complex that has an analog of our reproductive system is software but nevertheless software replicates itself uh if were speaking strictly for the replication in this kind of digital space so let me just to begin let me ask a question do you see a protective barrier or a gap between the physical world and the digital world lets not call it digital lets call it the logical world versus the physical world why logical well because even though we had lets say einsteins brain preserved uh it was meaningless to us as a physical object because we couldnt do anything with what was stored in it at a logical level and so the idea that something may be stored logically and that it may be stored physically uh are not necessarily uh we dont always benefit from synonymizing im not suggesting that there isnt a material basis to the logical world but that it does warrant identification with a separate layer that need not invoke logic gates and zeros and ones and uh so connecting those two worlds the logical world and the physical world or maybe just connecting to the logical world inside our brain einsteins brain you mentioned the idea of out outtelligence artificial outtelligence artificial outtelligence yes this is the only essay that john brockman ever invited me to write that he refused to publish in edge why well maybe it wasnt it wasnt well written um but i dont know the idea is quite compelling is quite unique and new and at least from my view of a stance point maybe you can explain it sure what i was thinking about is why it is that were waiting to be terrified by artificial general intelligence when in fact artificial life uh is terrifying in and of itself and its already here so in order to have a system of selective pressures you need three distinct elements you need variation within a population you need heritability and you need differential success so whats really unique and ive made this point i think elsewhere about software is that if you think about what humans know how to build thats impressive so i always take a car and i say does it have an analog of each of the physical physiological systems does it have a skeletal structure thats its frame does it have a neurological structure has an on board computer has a digestive system the one thing it doesnt have is a reproductive system but if you can call spawn on a process effectively you do have a reproductive system and that means that you can create something with variation heritability and differential success now the next step in the chain of thinking was where do we see inanimate non intelligent life outwitting intelligent life and um i have two favorite systems and i try to stay on them so that we dont get distracted one of which is the ofres orchid um subspecies or subclade i dont know what to call it theres a type of flower yeah its a type of flower that mimics the female of a pollinator species in order to dupe the males into uh engaging it was called pseudo copulation with the fake female which is usually represented by the lowest pedal and theres also a pheromone component to fool the males into thinking they have a mating opportunity but the flower doesnt have to give up energy energy in the form of nectar as a lure because its tricking the males the other system is a particular species uh of muscle lampicillus in the clear streams of missouri and it fools bass into biting a fleshy lip that contain its young and when the bass see this fleshy lip which looks exactly like a species of fish that the bass like to eat the uh the young explode and clamp onto the gills and parasitize the bass and also lose the best redistribute them as they eventually release both of these systems you have a highly intelligent dupe being fooled by a lower life form and what is sculpting these these convincing lures its the intelligence of previously duped targets for these strategies so when the target is smart enough to avoid the strategy uh those weaker mimics uh fall off they have terminal lines and only the better ones survive so its an arms race between the target species uh that is being parasitized getting smarter and this other less intelligent or non intelligent object getting as if smarter and so what you see is is that artificial intelligence artificial general intelligence is not needed to parasitize us its simply sufficient for us to outwit ourselves so you could have a program lets say you know one of these nigerian scams um that writes letters and uses whoever sends it bitcoin uh to figure out which aspects of the program should be kept which should be varied and thrown away and you dont need it to be in any way intelligent in order to have a really nightmarish scenario of being parasitized by something that has no idea what its doing so you you you phrased a few concepts really eloquently so let me try to uh as a few directions this goes so one first first of all in the way we write software today its not common that we allow it to self modify but we do have that ability now we have the ability its just not common its not just common so so your your thought is that that is a serious worry if there becomes uh self modifying code is is available now so theres theres different types of self modification right theres a personalization you know your email app your gmail is a self modifying to you after you log in or whatever you can think of it that way but ultimately its central all the information is centralized but youre thinking of ideas where youre completely so this is an unique entity uh operating under selective pressures and it changes well you just if you think about the fact that our immune systems uh dont know whats coming at them next but they have a small set of spanning components and if its if its a sufficiently expressive system in that any shape uh or binding region can be approximated uh with with the lego that is present um then you can have confidence that you dont need to know whats coming at you because the combinatorics um are sufficient to reach any configuration needed uh so thats a beautiful thing well terrifying thing to worry about because its so within our reach whatever i suggest these things i do always have a concern as to whether or not i will bring them into being by talking about them so uh theres this thing from open ai uh next next week to talk to the founder of open ai uh this idea that uh their text generation the new uh the new stuff they have for generating texts is they didnt want to bring it they didnt want to release it because theyre worried about the im delighted to hear that but theyre going to end up releasing yes so thats the thing is i think talking about it um well at least from my end im more a proponent of technology preventing tech uh so further innovation preventing the detrimental effects of innovation well were at a were sort of tumbling down a hill at accelerating speed so whether or not were proponents or it doesnt it doesnt really it may not matter but i well i do feel that there are people whove held things back and uh you know died poor than they mightve otherwise been we dont even know their names i dont think that we should discount the idea that having the smartest people showing off how smart they are by what theyve developed may be a terminal process im very mindful in particular of a beautiful letter that edward teller of all people wrote to leo zillard and where zillard was trying to figure out how to control the use of atomic weaponry at the end of world war ii and teller rather strangely because many of us view him as a monster um showed some a very advanced moral thinking talking about the slim chance we have for survival and that the only hope is to make warren thinkable i do think that not enough of us feel in our gut what it is we are playing with when we are working on technical problems and i would recommend to anyone who hasnt seen it a movie called the bridge over the bridge on the river kwai about i believe captured british pows who just in a desire to do a bridge well end up over collaborating with their japanese captors well now youre making me a question the unrestricted open discussion of ideas and ai im not saying i know the answer im just saying that i could make a decent case for either our need to talk about this and to become technologically focused on containing it or need to stop talking about this and try to hope that the relatively small number of highly adept individuals who are looking at these problems is small enough that we should in fact be talking about how to contain them well the way ideas the way innovation happens what new ideas develop newton with calculus whether if he was silent the idea would be would emerge elsewhere in the case of newton of course but in the case of ai how small is the set of individuals out of which such ideas would arise well the idea is that the researchers we know and those that we dont know who may live in countries that dont wish us to know what level theyre currently at are very disciplined in keeping these things to themselves of course i will point out that theres a religious school in kerala that developed something very close to the calculus certainly in terms of infinite series in i guess religious the opposite of that let me say what comforts me sort of biology or engineering uh at the end of the day does the thing work yeah you can test the crazies away and the crazy well see now youre saying but some ideas are truly crazy and some are are actually correct so well theres pre correct currently crazy yeah right and so you dont want to get rid of everybody whos pre correct and currently crazy um the problem is is that we dont have standards in general for trying to determine who has to be put to the sword in terms of their career and who has to be protected uh as some sort of giant time suck pain in the ass uh who may change everything do you think thats possible uh creating a mechanism of those select well youre not going to like the answer but here it comes oh boy it has to do with very human elements were trying to do this at the level of like rules and fairness thats not going to work cause the only thing that really understands this you read the double helix its a book oh you have to read this book not only did jim watson uh half discover this three dimensional structure of dna hes also one hell of a writer before he became an ass uh that no hes tried to destroy his own reputation i knew about the ass i didnt know about the good writer jim watson is one of the most important people now living and uh as ive said before jim watson is too important a legacy to be left to jim watson um yeah that book tells you more about what actually moves the dial right theres another story about him which i dont dont agree with which is that he stole everything from rosalind franklin i mean the the problems that he had with rosalind franklin are real but we should actually honor that tension in our history by delving into it rather than having a simple solution jim watson talks about francis crick being a pain in the ass that everybody secretly knew was super brilliant and theres an encounter between uh chargaff uh who came up with the equimolar relations between the nucleotides who should have gotten the structure of dna and watson and crick and you know he talks about missing a shiver in the heartbeat of biology and stuff is so gorgeous it just makes you tremble even thinking about it um look we know very often who is to be feared and we need to fund the people that we fear the people who are wasting our time need to be excluded from the conversation you see and you know maybe well make some errors in both directions but we have known our own people we know the pains in the asses that might work out and we know the people who are really just blowhards who really have very little to contribute most of the time its not a hundred percent but youre not going to get there with rules right its a using some kind of instinct i mean i to be honest im going to make you roll your eyes for a second but uh and the first time i heard that there is a large community of people who believe the earth is flat actually made me pause and ask myself the question why would there be such a community yeah is it possible the earth is flat so i had to like wait a minute i mean then you go through a thinking process that i think is really healthy it ultimately ends up being a geometry thing i think uh its an interesting its an interesting thought experiment at the very least well i dont i do a different version of it i say why is this community stable yeah thats a good uh way to analyze it well interesting that whatever weve done has not erased the community so you know theyre taking a long shot bet that wont pan out you know maybe we just havent thought enough about the rationality of the square root of two and somebody brilliant will figure it out maybe we will eventually land one day on the surface of jupiter and explore it right these are crazy things that will never happen so much of social media operates by ai algorithms you talked about this a little bit uh recommending the content you see so on this idea of radical thought how much should ai show you things you disagree with on twitter and so on in a twitter word verse in this question yeah yeah cause you dont know the answer no no no no look weve been theyve pushed out this cognitive lego to us that will just lead to madness its good to be challenged with things that you disagree with the answer is no its good to be challenged with interesting things with which you currently disagree but that might be true so i dont really care about whether or not i disagree with something or dont disagree i need to know why that particular disagreeable thing is being pushed out is it because its likely to be true is it because is there some reason because i can write i can write a computer generator uh to come up with an infinite number of disagreeable statements that nobody needs to look at so please before you push things at me that are disagreeable tell me why there is an aspect in which that question is quite dumb especially because its being used to uh almost um uh very generically by these different networks to say well were trying to work this out but you know basically uh how much do you see the value of seeing things uh you dont like not you disagree with because its very difficult to know exactly what you articulated which is uh the stuff thats important for you to consider that you disagree with thats really hard to figure out the bottom line is this stuff you dont like if youre a uh uh hillary clinton supporter you may not want to it might not make you feel good to see anything about donald trump thats the only thing algorithms can really optimize for currently they really cant now they can do better this is where were you think so no were engaged in some moronic back and forth where i have no idea why people who are capable of building google facebook twitter are having us in these incredibly low level discussions do they not know any smart people do they not have the phone numbers of people who can elevate these discussions they do but this theyre optimizing for a different thing and theyre pushing those people out of those rooms theyre theyre optimizing for things we cant see and yes profit is there nobody nobodys questioning that but theyre also optimizing for things like political control or the fact that theyre doing business in pakistan and so they dont want to talk about all the things that theyre going to be bending to in pakistan so were involved in a fake discussion you think so you think these conversations at that depth are happening inside google you dont think they have some basic metrics under user engagements youre having a fake conversation with us guys we know youre having a fake conversation i do not wish to be part of your fake conversation you know how to cool you know these units you know high availability like nobodys business my gmail never goes down almost so you think just because they can do incredible work on the software side with infrastructure they can also deal with some of these difficult questions about human behavior human understanding youre not i mean ive seen the ive seen the developers screens that people take shots of inside of google and ive heard stories inside of facebook and apple were not were engaged theyre engaging us in the wrong conversations we are not at this low level heres one of my favorite questions why is every piece of hardware that i purchase in tech space equipped as a listening device wheres my physical shutter to cover my lens we had this in the 1970s cameras that had lens caps you know how much would it cost to have a security model pay five extra bucks why is my indicator light software controlled why when my camera is on do i not see that the light is on by putting it as something that cannot be bypassed why have you set up my all of my devices at some difficulty to yourselves as listening devices and we dont even talk about this this is this thing is total fucking bullshit well i hope these discussions are happening about privacy is there a more difficult thing youre giving them credit for its not just privacy its about social control were talking about social control why do i not have controls over my own levers just have a really cute ui where i can switch i can dial things or i can at least see what the algorithms are you think that there is some deliberate choices being made here theres emergence and there is intention there are two dimensions the vector does not collapse onto either axis but the idea that anybody who suggests that intention is completely absent is a child thats really beautifully put and uh like many things youve said is going to make me can i turn this around slightly yeah i sit down with you and you say that youre obsessed with my feed i dont even know what my feed is what are you seeing that im not i was obsessively looking through your feed on twitter because it was really enjoyable because theres the tom layer element is the humor in it by the way that feed is eric r weinstein on twitter at eric r weinstein no but seriously why why did i find it enjoyable or what was i seeing what are you looking for why are we doing this what is this podcast about i know youve got all these interesting people im just some guy whos sort of a podcast guest sort of a podcast youre not even wearing a tie i mean its not even a serious interview im searching for meaning for happiness for a dopamine rush so short term long term and how are you finding your way to me i dont honestly know what im doing to reach you the representing ideas which feel common sense to me and not many people are speaking so its kind of like the intellectual dark web folks right these folks from sam harris to jordan peterson to yourself are saying things where youre like saying look theres an elephant and hes not wearing any clothes and i say yeah yeah lets have more of that conversation thats how im finding you im desperate to try to change the conversation were having im very worried weve got an election in 2020 i dont think we can afford four more years of a misinterpreted message which is what donald trump was and i dont want the destruction of our institutions they all seem hell bent on destroying themselves so im trying to save theoretical physics trying to save the new york times trying to save our various processes and i think it feels delusional to me that this is falling to a tiny group of people who are willing to speak out without getting so freaked out that everything they say will be misinterpreted and that their lives will be ruined through the process i mean i think were in an absolutely bananas period of time and i dont believe it should fall to such a tiny number of shoulders to shoulder this way so i have to ask you on the capitalism side you mentioned that technology is killing capitalism or it has effects that are unintended well not unintended but not what economists would predict or speak of capitalism creating i just want to talk to you about in general the effect of even then artificial intelligence or technology automation taking away jobs and these kinds of things and what you think is the way to alleviate that whether the andrew ng presidential candidate with universal basic income ubi what are your thoughts there how do we fight off the negative effects of technology that all right youre a software guy right yep a human being is a worker is an old idea a human being has a worker is a different object right yeah so if you think about object oriented programming as a paradigm a human being has a worker and a human being has a soul were talking about the fact that for a period of time the worker that a human being has was in a position to feed the soul that a human being has however we have two separate claims on the value in society one is as a worker and the other is as a soul and the soul needs sustenance it needs dignity it needs meaning it needs purpose as long as your means of support is not highly repetitive i think you have a while to go before you need to start worrying and if what you do is highly repetitive and its not terribly generative you are in the cross hairs of for loops and while loops and thats what computers excel at repetitive behavior and when i say repetitive i may mean things that have never happened through combinatorial possibilities but as long as it has a looped characteristic to it youre in trouble we are seeing a massive push towards socialism because capitalists are slow to address the fact that a worker may not be able to make claims a relatively undistinguished median member of our society is still has needs to reproduce needs to have to dignity and when capitalism abandons the median individual or the bottom 10th or whatever its going to do its flirting with revolution and what concerns me is that the capitalists arent sufficiently capitalistic to understand this you really want to court authoritarian control in our society because you cant see that people may not be able to defend themselves in the marketplace because the marginal product of their labor was too low to feed their dignity as a soul so my great concern is that our free society has to do with the fact that we are self organized i remember looking down from my office in manhattan when lehman brothers collapsed and thinking whos going to tell all these people that they need to show up at work when they dont have a financial system to incentivize them to show up at work so my complaint is first of all not with the socialists but with the capitalists which is you guys are being idiots youre courting revolution by continuing to harp on the same old ideas that well you know try try harder bootstrap yourself yeah to an extent that works to an extent but we are clearly headed in a place that theres nothing that ties together our need to contribute and our need to consume and that may not be provided by capitalism because it may have been a temporary phenomena so check out my article on anthropic capitalism and the new gimmick economy i think people are late getting the wake up call and we would be doing a better job saving capitalism from itself because i dont want this done under authoritarian control and the more we insist that everybody whos not thriving in our society during their reproductive years in order to have a family is failing at a personal level i mean what a disgusting thing that were saying what horrible message who who the hell have we become that weve so bought into the chicago model that we cant see the humanity that were destroying in that process and its i hate i hate the thought of communism i really do my family has flirted with it decades past its a wrong bad idea but we are going to need to figure out how to make sure that those souls are nourished and respected and capitalism better have an answer and im betting on capitalism but ive got to tell you im pretty disappointed with my team so youre still on the capitalism team you just uh theres a theme here radical capitalism hyper capitalism yeah i want i think hyper capitalism is going to have to be coupled to hyper socialism you need to allow the most productive people to create wonders and youve got to stop bogging them down with all of these extra nice requirements you know nice is dead good has a future nice doesnt have a future because nice ends up with with gulags damn thats a good line okay last question you tweeted today a simple quite insightful equation saying uh imagine that every unit f of fame you picked up as stalkers and h haters so i imagine s and h are dependent on your path to fame perhaps a little bit well its not as simple i mean people always take these things literally when you have like 280 characters to explain yourself so you mean that thats not a mathematical uh no theres no law oh okay all right so i put the word imagine because i still have a mathematicians desire for precision imagine that this were true but it was a beautiful way to imagine that there is a law that has those variables in it and uh youve become quite famous these days so how do you yourself optimize that equation with the peculiar kind of fame that you have gathered along the way i want to be kinder i want to be kinder to myself i want to be kinder to others i want to be able to have heart compassion or these things are really important and uh i have a pretty spectrumy kind of approach to analysis im quite literal i can go full rain man on you at any given moment no i cant i cant uh its facultative autism if you like and people are gonna get angry because they want autism to be respected so when you see me coding or you see me doing mathematics im you know i speak with speech apnea uh be right down to dinner you know we have to try to integrate ourselves and those tensions between you know its sort of back to us as a worker and us as a soul many of us are optimizing one to the at the expense of the other and i struggle with social media and i struggle with people making threats against our families and i struggle with um just how much pain people are in and if theres one message i would like to push out there um youre responsible everybody all of us myself included with struggling struggle struggle mightily because you its nobody elses job to do your struggle for you now with that said if youre struggling and youre trying and youre trying to figure out how to better yourself and where you failed and where youve let down your family your friends your workers all this kind of stuff give yourself a break you know if if if its not working out i have a lifelong relationship with failure and success theres been no period of my life where both havent been present in one form or another and i do wish to say that a lot of times people think this is glamorous im about to go you know do a show with sam harris people are going to listen in on two guys having a conversation on stage its completely crazy when im always trying to figure out how to make sure that those people get maximum value and uh thats why im doing this podcast you know just give yourself a break you owe us you owe us your struggle you dont owe your family or your coworkers or your lovers or your family members success um as long as youre in there and youre picking yourself up recognize that this this new situation with the economy that doesnt have the juice to sustain our institutions has caused the people whove risen to the top of those institutions to get quite brutal and cruel everybody is lying at the moment nobodys really a truth teller um try to keep your humanity about you try to recognize that if youre failing if things arent where you want them to be and youre struggling and youre trying to figure out what youre doing wrong which you could do its not necessarily all your fault we are in a global situation i have not met the people who are honest kind good successful nobody that ive met is checking all the boxes nobodys getting all tens so i just think thats an important message that doesnt get pushed out enough either people want to hold society responsible for their failures which is not reasonable you have to struggle you have to try or they want to say youre a hundred percent responsible for your failures which is total nonsense beautifully put eric thank you so much for talking today thanks for having me buddy prayer and rhyme and prose so its not that newton had any ability to hold that back and i dont really believe that we have an ability to hold it back i do think that we could change the proportion of the time we spend worrying about the effects of what if we are successful rather than simply trying to succeed and hope that well be able to contain things later beautifully put so on the idea of intelligence what form treading cautiously as weve agreed as we tumbled down the hill what form we cant stop ourselves can we we cannot what form do you see it taking so one example facebook google do want to i dont know a better word you want to influence users to behave a certain way and so thats one kind of example of how intelligence is systems perhaps modifying the behavior of these intelligent human beings in order to sell more product of different kinds but do you see other examples of this actually emerging in just take any parasitic system make sure that theres some way in which that theres differential success heritability and variation and those are the magic ingredients and if you really wanted to build a nightmare machine make sure that the system that expresses the variability has a spanning set so that it can learn to arbitrary levels by making it sufficiently expressive thats your nightmare so its your nightmare but it could also be its a really powerful mechanism by which to create well powerful systems so are you more worried about the negative direction that might go versus the positive so you said parasitic but that doesnt necessarily need to be what the system converges towards it could be what is it and the dividing line between parasitism and symbiosis is not so clear thats what they tell me about marriage im still single so i dont know well yeah we could go into that too but no i think we have to appreciate are you infected by your own mitochondria right right yeah so in marriage you fear the loss of independence but even though the american therapeutic community may be very concerned about codependence whats to say that codependence isnt whats necessary to have a stable relationship in which to raise children who are maximally case selected and require incredible amounts of care because you have to wait 13 years before theres any reproductive payout and most of us dont want our 13 year olds having kids thats a very tricky situation to analyze and i would say that predators and parasites drive much of our evolution and i dont know whether to be angry at them or thank them well ultimately i mean nobody knows the meaning of life or what even happiness is but there is some metrics they didnt tell you they didnt they didnt thats why all the poetry and books are about you know theres some metrics under which you can kind of measure how good it is that these ai systems are roaming about so youre more nervous about software than you are optimistic about ideas of yeah self replicating largely i dont think weve really felt where we are you know occasionally we get a wake up 9 11 was so anomalous compared to everything else weve experienced on american soil that it came to us as a complete shock that that was even a possibility what it really was was a highly creative and determined r and d team deep in the bowels of afghanistan showing us that we had certain exploits that we were open to that nobody had chosen to express i can think of several of these things that i dont talk about publicly that just seem to have to do with um how relatively unimaginative those who wish to cause havoc and destruction have been up until now but the great mystery of our time of this particular little era is how remarkably stable weve been since 1945 when we demonstrated the ability to use a nuclear weapons in anger and we dont know why things like that havent happened since then weve had several close calls weve had mistakes weve had a brinksmanship and whats now happened is that weve settled into a sense that oh its itll always be nothing its been so long since something was at that level of danger that weve got a wrong idea in our head and thats why when i went on the ben shapiro show i talked about the need to resume above ground testing of nuclear devices because we have people whose developmental experience suggests that when lets say donald trump and north korea engage on twitter oh its nothing its just posturing everybodys just in it for money theres theres an a sense that people are in a video game mode which has been the right call since 1945 weve been mostly in video game mode its amazing so youre worried about a generation which has not seen any existential weve lived under it you see youre younger i dont know if if and again you came from from moscow there was a tv show called the day after that had a huge effect on a generation growing up in the u s and it talked about what life would be like after a nuclear exchange we have not gone through an embodied experience collectively where weve thought about this and i think its one of the most irresponsible things that the elders among us have done which is to provide this beautiful garden in which the thorns are cut off of the of the rose bushes and all of the edges are rounded and sanded and so people have developed this this totally unreal idea which is everythings going to be just fine and do i think that my leading concern is agi or my leading concern is a thermonuclear exchange or gene drives or any one of these things i dont know but i know that our time here in this very long experiment here is finite because the toys that weve built are so impressive and the wisdom to accompany them has not materialized and i think its we actually got a wisdom uptick since 1945 we had a lot of dangerous skilled players on the world stage who nevertheless no matter how bad they were managed to not embroil us in something that we couldnt come back from the cold war yeah and the distance from the cold war you know im very mindful of a there was a russian tradition actually of on your wedding day going to visit a memorial to those who gave their lives can you imagine this where you on the happiest day of your life you go and you pay homage to the people who fought and died in the battle of stalingrad im not a huge fan of communism i got to say but there were a couple of things that the russians did that were really positive in the soviet era and i think trying to let people know how serious life actually is is the russian model of seriousness is better than the american model and maybe like you mentioned there was a small echo of that after 9 11 but we wouldnt let it form we talk about 9 11 but its 9 12 that really moved the needle when we were all just there and nobody wanted to speak we witnessed something super serious and we didnt want to run to our computers and blast out our deep thoughts and our feelings and it was profound because we woke up briefly you know i talk about the gated institutional narrative that sort of programs our lives ive seen it break three times in my life one of which was the election of donald trump another time was the fall of lehman brothers when everybody who knew that bear stearns wasnt that important knew that lehman brothers met aig was next and the other one was 9 11 and so if im 53 years old and i only remember three times that the global narrative was really interrupted that tells you how much weve been on top of developing events you know i mean we had the murrow federal building explosion but it didnt cause the narrative to break it wasnt profound enough around 9 12 we started to wake up out of our slumber and the powers that be did not want to coming together they you know the admonition was go shopping and the powers that be was what is that force as opposed to blaming individuals we dont know so whatever that whatever that force is theres a component of it thats emergent and theres a component of it thats deliberate so give yourself a portfolio with two components some amount of it is emergent but some amount of it is also an understanding that if people come together they become an incredible force and what youre seeing right now i think is there are forces that are trying to come together and there are forces that are trying to push things apart and you know one of them is the globalist narrative versus the national narrative where to the global uh globalist perspective uh the nation nations are bad things in essence that theyre temporary theyre nationalistic theyre jingoistic its all negative to people in the national more in the national idiom theyre saying look this is where i pay my taxes this is where i do my army service this is where i have a vote this is where i have a passport who the hell are you to tell me that because youve moved into someplace that you can make money globally that youve chosen to abandon other people to whom you have a special and elevated duty and i think that these competing narratives have been pushing towards the global perspective uh from the elite and a larger and larger number of disenfranchised people are saying hey i actually live in a in a place and i have laws and i speak a language i have a culture and who are you to tell me that because you can profit in some far away land that my obligations to my fellow countrymen are so so much diminished so these tensions between nations and so on ultimately you see being proud of your country and so on which creates potentially the kind of things that led to wars and so on they they ultimately it is human nature and it is good for us for wake up calls of different kinds well i think that these are tensions and my point isnt i mean nationalism run amok is a nightmare and internationalism run amok is a nightmare and the problem is were trying to push these pendulums uh to some place where theyre somewhat balanced where we we have a higher duty of care to those uh who share our log our laws and our citizenship but we dont forget our duties of care to the global system i would think this is elementary but the problem that were facing concerns the ability for some to profit at the by abandoning their obligations uh to others within their system and thats what weve had for decades you mentioned nuclear weapons i was hoping to get answers from you since one of the many things youve done as a economics and maybe you can understand human behavior of why the heck we havent blown each other up yet but okay so uh well get back i dont know the answer yes its a its a fast its really important to say that we really dont know a mild uptick in wisdom a mild uptick in wisdom well steven pinker who ive talked with has a lot of really good ideas about why but i dont trust his optimism listen im russian so i never trust a guy who was that optimistic no no no its just that youre talking about a guy whos looking at a system in which more and more of the kinetic energy like war has been turned into potential energy like unused nuclear weapons beautifully put you know now im looking at that system and im saying okay well if you dont have a potential energy term then everythings just getting better and better yeah wow thats beautifully put only a physicist could okay im not a physicist is that a dirty word no no i wish i were a physicist me too my dads a physicist im trying to live up that probably for the rest of my life hes probably gonna listen to this too so he did yeah so your friend sam harris uh worries a lot about the existential threat of ai not in the way that youve described but in the more well he hangs out with elon i dont know elon so are you worried about that kind of uh you know about the um about either robotic systems or you know traditionally defined ai systems essentially becoming a super intelligent much more intelligent than human beings and uh getting well they already are and theyre not when when seen as a um a collective you mean well i mean i i can mean all sorts of things but certainly many of the things that we thought were peculiar to general intelligence or do not require general intelligence so thats been one of the big awakenings that you can write a pretty convincing sports story from stats alone uh without needing to have watched the game so you know is it possible to write lively pros about politics yeah no not yet so we were sort of all over the map one of the one of the things about chess that youll theres a question i once asked on quora that didnt get a lot of response which was what is the greatest brilliancy ever produced by a computer in a chess game which was different than the question of what is the greatest game ever played so if you think about brilliancies is what really animates many of us to think of chess as an art form those are those moves and combinations that just show such flair panache and and and in soul um computers werent really great at that they were great positional monsters and you know recently we weve started seeing brilliancies and so the grandmasters have identified with uh with alpha zero that things were quite brilliant yeah so thats thats thats a you know thats an example of something we dont think that thats agi but in a very restricted set a set of rules like chess youre starting to see poetry uh of a high order and and so im not i dont like the idea that were waiting for agi agi is sort of slowly infiltrating our lives in the same way that i dont think a worm should be you know the c elegans shouldnt be treated as non conscious because it only has 300 neurons maybe it just has a very low level of consciousness because we dont understand what these things mean as they scale up so am i worried about this general phenomena sure but i think that one of the things thats happening is that a lot of us are fretting about this uh in part because of human needs weve always been worried about the golem right well the golem is the artificially created life you know its like frankenstein yeah sure its a jewish version and um frankenberg frankenstein yeah thats makes sense right so the uh but weve always been worried about creating something like this and its getting closer and closer and there are ways in which we have to realize that the whole thing is kind of the whole thing that weve experienced are the context of our lives is almost certainly coming to an end and i dont mean to suggest that uh we wont survive i dont know and i dont mean to suggest that its coming tomorrow and it could be 300 500 years but theres no plan that im aware of if we have three rocks that we could possibly inhabit that are uh sensible within current technological dreams the earth the moon and mars and we have a very competitive civilization that is still forced into violence to sort out disputes that cannot be arbitrated it is not clear to me that we have a longterm future until we get to the next stage which is to figure out whether or not the einsteinian speed limit can be broken and that requires our source code our source code the stuff in our brains to figure out what do you mean by our source code the source code of the context whatever it is that produces the quarks the electrons the neutrinos oh our source code i got it so this is youre talking about stuff thats written in a higher level language yeah yeah thats right youre talking about the low level the bits yeah thats what is currently keeping us here we cant even imagine you know we have harebrained schemes for staying within the einsteinian speed limit uh you know maybe if we could just drug ourselves and go into a suspended state or we could have multiple generations of that i think all that stuff is pretty silly but i think its also pretty silly to imagine that our wisdom is going to increase to the point that we can have the toys we have and uh were not going to use them for 500 years speaking of einstein i had a profound breakthrough when i realized youre just one letter away from the guy yeah but im also one letter away from feinstein its well you get to pick okay so unified theory you know youve worked uh you you enjoy the beauty of geometry i dont actually know if you enjoy it you certainly are quite good at it i tremble before it if youre religious that is one of the i dont have to be religious its just so beautiful you will tremble anyway i mean i just read einsteins biography and one of the ways uh one of the things youve done is try to explore a unified theory uh talking about a 14 dimensional observers that has the 4d space time continuum embedded in it i im just curious how you think and how philosophically at a high level about something more than four dimensions uh how do you try to what what does it make you feel talking in the mathematical world about dimensions that are greater than the ones we can perceive is there something that you take away thats more than just the math well first of all stick out your tongue at me okay now on the front of that time yeah there was a sweet receptor and next to that were salt receptors and two different sides a little bit farther back there were sour receptors and you wouldnt show me the back of your tongue where your bitter receptor was show the good side always okay so you had four dimensions of taste receptors but you also had pain receptors on that tongue and probably heat receptors on that time so lets assume that you had one of each that would be six dimensions so when you eat something you eat a slice of pizza and its got some some uh some hot pepper on it maybe some jalapeno youre having a six dimensional experience dude do you think we overemphasize the value of time as one of the dimensions or space well we certainly overemphasize the value of time cause we like things to start and end or we really dont like things to end but they seem to well what if you flipped one of the spatial dimensions into being a temporal dimension and you and i were to meet in new york city and say well where where and when should we meet what about ill meet you on a 36 in lexington at two in the afternoon and uh 11 oclock in the morning that would be very confusing well so its convenient for us to think about time you mean we happen to be in a delicious situation in which we have three dimensions of space and one of time and theyre woven together in this sort of strange fabric where we can trade off a little space for a little time but we still only have one dimension that is picked out relative to the other three its very much gladys knight and the pips so which one developed for who do we develop for these dimensions or did the dimensions or were they always there and it doesnt well do you imagine that there isnt a place where there are four temporal dimensions or two and two of space and time or three of time and one of space and then would time not be playing the role of space why do you imagine that the sector that youre in is all that there is i certainly do not but i cant imagine otherwise i mean i havent done ayahuasca or any of those drugs that hope to one day but instead of doing ayahuasca you could just head over to building two thats where the mathematicians are yeah thats where they hang just to look at some geometry well just ask about pseudo ramanian geometry thats what youre interested in okay or you could talk to a shaman and end up in peru and then its an extra money for that trip yeah but you wont be able to do any calculations if thats how you choose to go about it well a different kind of calculation so to speak yeah one of my favorite people edward frankel berkeley professor author of love and math great title for a book said that you are quite a remarkable intellect to come up with such beautiful original ideas in terms of unified theory and so on but youre working outside academia so one question in developing ideas that are truly original truly interesting whats the difference between inside academia and outside academia when it comes to developing such ideas oh its a terrible choice terrible choice so if you do it inside of academics you are forced to constantly show great loyalty to the consensus and you distinguish yourself with small almost microscopic heresies to make your reputation in general and you have very competent people and brilliant people who are working together who form very deep social networks and have a very high level of behavior at least within mathematics and at least technically within physics theoretical physics when you go outside you meet lunatics and crazy people madmen and these are people who do not usually subscribe to the consensus position and almost always lose their way and the key question is will progress likely come from someone who has miraculously managed to stay within the system and is able to take on a larger amount of heresy that is sort of unthinkable in which case that will be fascinating or is it more likely that somebody will maintain a level of discipline from outside of academics and be able to make use of the freedom that comes from not having to constantly affirm your loyalty to the consensus of your field so youve characterized in ways that academia in this particular sense is declining you posted a plot the older population of the faculty is getting larger the younger is getting smaller and so on so which direction of the two are you more hopeful about well the baby boomers cant hang on forever first of all in general true and second of all in academia but thats really what this time is about were used to financial bubbles that last a few years in length and then pop the baby boomer bubble is this really long lived thing and all of the ideology all of the behavior patterns the norms for example string theory is an almost entirely baby boomer phenomenon it was something that baby boomers were able to do because it required a very high level of mathematical ability you dont think of string theory as an original idea oh i mean it was original to veneziano probably is older than the baby boomers and there are people who are younger than the baby boomers who are still doing string theory and im not saying that nothing discovered within the large string theoretic complex is wrong quite the contrary a lot of brilliant mathematics and a lot of the structure of physics was elucidated by string theorists what do i think of the deliverable nature of this product that will not ship called string theory i think that it is largely an affirmative action program for highly mathematically and geometrically talented baby boomer physics physicists so that they can say that theyre working on something within the constraints of what they will say is quantum gravity now there are other schemes you know theres like asymptotic safety there are other things that you could imagine doing i dont think much of any of the major programs but to have inflicted this level of loyalty through a shibboleth well surely you dont question x well i question almost everything in the string program and thats why i got out of physics when you called me a physicist it was a great honor but the reason i didnt become a physicist wasnt that i fell in love with mathematics i said wow in 1984 1983 i saw the field going mad and i saw that mathematics which has all sorts of problems was not going insane and so instead of studying things within physics i thought it was much safer to study the same objects within mathematics theres a huge price to pay for that you lose physical intuition but the point is is that it wasnt a north korean reeducation camp either are you hopeful about cracking open the einstein unified theory in a way that has been really really understanding whether this uh uniting everything together with quantum theory and so on i mean im trying to play this role myself to do it to the extent of handing it over to the more responsible more professional more competent community um so i think that theyre wrong about a great number of their belief structures but i do believe i mean i have a really profound love hate relationship with this group of people i think the physics side cause the mathematicians actually seem to be much more open minded and uh well they are and they arent theyre open minded about anything that looks like great math right right theyll study something that isnt very important physics but if its beautiful mathematics then theyll have a they have great intuition about these things as good as the mathematicians are and i might even intellectually at some horsepower level give them the edge the theoretical theoretical physics community is bar none the most profound intellectual community that we have ever created it is the number one theres nobody in second place as far as im concerned like in their spare time and the spare time they invented molecular biology what what was the origin of molecular biology youre saying something like francis crick i mean a lot of a lot of the early molecular biologists were physicists yeah i mean you know schrodinger wrote what is life and that was highly inspirational i mean you have to appreciate that there is no community like the basic research community in theoretical physics and its not something im highly critical of these guys i think that they would just wasted the decades of time with a near religious devotion to their misconception of where the problems were in physics but this has been the greatest intellectual collapse ever witnessed within academics you see it as a collapse or just a lull oh im terrified that were about to lose the vitality we cant afford to pay these people we cant afford to give them an accelerator just to play with in case they find something at the next energy level these people created our economy they gave us the rad lab and radar they gave us two atomic devices to end world war two they created the semiconductor and the transistor to power our economy through moores law as a positive externality of particle accelerators they created the worldwide web and we have the insolence to say why should we fund you with our taxpayer dollars no the question is are you enjoying your physics dollars these guys signed the worlds worst licensing agreement and if they simply charged for every time you used a transistor or a url or enjoyed the piece that they have provided during this period of time through the terrible weapons that they developed or your communications devices all of the things that power our economy i really think came out of physics even to the extent the chemistry came out of physics and molecular biology came out of physics so first of all you have to know that im very critical of this community second of all it is our most important community we have neglected it weve abused it we dont take it seriously we dont even care to get them to rehab after a couple of generations of failure right no one i think the youngest person to have really contributed to the standard model of theoretical level was born in 1951 right frank wilczek and almost nothing has happened that in theoretical physics after 1973 74 that sent somebody to stockholm for theoretical development that predicted experiment so we have to understand that we are doing this to ourselves now with that said these guys have behaved abysmally in my opinion because they havent owned up to where they actually are what problems theyre really facing how definite they can actually be they havent shared some of their most brilliant discoveries which are desperately needed in other fields like gauge theory which at least the mathematicians can can share which is an upgrade of the differential calculus of newton and leibniz and they havent shared the importance of renormalization theory even though this should be standard operating procedure for people across the sciences dealing with different layers and different levels of phenomena and by shared you mean communicated in such a way that it disseminates throughout the different sizes these guys are sitting both theoretical physicists and mathematicians are sitting on top of a giant stockpile of intellectual gold right they have so many things that have not been manifested anywhere i was just on twitter i think i mentioned the habermann switch pitch that shows the self duality of the tetrahedron realized as a linkage mechanism now this is like a triviality and it makes an amazing toy thats you know built a market hopefully a fortune for chuck habermann well you have no idea how much great stuff that these priests have in their monastery so its truly a love and hate relationship for you yeah well it sounds like its more on the love side this building that were in right here is the building in which i really put together the conspiracy between the national academy of sciences and the national science foundation through the government university industry research round table to destroy the bargaining power of american academics uh using foreign labor with uh on microfeature in the base oh yeah that was done here in this building isnt that weird and im im truly speaking with a revolutionary and a radical uh no no no no no no no no no no no no at an intellectual level i am absolutely garden variety im just straight down the middle the system that we are in this this university is functionally insane yeah harvard is functionally insane and we dont understand that when we get these things wrong the financial crisis made this very clear there was a long period where every grownup everybody with a tie uh who spoke in a you know in barrett baritone tones uh with with the right degree at the end of their name yeah uh were talking about how we banished volunteer volatility we were in the great moderation okay they were all crazy and who was who was right it was like nassim taleb nouriel roubini now what happens is is that they claimed the market went crazy but the market didnt go crazy the market had been crazy and what happened is is that it suddenly went sane well thats where we are with academics academics right now is mad as a hatter and its its absolutely evident i can show you graph after graph i can show you the internal discussions i can show you the conspiracies barretts dealing with one right now over uh its admissions policies for people uh of color uh who happened to come from asia all of this madness is necessary to keep the game going what were talking about just on well were on the topic of revolutionaries is were talking about the danger of an outbreak of sanity yeah youre youre the guy pointing out the elephant in the room here and the elephant has no clothes is that how that goes i was going to talk a little bit to uh joe rogan about this ran out of time but i think youre you have some you just listening to you you could probably speak really eloquently to academia on the difference between the different fields so you think theres a difference between science engineering and then the humanities in academia in terms of tolerance that theyre willing to tolerate so from my perspective i thought computer science and maybe engineering is more tolerant to radical ideas but thats perhaps innocent of me is that i always you know all the battles going on now are a little bit more on the humanity side and gender studies and so on have you seen the uh american mathematical societys publication of an essay called get out the way i have not whats whats the idea is that white men who hold uh positions yeah within universities and mathematics should vacate their positions so that young black women can take over something like this thats in terms of diversity which i also want to ask you about but in terms of diversity of strictly ideas do you think cause youre basically saying physics as a community has become a little bit intolerant to some degree to new radical ideas or at least you uh you said its changed a little bit recently which is that even string theory is now admitting okay we dont look very promising in the short term right so the question is what compiles if you want to take the computer science metaphor what will get you into a journal will you spend your life trying to push some paper into a journal or will it be accepted easily what about the characteristics of the submitter and what gets taken up and what does not all of these fields are experiencing pressure because no field is performing so brilliantly well um that its revolutionizing our way of speaking and thinking in the ways in which weve become accustomed but dont you think even in theoretical physics a lot of times even with theories like string theory you could speak to this it does eventually lead to what are the ways that this theory would be testable yeah ultimately although look theres this thing about popper and the scientific method thats a cancer and a disease and the minds of very smart people thats not really how most of the stuff gets worked out its how it gets checked all right so and there is a dialogue between theory and experiment but everybody should read paul directs 1963 american scientific american article where he he you know its very interesting he talks about it as if it was about the schrodinger equation and schrodingers failure to advance his own work because of his failure to account for some phenomenon the key point is that if your theory is a slight bit off it wont agree with experiment but it doesnt mean that the theory is actually wrong um but direct could as easily have been talking about his own equation in which he predicted that the electrons should have an antiparticle and since the only positively charged particle that was known at the time was the proton heisenberg pointed out well shouldnt your antiparticle the proton have the same mass as the electron and doesnt that invalidate your theory so i think the direct was actually being quite potentially quite sneaky um and uh talking about the fact that he had been pushed off of his own theory to some extent by heisenberg um but look weve fetishized the scientific method and popper and falsification um because it protects us from crazy ideas entering the field so you know its a question of balancing type one and type two error and were pretty we were pretty maxed out in one direction', 'the following is a conversation with greg brockman hes the cofounder and cto of openai a world class research organization developing ideas in ai with a goal of eventually creating a safe and friendly artificial general intelligence one that benefits and empowers humanity openai is not only a source of publications algorithms tools and data sets their mission is a catalyst for an important public discourse about our future with both narrow and general intelligence systems this conversation is part of the artificial intelligence podcast at mit and beyond if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with greg brockman so in high school and right after you wrote a draft of a chemistry textbook saw that that covers everything from basic structure of the atom to quantum mechanics so its clear you have an intuition and a passion for both the physical world with chemistry and now robotics to the digital world with ai deep learning reinforcement learning so on do you see the physical world and the digital world as different and what do you think is the gap a lot of it actually boils down to iteration speed i think that a lot of what really motivates me is building things i think about mathematics for example where you think really hard about a problem you understand it you write it down in this very obscure form that we call a proof but then this is in humanitys library its there forever this is some truth that weve discovered maybe only five people in your field will ever read it but somehow youve kind of moved humanity forward and so i actually used to really think that i was going to be a mathematician and then i actually started writing this chemistry textbook one of my friends told me youll never publish it because you dont have a phd so instead i decided to build a website and try to promote my ideas that way and then i discovered programming and in programming you think hard about a problem you understand it you write it down in a very obscure form that we call a program but then once again its in humanitys library and anyone can get the benefit from it and the scalability is massive and so i think that the thing that really appeals to me about the digital world is that you can have this insane leverage a single individual with an idea is able to affect the entire planet and thats something i think is really hard to do if youre moving around physical atoms but you said mathematics so if you look at the wet thing over here our mind do you ultimately see it as just math as just information processing or is there some other magic as youve seen if youve seen through biology and chemistry and so on yeah i think its really interesting to think about humans as just information processing systems and that seems like its actually a pretty good way of describing a lot of how the world works or a lot of what were capable of to think that again if you just look at technological innovations over time that in some ways the most transformative innovation that weve had has been the computer in some ways the internet that what has the internet done the internet is not about these physical cables its about the fact that i am suddenly able to instantly communicate with any other human on the planet im able to retrieve any piece of knowledge that in some ways the human race has ever had and that those are these insane transformations do you see our society as a whole the collective as another extension of the intelligence of the human being so if you look at the human being as an information processing system you mentioned the internet the networking do you see us all together as a civilization as a kind of intelligent system yeah i think this is actually a really interesting perspective to take and to think about that you sort of have this collective intelligence of all of society the economy itself is this superhuman machine that is optimizing something right and in some ways a company has a will of its own right that you have all these individuals who are all pursuing their own individual goals and thinking really hard and thinking about the right things to do but somehow the company does something that is this emergent thing and that is a really useful abstraction and so i think that in some ways we think of ourselves as the most intelligent things on the planet and the most powerful things on the planet but there are things that are bigger than us that are the systems that we all contribute to and so i think actually its interesting to think about if youve read isaac asimovs foundation right that theres this concept of psychohistory in there which is effectively this that if you have trillions or quadrillions of beings then maybe you could actually predict what that being that huge macro being will do and almost independent of what the individuals want and i actually have a second angle on this that i think is interesting which is thinking about technological determinism one thing that i actually think a lot about with openai right is that were kind of coming on to this insanely transformational technology of general intelligence right that will happen at some point and theres a question of how can you take actions that will actually steer it to go better rather than worse and that i think one question you need to ask is as a scientist as an inventor as a creator what impact can you have in general right you look at things like the telephone invented by two people on the same day like what does that mean like what does that mean about the shape of innovation and i think that whats going on is everyones building on the shoulders of the same giants and so you can kind of you cant really hope to create something no one else ever would you know if einstein wasnt born someone else would have come up with relativity you know he changed the timeline a bit right that maybe it would have taken another 20 years but it wouldnt be that fundamentally humanity would never discover these fundamental truths so theres some kind of invisible momentum that some people like einstein or openai is plugging into that anybody else can also plug into and ultimately that wave takes us into a certain direction thats what he means by digital thats right thats right and you know this kind of seems to play out in a bunch of different ways that theres some exponential that is being written and that the exponential itself which one it is changes think about moores law an entire industry set its clock to it for 50 years like how can that be right how is that possible and yet somehow it happened and so i think you cant hope to ever invent something that no one else will maybe you can change the timeline a little bit but if you really want to make a difference i think that the thing that you really have to do the only real degree of freedom you have is to set the initial conditions under which a technology is born and so you think about the internet right that there are lots of other competitors trying to build similar things and the internet won and that the initial conditions were that it was created by this group that really valued people being able to be anyone being able to plug in this very academic mindset of being open and connected and i think that the internet for the next 40 years really played out that way you know maybe today things are starting to shift in a different direction but i think that those initial conditions were really important to determine the next 40 years worth of progress thats really beautifully put so another example that i think about you know i recently looked at it i looked at wikipedia the formation of wikipedia and i wondered what the internet would be like if wikipedia had ads you know theres an interesting argument that why they chose not to make it put advertisement on wikipedia i think wikipedias one of the greatest resources we have on the internet its extremely surprising how well it works and how well it was able to aggregate all this kind of good information and essentially the creator of wikipedia i dont know theres probably some debates there but set the initial conditions and now it carried itself forward thats really interesting so the way youre thinking about agi or artificial intelligence is youre focused on setting the initial conditions for the progress thats right thats powerful okay so looking to the future if you create an agi system like one that can ace the turing test natural language what do you think would be the interactions you would have with it what do you think are the questions you would ask like what would be the first question you would ask it her him thats right i think that at that point if youve really built a powerful system that is capable of shaping the future of humanity the first question that you really should ask is how do we make sure that this plays out well and so thats actually the first question that i would ask a powerful agi system is so you wouldnt ask your colleague you wouldnt ask like ilya you would ask the agi system oh weve already had the conversation with ilya right and everyone here and so you want as many perspectives and a piece of wisdom as you can for answering this question so i dont think you necessarily defer to whatever your powerful system tells you but you use it as one input to try to figure out what to do but and i guess fundamentally what it really comes down to is if you built something really powerful and you think about for example the creation of shortly after the creation of nuclear weapons right the most important question in the world was whats the world order going to be like how do we set ourselves up in a place where were going to be able to survive as a species with agi i think the question is slightly different right that there is a question of how do we make sure that we dont get the negative effects but theres also the positive side right you imagine that like what wont agi be like like what will it be capable of and i think that one of the core reasons that an agi can be powerful and transformative is actually due to technological development right if you have something thats capable as a human and that its much more scalable that you absolutely want that thing to go read the whole scientific literature and think about how to create cures for all the diseases right you want it to think about how to go and build technologies to help us create material abundance and to figure out societal problems that we have trouble with like how are we supposed to clean up the environment and maybe you want this to go and invent a bunch of little robots that will go out and be biodegradable and turn ocean debris into harmless molecules and i think that that positive side is something that i think people miss sometimes when thinking about what an agi will be like and so i think that if you have a system thats capable of all of that you absolutely want its advice about how do i make sure that were using your capabilities in a positive way for humanity so what do you think about that psychology that looks at all the different possible trajectories of an agi system many of which perhaps the majority of which are positive and nevertheless focuses on the negative trajectories i mean you get to interact with folks you get to think about this maybe within yourself as well you look at sam harris and so on it seems to be sorry to put it this way but almost more fun to think about the negative possibilities whatever thats deep in our psychology what do you think about that and how do we deal with it because we want ai to help us so i think theres kind of two problems entailed in that question the first is more of the question of how can you even picture what a world with a new technology will be like now imagine were in 1950 and im trying to describe uber to someone apps and the internet yeah i mean thats going to be extremely complicated but its imaginable its imaginable right and now imagine being in 1950 and predicting uber right and you need to describe the internet you need to describe gps you need to describe the fact that everyones going to have this phone in their pocket and so i think that just the first truth is that it is hard to picture how a transformative technology will play out in the world weve seen that before with technologies that are far less transformative than agi will be and so i think that one piece is that its just even hard to imagine and to really put yourself in a world where you can predict what that positive vision would be like and i think the second thing is that i think it is always easier to support the negative side than the positive side its always easier to destroy than create and less in a physical sense and more just in an intellectual sense right because i think that with creating something you need to just get a bunch of things right and to destroy you just need to get one thing wrong and so i think that what that means is that i think a lot of peoples thinking dead ends as soon as they see the negative story but that being said i actually have some hope right i think that the positive vision is something that i think can be is something that we can talk about and i think that just simply saying this fact of yeah theres positive theres negatives everyone likes to dwell on the negative people actually respond well to that message and say huh youre right theres a part of this that were not talking about not thinking about and thats actually something thats i think really been a key part of how we think about agi at openai you can kind of look at it as like okay openai talks about the fact that there are risks and yet theyre trying to build this system how do you square those two facts so do you share the intuition that some people have i mean from sam harris to even elon musk himself that its tricky as you develop agi to keep it from slipping into the existential threats into the negative whats your intuition about how hard is it to keep ai development on the positive track whats your intuition there to answer that question you can really look at how we structure openai so we really have three main arms we have capabilities which is actually doing the technical work and pushing forward what these systems can do theres safety which is working on technical mechanisms to ensure that the systems we build are aligned with human values and then theres policy which is making sure that we have governance mechanisms answering that question of well whose values and so i think that the technical safety one is the one that people kind of talk about the most right you talk about like think about all of the dystopic ai movies a lot of that is about not having good technical safety in place and what weve been finding is that you know i think that actually a lot of people look at the technical safety problem and think its just intractable right this question of what do humans want how am i supposed to write that down can i even write down what i want no way and then they stop there but the thing is weve already built systems that are able to learn things that humans cant specify you know even the rules for how to recognize if theres a cat or a dog in an image turns out its intractable to write that down and yet were able to learn it and that what were seeing with systems we build at openai and theyre still in early proof of concept stage is that you are able to learn human preferences youre able to learn what humans want from data and so thats kind of the core focus for our technical safety team and i think that there actually weve had some pretty encouraging updates in terms of what weve been able to make work so you have an intuition and a hope that from data you know looking at the value alignment problem from data we can build systems that align with the collective better angels of our nature so align with the ethics and the morals of human beings to even say this in a different way i mean think about how do we align humans right think about like a human baby can grow up to be an evil person or a great person and a lot of that is from learning from data right that you have some feedback as a child is growing up they get to see positive examples and so i think that just like that the only example we have of a general intelligence that is able to learn from data to align with human values and to learn values i think we shouldnt be surprised that we can do the same sorts of techniques or whether the same sort of techniques end up being how we solve value alignment for agis so lets go even higher i dont know if youve read the book sapiens but theres an idea that you know that as a collective as us human beings we kind of develop together ideas that we hold theres no in that context objective truth we just kind of all agree to certain ideas and hold them as a collective did you have a sense that there is in the world of good and evil do you have a sense that to the first approximation there are some things that are good and that you could teach systems to behave to be good so i think that this actually blends into our third team right which is the policy team and this is the one the aspect i think people really talk about way less than they should right because imagine that we build super powerful systems that weve managed to figure out all the mechanisms for these things to do whatever the operator wants the most important question becomes whos the operator what do they want and how is that going to affect everyone else right and i think that this question of what is good what are those values i mean i think you dont even have to go to those those very grand existential places to start to realize how hard this problem is you just look at different countries and cultures across the world and that theres a very different conception of how the world works and what kinds of ways that society wants to operate and so i think that the really core question is actually very concrete and i think its not a question that we have ready answers to right its how do you have a world where all of the different countries that we have united states china russia and the hundreds of other countries out there are able to continue to not just operate in the way that they see fit but in the world that emerges where you have these very powerful systems operating alongside humans ends up being something that empowers humans more that makes human existence be a more meaningful thing and that people are happier and wealthier and able to live more fulfilling lives its not an obvious thing for how to design that world once you have that very powerful system so if we take a little step back and were having a fascinating conversation and openai is in many ways a tech leader in the world and yet were thinking about these big existential questions which is fascinating really important i think youre a leader in that space and thats a really important space of just thinking how ai affects society in a big picture view so oscar wilde said were all in the gutter but some of us are looking at the stars and i think openai has a charter that looks to the stars i would say to create intelligence to create general intelligence make it beneficial safe and collaborative so can you tell me how that came about how a mission like that and the path to creating a mission like that at openai was founded yeah so i think that in some ways it really boils down to taking a look at the landscape so if you think about the history of ai that basically for the past 60 or 70 years people have thought about this goal of what could happen if you could automate human intellectual labor imagine you could build a computer system that could do that what becomes possible we have a lot of sci fi that tells stories of various dystopias and increasingly you have movies like her that tell you a little bit about maybe more of a little bit utopic vision you think about the impacts that weve seen from being able to have bicycles for our minds and computers and i think that the impact of computers and the internet has just far outstripped what anyone really could have predicted and so i think that its very clear that if you can build an agi it will be the most transformative technology that humans will ever create and so what it boils down to then is a question of well is there a path is there hope is there a way to build such a system and i think that for 60 or 70 years that people got excited and that ended up not being able to deliver on the hopes that people had pinned on them and i think that then that after two winters of ai development that people i think kind of almost stopped daring to dream right and its like evolutionary history baking in all this information getting very very good at this predictive process and then at runtime i just kind of do one forward pass and im able to generate stuff and so you know there might be small tweaks to what we do in order to get the type signature right for example well you know its not really one forward pass right you know you generate symbol by symbol and so maybe you generate like a whole sequence of thoughts and you only keep like the last bit or something but i think that at the very least i would expect you have to make changes like that yeah just exactly how we you said think is the process of generating thought by thought in the same kind of way like you said keep the last bit the thing that we converge towards yep and i think theres another piece which is interesting which is this out of distribution generalization right that like thinking somehow lets us do that right that we havent experienced a thing and yet somehow we just kind of keep refining our mental model of it this is again something that feels tied to whatever reasoning is and maybe its a small tweak to what we do maybe its many ideas and well take as many decades yeah so the assumption there generalization out of distribution is that its possible to create new ideas mm hmm you know its possible that nobodys ever created any new ideas and then with scaling gpt2 to gpt20 you would essentially generalize to all possible thoughts that us humans could have i mean just to play devils advocate right right right i mean how many new story ideas have we come up with since shakespeare right yeah exactly its just all different forms of love and drama and so on okay not sure if you read bitter lesson a recent blog post by rich sutton yep i have he basically says something that echoes some of the ideas that youve been talking about which is he says the biggest lesson that can be read from 70 years of ai research is that general methods that leverage computation are ultimately going to ultimately win out do you agree with this so basically and openai in general but the ideas youre exploring about coming up with methods whether its gpt2 modeling or whether its openai 5 playing dota or a general method is better than a more fine tuned expert tuned method yeah so i think that well one thing that i think was really interesting about the reaction to that blog post was that a lot of people have read this as saying that compute is all that matters and thats a very threatening idea right and i dont think its a true idea either right its very clear that we have algorithmic ideas that have been very important for making progress and to really build agi you wanna push as far as you can on the computational scale and you wanna push as far as you can on human ingenuity and so i think you need both but i think the way that you phrased the question is actually very good right that its really about what kind of ideas should we be striving for and absolutely if you can find a scalable idea you pour more compute into it you pour more data into it it gets better like thats the real holy grail and so i think that the answer to the question i think is yes that thats really how we think about it and that part of why were excited about the power of deep learning the potential for building agi is because we look at the systems that exist in the most successful ai systems and we realize that you scale those up theyre gonna work better and i think that that scalability is something that really gives us hope for being able to build transformative systems so ill tell you this is partially an emotional a response that people often have if compute is so important for state of the art performance individual developers maybe a 13 year old sitting somewhere in kansas or something like that theyre sitting they might not even have a gpu or may have a single gpu a 1080 or something like that and theres this feeling like well how can i possibly compete or contribute to this world of ai if scale is so important so if you can comment on that and in general do you think we need to also in the future focus on democratizing compute resources more or as much as we democratize the algorithms well so the way that i think about it is that theres this space of possible progress right theres a space of ideas and sort of systems that will work that will move us forward and theres a portion of that space and to some extent an increasingly significant portion of that space that does just require massive compute resources and for that i think that the answer is kind of clear and that part of why we have the structure that we do is because we think its really important to be pushing the scale and to be building these large clusters and systems but theres another portion of the space that isnt about the large scale compute that are these ideas that and again i think that for the ideas to really be impactful and really shine that they should be ideas that if you scale them up would work way better than they do at small scale but that you can discover them without massive computational resources and if you look at the history of recent developments you think about things like the gan or the vae that these are ones that i think you could come up with them without having and in practice people did come up with them without having massive massive computational resources right i just talked to ian goodfellow but the thing is the initial gan produced pretty terrible results right so only because it was in a very specific it was only because theyre smart enough to know that this is quite surprising it can generate anything that they know do you see a world or is that too optimistic and dreamer like to imagine that the compute resources are something thats owned by governments and provided as utility actually to some extent this question reminds me of a blog post from one of my former professors at harvard this guy matt welsh who was a systems professor i remember sitting in his tenure talk right and that he had literally just gotten tenure he went to google for the summer and then decided he wasnt going back to academia right and kind of in his blog post he makes this point that look as a systems researcher that i come up with these cool system ideas right and i kind of build a little proof of concept and the best thing i can hope for is that the people at google or yahoo which was around at the time will implement it and actually make it work at scale right thats like the dream for me right i build the little thing and they turn it into the big thing thats actually working and for him he said im done with that i want to be the person whos actually doing building and deploying and i think that theres a similar dichotomy here right i think that there are people who really actually find value and i think it is a valuable thing to do to be the person who produces those ideas right who builds the proof of concept and yeah you dont get to generate the coolest possible gan images but you invented the gan right and so theres a real trade off there and i think that thats a very personal choice but i think theres value in both sides so do you think creating agi or some new models we would see echoes of the brilliance even at the prototype level so you would be able to develop those ideas without scale the initial seeds so take a look at you know i always like to look at examples that exist right look at real precedent and so take a look at the june 2018 model that we released that we scaled up to turn into gpt2 and you can see that at small scale it set some records right this was the original gpt we actually had some cool generations they werent nearly as amazing and really stunning as the gpt2 ones but it was promising it was interesting and so i think it is the case that with a lot of these ideas that you see promise at small scale but there is an asterisk here a very big asterisk which is sometimes we see behaviors that emerge that are qualitatively different from anything we saw at small scale and that the original inventor of whatever algorithm looks at and says i didnt think it could do that this is what we saw in dota right so ppo was created by john shulman whos a researcher here and with dota we basically just ran ppo at massive massive scale and theres some tweaks in order to make it work but fundamentally its ppo at the core and we were able to get this long term planning these behaviors to really play out on a time scale that we just thought was not possible and john looked at that and was like i didnt think it could do that thats what happens when youre at three orders of magnitude more scale than you tested at yeah but it still has the same flavors of you know at least echoes of the expected billions although i suspect with gpt scaled more and more you might get surprising things so yeah youre right its interesting its difficult to see how far an idea will go when its scaled its an open question well so to that point with dota and ppo like i mean heres a very concrete one right its like its actually one thing thats very surprising about dota that i think people dont really pay that much attention to is the decree of generalization out of distribution that happens right that you have this ai thats trained against other bots for its entirety the entirety of its existence sorry to take a step back can you talk through you know a story of dota a story of leading up to opening i5 and that past and what was the process of self play and so on of training on this yeah yeah yeah so with dota what is dota yeah dota is a complex video game and we started trying to solve dota because we felt like this was a step towards the real world relative to other games like chess or go right those very cerebral games where you just kind of have this board very discreet moves dota starts to be much more continuous time that you have this huge variety of different actions that you have a 45 minute game with all these different units and its got a lot of messiness to it that really hasnt been captured by previous games and famously all of the hard coded bots for dota were terrible right its just impossible to write anything good for it because its so complex and so this seemed like a really good place to push whats the state of the art in reinforcement learning and so we started by focusing on the one versus one version of the game and were able to solve that were able to beat the world champions and the skill curve was this crazy exponential right and it was like constantly we were just scaling up that we were fixing bugs and that you look at the skill curve and it was really a very very smooth one this is actually really interesting to see how that human iteration loop yielded very steady exponential progress and to one side note first of all its an exceptionally popular video game the side effect is that theres a lot of incredible human experts at that video game so the benchmark that youre trying to reach is very high and the other can you talk about the approach that was used initially and throughout training these agents to play this game yep and so the approach that we used is self play and so you have two agents that dont know anything they battle each other they discover something a little bit good and now they both know it and they just get better and better and better without bound and thats a really powerful idea right that we then went from the one versus one version of the game and scaled up to five versus five right so you think about kind of like with basketball where you have this like team sport and you need to do all this coordination and we were able to push the same idea the same self play to really get to the professional level at the full five versus five version of the game and the things i think are really interesting here is that these agents in some ways theyre almost like an insect like intelligence right where they have a lot in common with how an insect is trained right an insect kind of lives in this environment for a very long time or the ancestors of this insect have been around for a long time and had a lot of experience that gets baked into this agent and its not really smart in the sense of a human right its not able to go and learn calculus but its able to navigate its environment extremely well and its able to handle unexpected things in the environment that its never seen before pretty well and we see the same sort of thing with our dota bots right that theyre able to within this game theyre able to play against humans which is something that never existed in its evolutionary environment totally different play styles from humans versus the bots and yet its able to handle it extremely well and thats something that i think was very surprising to us was something that doesnt really emerge from what weve seen with ppo at smaller scale right and the kind of scale were running this stuff at was i could say like 100000 cpu cores running with like hundreds of gpus it was probably about something like hundreds of years of experience going into this bot every single real day and so that scale is massive and we start to see very different kinds of behaviors out of the algorithms that we all know and love dota you mentioned beat the world expert one v one and then you werent able to win five v five this year yeah at the best players in the world so whats the comeback story first of all talk through that that was an exceptionally exciting event and whats the following months and this year look like yeah yeah so one thing thats interesting is that we lose all the time because we play whos we here the dota team at openai we play the bot against better players than our system all the time or at least we used to right like the first time we lost publicly was we went up on stage at the international and we played against some of the best teams in the world and we ended up losing both games but we gave them a run for their money right that both games were kind of 30 minutes 25 minutes and they went back and forth back and forth back and forth and so i think that really shows that were at the professional level and that kind of looking at those games we think that the coin could have gone a different direction and we could have had some wins that was actually very encouraging for us and its interesting because the international was at a fixed time right so we knew exactly what day we were going to be playing and we pushed as far as we could as fast as we could two weeks later we had a bot that had an 80 win rate versus the one that played at ti so the march of progress you should think of it as a snapshot rather than as an end state and so in fact well be announcing our finals pretty soon i actually think that well announce our final match prior to this podcast being released so well be playing against the world champions and for us its really less about like the way that we think about whats upcoming is the final milestone the final competitive milestone for the project right that our goal in all of this isnt really about beating humans at dota our goal is to push the state of the art in reinforcement learning and weve done that right and weve actually learned a lot from our system and that we have i think a lot of exciting next steps that we want to take and so kind of as a final showcase of what we built were going to do this match but for us its not really the success or failure to see do we have the coin flip go in our direction or against where do you see the field of deep learning heading in the next few years where do you see the work and reinforcement learning perhaps heading and more specifically with openai all the exciting projects that youre working on what does 2019 hold for you massive scale scale i will put an asterisk on that and just say i think that its about ideas plus scale you need both so thats a really good point so the question in terms of ideas you have a lot of projects that are exploring different areas of intelligence and the question is when you think of scale do you think about growing the scale of those individual projects or do you think about adding new projects and sorry to and if youre thinking about adding new projects or if you look at the past whats the process of coming up with new projects and new ideas yep so we really have a life cycle of project here so we start with a few people just working on a small scale idea and language is actually a very good example of this that it was really one person here who was pushing on language for a long time i mean then you get signs of life right and so this is like lets say with the original gpt we had something that was interesting and we said okay its time to scale this right its time to put more people on it put more computational resources behind it and then we just kind of keep pushing and keep pushing and the end state is something that looks like dota or robotics where you have a large team of 10 or 15 people that are running things at very large scale and that youre able to really have material engineering and sort of machine learning science coming together to make systems that work and get material results that just would have been impossible otherwise so we do that whole life cycle weve done it a number of times typically end to end its probably two years or so to do it the organization has been around for three years so maybe well find that we also have longer life cycle projects but well work up to those so one team that we were actually just starting ilya and i are kicking off a new team called the reasoning team and that this is to really try to tackle how do you get neural networks to reason and we think that this will be a long term project its one that were very excited about in terms of reasoning super exciting topic what kind of benchmarks what kind of tests of reasoning do you envision what would if you sat back with whatever drink and you would be impressed that this system is able to do something what would that look like theorem proving theorem proving so some kind of logic and especially mathematical logic i think so i think that theres other problems that are dual to theorem proving in particular you think about programming you think about even security analysis of code that these all kind of capture the same sorts of core reasoning and being able to do some out of distribution generalization so it would be quite exciting if openai reasoning team was able to prove that p equals np that would be very nice it would be very very very exciting especially if it turns out that p equals np thatll be interesting too it would be ironic and humorous so what problem stands out to you as the most exciting and challenging and impactful to the work for us as a community in general and for openai this year you mentioned reasoning i think thats a heck of a problem yeah so i think reasonings an important one i think its gonna be hard to get good results in 2019 again just like we think about the life cycle takes time i think for 2019 language modeling seems to be kind of on that ramp its at the point that we have a technique that works we wanna scale 100x 1000x see what happens awesome do you think were living in a simulation i think its hard to have a real opinion about it its actually interesting i separate out things that i think can have like yield materially different predictions about the world from ones that are just kind of fun to speculate about i kind of view simulation as more like is there a flying teapot between mars and jupiter like maybe but its a little bit hard to know what that would mean for my life so there is something actionable so some of the best work openai has done is in the field of reinforcement learning and some of the success of reinforcement learning come from being able to simulate the problem youre trying to solve so do you have a hope for reinforcement for the future of reinforcement learning and for the future of simulation like whether its were talking about autonomous vehicles or any kind of system do you see that scaling to where well be able to simulate systems and hence be able to create a simulator that echoes our real world and proving once and for all even though youre denying it that were living in a simulation i feel like its two separate questions right so kind of at the core there of like can we use simulation for self driving cars take a look at our robotic system dactyl right that was trained in simulation using the dota system in fact and it transfers to a physical robot and i think everyone looks at our dota system theyre like okay its just a game how are you ever gonna escape to the real world and the answer is well we did it with a physical robot that no one could program and so i think the answer is simulation goes a lot further than you think if you apply the right techniques to it now theres a question of are the beings in that simulation gonna wake up and have consciousness i think that one seems a lot harder to again reason about i think that you really should think about where exactly does human consciousness come from in our own self awareness and is it just that once you have a complicated enough neural net you have to worry about the agents feeling pain and i think theres interesting speculation to do there but again i think its a little bit hard to know for sure well let me just keep with the speculation do you think to create intelligence general intelligence you need one consciousness and two a body do you think any of those elements are needed or is intelligence something thats orthogonal to those ill stick to the non grand answer first right so the non grand answer is just to look at what are we already making work you look at gpt2 a lot of people would have said that to even get these kinds of results you need real world experience you need a body you need grounding how are you supposed to reason about any of these things how are you supposed to like even kind of know about smoke and fire and those things if youve never experienced them and gpt2 shows that you can actually go way further than that kind of reasoning would predict so i think that in terms of do we need consciousness do we need a body it seems the answer is probably not right that we could probably just continue to push kind of the systems we have they already feel general theyre not as competent or as general or able to learn as quickly as an agi would but theyre at least like kind of proto agi in some way and they dont need any of those things now lets move to the grand answer which is are our neural nets conscious already would we ever know how can we tell right and heres where the speculation starts to become at least interesting or fun and maybe a little bit disturbing depending on where you take it but it certainly seems that when we think about animals that theres some continuum of consciousness you know my cat i think is conscious in some way right not as conscious as a human and you could imagine that you could build a little consciousness meter right you point at a cat it gives you a little reading point at a human it gives you much bigger reading what would happen if you pointed one of those at a donor neural net and if youre training in this massive simulation do the neural nets feel pain you know it becomes pretty hard to know that the answer is no and it becomes pretty hard to really think about what that would mean if the answer were yes and its very possible you know for example you could imagine that maybe the reason that humans have consciousness is because its a convenient computational shortcut right if you think about it if you have a being that wants to avoid pain which seems pretty important to survive in this environment and wants to like you know eat food then that maybe the best way of doing it is to have a being thats conscious right that you know in order to succeed in the environment you need to have those properties and how are you supposed to implement them and maybe this consciousnesss way of doing that if thats true then actually maybe we should expect that really competent reinforcement learning agents will also have consciousness but you know thats a big if and i think there are a lot of other arguments they can make in other directions i think thats a really interesting idea that even gpt2 has some degree of consciousness thats something its actually not as crazy to think about its useful to think about as we think about what it means to create intelligence of a dog intelligence of a cat and the intelligence of a human so last question do you think we will ever fall in love like in the movie her with an artificial intelligence system or an artificial intelligence system falling in love with a human i hope so if theres any better way to end it is on love so greg thanks so much for talking today thank you for having me that really talking about agi or thinking about agi became almost this taboo in the community but i actually think that people took the wrong lesson from ai history and if you look back starting in 1959 is when the perceptron was released and this is basically one of the earliest neural networks it was released to what was perceived as this massive overhype so in the new york times in 1959 you have this article saying that the perceptron will one day recognize people call out their names instantly translate speech between languages and people at the time looked at this and said this is your system cant do any of that and basically spent 10 years trying to discredit the whole perceptron direction and succeeded and all the funding dried up and people kind of went in other directions and in the 80s there was this resurgence and id always heard that the resurgence in the 80s was due to the invention of backpropagation and these algorithms that got people excited but actually the causality was due to people building larger computers that you can find these articles from the 80s saying that the democratization of computing power suddenly meant that you could run these larger neural networks and then people started to do all these amazing things backpropagation algorithm was invented and the neural nets people were running were these tiny little 20 neuron neural nets what are you supposed to learn with 20 neurons and so of course they werent able to get great results and it really wasnt until 2012 that this approach thats almost the most simple natural approach that people had come up with in the 50s in some ways even in the 40s before there were computers with the pitts–mccullough neuron suddenly this became the best way of solving problems and i think there are three core properties that deep learning has that i think are very worth paying attention to the first is generality we have a very small number of deep learning tools sgd deep neural net maybe some rl and it solves this huge variety of problems speech recognition machine translation game playing all of these problems small set of tools so theres the generality theres a second piece which is the competence you want to solve any of those problems throw up 40 years worth of normal computer vision research replace it with a deep neural net its going to work better and theres a third piece which is the scalability one thing that has been shown time and time again is that if you have a larger neural network throw more compute more data at it it will work better those three properties together feel like essential parts of building a general intelligence now it doesnt just mean that if we scale up what we have that we will have an agi right there are clearly missing pieces there are missing ideas we need to have answers for reasoning but i think that the core here is that for the first time it feels that we have a paradigm that gives us hope that general intelligence can be achievable and so as soon as you believe that everything else comes into focus right if you imagine that you may be able to and you know that the timeline i think remains uncertain but i think that certainly within our lifetimes and possibly within a much shorter period of time than people would expect if you can really build the most transformative technology that will ever exist you stop thinking about yourself so much right you start thinking about just like how do you have a world where this goes well and that you need to think about the practicalities of how do you build an organization and get together a bunch of people and resources and to make sure that people feel motivated and ready to do it but i think that then you start thinking about well what if we succeed and how do we make sure that when we succeed that the world is actually the place that we want ourselves to exist in and almost in the rawlsian veil sense of the word and so thats kind of the broader landscape and openai was really formed in 2015 with that high level picture of agi might be possible sooner than people think and that we need to try to do our best to make sure its going to go well and then we spent the next couple of years really trying to figure out what does that mean how do we do it and i think that typically with a company you start out very small see you in a co founder and you build a product you get some users you get a product market fit then at some point you raise some money you hire people you scale and then down the road then the big companies realize you exist and try to kill you and for openai it was basically everything in exactly the opposite order let me just pause for a second you said a lot of things and let me just admire the jarring aspect of what openai stands for which is daring to dream i mean you said its pretty powerful it caught me off guard because i think thats very true the step of just daring to dream about the possibilities of creating intelligence in a positive in a safe way but just even creating intelligence is a very powerful is a much needed refreshing catalyst for the ai community so thats the starting point okay so then formation of openai whats that i would just say that when we were starting openai that kind of the first question that we had is is it too late to start a lab with a bunch of the best people right is that even possible wow okay that was an actual question that was the core question of we had this dinner in july of 2015 and that was really what we spent the whole time talking about and you know because you think about kind of where ai was is that it had transitioned from being an academic pursuit to an industrial pursuit and so a lot of the best people were in these big research labs and that we wanted to start our own one that no matter how much resources we could accumulate would be pale in comparison to the big tech companies and we knew that and it was a question of are we going to be actually able to get this thing off the ground you need critical mass you cant just do you and a cofounder build a product you really need to have a group of five to 10 people and we kind of concluded it wasnt obviously impossible so it seemed worth trying well youre also a dreamer so who knows right thats right okay so speaking of that competing with the big players lets talk about some of the tricky things as you think through this process of growing of seeing how you can develop these systems at a scale that competes so you recently formed openai lp a new cap profit company that now carries the name openai so openai is now this official company the original nonprofit company still exists and carries the openai nonprofit name so can you explain what this company is what the purpose of this creation is and how did you arrive at the decision to create it openai the whole entity and openai lp as a vehicle is trying to accomplish the mission of ensuring that artificial general intelligence benefits everyone and the main way that were trying to do that is by actually trying to build general intelligence ourselves and make sure the benefits are distributed to the world thats the primary way were also fine if someone else does this right doesnt have to be us if someone else is going to build an agi and make sure that the benefits dont get locked up in one company or with one set of people like were actually fine with that and so those ideas are baked into our charter which is kind of the foundational document that describes kind of our values and how we operate but its also really baked into the structure of openai lp and so the way that weve set up openai lp is that in the case where we succeed right if we actually build what were trying to build then investors are able to get a return but that return is something that is capped and so if you think of agi in terms of the value that you could really create youre talking about the most transformative technology ever created its going to create orders of magnitude more value than any existing company and that all of that value will be owned by the world like legally titled to the nonprofit to fulfill that mission and so thats the structure so the mission is a powerful one and its one that i think most people would agree with its how we would hope ai progresses and so how do you tie yourself to that mission how do you make sure you do not deviate from that mission that other incentives that are profit driven dont interfere with the mission so this was actually a really core question for us for the past couple of years because id say that like the way that our history went was that for the first year we were getting off the ground right we had this high level picture but we didnt know exactly how we wanted to accomplish it and really two years ago is when we first started realizing in order to build agi were just going to need to raise way more money than we can as a nonprofit and were talking many billions of dollars and so the first question is how are you supposed to do that and stay true to this mission and we looked at every legal structure out there and concluded none of them were quite right for what we wanted to do and i guess it shouldnt be too surprising if youre gonna do some like crazy unprecedented technology that youre gonna have to come with some crazy unprecedented structure to do it in and a lot of our conversation was with people at openai the people who really joined because they believe so much in this mission and thinking about how do we actually raise the resources to do it and also stay true to what we stand for and the place you gotta start is to really align on what is it that we stand for right what are those values whats really important to us and so id say that we spent about a year really compiling the openai charter and that determines and if you even look at the first line item in there it says that look we expect were gonna have to marshal huge amounts of resources but were going to make sure that we minimize conflict of interest with the mission and that kind of aligning on all of those pieces was the most important step towards figuring out how do we structure a company that can actually raise the resources to do what we need to do i imagine openai the decision to create openai lp was a really difficult one and there was a lot of discussions as you mentioned for a year and there was different ideas perhaps detractors within openai sort of different paths that you could have taken what were those concerns what were the different paths considered what was that process of making that decision like yep so if you look actually at the openai charter theres almost two paths embedded within it there is we are primarily trying to build agi ourselves but were also okay if someone else does it and this is a weird thing for a company its really interesting actually there is an element of competition that you do wanna be the one that does it but at the same time youre okay if somebody else doesnt well talk about that a little bit that trade off that dance thats really interesting and i think this was the core tension as we were designing openai lp and really the openai strategy is how do you make sure that both you have a shot at being a primary actor which really requires building an organization raising massive resources and really having the will to go and execute on some really really hard vision right you need to really sign up for a long period to go and take on a lot of pain and a lot of risk and to do that normally you just import the startup mindset right and that you think about okay like how do we out execute everyone you have this very competitive angle but you also have the second angle of saying that well the true mission isnt for openai to build agi the true mission is for agi to go well for humanity and so how do you take all of those first actions and make sure you dont close the door on outcomes that would actually be positive and fulfill the mission and so i think its a very delicate balance right and i think that going 100 one direction or the other is clearly not the correct answer and so i think that even in terms of just how we talk about openai and think about it theres just like one thing thats always in the back of my mind is to make sure that were not just saying openais goal is to build agi right that its actually much broader than that right that first of all its not just agi its safe agi thats very important but secondly our goal isnt to be the ones to build it our goal is to make sure it goes well for the world and so i think that figuring out how do you balance all of those and to get people to really come to the table and compile a single document that encompasses all of that wasnt trivial so part of the challenge here is your mission is i would say beautiful empowering and a beacon of hope for people in the research community and just people thinking about ai so your decisions are scrutinized more than i think a regular profit driven company do you feel the burden of this in the creation of the charter and just in the way you operate yes so why do you lean into the burden by creating such a charter why not keep it quiet i mean it just boils down to the mission right like im here and everyone else is here because we think this is the most important mission dare to dream all right so do you think you can be good for the world or create an agi system thats good when youre a for profit company from my perspective i dont understand why profit interferes with positive impact on society i dont understand why google that makes most of its money from ads cant also do good for the world or other companies facebook anything i dont understand why those have to interfere you know profit isnt the thing in my view that affects the impact of a company what affects the impact of the company is the charter is the culture is the people inside and profit is the thing that just fuels those people so what are your views there yeah so i think thats a really good question and theres some real longstanding debates in human society that are wrapped up in it the way that i think about it is just think about what are the most impactful non profits in the world what are the most impactful for profits in the world right its much easier to list the for profits thats right and i think that theres some real truth here that the system that we set up the system for kind of how todays world is organized is one that really allows for huge impact and that kind of part of that is that you need to be that for profits are self sustaining and able to kind of build on their own momentum and i think thats a really powerful thing its something that when it turns out that we havent set the guardrails correctly causes problems right think about logging companies that go into forest the rainforest thats really bad we dont want that and its actually really interesting to me that kind of this question of how do you get positive benefits out of a for profit company its actually very similar to how do you get positive benefits out of an agi right that you have this like very powerful system its more powerful than any human and is kind of autonomous in some ways its superhuman in a lot of axes and somehow you have to set the guardrails to get good things to happen but when you do the benefits are massive and so i think that when i think about nonprofit versus for profit i think just not enough happens in nonprofits theyre very pure but its just kind of its just hard to do things there in for profits in some ways like too much happens but if kind of shaped in the right way it can actually be very positive and so with openai lp were picking a road in between now the thing that i think is really important to recognize is that the way that we think about openai lp is that in the world where agi actually happens right in a world where we are successful we build the most transformative technology ever the amount of value were gonna create will be astronomical and so then in that case that the cap that we have will be a small fraction of the value we create and the amount of value that goes back to investors and employees looks pretty similar to what would happen in a pretty successful startup and thats really the case that were optimizing for right that were thinking about in the success case making sure that the value we create doesnt get locked up and i expect that in other for profit companies that its possible to do something like that i think its not obvious how to do it right i think that as a for profit company you have a lot of fiduciary duty to your shareholders and that there are certain decisions that you just cannot make in our structure weve set it up so that we have a fiduciary duty to the charter that we always get to make the decision that is right for the charter rather than even if it comes at the expense of our own stakeholders and so i think that when i think about whats really important its not really about nonprofit versus for profit its really a question of if you build agi and you kind of humanitys now in this new age who benefits whose lives are better and i think that whats really important is to have an answer that is everyone yeah which is one of the core aspects of the charter so one concern people have not just with openai but with google facebook amazon anybody really thats creating impact at scale is how do we avoid as your charter says avoid enabling the use of ai or agi to unduly concentrate power why would not a company like openai keep all the power of an agi system to itself the charter the charter so how does the charter actualize itself in day to day so i think that first to zoom out that the way that we structure the company is so that the power for sort of dictating the actions that openai takes ultimately rests with the board the board of the nonprofit and the board is set up in certain ways with certain restrictions that you can read about in the openai lp blog post but effectively the board is the governing body for openai lp and the board has a duty to fulfill the mission of the nonprofit and so thats kind of how we tie how we thread all these things together now theres a question of so day to day how do people the individuals who in some ways are the most empowered ones right now the board sort of gets to call the shots at the high level but the people who are actually executing are the employees right people here on a day to day basis who have the keys to the technical whole kingdom and there i think that the answer looks a lot like well how does any companys values get actualized right and i think that a lot of that comes down to that you need people who are here because they really believe in that mission and they believe in the charter and that they are willing to take actions that maybe are worse for them but are better for the charter and thats something thats really baked into the culture and honestly i think its you know i think that thats one of the things that we really have to work to preserve as time goes on and thats a really important part of how we think about hiring people and bringing people into openai so theres people here theres people here who could speak up and say like hold on a second this is totally against what we stand for culture wise yeah yeah for sure i mean i think that we actually have i think thats like a pretty important part of how we operate and how we have even again with designing the charter and designing openai lp in the first place that there has been a lot of conversation with employees here and a lot of times where employees said wait a second this seems like its going in the wrong direction and lets talk about it and so i think one thing thats i think a really and you know heres actually one thing that i think is very unique about us as a small company is that if youre at a massive tech giant thats a little bit hard for someone whos a line employee to go and talk to the ceo and say i think that were doing this wrong and you know youll get companies like google that have had some collective action from employees to make ethical change around things like maven and so maybe there are mechanisms at other companies that work but here super easy for anyone to pull me aside to pull sam aside to pull ilya aside and people do it all the time one of the interesting things in the charter is this idea that itd be great if you could try to describe or untangle switching from competition to collaboration in late stage agi development its really interesting this dance between competition and collaboration how do you think about that yeah assuming that you can actually do the technical side of agi development i think theres going to be two key problems with figuring out how do you actually deploy it make it go well the first one of these is the run up to building the first agi you look at how self driving cars are being developed and its a competitive race and the thing that always happens in competitive race is that you have huge amounts of pressure to get rid of safety and so thats one thing were very concerned about is that people multiple teams figuring out we can actually get there but if we took the slower path that is more guaranteed to be safe we will lose and so were going to take the fast path and so the more that we can both ourselves be in a position where we dont generate that competitive race where we say if the race is being run and that someone else is further ahead than we are were not going to try to leapfrog were going to actually work with them right we will help them succeed as long as what theyre trying to do is to fulfill our mission then were good we dont have to build agi ourselves and i think thats a really important commitment from us but it cant just be unilateral right i think that its really important that other players who are serious about building agi make similar commitments right i think that again to the extent that everyone believes that agi should be something to benefit everyone then it actually really shouldnt matter which company builds it and we should all be concerned about the case where we just race so hard to get there that something goes wrong so what role do you think government our favorite entity has in setting policy and rules about this domain from research to the development to early stage to late stage ai and agi development so i think that first of all its really important that governments in there right in some way shape or form at the end of the day were talking about building technology that will shape how the world operates and that there needs to be government as part of that answer and so thats why weve done a number of different congressional testimonies we interact with a number of different lawmakers and that right now a lot of our message to them is that its not the time for regulation it is the time for measurement right that our main policy recommendation is that people and the government does this all the time with bodies like nist spend time trying to figure out just where the technology is how fast its moving and can really become literate and up to speed with respect to what to expect so i think that today the answer really is about measurement and i think that there will be a time and place where that will change and i think its a little bit hard to predict exactly what exactly that trajectory should look like so there will be a point at which regulation federal in the united states the government steps in and helps be the i dont wanna say the adult in the room to make sure that there is strict rules maybe conservative rules that nobody can cross well i think theres kind of maybe two angles to it so today with narrow ai applications that i think there are already existing bodies that are responsible and should be responsible for regulation you think about for example with self driving cars that you want the national highway netsa yeah exactly to be regulating that that makes sense right that basically what were saying is that were going to have these technological systems that are going to be performing applications that humans already do great we already have ways of thinking about standards and safety for those so i think actually empowering those regulators today is also pretty important and then i think for agi that theres going to be a point where well have better answers and i think that maybe a similar approach of first measurement and start thinking about what the rules should be i think its really important that we dont prematurely squash progress i think its very easy to kind of smother a budding field and i think thats something to really avoid but i dont think that the right way of doing it is to say lets just try to blaze ahead and not involve all these other stakeholders so you recently released a paper on gpt2 language modeling but did not release the full model because you had concerns about the possible negative effects of the availability of such model its outside of just that decision its super interesting because of the discussion at a societal level the discourse it creates so its fascinating in that aspect but if you think thats the specifics here at first what are some negative effects that you envisioned and of course what are some of the positive effects yeah so again i think to zoom out the way that we thought about gpt2 is that with language modeling we are clearly on a trajectory right now where we scale up our models and we get qualitatively better performance gpt2 itself was actually just a scale up of a model that weve released in the previous june we just ran it at much larger scale and we got these results where suddenly starting to write coherent pros which was not something wed seen previously and what are we doing now well were gonna scale up gpt2 by 10x by 100x by 1000x and we dont know what were gonna get and so its very clear that the model that we released last june i think its kind of like its a good academic toy its not something that we think is something that can really have negative applications or to the extent that it can that the positive of people being able to play with it is far outweighs the possible harms you fast forward to not gpt2 but gpt20 and you think about what thats gonna be like and i think that the capabilities are going to be substantive and so there needs to be a point in between the two where you say this is something where we are drawing the line and that we need to start thinking about the safety aspects and i think for gpt2 we could have gone either way and in fact when we had conversations internally that we had a bunch of pros and cons and it wasnt clear which one outweighed the other and i think that when we announced that hey we decide not to release this model then there was a bunch of conversation where various people said its so obvious that you should have just released it there are other people said its so obvious you should not have released it and i think that that almost definitionally means that holding it back was the correct decision right if its not obvious whether something is beneficial or not you should probably default to caution and so i think that the overall landscape for how we think about it is that this decision could have gone either way there are great arguments in both directions but for future models down the road and possibly sooner than youd expect because scaling these things up doesnt actually take that long those ones youre definitely not going to want to release into the wild and so i think that we almost view this as a test case and to see can we even design you know how do you have a society or how do you have a system that goes from having no concept of responsible disclosure where the mere idea of not releasing something for safety reasons is unfamiliar to a world where you say okay we have a powerful model lets at least think about it lets go through some process and you think about the security community it took them a long time to design responsible disclosure right you know you think about this question of well i have a security exploit i send it to the company the company is like tries to prosecute me or just sit just ignores it what do i do right and so you know the alternatives of oh i just always publish your exploits that doesnt seem good either right and so it really took a long time and took this it was bigger than any individual right its really about building a whole community that believe that okay well have this process where you send it to the company you know if they dont act in a certain time then you can go public and youre not a bad person youve done the right thing and i think that in ai part of the response at gpt2 just proves that we dont have any concept of this so thats the high level picture and so i think that i think this was a really important move to make and we could have maybe delayed it for gpt3 but im really glad we did it for gpt2 and so now you look at gpt2 itself and you think about the substance of okay what are potential negative applications so you have this model thats been trained on the internet which you know its also going to be a bunch of very biased data a bunch of you know very offensive content in there and you can ask it to generate content for you on basically any topic right you just give it a prompt and itll just start writing and it writes content like you see on the internet you know even down to like saying advertisement in the middle of some of its generations and you think about the possibilities for generating fake news or abusive content and you know its interesting seeing what people have done with you know we released a smaller version of gpt2 and the people have done things like try to generate you know take my own facebook message history and generate more facebook messages like me and people generating fake politician content or you know theres a bunch of things there where you at least have to think is this going to be good for the world theres the flip side which is i think that theres a lot of awesome applications that we really want to see like creative applications in terms of if you have sci fi authors that can work with this tool and come up with cool ideas like that seems awesome if we can write better sci fi through the use of these tools and weve actually had a bunch of people write into us asking hey can we use it for you know a variety of different creative applications so the positive are actually pretty easy to imagine theyre you know the usual nlp applications are really interesting but lets go there its kind of interesting to think about a world where look at twitter where not just fake news but smarter and smarter bots being able to spread in an interesting complex networking way information that just floods out us regular human beings with our original thoughts so what are your views of this world with gpt20 right how do we think about it again its like one of those things about in the 50s trying to describe the internet or the smartphone what do you think about that world the nature of information one possibility is that well always try to design systems that identify robot versus human and well do so successfully and so well authenticate that were still human and the other world is that we just accept the fact that were swimming in a sea of fake news and just learn to swim there well have you ever seen the popular meme of robot with a physical arm and pen clicking the im not a robot button yeah i think the truth is that really trying to distinguish between robot and human is a losing battle ultimately you think its a losing battle i think its a losing battle ultimately right i think that that is in terms of the content in terms of the actions that you can take i mean think about how captures have gone right the captures used to be a very nice simple you just have this image all of our ocr is terrible you put a couple of artifacts in it humans are gonna be able to tell what it is an ai system wouldnt be able to today i could barely do captures and i think that this is just kind of where were going i think captures were a moment in time thing and as ai systems become more powerful that there being human capabilities that can be measured in a very easy automated way that ais will not be capable of i think thats just like its just an increasingly hard technical battle but its not that all hope is lost right you think about how do we already authenticate ourselves right that we have systems we have social security numbers if youre in the us or you have ways of identifying individual people and having real world identity tied to digital identity seems like a step towards authenticating the source of content rather than the content itself now there are problems with that how can you have privacy and anonymity in a world where the only content you can really trust is or the only way you can trust content is by looking at where it comes from and so i think that building out good reputation networks may be one possible solution but yeah i think that this question is not an obvious one and i think that we maybe sooner than we think will be in a world where today i often will read a tweet and be like hmm do i feel like a real human wrote this or do i feel like this is genuine i feel like i can kind of judge the content a little bit and i think in the future it just wont be the case you look at for example the fcc comments on net neutrality it came out later that millions of those were auto generated and that the researchers were able to do various statistical techniques to do that what do you do in a world where those statistical techniques dont exist its just impossible to tell the difference between humans and ais and in fact the most persuasive arguments are written by ai all that stuff its not sci fi anymore you look at gpt2 making a great argument for why recycling is bad for the world you gotta read that and be like huh youre right we are addressing just the symptoms yeah thats quite interesting i mean ultimately it boils down to the physical world being the last frontier of proving so you said like basically networks of people humans vouching for humans in the physical world and somehow the authentication ends there i mean if i had to ask you i mean youre way too eloquent for a human so if i had to ask you to authenticate like prove how do i know youre not a robot and how do you know im not a robot yeah i think thats so far where in this space this conversation we just had the physical movements we did is the biggest gap between us and ai systems is the physical manipulation so maybe thats the last frontier well heres another question is why is why is solving this problem important right like what aspects are really important to us and i think that probably where well end up is well hone in on what do we really want out of knowing if were talking to a human and i think that again this comes down to identity and so i think that the internet of the future i expect to be one that will have lots of agents out there that will interact with you but i think that the question of is this flesh real flesh and blood human or is this an automated system may actually just be less important lets actually go there its gpt2 is impressive and lets look at gpt20 why is it so bad that all my friends are gpt20 why is it so important on the internet do you think to interact with only human beings why cant we live in a world where ideas can come from models trained on human data yeah i think this is actually a really interesting question this comes back to the how do you even picture a world with some new technology and i think that one thing that i think is important is you know lets say honesty and i think that if you have almost in the turing test style sense of technology you have ais that are pretending to be humans and deceiving you i think that feels like a bad thing right i think that its really important that we feel like were in control of our environment right that we understand who were interacting with and if its an ai or a human thats not something that were being deceived about but i think that the flip side of can i have as meaningful of an interaction with an ai as i can with a human well i actually think here you can turn to sci fi and her i think is a great example of asking this very question right one thing i really love about her is it really starts out almost by asking how meaningful are human virtual relationships right and then you have a human who has a relationship with an ai and that you really start to be drawn into that right that all of your emotional buttons get triggered in the same way as if there was a real human that was on the other side of that phone and so i think that this is one way of thinking about it is that i think that we can have meaningful interactions and that if theres a funny joke some sense it doesnt really matter if it was written by a human or an ai but what you dont want and why i think we should really draw hard lines is deception and i think that as long as were in a world where why do we build ai systems at all right the reason we want to build them is to enhance human lives to make humans be able to do more things to have humans feel more fulfilled and if we can build ai systems that do that sign me up so the process of language modeling how far do you think itd take us lets look at movie her do you think a dialogue natural language conversation is formulated by the turing test for example do you think that process could be achieved through this kind of unsupervised language modeling so i think the turing test in its real form isnt just about language right its really about reasoning too right to really pass the turing test i should be able to teach calculus to whoevers on the other side and have it really understand calculus and be able to go and solve new calculus problems and so i think that to really solve the turing test we need more than what were seeing with language models we need some way of plugging in reasoning now how different will that be from what we already do thats an open question right might be that we need some sequence of totally radical new ideas or it might be that we just need to kind of shape our existing systems in a slightly different way but i think that in terms of how far language modeling will go its already gone way further than many people would have expected right i think that things like and i think theres a lot of really interesting angles to poke in terms of how much does gpt2 understand physical world like you read a little bit about fire underwater in gpt2 so its like okay maybe it doesnt quite understand what these things are but at the same time i think that you also see various things like smoke coming from flame and a bunch of these things that gpt2 it has no body it has no physical experience its just statically read data and i think that the answer is like we dont know yet these questions though were starting to be able to actually ask them to physical systems to real systems that exist and thats very exciting do you think whats your intuition do you think if you just scale language modeling like significantly scale that reasoning can emerge from the same exact mechanisms i think its unlikely that if we just scale gpt2 that well have reasoning in the full fledged way and i think that theres like the type signatures a little bit wrong right that like theres something we do with that we call thinking right where we spend a lot of compute like a variable amount of compute to get to better answers right i think a little bit harder i get a better answer and that that kind of type signature isnt quite encoded in a gpt right gpt will kind of like its been a long time', 'the following is a conversation with elon musk hes the ceo of tesla spacex neuralink and a cofounder of several other companies this conversation is part of the artificial intelligence podcast the series includes leading researchers in academia and industry including ceos and ctos of automotive robotics ai and technology companies this conversation happened after the release of the paper from our group at mit on driver functional vigilance during use of teslas autopilot the tesla team reached out to me offering a podcast conversation with mr musk i accepted with full control of questions i could ask and the choice of what is released publicly i ended up editing out nothing of substance ive never spoken with elon before this conversation publicly or privately neither he nor his companies have any influence on my opinion nor on the rigor and integrity of the scientific method that i practice in my position at mit tesla has never financially supported my research and ive never owned a tesla vehicle and ive never owned tesla stock this podcast is not a scientific paper it is a conversation i respect elon as i do all other leaders and engineers ive spoken with we agree on some things and disagree on others my goal is always with these conversations is to understand the way the guest sees the world one particular point of disagreement in this conversation was the extent to which camera based driver monitoring will improve outcomes and for how long it will remain relevant for ai assisted driving as someone who works on and is fascinated by human centered artificial intelligence i believe that if implemented and integrated effectively camera based driver monitoring is likely to be of benefit in both the short term and the long term in contrast elon and teslas focus is on the improvement of autopilot such that its statistical safety benefits override any concern of human behavior and psychology elon and i may not agree on everything but i deeply respect the engineering and innovation behind the efforts that he leads my goal here is to catalyze a rigorous nuanced and objective discussion in industry and academia on ai assisted driving one that ultimately makes for a safer and better world and now heres my conversation with elon musk what was the vision the dream of autopilot when in the beginning the big picture system level when it was first conceived and started being installed in 2014 the hardware and the cars what was the vision the dream i wouldnt characterize the vision or dream simply that there are obviously two massive revolutions in in the automobile industry one is the transition to electrification and then the other is autonomy and it became obvious to me that in the future any car that does not have autonomy would be about as useful as a horse which is not to say that theres no use its just rare and somewhat idiosyncratic if somebody has a horse at this point its just obvious that cars will drive themselves completely its just a question of time and if we did not participate in the autonomy revolution then our cars would not be useful to people relative to cars that are autonomous i mean an autonomous car is arguably worth five to 10 times more than a car which is not autonomous in the long term turns out what you mean by long term but lets say at least for the next five years perhaps 10 years so there are a lot of very interesting design choices with autopilot early on first is showing on the instrument cluster or in the model 3 on the center stack display what the combined sensor suite sees what was the thinking behind that choice was there a debate what was the process the whole point of the display is to provide a health check on the vehicles perception of reality so the vehicles taking information from a bunch of sensors primarily cameras but also radar and ultrasonics gps and so forth and then that that information is then rendered into vector space and that you know with a bunch of objects with with properties like lane lines and traffic lights and other cars and then in vector space that is rerendered onto a display so you can confirm whether the car knows whats going on or not by looking out the window right i think thats an extremely powerful thing for people to get an understanding so it become one with the system and understanding what the system is capable of now have you considered showing more so if we look at the computer vision you know like road segmentation lane detection vehicle detection object detection underlying the system there is at the edges some uncertainty have you considered revealing the parts that the vehicle is in the parts that the the uncertainty in the system the sort of probabilities associated with with say image recognition or something like that yeah so right now it shows like the vehicles in the vicinity a very clean crisp image and people do confirm that theres a car in front of me and the system sees theres a car in front of me but to help people build an intuition of what computer vision is by showing some of the uncertainty well i think its in my car i always look at the sort of the debug view and theres theres two debug views uh one is augmented vision uh where which im sure youve seen where its basically we draw boxes and labels around objects that are recognized and then theres a work called the visualizer which is basically vector space representation summing up the input from all sensors that doesnt that doesnt does not show any pictures but it shows uh all of the its basically shows the cars view of of of the world in vector space um but i think this is very difficult for people to know normal people to understand they would not know what theyre looking at so its almost an hmi challenge to the current things that are being displayed is optimized for the general public understanding of what the system is capable of its like if you have no idea what how computer vision works or anything you can sort of look at the screen and see if the car knows whats going on and then if youre you know if youre a development engineer or if youre you know if youre if you have the development build like i do then you can see uh you know all the debug information but those would just be like total diverse to most people whats your view on how to best distribute effort so theres three i would say technical aspects of autopilot that are really important so its the underlying algorithms like the neural network architecture theres the data so that the strain on and then theres a hardware development there may be others but so look algorithm data hardware you dont you only have so much money only have so much time what do you think is the most important thing to to uh allocate resources to or do you see it as pretty evenly distributed between those three we automatically get a fast amounts of data because all of our cars have eight external facing cameras and radar and usually 12 ultrasonic sensors uh gps obviously um and uh imu and so we basically have a fleet that has uh and weve got about 400000 cars on the road that have that level of data i think you keep quite close track of it actually yes yeah so were were approaching half a million cars on the road that have the full sensor suite um so this is im im not sure how many other cars on the road have the sensor suite but i would be surprised if its more than 5000 which means that we have 99 of all the data so theres this huge inflow of data absolutely massive inflow of data and then we its its taken us about three years but now weve finally developed our full self driving computer which can process uh and in order of magnitude as much as the nvidia system that we currently have in the in the cars and its really just a to use it youve unplugged the nvidia computer and plug the tesla computer in and thats it and its its uh in fact were not even were still exploring the boundaries of capabilities uh but were able to run the cameras at full frame rate full resolution uh not even crop the images and its still got headroom even on one of the systems the harder full self driving computer is really two computers two systems on a chip that are fully redundant so you could put a bolt through basically any part of that system and it still works the redundancy are they perfect copies of each other or also its purely for redundancy as opposed to an argue machine kind of architecture where theyre both making decisions this is purely for redundancy i think it would more like its if you have a twin engine aircraft uh commercial aircraft the system will operate best if both systems are operating but its its capable of operating safely on one so but as it is right now we can just run were we havent even hit the the the edge of performance so theres no need to actually distribute functionality across both socs we can actually just run a full duplicate on on on each one do you havent really explored or hit the limit of this not yet at the limiter so the magic of deep learning is that it gets better with data you said theres a huge inflow of data but the thing about driving the really valuable data to learn from is the edge cases so how do you i mean ive ive heard you talk somewhere about uh autopilot disengagements being an important moment of time to use is there other edge cases where you can you know you can you can you can drive is there other edge cases or perhaps can you speak to those edge cases what aspects of that might be valuable or if you have other ideas how to discover more and more and more edge cases in driving well theres a lot of things that are learned there are certainly edge cases where i say somebody is on autopilot and they they take over and then okay that that that thats a trigger that goes to our system that says okay did they take over for convenience or do they take over because the autopilot wasnt working properly theres also like lets say were were trying to figure out what is the optimal spline for traversing an intersection um then then the ones where there are no interventions and are the right ones so you then say okay when it looks like this do the following and then and then you get the optimal spline for a complex uh navigating a complex uh intersection so thats for this so theres kind of the common case youre trying to uh capture a huge amount of samples of a particular intersection how when things went right and then theres the edge case where uh as you said not for convenience but something didnt go exactly right somebody took over somebody asserted manual control from autopilot and really like the way to look at this as view all input is error if the user had to do input it does something all input is error thats a powerful line thats a powerful line to think of it that way because they may very well be error but if you want to exit the highway or if you want to uh its a navigation decision that all autopilot is not currently designed to do then the driver takes over how do you know the difference thats going to change with navigate an autopilot which we were just released and without still confirm so the navigation like lane change based like a certain control in order to change do a lane change or exit a freeway or or doing a highway under change the vast majority of that will go away with um the release that just went out yeah so that that i dont think people quite understand how big of a step that is yeah they dont so if you drive the car then you do so you still have to keep your hands on the steering wheel currently when it does the automatic lane change what are so theres theres these big leaps through the development of autopilot through its history and what stands out to you as the big leaps i would say this one navigate an autopilot without uh confirm without having to confirm is a huge leap it is a huge leap it also automatically overtakes low cars so its its both navigation um and seeking the fastest lane so itll itll itll you know overtake a slow cause um and exit the freeway and take highway interchanges and and then uh we have uh traffic lights uh recognition which introduced initially as a as a warning i mean on the development version that im driving the car fully fully stops and goes at traffic lights so those are the steps right youve just mentioned something sort of inkling a step towards full autonomy what would you say are the biggest technological roadblocks to full self driving actually i dont think i think we just the full self driving computer that we just uh that the tesla what we call the fsd computer uh that thats now in production uh so if you order uh any model srx or any model three that has the full self driving package youll get the fsd computer that that was thats important to have enough uh base computation uh then refining the neural net and the control software uh which but all of that can just be provided as an over there update the thing thats really profound and where ill be emphasizing at the uh sort of what that investor day that were having focused on autonomy is that the cars currently being produced with the hardware currently being produced is capable of full self driving but capable is an interesting word because um like the hardware is and as we refine the software the capabilities will increase dramatically um and then the reliability will increase dramatically and then it will receive regulatory approval so essentially buying a car today is an investment in the future youre essentially buying a car youre buying the i think the most profound thing is that if you buy a tesla today i believe you are buying an appreciating asset not a depreciating asset so thats a really important statement there because if hardware is capable enough thats the hard thing to upgrade usually exactly so then the rest is a software problem yes software has no marginal cost really but whats your intuition on the software side how hard are the remaining steps to to get it to where um you know uh the the experience uh not just the safety but the full experience is something that people would uh enjoy well i think people enjoy it very much so on on on the highways its its a total game changer for quality of life for using you know tesla autopilot on the highways uh so its really just extending that functionality to city streets adding in the traffic light recognition uh navigating complex intersections and um and then uh being able to navigate complicated parking lots so the car can uh exit a parking space and come and find you even if its in a complete maze of a parking lot um and and and and then if and then you can just it can just drop you off and find a parking spot by itself yeah in terms of enjoyability and something that people would uh would actually find a lot of use from the parking lot is a is a really you know its its rich of annoyance when you have to do it manually so theres a lot of benefit to be gained from automation there so let me start injecting the human into this discussion a little bit uh so lets talk about uh the the the the the the the the the the about full autonomy if you look at the current level four vehicles being tested on road like waymo and so on theyre only technically autonomous theyre really level two systems with just the different design philosophy because theres always a safety driver in almost all cases and theyre monitoring the system right do you see teslas full self driving as still for a time to come requiring supervision of the human being so its capabilities are powerful enough to drive but nevertheless requires the human to still be supervising just like a safety driver is in a other fully autonomous vehicles i think it will require detecting hands on wheel for at least uh six months or something like that from here it really is a question of like from a regulatory standpoint uh what how much safer than a person does autopilot need to be for it to be okay to not monitor the car you know and and this is a debate that one can have it and then if you but you need you know a large sample a large amount of data um so you can prove with high confidence statistically speaking that the car is dramatically safer than a person um and that adding in the person monitoring does not materially affect the safety so it might need to be like two or 300 safer than a person and how do you prove that incidents per mile incidents per mile crashes and fatalities fatalities would be a factor but there there are just not enough fatalities to be statistically significant at scale but there are enough crashes you know there are far more crashes than there are fatalities so you can assess what is the probability of a crash that then theres another step which probability of injury and probability of permanent injury the probability of death and all of those need to be a much better than a person uh by at least perhaps 200 and you think theres uh the ability to have a healthy discourse with the regulatory bodies on this topic i mean theres no question that um but um regulators pay just disproportionate amount of attention to that which generates press this is just an objective fact um and tesla generates a lot of press so the you know in the united states this i think almost you know uh in the united states this i think almost 40000 automotive deaths per year uh but if there are four in tesla theyll probably receive a thousand times more press than anyone else so the the psychology of that is actually fascinating i dont think well have enough time to talk about that but i have to talk to you about the human side of things so myself and our team at mit recently released the paper on functional vigilance of drivers while using autopilot this is work weve been doing since autopilot was first released publicly over three years ago collecting video of driver faces and driver body so i saw that you tweeted a quote from the abstract so i can at least uh guess that youve glanced at it yeah i read it can i talk you through what we found sure okay so it appears that in the data that weve collected that drivers are maintaining functional vigilance such that were looking at 18000 disengagement from autopilot 18900 and annotating were they able to take over control in a timely manner so they were there present looking at the road uh to take over control okay so this uh goes against what what many would predict from the body of literature on vigilance with automation now the question is do you think these results hold across the broader population so ours is just a small subset do you think uh one of the criticism is that you know theres a small minority of drivers that may be highly responsible where their vigilance decrement would increase with autopilot use i think this is all really going to be swept i mean the systems improving so much so fast that this is going to be a mood point very soon where vigilance is like if somethings many times safer than a person then adding a person uh does the the the effect on safety is is limited um and in fact uh it could be negative thats really interesting so the uh the so the fact that a human may some percent of the population may uh exhibit a vigilance decrement will not affect overall statistics numbers of safety no in fact i think it will become uh very very quickly maybe even towards the end of this year but id say id be shocked if its not next year at the latest that um having the person having a human intervene will decrease safety decrease its like imagine if youre an elevator and it used to be that there were elevator operators um and and you couldnt go on an elevator by yourself and work the lever to move between floors um and now uh nobody wants it an elevator operator because the automated elevator that stops the floors is much safer than the elevator operator and in fact it would be quite dangerous to have someone with a lever that can move the elevator between floors so thats a thats a really powerful statement and really interesting one but i also have to ask from a user experience and from a safety perspective one of the passions for me algorithmically is a camera based detection of uh of just sensing the human but detecting what the driver is looking at cognitive load body pose on the computer vision side thats a fascinating problem but do you and theres many in industry believe you have to have camera based driver monitoring do you think there could be benefit gained from driver monitoring if you have a system thats thats at thats at or below a human level reliability then driver monitoring makes sense but if your system is dramatically better more likely to be better more liable than than a human then drive monitoring monitoring is not just not help much and uh like i said you you just like as an you wouldnt want someone into like you wouldnt want someone in the elevator if youre in an elevator do you really want someone with a big lever some some random person operating the elevator between floors i wouldnt trust that or rather have the buttons okay youre optimistic about the pace of improvement of the system that from what youve seen with the full self driving car computer the rate of improvement is exponential so one of the other very interesting design choices early on that connects to this is the operational design domain of autopilot so where autopilot is able to be turned on the so contrast another vehicle system that were studying is the cadillac supercrew system thats in terms of odd very constrained to particular kinds of highways well mapped tested but its much narrower than the odd of tesla vehicles whats theres theres pros and its like add yeah thats good thats a thats a good line uh what was the design decision uh what in that different philosophy of thinking where theres pros and cons what we see with uh a wide odd is drive tesla drivers are able to explore more the limitations of the system at least early on and they understand together with the instrument cluster display they start to understand what are the capabilities so thats a benefit the con is you go youre letting drivers use it basically anywhere so anyway that could detect lanes with confidence was there a philosophy uh design decisions that were challenging that were being made there or from the very beginning was that uh done on purpose with intent well i mean i think its frankly its pretty crazy giving it letting people drive a two ton death machine manually uh thats crazy like like in the future of people who are like i cant believe anyone was just allowed to drive for one of these two ton death machines and they just drive wherever they wanted just like elevators he was like move the elevator with that lever wherever you want it can stop at halfway between floors if you want its pretty crazy so its going to seem like a mad thing in the future that people were driving cars so i have a bunch of questions about the human psychology about behavior and so on that would become that because uh you have faith in the ai system uh not faith but uh the both on the hardware side and the deep learning approach of learning from data will make it just far safer than humans yeah exactly recently there are a few hackers who uh tricked autopilot to act in unexpected ways with adversarial examples so we all know that neural network systems are very sensitive to minor disturbances to these adversarial examples on input do you think its possible to defend against something like this for the broader for the industry sure so can you elaborate on the on the confidence behind that answer um well the you know neural net is just like a basic bunch of matrix math or you have to be like a very sophisticated somebody who really understands neural nets and like basically reverse engineer how the matrix is being built and then create a little thing thats just exactly um causes the matrix math to be slightly off but its very easy to then block it block that by by having basically anti negative recognition its like if you if the system sees something that looks like a matrix hack uh exclude it so its such an easy thing to do so learn both on the the valid data and the invalid data so basically learn on the adversarial examples to be able to exclude them yeah like you basically want to both know what is what is a car and what is definitely not a car and you train for this is a car and this is definitely not a car those are two different things people have no idea neural nets really they probably think neural nets are both like you know fishing net only so as you know so taking a step beyond just tesla and autopilot uh current deep learning approaches still seem in some ways to be far from general intelligence systems do you think the current approaches will take us to general intelligence or do totally new ideas need to be invented i think were missing a few key ideas for general intelligence general artificial general intelligence but its going to be upon us very quickly and then well need to figure out what shall we do if we even have that choice but its amazing how people cant differentiate between say the narrow ai that you know allows a car to figure out what a lane line is and and and you know and navigate streets versus general intelligence like these are just very different things like your toaster and your computer are both machines but ones much more sophisticated than another youre confident with tesla you can create the worlds best toaster the worlds best toaster yes the worlds best toaster yes the worlds best self driving im i yes to me right now this seems game set match i dont i mean that sounds i dont want to be complacent or overconfident but thats what it appears that is just literally what it how it appears right now i could be wrong but it appears to be the case that tesla is vastly ahead of everyone do you think we will ever create an ai system that we can love and loves us back in a deep meaningful way like in the movie her i think ai will be capable of convincing you to fall in love with it very well and thats different than us humans you know we start getting into a metaphysical question of like do emotions and thoughts exist in a different realm than the physical and maybe they do maybe they dont i dont know but from a physics standpoint i tend to think of things you know like physics was my main sort of training and from a physics standpoint essentially if it loves you in a way that is that you cant tell whether its real or not it is real thats a physics view of love yeah if theres no if you cannot just if you cannot prove that it does not if theres no if theres no test that you can apply that would make it allow you to tell the difference then there is no difference right and its similar to seeing our world as simulation there may not be a test to tell the difference between what the real world and the simulation and therefore from a physics perspective it might as well be the same thing yes and there may be ways to test whether its a simulation there might be im not saying there arent but you could certainly imagine that a simulation could correct that once an entity in the simulation found a way to detect the simulation it could either restart you know pause the simulation start a new simulation or do one of many other things that then corrects for that error so when maybe you or somebody else creates an agi system and you get to ask her one question what would that question be whats outside the simulation elon thank you so much for talking today it was a pleasure all right thank you', 'the following is a conversation with ian goodfellow hes the author of the popular textbook on deep learning simply titled deep learning he coined the term of generative adversarial networks otherwise known as gans and with his 2014 paper is responsible for launching the incredible growth of research and innovation in this subfield of deep learning he got his bs and ms at stanford his phd at university of montreal with yoshua bengio and aaron kerrville he held several research positions including at openai google brain and now at apple as the director of machine learning this recording happened while ian was still at google brain but we dont talk about anything specific to google or any other organization this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with ian goodfellow you open your popular deep learning book with a russian doll type diagram that shows deep learning is a subset of representation learning which in turn is a subset of machine learning and finally a subset of ai so this kind of implies that there may be limits to deep learning in the context of ai so what do you think is the current limits of deep learning and are those limits something that we can overcome with time yeah i think one of the biggest limitations of deep learning is that right now it requires really a lot of data especially labeled data there are some unsupervised and semi supervised learning algorithms that can reduce the amount of labeled data you need but they still require a lot of unlabeled data reinforcement learning algorithms they dont need labels but they need really a lot of experiences as human beings we dont learn to play pong by failing at pong 2 million times so just getting the generalization ability better is one of the most important bottlenecks in the capability of the technology today and then i guess id also say deep learning is like a component of a bigger system so far nobody is really proposing to have only what youd call deep learning as the entire ingredient of intelligence you use deep learning as sub modules of other systems like alphago has a deep learning model that estimates the value function most reinforcement learning algorithms have a deep learning module that estimates which action to take next but you might have other components so youre basically building a function estimator do you think its possible you said nobodys kind of been thinking about this so far but do you think neural networks could be made to reason in the way symbolic systems did in the 80s and 90s to do more create more like programs as opposed to functions yeah i think we already see that a little bit i already kind of think of neural nets as a kind of program i think of deep learning as basically learning programs that have more than one step so if you draw a flow chart or if you draw a tensorflow graph describing your machine learning model i think of the depth of that graph as describing the number of steps that run in sequence and then the width of that graph is the number of steps that run in parallel now its been long enough that weve had deep learning working that its a little bit silly to even discuss shallow learning anymore but back when i first got involved in ai when we used machine learning we were usually learning things like support vector machines you could have a lot of input features to the model and you could multiply each feature by a different weight all those multiplications were done in parallel to each other there wasnt a lot done in series i think what we got with deep learning was really the ability to have steps of a program that run in sequence and i think that weve actually started to see that whats important with deep learning is more the fact that we have a multi step program rather than the fact that weve learned a representation if you look at things like resonance for example they take one particular kind of representation and they update it several times back when deep learning first really took off in the academic world in 2006 when jeff hinton showed that you could train deep belief networks everybody who was interested in the idea thought of it as each layer learns a different level of abstraction that the first layer trained on images learns something like edges and the second layer learns corners and eventually you get these kind of grandmother cell units that recognize specific objects today i think most people think of it more as a computer program where as you add more layers you can do more updates before you output your final number but i dont think anybody believes that layer 150 of the resnet is a grandmother cell and layer 100 is contours or something like that okay so youre not thinking of it as a singular representation that keeps building you think of it as a program sort of almost like a state representation is a state of understanding yeah i think of it as a program that makes several updates and arrives at better and better understandings but its not replacing the representation at each step its refining it and in some sense thats a little bit like reasoning its not reasoning in the form of deduction but its reasoning in the form of taking a thought and refining it and refining it carefully until its good enough to use so do you think and i hope you dont mind well jump philosophical every once in a while do you think of cognition human cognition or even consciousness as simply a result of this kind of sequential representation learning do you think that can emerge cognition yes i think so consciousness its really hard to even define what we mean by that i guess theres consciousness is often defined as things like having self awareness and thats relatively easy to turn into something actionable for a computer scientist to reason about people also define consciousness in terms of having qualitative states of experience like qualia and theres all these philosophical problems like could you imagine a zombie who does all the same information processing as a human but doesnt really have the qualitative experiences that we have that sort of thing i have no idea how to formalize or turn it into a scientific question i dont know how you could run an experiment to tell whether a person is a zombie or not and similarly i dont know how you could run an experiment to tell whether an advanced ai system had become conscious in the sense of qualia or not but in the more practical sense like almost like self attention you think consciousness and cognition can in an impressive way emerge from current types of architectures that we think of as learning or if you think of consciousness in terms of self awareness and just making plans based on the fact that the agent itself exists in the world reinforcement learning algorithms are already more or less forced to model the agents effect on the environment so that more limited version of consciousness is already something that we get limited versions of with reinforcement learning algorithms if theyre trained well but you say limited so the big question really is how you jump from limited to human level right and whether its possible even just building common sense reasoning seems to be exceptionally difficult so if we scale things up if we get much better on supervised learning if we get better at labeling if we get bigger data sets more compute do you think well start to see really impressive things that go from limited to something echoes of human level cognition i think so yeah im optimistic about what can happen just with more computation and more data i do think itll be important to get the right kind of data today most of the machine learning systems we train are mostly trained on one type of data for each model but the human brain we get all of our different senses and we have many different experiences like riding a bike driving a car talking to people reading i think when we get that kind of integrated data set working with a machine learning model that can actually close the loop and interact we may find that algorithms not so different from what we have today learn really interesting things when you scale them up a lot and train them on a large amount of multimodal data so multimodal is really interesting but within like youre working adversarial examples so selecting within modal within one mode of data selecting better at what are the difficult cases from which youre most useful to learn from oh yeah like could we get a whole lot of mileage out of designing a model thats resistant to adversarial examples or something like that right thats the question my thinking on that has evolved a lot over the last few years when i first started to really invest in studying adversarial examples i was thinking of it mostly as adversarial examples reveal a big problem with machine learning and we would like to close the gap between how machine learning models respond to adversarial examples and how humans respond after studying the problem more i still think that adversarial examples are important i think of them now more of as a security liability than as an issue that necessarily shows theres something uniquely wrong with machine learning as opposed to humans also do you see them as a tool to improve the performance of the system not on the security side but literally just accuracy i do see them as a kind of tool on that side but maybe not quite as much as i used to think weve started to find that theres a trade off between accuracy on adversarial examples and accuracy on clean examples back in 2014 when i did the first adversarily trained classifier that showed resistance to some kinds of adversarial examples it also got better at the clean data on mnist and thats something weve replicated several times on mnist that when we train against weak adversarial examples mnist classifiers get more accurate so far that hasnt really held up on other data sets and hasnt held up when we train against stronger adversaries it seems like when you confront a really strong adversary you tend to have to give something up interesting but its such a compelling idea because it feels like thats how us humans learn is through the difficult cases we try to think of what would we screw up and then we make sure we fix that its also in a lot of branches of engineering you do a worst case analysis and make sure that your system will work in the worst case and then that guarantees that itll work in all of the messy average cases that happen when you go out into a really randomized world yeah with driving with autonomous vehicles there seems to be a desire to just look for think adversarially try to figure out how to mess up the system and if you can be robust to all those difficult cases then you can its a hand wavy empirical way to show your system is safe today most adversarial example research isnt really focused on a particular use case but there are a lot of different use cases where youd like to make sure that the adversary cant interfere with the operation of your system like in finance if you have an algorithm making trades for you people go to a lot of an effort to obfuscate their algorithm thats both to protect their ip because you dont want to research and develop a profitable trading algorithm then have somebody else capture the gains but its at least partly because you dont want people to make adversarial examples that fool your algorithm into making bad trades or i guess one area thats been popular in the academic literature is speech recognition if you use speech recognition to hear an audio wave form and then turn that into a command that a phone executes for you you dont want a malicious adversary to be able to produce audio that gets interpreted as malicious commands especially if a human in the room doesnt realize that something like that is happening and speech recognition has there been much success in being able to create adversarial examples that fool the system yeah actually i guess the first work that im aware of is a paper called hidden voice commands that came out in 2016 i believe and they were able to show that they could make sounds that are not understandable by a human but are recognized as the target phrase that the attacker wants the phone to recognize it as since then things have gotten a little bit better on the attackers side when worse on the defenders side its become possible to make sounds that sound like normal speech but are actually interpreted as a different sentence than the human hears the level of perceptibility of the adversarial perturbation is still kind of high when you listen to the recording it sounds like theres some noise in the background just like rustling sounds but those rustling sounds are actually the adversarial perturbation that makes the phone hear a completely different sentence yeah thats so fascinating peter norvig mentioned that youre writing the deep learning chapter for the fourth edition of the artificial intelligence a modern approach book so how do you even begin summarizing the field of deep learning in a chapter well in my case i waited like a year before i actually wrote anything even having written a full length textbook before its still pretty intimidating to try to start writing just one chapter that covers everything one thing that helped me make that plan was actually the experience of having written the full book before and then watching how the field changed after the book came out ive realized theres a lot of topics that were maybe extraneous in the first book and just seeing what stood the test of a few years of being published and what seems a little bit less important to have included now helped me pare down the topics i wanted to cover for the book its also really nice now that the field is kind of stabilized to the point where some core ideas from the 1980s are still used today when i first started studying machine learning almost everything from the 1980s had been rejected and now some of it has come back so that stuff thats really stood the test of time is what i focused on putting into the book theres also i guess two different philosophies about how you might write a book one philosophy is you try to write a reference that covers everything the other philosophy is you try to provide a high level summary that gives people the language to understand a field and tells them what the most important concepts are the first deep learning book that i wrote with joshua and aaron was somewhere between the two philosophies that its trying to be both a reference and an introductory guide writing this chapter for russell norvigs book i was able to focus more on just a concise introduction of the key concepts and the language you need to read about them more in a lot of cases i actually just wrote paragraphs that said heres a rapidly evolving area that you should pay attention to its pointless to try to tell you what the latest and best version of a learn to learn model is i can point you to a paper thats recent right now but there isnt a whole lot of a reason to delve into exactly whats going on with the latest learning to learn approach or the latest module produced by a learning to learn algorithm you should know that learning to learn is a thing and that it may very well be the source of the latest and greatest convolutional net or recurrent net module that you would want to use in your latest project but there isnt a lot of point in trying to summarize exactly which architecture and which learning approach got to which level of performance so you maybe focus more on the basics of the methodology so from back propagation to feed forward to recurrent neural networks convolutional that kind of thing yeah yeah so if i were to ask you i remember i took algorithms and data structures algorithms course i remember the professor asked what is an algorithm and yelled at everybody in a good way that nobody was answering it correctly everybody knew what the algorithm it was graduate course everybody knew what an algorithm was but they werent able to answer it well so let me ask you in that same spirit what is deep learning i would say deep learning is any kind of machine learning that involves learning parameters of more than one consecutive step so that i mean shallow learning is things where you learn a lot of operations that happen in parallel you might have a system that makes multiple steps like you might have hand designed feature extractors but really only one step is learned deep learning is anything where you have multiple operations in sequence and that includes the things that are really popular today like convolutional networks and recurrent networks but it also includes some of the things that have died out like bolton machines where we werent using back propagation today i hear a lot of people define deep learning as gradient descent applied to these differentiable functions and i think thats a legitimate usage of the term its just different from the way that i use the term myself so whats an example of deep learning that is not gradient descent and differentiable functions in your i mean not specifically perhaps but more even looking into the future whats your thought about that space of approaches yeah so i tend to think of machine learning algorithms as decomposed into really three different pieces theres the model which can be something like a neural net or a bolton machine or a recurrent model and that basically just describes how do you take data and how do you take parameters and what function do you use to make a prediction given the data and the parameters another piece of the learning algorithm is the optimization algorithm or not every algorithm can be really described in terms of optimization but whats the algorithm for updating the parameters or updating whatever the state of the network is and then the last part is the data set like how do you actually represent the world as it comes into your machine learning system so i think of deep learning as telling us something about what does the model look like and basically to qualify as deep i say that it just has to have multiple layers that can be multiple steps in a feed forward differentiable computation that can be multiple layers in a graphical model theres a lot of ways that you could satisfy me that something has multiple steps that are each parameterized separately i think of gradient descent as being all about that other piece right now we all talk a lot about how interpretable different machine learning algorithms are but its really just peoples opinion and everybody probably has a different idea of what interpretability means in their head if we could define some concept related to interpretability thats actually measurable that would be a huge leap forward even without a new algorithm that increases that quantity and also once we had the definition of differential privacy it was fast to get the algorithms that guaranteed it so you could imagine once we have definitions of good concepts and interpretability we might be able to provide the algorithms that have the interpretability guarantees quickly too so what do you think it takes to build a system with human level intelligence as we quickly venture into the philosophical so artificial general intelligence what do you think it takes i think that it definitely takes better environments than we currently have for training agents that we want them to have a really wide diversity of experiences i also think its gonna take really a lot of computation its hard to imagine exactly how much so youre optimistic about simulation simulating a variety of environments as the path forward i think its a necessary ingredient yeah i dont think that were going to get to artificial general intelligence by training on fixed data sets or by thinking really hard about the problem i think that the agent really needs to interact and have a variety of experiences within the same lifespan and today we have many different models that can each do one thing and we tend to train them on one data set or one rl environment sometimes there are actually papers about getting one set of parameters to perform well in many different rl environments but we dont really have anything like an agent that goes seamlessly from one type of experience to another and really integrates all the different things that it does over the course of its life when we do see multi agent environments they tend to be or so many multi environment agents they tend to be similar environments like all of them are playing like an action based video game we dont really have an agent that goes from playing a video game to like reading the wall street journal to predicting how effective a molecule will be as a drug or something like that what do you think is a good test for intelligence in your view theres been a lot of benchmarks started with the with alan turing natural conversation being a good benchmark for intelligence what would ian goodfellow sit back and be really damn impressed if a system was able to accomplish something that doesnt take a lot of glue from human engineers so imagine that instead of having to go to the cifar website and download cifar 10 and then write a python script to parse it and all that you could just point an agent at the cifar 10 problem and it downloads and extracts the data and trains a model and starts giving you predictions i feel like something that doesnt need to have every step of the pipeline assembled for it definitely understands what its doing is automl moving into that direction or are you thinking way even bigger automl has mostly been moving toward once weve built all the glue can the machine learning system design the architecture really well and so im more of saying like if something knows how to pre process the data so that it successfully accomplishes the task then it would be very hard to argue that it doesnt truly understand the task in some fundamental sense and i dont necessarily know that thats like the philosophical definition of intelligence but thats something that would be really cool to build that would be really useful and would impress me and would convince me that weve made a step forward in real ai so you give it like the url for wikipedia and then next day expect it to be able to solve cifar 10 or like you type in a paragraph explaining what you want it to do and it figures out what web searches it should run and downloads all the necessary ingredients so you have a very clear calm way of speaking no ums easy to edit ive seen comments for both you and i have been identified as both potentially being robots if you have to prove to the world that you are indeed human how would you do it i can understand thinking that im a robot its the flip side of the turing test i think yeah yeah the prove your human test intellectually so you have to is there something thats truly unique in your mind does it go back to just natural language again just being able to talk the way out of it proving that im not a robot with todays technology yeah thats pretty straightforward like my conversation today hasnt veered off into talking about the stock market or something because of my training data but i guess more generally trying to prove that something is real from the content alone is incredibly hard thats one of the main things ive gotten out of my gan research that you can simulate almost anything and so you have to really step back to a separate channel to prove that something is real so like i guess i should have had myself stamped on a blockchain when i was born or something but i didnt do that so according to my own research methodology theres just no way to know at this point so what last question problem stands out for you that youre really excited about challenging in the near future so i think resistance to adversarial examples figuring out how to make machine learning secure against an adversary who wants to interfere and control it that is one of the most important things researchers today could solve in all domains image language driving and everything i guess im most concerned about domains we havent really encountered yet like imagine 20 years from now when were using advanced ais to do things we havent even thought of yet like if you ask people what are the important problems in security of phones in like 2002 i dont think we would have anticipated that were using them for nearly as many things as were using them for today i think its gonna be like that with ai that you can kind of try to speculate about where its going but really the business opportunities that end up taking off would be hard to predict ahead of time what you can predict ahead of time is that almost anything you can do with machine learning you would like to make sure that people cant get it to do what they want rather than what you want just by showing it a funny qr code or a funny input pattern and you think that the set of methodology to do that can be bigger than any one domain i think so yeah yeah like one methodology that i think is not a specific methodology but like a category of solutions that im excited about today is making dynamic models that change every time they make a prediction so right now we tend to train models and then after theyre trained we freeze them and we just use the same rule to classify everything that comes in from then on thats really a sitting duck from a security point of view if you always output the same answer for the same input then people can just run inputs through until they find a mistake that benefits them and then they use the same mistake over and over and over again i think having a model that updates its predictions so that its harder to predict what youre gonna get will make it harder for an adversary to really take control of the system and make it do what they want it to do yeah models that maintain a bit of a sense of mystery about them because they always keep changing ian thanks so much for talking today it was awesome thank you for coming in its great to see you the how do you actually update the parameters piece so you could imagine having a deep model like a convolutional net and training it with something like evolution or a genetic algorithm and i would say that still qualifies as deep learning and then in terms of models that arent necessarily differentiable i guess bolton machines are probably the main example of something where you cant really take a derivative and use that for the learning process but you can still argue that the model has many steps of processing that it applies when you run inference in the model so its the steps of processing thats key so jeff hinton suggests that we need to throw away back propagation and start all over what do you think about that what could an alternative direction of training neural networks look like i dont know that back propagation is gonna go away entirely most of the time when we decide that a machine learning algorithm isnt on the critical path to research for improving ai the algorithm doesnt die it just becomes used for some specialized set of things a lot of algorithms like logistic regression dont seem that exciting to ai researchers who are working on things like speech recognition or autonomous cars today but theres still a lot of use for logistic regression and things like analyzing really noisy data in medicine and finance or making really rapid predictions in really time limited contexts so i think back propagation and gradient descent are around to stay but they may not end up being everything that we need to get to real human level or super human ai are you optimistic about us discovering back propagation has been around for a few decades so are you optimistic about us as a community being able to discover something better yeah i am i think we likely will find something that works better you could imagine things like having stacks of models where some of the lower level models predict parameters of the higher level models and so at the top level youre not learning in terms of literally calculating gradients but just predicting how different values will perform you can kind of see that already in some areas like bayesian optimization where you have a gaussian process that predicts how well different parameter values will perform we already use those kinds of algorithms for things like hyper parameter optimization and in general we know a lot of things other than back prop that work really well for specific problems the main thing we havent found is a way of taking one of these other non back prop based algorithms and having it really advanced the state of the art on an ai level problem right but i wouldnt be surprised if eventually we find that some of these algorithms that even the ones that already exist not even necessarily new one we might find some way of customizing one of these algorithms to do something really interesting at the level of cognition or the level of i think one system that we really dont have working quite right yet is like short term memory we have things like lstms theyre called long short term memory they still dont do quite what a human does with short term memory like gradient descent to learn a specific fact has to do multiple steps on that fact like if i tell you the meeting today is at 3 pm i dont need to say over and over again its at 3 pm its at 3 pm its at 3 pm its at 3 pm for you to do a gradient step on each one you just hear it once and you remember it theres been some work on things like self attention and attention like mechanisms like the neural turing machine that can write to memory cells and update themselves with facts like that right away but i dont think weve really nailed it yet and thats one area where id imagine that new optimization algorithms or different ways of applying existing optimization algorithms could give us a way of just lightning fast updating the state of a machine learning system to contain a specific fact like that without needing to have it presented over and over and over again so some of the success of symbolic systems in the 80s is they were able to assemble these kinds of facts better but theres a lot of expert input required and its very limited in that sense do you ever look back to that as something that well have to return to eventually sort of dust off the book from the shelf and think about how we build knowledge representation knowledge base like will we have to use graph searches graph searches right and like first order logic and entailment and things like that that kind of thing yeah exactly in my particular line of work which has mostly been machine learning security and also generative modeling i havent usually found myself moving in that direction for generative models i could see a little bit of it could be useful if you had something like a differentiable knowledge base or some other kind of knowledge base where its possible for some of our fuzzier machine learning algorithms to interact with a knowledge base i mean your network is kind of like that its a differentiable knowledge base of sorts yeah but if we had a really easy way of giving feedback to machine learning models that would clearly help a lot with generative models and so you could imagine one way of getting there would be get a lot better at natural language processing but another way of getting there would be take some kind of knowledge base and figure out a way for it to actually interact with a neural network being able to have a chat with a neural network yeah so like one thing in generative models we see a lot today is youll get things like faces that are not symmetrical like people that have two eyes that are different colors i mean there are people with eyes that are different colors in real life but not nearly as many of them as you tend to see in the machine learning generated data so if you had either a knowledge base that could contain the fact peoples faces are generally approximately symmetric and eye color is especially likely to be the same on both sides being able to just inject that hint into the machine learning model without it having to discover that itself after studying a lot of data would be a really useful feature i could see a lot of ways of getting there without bringing back some of the 1980s technology but i also see some ways that you could imagine extending the 1980s technology to play nice with neural nets and have it help get there awesome so you talked about the story of you coming up with the idea of gans at a bar with some friends you were arguing that this you know gans would work generative adversarial networks and the others didnt think so then you went home at midnight coded it up and it worked so if i was a friend of yours at the bar i would also have doubts its a really nice idea but im very skeptical that it would work what was the basis of their skepticism what was the basis of your intuition why it should work i dont want to be someone who goes around promoting alcohol for the purposes of science but in this case i do actually think that drinking helped a little bit when your inhibitions are lowered youre more willing to try out things that you wouldnt try out otherwise so i have noticed in general that im less prone to shooting down some of my own ideas when i have had a little bit to drink i think if i had had that idea at lunchtime i probably would have thought its hard enough to train one neural net you cant train a second neural net in the inner loop of the outer neural net that was basically my friends objection was that trying to train two neural nets at the same time would be too hard so it was more about the training process unless so my skepticism would be you know im sure you could train it but the thing it would converge to would not be able to generate anything reasonable any kind of reasonable realism yeah so part of what all of us were thinking about when we had this conversation was deep bolton machines which a lot of us in the lab including me were a big fan of deep bolton machines at the time they involved two separate processes running at the same time one of them is called the positive phase where you load data into the model and tell the model to make the data more likely the other one is called the negative phase where you draw samples from the model and tell the model to make those samples less likely in a deep bolton machine its not trivial to generate a sample you have to actually run an iterative process that gets better and better samples coming closer and closer to the distribution the model represents so during the training process youre always running these two systems at the same time one thats updating the parameters of the model and another one thats trying to generate samples from the model and they worked really well in things like mnist but a lot of us in the lab including me had tried to get deep bolton machines to scale past mnist to things like generating color photos and we just couldnt get the two processes to stay synchronized so when i had the idea for gans a lot of people thought that the discriminator would have more or less the same problem as the negative phase in the bolton machine that trying to train the discriminator in the inner loop you just couldnt get it to keep up with the generator in the outer loop and that would prevent it from converging to anything useful yeah i share that intuition yeah but turns out to not be the case a lot of the time with machine learning algorithms its really hard to predict ahead of time how well theyll actually perform you have to just run the experiment and see what happens and i would say i still today dont have like one factor i can put my finger on and say this is why gans worked for photo generation and deep bolton machines dont there are a lot of theory papers showing that under some theoretical settings the gan algorithm does actually converge but those settings are restricted enough that they dont necessarily explain the whole picture in terms of all the results that we see in practice so taking a step back can you in the same way as we talked about deep learning can you tell me what generative adversarial networks are yeah so generative adversarial networks are a particular kind of generative model a generative model is a machine learning model that can train on some set of data like so you have a collection of photos of cats and you want to generate more photos of cats or you want to estimate a probability distribution over cats so you can ask how likely it is that some new image is a photo of a cat gans are one way of doing this some generative models are good at creating new data other generative models are good at estimating that density function and telling you how likely particular pieces of data are to come from the same distribution as the training data gans are more focused on generating samples rather than estimating the density function there are some kinds of gans like flowgan that can do both but mostly gans are about generating samples generating new photos of cats that look realistic and they do that completely from scratch its analogous to human imagination when a gan creates a new image of a cat its using a neural network to produce a cat that has not existed before it isnt doing something like compositing photos together youre not literally taking the eye off of one cat and the ear off of another cat its more of this digestive process where the neural net trains in a lot of data and comes up with some representation of the probability distribution and generates entirely new cats there are a lot of different ways of building a generative model whats specific to gans is that we have a two player game in the game theoretic sense and as the players in this game compete one of them becomes able to generate realistic data the first player is called the generator it produces output data such as just images for example and at the start of the learning process itll just produce completely random images the other player is called the discriminator the discriminator takes images as input and guesses whether theyre real or fake you train it both on real data so photos that come from your training set actual photos of cats and you train it to say that those are real you also train it on images that come from the generator network and you train it to say that those are fake as the two players compete in this game the discriminator tries to become better at recognizing whether images are real or fake and the generator becomes better at fooling the discriminator into thinking that its outputs are real and you can analyze this through the language of game theory and find that theres a nash equilibrium where the generator has captured the correct probability distribution so in the cat example it makes perfectly realistic cat photos and the discriminator is unable to do better than random guessing because all the samples coming from both the data and the generator look equally likely to have come from either source so do you ever sit back and does it just blow your mind that this thing works so from very so its able to estimate that density function enough to generate realistic images i mean does it yeah do you ever sit back and think how does this even why this is quite incredible especially where gans have gone in terms of realism yeah and not just to flatter my own work but generative models all of them have this property that if they really did what we ask them to do they would do nothing but memorize the training data right exactly models that are based on maximizing the likelihood the way that you obtain the maximum likelihood for a specific training set is you assign all of your probability mass to the training examples and nowhere else for gans the game is played using a training set so the way that you become unbeatable in the game is you literally memorize training examples one of my former interns wrote a paper his name is vaishnav nagarajan and he showed that its actually hard for the generator to memorize the training data hard in a statistical learning theory sense that you can actually create reasons for why it would require quite a lot of learning steps and a lot of observations of different latent variables before you could memorize the training data that still doesnt really explain why when you produce samples that are new why do you get compelling images rather than just garbage thats different from the training set and i dont think we really have a good answer for that especially if you think about how many possible images are out there and how few images the generative model sees during training it seems just unreasonable that generative models create new images as well as they do especially considering that were basically training them to memorize rather than generalize i think part of the answer is theres a paper called deep image prior where they show that you can take a convolutional net and you dont even need to learn the parameters of it at all you just use the model architecture and its already useful for things like inpainting images i think that shows us that the convolutional network architecture captures something really important about the structure of images and we dont need to actually use the learning to capture all the information coming out of the convolutional net that would imply that it would be much harder to make generative models in other domains so far were able to make reasonable speech models and things like that but to be honest we havent actually explored a whole lot of different data sets all that much we dont for example see a lot of deep learning models of like biology data sets where you have lots of microarrays measuring the amount of different enzymes and things like that so we may find that some of the progress that weve seen for images and speech turns out to really rely heavily on the model architecture and we were able to do what we did for vision by trying to reverse engineer the human visual system and maybe itll turn out that we cant just use that same trick for arbitrary kinds of data right so theres aspect to the human vision system the hardware of it that makes it without learning without cognition just makes it really effective at detecting the patterns we see in the visual world yeah yeah thats really interesting what in a big quick overview in your view what types of gans are there and what other generative models besides gans are there yeah so its maybe a little bit easier to start with what kinds of generative models are there other than gans so most generative models are likelihood based where to train them you have a model that tells you how much probability it assigns to a particular example and you just maximize the probability assigned to all the training examples it turns out that its hard to design a model that can create really complicated images or really complicated audio waveforms and still have it be possible to estimate the likelihood function from a computational point of view most interesting models that you would just write down intuitively it turns out that its almost impossible to calculate the amount of probability they assign to a particular point so theres a few different schools of generative models in the likelihood family one approach is to very carefully design the model so that it is computationally tractable to measure the density it assigns to a particular point so there are things like autoregressive models like pixelcnn those basically break down the probability distribution into a product over every single feature so for an image you estimate the probability of each pixel given all of the pixels that came before it theres tricks where if you want to measure the density function you can actually calculate the density for all these pixels more or less in parallel generating the image still tends to require you to go one pixel at a time and that can be very slow but there are again tricks for doing this in a hierarchical pattern where you can keep the runtime under control are the quality of the images it generates putting runtime aside pretty good theyre reasonable yeah i would say a lot of the best results are from gans these days but it can be hard to tell how much of that is based on whos studying which type of algorithm if that makes sense the amount of effort invested in a particular yeah or like the kind of expertise so a lot of people whove traditionally been excited about graphics or art and things like that have gotten interested in gans and to some extent its hard to tell are gans doing better because they have a lot of graphics and art experts behind them or are gans doing better because theyre more computationally efficient or are gans doing better because they prioritize the realism of samples over the accuracy of the density function i think all of those are potentially valid explanations and its hard to tell so can you give a brief history of gans from 2014 were you paper 13 yeah so a few highlights in the first paper we just showed that gans basically work if you look back at the samples we had now they look terrible on the cifar 10 data set you cant even recognize objects in them your paper sorry you used cifar 10 we used mnist which is little handwritten digits we used the toronto face database which is small grayscale photos of faces we did have recognizable faces my colleague bing xu put together the first gan face model for that paper we also had the cifar 10 data set which is things like very small 32 by 32 pixels of cars and cats and dogs for that we didnt get recognizable objects but all the deep learning people back then were really used to looking at these failed samples and kind of reading them like tea leaves and people who are used to reading the tea leaves recognize that our tea leaves at least look different maybe not necessarily better but there was something unusual about them and that got a lot of us excited one of the next really big steps was lapgan by emily denton and sumit chintala at facebook ai research where they actually got really good high resolution photos working with gans for the first time they had a complicated system where they generated the image starting at low res and then scaling up to high res but they were able to get it to work and then in 2015 i believe later that same year alec radford and sumit chintala and luke metz published the dcgan paper which it stands for deep convolutional gan its kind of a non unique name because these days basically all gans and even some before that were deep and convolutional but they just kind of picked a name for a really great recipe where they were able to actually using only one model instead of a multi step process actually generate realistic images of faces and things like that that was sort of like the beginning of the cambrian explosion of gans like once you had animals that had a backbone you suddenly got lots of different versions of fish and four legged animals and things like that so dcgan became kind of the backbone for many different models that came out its used as a baseline even still yeah yeah and so from there i would say some interesting things weve seen are theres a lot you can say about how just the quality of standard image generation gans has increased but whats also maybe more interesting on an intellectual level is how the things you can use gans for has also changed one thing is that you can use them to learn classifiers without having to have class labels for every example in your training set so thats called semi supervised learning my colleague at openai tim solomons whos at brain now wrote a paper called improve techniques for training gans im a coauthor on this paper but i cant claim any credit for this particular part one thing he showed in the paper is that you can take the gan discriminator and use it as a classifier that actually tells you this image is a cat this image is a dog this image is a car this image is a truck and so on not just to say whether the image is real or fake but if it is real to say specifically what kind of object it is and he found that you can train these classifiers with far fewer labeled examples than traditional classifiers so if you supervise based on also not just your discrimination ability but your ability to classify youre going to do much youre going to converge much faster to being effective at being a discriminator yeah so for example for the mnist dataset you want to look at an image of a handwritten digit and say whether its a zero a one or a two and so on to get down to less than 1 accuracy required around 60000 examples until maybe about 2014 or so in 2016 with this semi supervised gan project tim was able to get below 1 error using only 100 labeled examples so that was about a 600x decrease in the amount of labels that he needed hes still using more images than that but he doesnt need to have each of them labeled as this ones a one this ones a two this ones a zero and so on then to be able to for gans to be able to generate recognizable objects so objects from a particular class you still need labeled data because you need to know what it means to be a particular class cat dog how do you think we can move away from that yeah some researchers at brain zurich actually just released a really great paper on semi supervised gans where their goal isnt to classify its to make recognizable objects despite not having a lot of labeled data they were working off of deepminds biggan project and they showed that they can match the performance of biggan using only 10 i believe of the labels biggan was trained on the imagenet data set which is about 12 million images and had all of them labeled this latest project from brain zurich shows that theyre able to get away with only having about 10 of the images labeled and they do that essentially using a clustering algorithm where the discriminator learns to assign the objects to groups and then this understanding that objects can be grouped into similar types helps it to form more realistic ideas of what should be appearing in the image because it knows that every image it creates has to come from one of these archetypal groups rather than just being some arbitrary image if you train a gan with no class labels you tend to get things that look sort of like grass or water or brick or dirt but without necessarily a lot going on in them and i think thats partly because if you look at a large imagenet image the object doesnt necessarily occupy the whole image and so you learn to create realistic sets of pixels but you dont necessarily learn that the object is the star of the show and you want it to be in every image you make yeah ive heard you talk about the horse the zebra cycle gan mapping and how it turns out again thought provoking that horses are usually on grass and zebras are usually on drier terrain so when youre doing that kind of generation youre going to end up generating greener horses or whatever so those are connected together its not just youre not able to segment be able to generate in a segment away so are there other types of games you come across in your mind that neural networks can play with each other to be able to solve problems yeah the one that i spend most of my time on is in security you can model most interactions as a game where theres attackers trying to break your system and youre the defender trying to build a resilient system theres also domain adversarial learning which is an approach to domain adaptation that looks really a lot like gans the authors had the idea before the gan paper came out their paper came out a little bit later and theyre very nice and cited the gan paper but i know that they actually had the idea before it came out domain adaptation is when you want to train a machine learning model in one setting called a domain and then deploy it in another domain later and you would like it to perform well in the new domain even though the new domain is different from how it was trained so for example you might want to train on a really clean image data set like imagenet but then deploy on users phones where the user is taking pictures in the dark and pictures while moving quickly and just pictures that arent really centered or composed all that well when you take a normal machine learning model it often degrades really badly when you move to the new domain because it looks so different from what the model was trained on domain adaptation algorithms try to smooth out that gap and the domain adversarial approach is based on training a feature extractor where the features have the same statistics regardless of which domain you extracted them on so in the domain adversarial game you have one player thats a feature extractor and another player thats a domain recognizer the domain recognizer wants to look at the output of the feature extractor and guess which of the two domains the features came from so its a lot like the real versus fake discriminator in gans and then the feature extractor you can think of as loosely analogous to the generator in gans except what its trying to do here is both fool the domain recognizer into not knowing which domain the data came from and also extract features that are good for classification so at the end of the day in the cases where it works out you can actually get features that work about the same in both domains sometimes this has a drawback where in order to make things work the same in both domains it just gets worse at the first one but there are a lot of cases where it actually works out well on both so do you think of gans being useful in the context of data augmentation yeah one thing you could hope for with gans is you could imagine ive got a limited training set and id like to make more training data to train something else like a classifier you could train the gan on the training set and then create more data and then maybe the classifier would perform better on the test set after training on this bigger gan generated data set so thats the simplest version of something you might hope would work ive never heard of that particular approach working but i think theres some closely related things that i think could work in the future and some that actually already have worked so if we think a little bit about what wed be hoping for if we use the gan to make more training data were hoping that the gan will generalize to new examples better than the classifier would have generalized if it was trained on the same data and i dont know of any reason to believe that the gan would generalize better than the classifier would but what we might hope for is that the gan could generalize differently from a specific classifier so one thing i think is worth trying that i havent personally tried but someone could try is what if you trained a whole lot of different generative models on the same training set create samples from all of them and then train a classifier on that because each of the generative models might generalize in a slightly different way they might capture many different axes of variation that one individual model wouldnt and then the classifier can capture all of those ideas by training in all of their data so itd be a little bit like making an ensemble of classifiers and i think that ensemble of gans in a way i think that could generalize better the other thing that gans are really good for is not necessarily generating new data thats exactly like what you already have but by generating new data that has different properties from the data you already had one thing that you can do is you can create differentially private data so suppose that you have something like medical records and you dont want to train a classifier on the medical records and then publish the classifier because someone might be able to reverse engineer some of the medical records you trained on theres a paper from casey greens lab that shows how you can train a gan using differential privacy and then the samples from the gan still have the same differential privacy guarantees as the parameters of the gan so you can make fake patient data for other researchers to use and they can do almost anything they want with that data because it doesnt come from real people and the differential privacy mechanism gives you clear guarantees on how much the original peoples data has been protected thats really interesting actually i havent heard you talk about that before in terms of fairness ive seen from aaai your talk how can adversarial machine learning help models be more fair with respect to sensitive variables yeah so theres a paper from amos starkeys lab about how to learn machine learning models that are incapable of using specific variables so say for example you wanted to make predictions that are not affected by gender it isnt enough to just leave gender out of the input to the model you can often infer gender from a lot of other characteristics like say that you have the persons name but youre not told their gender well if their name is ian theyre kind of obviously a man so what youd like to do is make a machine learning model that can still take in a lot of different attributes and make a really accurate informed prediction but be confident that it isnt reverse engineering gender or another sensitive variable internally you can do that using something very similar to the domain adversarial approach where you have one player thats a feature extractor and another player thats a feature analyzer and you want to make sure that the feature analyzer is not able to guess the value of the sensitive variable that youre trying to keep private right thats yeah i love this approach so yeah with the feature youre not able to infer the sensitive variables brilliant thats quite brilliant and simple actually another way i think that gans in particular could be used for fairness would be to make something like a cyclegan where you can take data from one domain and convert it into another weve seen cyclegan turning horses into zebras weve seen other unsupervised gans made by mingyu liu doing things like turning day photos into night photos i think for fairness you could imagine taking records for people in one group and transforming them into analogous people in another group and testing to see if theyre treated equitably across those two groups theres a lot of things thatd be hard to get right to make sure that the conversion process itself is fair and i dont think its anywhere near something that we could actually use yet but if you could design that conversion process very carefully it might give you a way of doing audits where you say what if we took people from this group converted them into equivalent people in another group does the system actually treat them how it ought to thats also really interesting you know in popular press and in general in our imagination you think well gans are able to generate data and you start to think about deep fakes or being able to sort of maliciously generate data that fakes the identity of other people is this something of a concern to you is this something if you look 10 20 years into the future is that something that pops up in your work in the work of the community thats working on generating models im a lot less concerned about 20 years from now than the next few years i think therell be a kind of bumpy cultural transition as people encounter this idea that there can be very realistic videos and audio that arent real i think 20 years from now people will mostly understand that you shouldnt believe something is real just because you saw a video of it people will expect to see that its been cryptographically signed or have some other mechanism to make them believe that the content is real theres already people working on this like theres a startup called truepick that provides a lot of mechanisms for authenticating that an image is real theyre maybe not quite up to having a state actor try to evade their verification techniques but its something that people are already working on and i think well get right eventually so you think authentication will eventually win out so being able to authenticate that this is real and this is not yeah as opposed to gans just getting better and better or generative models being able to get better and better to where the nature of what is real is normal i dont think well ever be able to look at the pixels of a photo and tell you for sure that its real or not real and i think it would actually be somewhat dangerous to rely on that approach too much if you make a really good fake detector and then someones able to fool your fake detector and your fake detector says this image is not fake then its even more credible than if youve never made a fake detector in the first place what i do think well get to is systems that we can kind of use behind the scenes to make estimates of whats going on and maybe not like use them in court for a definitive analysis i also think we will likely get better authentication systems where imagine that every phone cryptographically signs everything that comes out of it you wouldnt be able to conclusively tell that an image was real but you would be able to tell somebody who knew the appropriate private key for this phone was actually able to sign this image and upload it to this server at this timestamp okay so you could imagine maybe you make phones that have the private keys hardware embedded in them if like a state security agency really wants to infiltrate the company they could probably plant a private key of their choice or break open the chip and learn the private key or something like that but it would make it a lot harder for an adversary with fewer resources to fake things for most of us it would be okay so you mentioned the beer and the bar and the new ideas you were able to implement this or come up with this new idea pretty quickly and implement it pretty quickly do you think theres still many such groundbreaking ideas in deep learning that could be developed so quickly yeah i do think that there are a lot of ideas that can be developed really quickly gans were probably a little bit of an outlier on the whole like one hour timescale but just in terms of like low resource ideas where you do something really different on the algorithm scale and get a big payback i think its not as likely that youll see that in terms of things like core machine learning technologies like a better classifier or a better reinforcement learning algorithm or a better generative model if i had the gan idea today it would be a lot harder to prove that it was useful than it was back in 2014 because i would need to get it running on something like imagenet or celeb a at high resolution you know those take a while to train you couldnt train it in an hour and know that it was something really new and exciting back in 2014 training on mnist was enough but there are other areas of machine learning where i think a new idea could actually be developed really quickly with low resources whats your intuition about what areas of machine learning are ripe for this yeah so i think fairness and interpretability are areas where we just really dont have any idea how anything should be done yet like for interpretability i dont think we even have the right definitions and even just defining a really useful concept you dont even need to run any experiments could have a huge impact on the field weve seen that for example in differential privacy that cynthia dwork and her collaborators made this technical definition of privacy where before a lot of things were really mushy and then with that definition you could actually design randomized algorithms for accessing databases and guarantee that they preserved individual peoples privacy in like a mathematical quantitative sense', 'the following is a conversation with ariel vinales hes a senior research scientist at google deepmind and before that he was at google brain and berkeley his research has been cited over 39000 times hes truly one of the most brilliant and impactful minds in the field of deep learning hes behind some of the biggest papers and ideas in ai including sequence to sequence learning audio generation image captioning neural machine translation and of course reinforcement learning hes a lead researcher of the alphastar project creating an agent that defeated a top professional at the game of starcraft this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with ariel vinales you spearheaded the deepmind team behind alphastar that recently beat a top professional player at starcraft so you have an incredible wealth of work in deep learning and a bunch of fields but lets talk about starcraft first lets go back to the very beginning even before alphastar before deepmind before deep learning first what came first for you a love for programming or a love for video games i think for me it definitely came first the drive to play video games i really liked computers i didnt really code much but what i would do is i would just mess with the computer break it and fix it that was the level of skills i guess that i gained in my very early days i mean when i was 10 or 11 and then i really got into video games especially starcraft actually the first version i spent most of my time just playing kind of pseudo professionally as professionally as you could play back in 98 in europe which was not a very main scene like whats called nowadays esports right of course in the 90s so howd you get into starcraft what was your favorite race how did you develop your skill what was your strategy all that kind of thing so as a player i tended to try to play not many games not to kind of disclose the strategies that i kind of developed and i like to play random actually not in competitions but just to i think in starcraft theres three main races and i found it very useful to play with all of them and so i would choose random many times even sometimes in tournaments to gain skill on the three races because its not how you play against someone but also if you understand the race because you played you also understand whats annoying then when youre on the other side what to do to annoy that person to try to gain advantages here and there and so on so i actually played random although i must say in terms of favorite race i really liked zerg i was probably best at zerg and thats probably what i tend to use towards the end of my career before starting university so lets step back a little bit could you try to describe starcraft to people that may never have played video games especially the massively online variety like starcraft so starcraft is a real time strategy game and the way to think about starcraft perhaps if you understand a bit chess is that theres a board which is called map or the map where people play against each other theres obviously many ways you can play but the most interesting one is the one versus one setup where you just play against someone else or even the built in ai right blizzard put a system that can play the game reasonably well if you dont know how to play and then in this board you have again pieces like in chess but these pieces are not there initially like they are in chess you actually need to decide to gather resources to decide which pieces to build so in a way youre starting almost with no pieces you start gathering resources in starcraft theres minerals and gas that you can gather and then you must decide how much do you wanna focus for instance on gathering more resources or starting to build units or pieces and then once you have enough pieces or maybe like attack a good attack composition then you go and attack the other side of the map and now the other main difference with chess is that you dont see the other side of the map so youre not seeing the moves of the enemy its what we call partially observable so as a result you must not only decide trading off economy versus building your own units but you also must decide whether you wanna scout to gather information but also by scouting you might be giving away some information that you might be hiding from the enemy so theres a lot of complex decision making all in real time theres also unlike chess this is not a turn based game you play basically all the time continuously and thus some skill in terms of speed and accuracy of clicking is also very important and people that train for this really play this game at an amazing skill level ive seen many times these and if you can witness this life its really really impressive so in a way its kind of a chess where you dont see the other side of the board youre building your own pieces and you also need to gather resources to basically get some money to build other buildings pieces technology and so on from the perspective of a human player the difference between that and chess or maybe that and a game like turn based strategy like heroes of might and magic is that theres an anxiety because you have to make these decisions really quickly and if you are not actually aware of what decisions work its a very stressful balance everything you describe is actually quite stressful difficult to balance for an amateur human player i dont know if it gets easier at the professional level like if theyre fully aware of what they have to do but at the amateur level theres this anxiety oh crap im being attacked oh crap i have to build up resource oh i have to probably expand and all these the time the real time strategy aspect is really stressful and computationally im sure difficult well get into it but for me battlenet so starcraft was released in 98 20 years ago which is hard to believe and blizzard battlenet with diablo in 96 came out and to me it might be a narrow perspective but it changed online gaming and perhaps society forever yeah but i may have made way too narrow viewpoint but from your perspective can you talk about the history of gaming over the past 20 years is this how transformational how important is this line of games right so i think i kind of was an active gamer whilst this was developing the internet online gaming so for me the way it came was i played other games strategy related i played a bit of common and conquer and then i played warcraft ii which is from blizzard but at the time i didnt know i didnt understand about what blizzard was or anything warcraft ii was just a game which was actually very similar to starcraft in many ways its also real time strategy game where theres orcs and humans so theres only two races but it was offline and it was offline right so i remember a friend of mine came to school say oh theres this new cool game called starcraft and i just said oh this sounds like just a copy of warcraft ii until i kind of installed it and at the time i am from spain so we didnt have very good internet right so there was for us starcraft became first kind of an offline experience where you kind of start to play these missions right you play against some sort of scripted things to develop the story of the characters in the game and then later on i start playing against the built in ai and i thought it was impossible to defeat it then eventually you defeat one and you can actually play against seven built in ais at the same time which also felt impossible but actually its not that hard to beat seven built in ais at once so once we achieved that also we discovered that we could play as i said internet wasnt that great but we could play with the lan right like basically against each other if we were in the same place because you could just connect machines with like cables right so we started playing in lan mode and as a group of friends and it was really really like much more entertaining than playing against ais and later on as internet was starting to develop and being a bit faster and more reliable then its when i started experiencing battlenet which is this amazing universe not only because of the fact that you can play the game against anyone in the world but you can also get to know more people you just get exposed to now like this vast variety of its kind of a bit when the chats came about right there was a chat system you could play against people but you could also chat with people not only about stalker but about anything and that became a way of life for kind of two years and obviously then it became like kind of it exploded in me in that i started to play more seriously going to tournaments and so on and so forth do you have a sense on a societal sociological level whats this whole part of society that many of us are not aware of and its a huge part of society which is gamers i mean every time i come across that in youtube or streaming sites i mean this is the huge number of people play games religiously do you have a sense of those folks especially now that youve returned to that realm a little bit on the ai side yeah so in fact even after stalker i actually played world of warcraft which is maybe the main sort of online worlds or in presence that you get to interact with lots of people so i played that for a little bit it was to me it was a bit less stressful than starcraft because winning was kind of a given you just put in this world and you can always complete missions but i think it was actually the social aspect of especially starcraft first and then games like world of warcraft really shaped me in a very interesting ways because what you get to experience is just people you wouldnt usually interact with right so even nowadays i still have many facebook friends from the area where i played online and their ways of thinking is even political they just we dont live in like we dont interact in the real world but we were connected by basically fiber and that way i actually get to understand a bit better that we live in a diverse world and these were just connections that were made by because you know i happened to go in a city in a virtual city as a priest and i met this warrior and we became friends and then we start like playing together right so i think its transformative and more and more and more people are more aware of it i mean its becoming quite mainstream but back in the day as you were saying in 2000 2005 even it was very still very strange thing to do especially in europe i think there were exceptions like korea for instance it was amazing that everything happened so early in terms of cybercafes like if you go to seoul its a city that back in the day starcraft was kind of you could be a celebrity by playing starcraft but this was like 99 2000 right its not like recently so yeah its quite interesting to look back and yeah i think its changing society the same way of course like technology and social networks and so on are also transforming things and a quick tangent let me ask youre also one of the most productive people in your particular chosen passion and path in life and yet youre also appreciate and enjoy video games do you think its possible to do to enjoy video games in moderation someone told me that you could choose two out of three when i was playing video games you could choose having a girlfriend playing video games or studying and i think for the most part it was relatively true these things do take time games like starcraft if you take the game pretty seriously and you wanna study it then you obviously will dedicate more time to it and i definitely took gaming and obviously studying very seriously i love learning science and et cetera so to me especially when i started university undergrad i kind of step off starcraft i actually fully stopped playing and then world of warcraft was a bit more casual you could just connect online and i mean it was fun but as i said that was not as much time investment as it was for me in starcraft okay so lets get into alphastar what are the youre behind the team so deepmind has been working on starcraft and released a bunch of cool open source agents and so on the past few years but alphastar really is the moment where the first time you beat a world class player so what are the parameters of the challenge in the way that alphastar took it on and how did you and david and the rest of the deepmind team get into it consider that you can even beat the best in the world or top players i think it all started back in 2015 actually im lying i think it was 2014 when deepmind was acquired by google and i at the time was at google brain which was in california is still in california we had this summit where we got together the two groups so google brain and google deepmind got together and we gave a series of talks and given that they were doing deep reinforcement learning for games i decided to bring up part of my past which i had developed at berkeley like this thing which we call berkeley overmind which is really just a starcraft one bot right so i talked about that and i remember demis just came to me and said well maybe not now its perhaps a bit too early but you should just come to deepmind and do this again with deep reinforcement learning right and at the time it sounded very science fiction for several reasons but then in 2016 when i actually moved to london and joined deepmind transferring from brain it became apparent that because of the alphago moment and kind of blizzard reaching out to us to say wait like do you want the next challenge and also me being full time at deepmind so sort of kind of all these came together and then i went to irvine in california to the blizzard headquarters to just chat with them and try to explain how would it all work before you do anything and the approach has always been about the learning perspective right so in berkeley we did a lot of rule based conditioning and if you have more than three units then go attack and if the other has more units than me i retreat and so on and so forth and of course the point of deep reinforcement learning deep learning machine learning in general is that all these should be learned behavior so that kind of was the dna of the project since its inception in 2016 where we just didnt even have an environment to work with and so thats how it all started really so if you go back to that conversation with demis or even in your own head how far away did you because were talking about atari games were talking about go which is kind of if youre honest about it really far away from starcraft in well now that youve beaten it maybe you could say its close but its much it seems like starcraft is way harder than go philosophically and mathematically speaking so how far away did you think you were do you think its 2019 and 18 you could be doing as well as you have yeah when i kind of thought about okay im gonna dedicate a lot of my time and focus on this and obviously i do a lot of different research in deep learning so spending time on it i mean i really had to kind of think theres gonna be something good happening out of this so really i thought well this sounds impossible and it probably is impossible to do the full thing like the full game where you play one versus one and its only a neural network playing and so on so it really felt like i just didnt even think it was possible but on the other hand i could see some stepping stones towards that goal clearly you could define sub problems in starcraft and sort of dissect it a bit and say okay here is a part of the game heres another part and also obviously the fact so this was really also critical to me the fact that we could access human replays right so blizzard was very kind and in fact they open source these for the whole community where you can just go and its not every single starcraft game ever played but its a lot of them you can just go and download and every day they will you can just query a data set and say well give me all the games that were played today and given my kind of experience with language and sequences and supervised learning i thought well thats definitely gonna be very helpful and something quite unique now because ever before we had such a large data set of replays of people playing the game at this scale of such a complex video game right so that to me was a precious resource and as soon as i knew that blizzard was able to kind of give this to the community i started to feel positive about something non trivial happening but i also thought the full thing like really no rules no single line of code that tries to say well i mean if you see this unit build a detector all these not having any of these specializations seemed really really really difficult to me intuitively i do also like that blizzard was teasing or even trolling you sort of almost yeah pulling you in into this really difficult challenge do they have any awareness whats the interest from the perspective of blizzard except just curiosity yeah i think blizzard has really understood and really bring forward this competitiveness of esports in games the starcraft really kind of sparked a lot of like something that almost was never seen especially as i was saying back in korea so they just probably thought well this is such a pure one versus one setup that it would be great to see if something that can play atari or go and then later on chess could even tackle these kind of complex real time strategy game right so for them they wanted to see first obviously whether it was possible if the game they created was in a way solvable to some extent and i think on the other hand they also are a pretty modern company that innovates a lot so just starting to understand ai for them to how to bring ai into games is not ai for games but games for ai right i mean both ways i think can work and we obviously at deepmind use games for ai right i mean it was so exciting i mean so looking back to those last days of 2018 really thats when the games were played im sure i look back at that moment ill say oh my god i want to be in a project like that its like i already feel the nostalgia of like yeah that was huge in terms of the energy and the team effort that went into it and so in that sense as soon as it happened i already knew it was kind of i was losing it a little bit so it is almost like sad that it happened and oh my god but on the other hand it also verifies the approach but to me also theres so many challenges and interesting aspects of intelligence that even though we can train a neural network to play at the level of the best humans theres still so many challenges so for me its also like well this is really an amazing achievement but i already was also thinking about next steps i mean as i said these asians play protoss versus protoss but they should be able to play a different race much quicker right so that would be an amazing achievement some people call this meta reinforcement learning meta learning and so on right so theres so many possibilities after that moment but the moment itself it really felt great we had this bet so im kind of a pessimist in general so i kind of send an email to the team i said okay lets against tlo first right like whats gonna be the result and i really thought we would lose like five zero right we had some calibration made against the 5000 mmr player tlo was much stronger than that player even if he played protoss which is his off race but yeah i was not imagining we would win so for me that was just kind of a test run or something and then it really kind of he was really surprised and unbelievably we went to this bar to celebrate and dave tells me well why dont we invite someone who is a thousand mmr stronger in protoss like actual protoss player like that it turned up being mana right and we had some drinks and i said sure why not but then i thought well thats really gonna be impossible to beat i mean even because its so much ahead a thousand mmr is really like 99 probability that mana would beat tlo as protoss versus protoss right so we did that and to me the second game was much more important even though a lot of uncertainty kind of disappeared after we kind of beat tlo i mean he is a professional player so that was kind of oh but thats really a very nice achievement but mana really was at the top and you could see he played much better but our agents got much better too so its like ah and then after the first game i said if we take a single game at least we can say we beat a game i mean even if we dont beat the series for me that was a huge relief and i mean i remember the hugging demis and i mean it was really like this moment for me will resonate forever as a researcher and i mean as a person and yeah its a really like great accomplishment and it was great also to be there with the team in the room i dont know if you saw like this so it was really like i mean from my perspective the other interesting thing is just like watching kasparov watching mana was also interesting because he didnt he has kind of a loss of words i mean whenever you lose ive done a lot of sports you sometimes say excuses you look for reasons and he couldnt really come up with reasons i mean so with the off race for protoss you could say well it felt awkward it wasnt but here it was just beaten and it was beautiful to look at a human being being superseded by an ai system i mean its a beautiful moment for researchers so yeah for sure it was i mean probably the highlight of my career so far because of its uniqueness and coolness and i dont know i mean its obviously as you said you can look at papers citations and so on but these really is like a testament of the whole machine learning approach and using games to advance technology i mean it really was everything came together at that moment thats really the summary also on the other side its a popularization of ai too because its just like traveling to the moon and so on i mean this is where a very large community of people that dont really know ai they get to really interact with it which is very important i mean we must you know writing papers helps our peers researchers to understand what were doing but i think ai is becoming mature enough that we must sort of try to explain what it is and perhaps through games is an obvious way because these games always had built in ai so it may be everyone experience an ai playing a video game even if they dont know because theres always some scripted element and some people might even call that ai already right so what are other applications of the approaches underlying alphastar that you see happening theres a lot of echoes of you said transformer of language modeling and so on have you already started thinking where the breakthroughs in alphastar get expanded to other applications right so i thought about a few things for like kind of next month next years the main thing im thinking about actually is whats next as a kind of a grand challenge because for me like weve seen atari and then theres like the sort of three dimensional walls that weve seen also like pretty good performance from these capture the flag agents that also some people at deepmind and elsewhere are working on weve also seen some amazing results on like for instance dota 2 which is also a very complicated game so for me like the main thing im thinking about is whats next in terms of challenge so as a researcher i see sort of two tensions between research and then applications or areas or domains where you apply them so on the one hand weve done thanks to the application of starcraft is very hard we developed some techniques some new research that now we could look at elsewhere like are there other applications where we can apply these and the obvious ones absolutely you can think of feeding back to sort of the community we took from which was mostly sequence modeling or natural language processing so weve developed and extended things from the transformer and we use pointer networks we combine lstm and transformers in interesting ways so thats perhaps the kind of lowest hanging fruit of feeding back to now a different field of machine learning thats not playing video games let me go old school and jump to mr alan turing so the turing test is a natural language test a conversational test whats your thought of it as a test for intelligence do you think it is a grand challenge thats worthy of undertaking maybe if it is would you reformulate it or phrase it somehow differently right so i really love the turing test because i also like sequences and language understanding and in fact some of the early work we did in machine translation we tried to apply to kind of a neural chatbot which obviously would never pass the turing test because it was very limited but it is a very fascinating idea that you could really have an ai that would be indistinguishable from humans in terms of asking or conversing with it so i think the test itself seems very nice and its kind of well defined actually like the passing it or not i think theres quite a few rules that feel pretty simple and i think they have these competitions every year yes theres the lebner prize but i dont know if youve seen the kind of bots that emerge from that competition theyre not quite as what you would so it feels like that theres weaknesses with the way turing formulated it it needs to be that the definition of a genuine rich fulfilling human conversation it needs to be something else like the alexa prize which im not as well familiar with has tried to define that more i think by saying you have to continue keeping a conversation for 30 minutes something like that so basically forcing the agent not to just fool but to have an engaging conversation kind of thing have you thought about this problem richly and if you have in general how far away are we from you worked a lot on language understanding language generation but the full dialogue the conversation just sitting at the bar having a couple of beers for an hour that kind of conversation have you thought about it yeah so i think you touched here on the critical point which is feasibility so theres a great essay by hamming which describes sort of grand challenges of physics and he argues that well ok for instance teleportation or time travel are great grand challenges of physics but theres no attacks we really dont know or cannot kind of make any progress so thats why most physicists and so on they dont work on these in their phds and as part of their careers so i see the turing test in the full turing test as a bit still too early like i think were especially with the current trend of deep learning language models weve seen some amazing examples i think gpt2 being the most recent one which is very impressive but to understand to fully solve passing or fooling a human to think that theres a human on the other side i think were quite far so as a result i dont see myself and i probably would not recommend people doing a phd on solving the turing test because it just feels its kind of too early or too hard of a problem yeah but that said you said the exact same thing about starcraft about a few years ago indeed to demis so youll probably also be the person who passes the turing test in three years i mean i think that yeah so we have this on record this is nice its true i mean its true that progress sometimes is a bit unpredictable i really wouldnt have not even six months ago i would not have predicted the level that we see that these agents can deliver at grandmaster level but i have worked on language enough and basically my concern is not that something could happen a breakthrough could happen that would bring us to solving or passing the turing test is that i just think the statistical approach to it is not going to cut it so we need a breakthrough which is great for the community but given that i think theres quite more uncertainty whereas for starcraft i knew what the steps would be to get us there i think it was clear that using the imitation learning part and then using this battle net for agents were going to be key and it turned out that this was the case and a little more was needed but not much more for turing test i just dont know what the plan or execution plan would look like so thats why i myself working on it as a grand challenge is hard but there are quite a few sub challenges that are related that you could say well i mean what if you create a great assistant like google already has like the google assistant so can we make it better and can we make it fully neural and so on that i start to believe maybe were reaching a point where we should attempt these challenges i like this conversation so much because it echoes very much the starcraft conversation its exactly how you approach starcraft lets break it down into small pieces and solve those and you end up solving the whole game great but that said youre behind some of the biggest pieces of work in deep learning in the last several years so you mentioned some limits what do you think of the current limits of deep learning and how do we overcome those limits so if i had to actually use a single word to define the main challenge in deep learning its a challenge that probably has been the challenge for many years and its that of generalization so what that means is that all that were doing is fitting functions to data and when the data we see is not from the same distribution or even if there are some times that it is very close to distribution but because of the way we train it with limited samples we then get to this stage where we just dont see generalization as much as we can generalize and i think adversarial examples are a clear example of this but if you study machine learning and literature and the reason why svms came very popular were because they were dealing and they had some guarantees about generalization which is unseen data or out of distribution or even within distribution where you take an image adding a bit of noise these models fail so i think really i dont see a lot of progress on generalization in the strong generalization sense of the word i think our neural networks you can always find design examples that will make their outputs arbitrary which is not good because we humans would never be fooled by these kind of images or manipulation of the image and if you look at the mathematics you kind of understand this is a bunch of matrices multiplied together theres probably numerics and instability that you can just find corner cases so i think thats really the underlying topic many times we see when even at the grand stage of turing test generalization if you start passing the turing test should it be in english or should it be in any language as a human if you ask something in a different language you actually will go and do some research and try to translate it and so on should the turing test include that and its really a difficult problem and very fascinating and very mysterious actually yeah absolutely but do you think if you were to try to solve it can you not grow the size of data intelligently in such a way that the distribution of your training set does include the entirety of the testing set is that one path the other path is totally a new methodology its not statistical so a path that has worked well and it worked well in starcraft and in machine translation and in languages scaling up the data and the model and thats kind of been maybe the only single formula that still delivers today in deep learning right its that data scale and model scale really do more and more of the things that we thought oh theres no way it can generalize to these or theres no way it can generalize to that but i dont think fundamentally it will be solved with this and for instance im really liking some style or approach that would not only have neural networks but it would have programs or some discrete decision making because there is where i feel theres a bit more i mean the best example i think for understanding this is i also worked a bit on oh we can learn an algorithm with a neural network right so you give it many examples and its going to sort the input numbers or something like that but really strong generalization is you give me some numbers or you ask me to create an algorithm that sorts numbers and instead of creating a neural net which will be fragile because its going to go out of range at some point youre going to give it numbers that are too large too small and whatnot if you just create a piece of code that sorts the numbers then you can prove that that will generalize to absolutely all the possible input you could give so i think the problem comes with some exciting prospects i mean scale is a bit more boring but it really works and then maybe programs and discrete abstractions are a bit less developed but clearly i think theyre quite exciting in terms of future for the field do you draw any insight wisdom from the 80s and expert systems and symbolic systems symbolic computing do you ever go back to those reasoning that kind of logic do you think that might make a comeback youll have to dust off those books yeah i actually love actually adding more inductive biases to me the problem really is what are you trying to solve if what youre trying to solve is so important that try to solve it no matter what then absolutely use rules use domain knowledge and then use a bit of the magic of machine learning to empower to make the system as the best system that will detect cancer or detect weather patterns right or in terms of starcraft it also was a very big challenge so i was definitely happy that if we had to cut a corner here and there it could have been interesting to do and in fact in starcraft we start thinking about expert systems because its a very you know you can define i mean people actually build starcraft bots by thinking about those principles like state machines and rule based and then you could think of combining a bit of a rule based system but that has also neural networks incorporated to make it generalize a bit better so absolutely i mean we should definitely go back to those ideas and anything that makes the problem simpler as long as your problem is important thats ok and thats research driving a very important problem and on the other hand if you want to really focus on the limits of reinforcement learning then of course you must try not to look at imitation data or to look for some rules of the domain that would help a lot or even feature engineering right so this is a tension that depending on what you do i think both ways are definitely fine and i would never not do one or the other as long as what youre doing is important and needs to be solved right right so theres a bunch of different ideas that you developed that i really enjoy but one is translating from image captioning translating from image to text just another beautiful idea i think that resonates throughout your work actually so the underlying nature of reality being language always somehow so whats the connection between images and text or rather the visual world and the world of language in your view right so i think a piece of research thats been central to i would say even extending into stargraph is this idea of sequence to sequence learning which what we really meant by that is that you can now really input anything to a neural network as the input x and then the neural network will learn a function f that will take x as an input and produce any output y and these x and ys dont need to be static or features like fixed vectors or anything like that it could be really sequences and now beyond data structures so that paradigm was tested in a very interesting way when we moved from translating french to english to translating an image to its caption but the beauty of it is that really and thats actually how it happened i changed a line of code in this thing that was doing machine translation and i came the next day and i saw how it was producing captions that seemed like oh my god this is really really working and the principle is the same so i think i dont see text vision speech waveforms as something different as long as you basically learn a function that will vectorize these into and then after we vectorize it we can then use transformers lstms whatever the flavor of the month of the model is and then as long as we have enough supervised data really this formula will work and will keep working i believe to some extent modulo these generalization issues that i mentioned before but the task there is to vectorize so to form a representation thats meaningful and your intuition now having worked with all this media is that once you are able to form that representation you could basically take any things any sequence going back to starcraft is there limits on the length so that we didnt really touch on the long term aspect how did you overcome the whole really long term aspect of things here is there some tricks so the main trick so starcraft if you look at absolutely every frame you might think its quite a long game so we would have to multiply 22 times 60 seconds per minute times maybe at least 10 minutes per game on average so there are quite a few frames but the trick really was to only observe in fact which might be seen as a limitation but it is also a computational advantage only observe when you act and then what the neural network decides is what is the gap going to be until the next action and if you look at most starcraft games that we have in the data set that blizzard provided it turns out that most games are actually only i mean it is still a long sequence but its maybe like 1000 to 1500 actions which if you start looking at lstms large lstms transformers its not that difficult especially if you have supervised learning if you had to do it with reinforcement learning the credit assignment problem what is it in this game that made you win that would be really difficult but thankfully because of imitation learning we didnt have to deal with these directly although if we had to we tried it and what happened is you just take all your workers and attack with them and that is kind of obvious in retrospect because you start trying random actions one of the actions will be a worker that goes to the enemy base and because its self play its not going to know how to defend because it basically doesnt know almost anything and eventually what you develop is this take all workers and attack because the credit assignment issue in a rally is really really hard i do believe we could do better and thats maybe a research challenge for the future but yeah even in starcraft the sequences are maybe 1000 which i believe is within the realm of what transformers can do yeah i guess the difference between starcraft and go is in go and chess stuff starts happening right away so theres not yeah its pretty easy to self play not easy but to self play its possible to develop reasonable strategies quickly as opposed to starcraft i mean in go theres only 400 actions but one action is what people would call the god action that would be if you had expanded the whole search tree thats the best action if you did minimax or whatever algorithm you would do if you had the computational capacity but in starcraft 400 is minuscule like in 400 you couldnt even click on the pixels around a unit so i think the problem there is in terms of action space size is way harder and that search is impossible so theres quite a few challenges indeed that make this kind of a step up in terms of machine learning for humans maybe playing starcraft seems more intuitive because it looks real i mean the graphics and everything moves smoothly whereas i dont know how to i mean go is a game that i would really need to study it feels quite complicated but for machines kind of maybe its the reverse yes which shows you the gap actually between deep learning and however the heck our brains work so you developed a lot of really interesting ideas its interesting to just ask whats your process of developing new ideas do you like brainstorming with others do you like thinking alone do you like what was it ian goodfellow said he came up with gans after a few beers he thinks beers are essential for coming up with new ideas we had beers to decide to play another game of starcraft after a week so its really similar to that story actually i explained this in a deepmind retreat and i said this is the same as the gan story i mean we were in a bar and we decided lets play a gan next week and thats what happened i feel like were giving the wrong message to young undergrads yeah i know but in general do you like brainstorming do you like thinking alone working stuff out so i think throughout the years also things changed so initially i was very fortunate to be with great minds like jeff hinton jeff dean ilya sutskever i was really fortunate to join brain at a very good time so at that point ideas i was just brainstorming with my colleagues and learned a lot and keep learning is actually something you should never stop doing so learning implies reading papers and also discussing ideas with others its very hard at some point to not communicate that being reading a paper from someone or actually discussing so definitely that communication aspect needs to be there whether its written or oral nowadays im also trying to be a bit more strategic about what research to do so i was describing a little bit this tension between research for the sake of research and then you have on the other hand applications that can drive the research and honestly the formula that has worked best for me is just find a hard problem and then try to see how research fits into it how it doesnt fit into it and then you must innovate so i think machine translation drove sequence to sequence then maybe learning algorithms that had to combinatorial algorithms led to pointer networks starcraft led to really scaling up imitation learning and the alphastarleague so thats been a formula that i personally like but the other one is also valid and ive seen it succeed a lot of the times where you just want to investigate model based rl as a research topic and then you must then start to think well how are the tests how are you going to test these ideas you need a minimal environment to try things you need to read a lot of papers and so on and thats also very fun to do and something ive also done quite a few times both at brain at deepmind and obviously as a phd so i think besides the ideas and discussions i think its important also because you start sort of guiding not only your own goals but other peoples goals to the next breakthrough so you must really kind of understand this feasibility also as we were discussing before whether this domain is ready to be tackled or not and you dont want to be too early you obviously dont want to be too late so its really interesting this strategic component of research which i think as a grad student i just had no idea i just read papers and discussed ideas and i think this has been maybe the major change and i recommend people kind of feed forward to success how it looks like and try to backtrack other than just kind of looking oh this looks cool this looks cool and then you do a bit of random work which sometimes you stumble upon some interesting things but in general its also good to plan a bit yeah i like it especially like your approach of taking a really hard problem stepping right in and then being super skeptical about being able to solve the problem i mean theres a balance of both right theres a silly optimism and a critical sort of skepticism thats good to balance which is why its good to have a team of people that balance that you dont do that on your own you have both mentors that have seen or you obviously want to chat and discuss whether its the right time i mean demis came in 2014 and he said maybe in a bit well do starcraft and maybe he knew and im just following his lead which is great because hes brilliant right so these things are obviously quite important that you want to be surrounded by people who are diverse they have their knowledge theres also important to i mean ive learned a lot from people who actually have an idea that i might not think its good but if i give them the space to try it ive been proven wrong many many times as well so thats great i think your colleagues are more important than yourself i think sure now lets real quick talk about another impossible problem agi right what do you think it takes to build a system thats human level intelligence we talked a little bit about the turing test starcraft all of these have echoes of general intelligence but if you think about just something that you would sit back and say wow this is really something that resembles human level intelligence what do you think it takes to build that so i find that agi oftentimes is maybe not very well defined so what im trying to then come up with for myself is what would be a result look like that you would start to believe that you would have agents or neural nets that no longer overfeed to a single task but actually learn the skill of learning so to speak and that actually is a field that i am fascinated by which is the learning to learn or meta learning which is about no longer learning about a single domain so you can think about the learning algorithm itself is general so the same formula we applied for alphastar or starcraft we can now apply to almost any video game or you could apply to many other problems and domains but the algorithm is whats generalizing but the neural network those weights are useless even to play another race i train a network to play very well at protos versus protos i need to throw away those weights if i want to play now terran versus terran i would need to retrain a network from scratch with the same algorithm thats beautiful but the network itself will not be useful so i think if i see an approach that can absorb or start solving new problems without the need to kind of restart the process i think that to me would be a nice way to define some form of agi again i dont know the grandiose like age i mean should turing tests be solved before agi i mean i dont know i think concretely i would like to see clearly that meta learning happen meaning that there is an architecture or a network that as it sees new problem or new data it solves it and to make it kind of a benchmark it should solve it at the same speed that we do solve new problems when i define you a new object and you have to recognize it when you start playing a new game you played all the atari games but now you play a new atari game well youre going to be pretty quickly pretty good at the game so thats perhaps whats the domain and whats the exact benchmark is a bit difficult i think as a community we might need to do some work to define it but i think this first step i could see it happen relatively soon but then the whole what agi means and so on i am a bit more confused about what i think people mean different things theres an emotional psychological level that like even the turing test passing the turing test is something that we just pass judgment on as human beings what it means to be as a dog in agi system yeah what level what does it mean what does it mean but i like the generalization and maybe as a community we converge towards a group of domains that are sufficiently far away that would be really damn impressive if it was able to generalize so perhaps not as close as protoss and zerg but like wikipedia that would be a step yeah that would be a good step and then a really good step but then like from starcraft to wikipedia and back yeah that kind of thing and that feels also quite hard and far but i think as long as you put the benchmark out as we discovered for instance with imagenet then tremendous progress can be had so i think maybe theres a lack of benchmark but im sure well find one and the community will then work towards that and then beyond what agi might mean or would imply i really am hopeful to see basically machine learning or ai just scaling up and helping people that might not have the resources to hire an assistant or that they might not even know what the weather is like so i think in terms of the positive impact of ai i think thats maybe what we should also not lose focus the research community building agi i mean thats a real nice goal but i think the way that deepmind puts it is and then use it to solve everything else so i think we should paralyze yeah we shouldnt forget about all the positive things that are actually coming out of ai already and are going to be coming out right but on that note let me ask relative to popular perception do you have any worry about the existential threat of artificial intelligence in the near or far future that some people have i think in the near future im skeptical so i hope im not wrong but im not concerned but i appreciate efforts ongoing efforts and even like whole research field on ai safety emerging and in conferences and so on i think thats great in the long term i really hope we just can simply have the benefits outweigh the potential dangers i am hopeful for that but also we must remain vigilant to monitor and assess whether the tradeoffs are there and we have enough also lead time to prevent or to redirect our efforts if need be but im quite optimistic about the technology and definitely more fearful of other threats in terms of planetary level at this point but obviously thats the one i have more power on so clearly i do start thinking more and more about this and its grown in me actually to start reading more about ai safety which is a field that so far i have not really contributed to but maybe theres something to be done there as well i think its really important i talk about this with a few folks but its important to ask you and shove it in your head because youre at the leading edge of actually what people are excited about in ai the work with alphastar its arguably at the very cutting edge of the kind of thing that people are afraid of and so you speaking to that fact and that were actually quite far away to the kind of thing that people might be afraid of but its still worthwhile to think about and its also good that youre not as worried and youre also open to thinking about it theres two aspects i mean me not being worried but obviously we should prepare for things that could go wrong misuse of the technologies as with any technologies so i think theres always trade offs and as a society weve kind of solved this to some extent in the past so im hoping that by having the researchers and the whole community brainstorm and come up with interesting solutions to the new things that will happen in the future that we can still also push the research to the avenue that i think is kind of the greatest avenue which is to understand intelligence how are we doing what were doing and obviously from a scientific standpoint that is kind of my personal drive of all the time that i spend doing what im doing really where do you see the deep learning as a field heading where do you think the next big breakthrough might be so i think deep learning i discussed a little of this before deep learning has to be combined with some form of discretization program synthesis i think thats kind of as a research in itself is an interesting topic to expand and start doing more research and then as kind of what will deep learning enable to do in the future i dont think thats going to be whats going to happen this year but also this idea of starting not to throw away all the weights that this idea of learning to learn and really having these agents not having to restart their weights and you can have an agent that is kind of solving or classifying images on imagenet but also generating speech if you ask it to generate some speech and it should really be kind of almost the same network but it might not be a neural network it might be a neural network with an optimization algorithm attached to it but i think this idea of generalization to new task is something that we first must define good benchmarks but then i think thats going to be exciting and im not sure how close we are but i think if you have a very limited domain i think we can start doing some progress and much like how we did a lot of programs in computer vision we should start thinking i really like a talk that leon buto gave at icml a few years ago which is this train test paradigm should be broken we should stop thinking about a training set and a test set and these are closed things that are untouchable i think we should go beyond these and in meta learning we call these the meta training set and the meta test set which is really thinking about if i know about imagenet why would that network not work on mnist which is a much simpler problem but right now it really doesnt but it just feels wrong so i think thats kind of the on the application or the benchmark sites we probably will see quite a few more interest and progress and hopefully people defining new and exciting challenges really do you have any hope or interest in knowledge graphs within this context so this kind of constructing graph so going back to graphs well neural networks and graphs but i mean a different kind of knowledge graph sort of like semantic graphs or those concepts yeah so i think the idea of graphs is so ive been quite interested in sequences first and then more interesting or different data structures like graphs and ive studied graph neural networks in the last three years or so i found these models just very interesting from deep learning sites standpoint but then why do we want these models and why would we use them whats the application whats kind of the killer application of graphs and perhaps if we could extract a knowledge graph from wikipedia automatically that would be interesting because then these graphs have this very interesting structure that also is a bit more compatible with this idea of programs and deep learning kind of working together jumping neighborhoods and so on you could imagine defining some primitives to go around graphs right so i think i really like the idea of a knowledge graph and in fact when we started or as part of the research we did for starcraft i thought wouldnt it be cool to give the graph of all these buildings that depend on each other and units that have prerequisites of being built by that and so this is information that the network can learn and extract but it would have been great to see or to think of really starcraft as a giant graph that even also as the game evolves you start taking branches and so on and we did a bit of research on these nothing too relevant but i really like the idea and it has elements that are something you also worked with in terms of visualizing your networks it has elements of having human interpretable being able to generate knowledge representations that are human interpretable that maybe human experts can then tweak or at least understand so theres a lot of interesting aspect there and for me personally im just a huge fan of wikipedia and its a shame that our neural networks arent taking advantage of all the structured knowledge thats on the web whats next for you whats next for deepmind what are you excited about for alphastar yeah so i think the obvious next steps would be to apply alphastar to other races i mean that sort of shows that the algorithm works because we wouldnt want to have created by mistake something in the architecture that happens to work for protoss but not for other races so as verification i think thats an obvious next step that we are working on and then i would like to see so agents and players can specialize on different skill sets that allow them to be very good i think weve seen alphastar understanding very well when to take battles and when to not to do that also very good at micromanagement and moving the units around and so on and also very good at producing nonstop and trading off economy with building units but i have not perhaps seen as much as i would like this idea of the poker idea that you mentioned right im not sure starcraft or alphastar rather has developed a very deep understanding of what the opponent is doing and reacting to that and sort of trying to trick the player to do something else or that so this kind of reasoning i would like to see more so i think purely from a research standpoint theres perhaps also quite a few things to be done there in the domain of starcraft yeah in the domain of games ive seen some interesting work in even auctions manipulating other players sort of forming a belief state and just messing with people yeah its called theory of mind i guess theory of mind yeah so its a fascinating theory of mind on starcraft is kind of theyre really made for each other so that would be very exciting to see those techniques apply to starcraft or perhaps starcraft driving new techniques right as i said this is always the tension between the two well orel thank you so much for talking today awesome it was great to be here thanks to drive ai progress but blizzard might actually be able to do and many other companies to start to understand and do the opposite so i think that is also something they can get out of these and they definitely we have brainstormed a lot about these right but one of the interesting things to me about starcraft and diablo and these games that blizzard has created is the task of balancing classes for example sort of making the game fair from the starting point and then let skill determine the outcome is there i mean can you first comment theres three races zerg protoss and terran i dont know if ive ever said that out loud is that how you pronounce it terran yeah terran yeah yeah i dont think ive ever in person interacted with anybody about starcraft thats funny so they seem to be pretty balanced i wonder if the ai the work that youre doing with alphastar would help balance them even further is that something you think about is that something that blizzard is thinking about right so balancing when you add a new unit or a new spell type is obviously possible given that you can always train or pre train at scale some agent that might start using that in unintended ways but i think actually if you understand how starcraft has kind of co evolved with players in a way i think its actually very cool the ways that many of the things and strategies that people came up with right so i think weve seen it over and over in starcraft that blizzard comes up with maybe a new unit and then some players get creative and do something kind of unintentional or something that blizzard designers that just simply didnt test or think about and then after that becomes kind of mainstream in the community blizzard patches the game and then they kind of maybe weaken that strategy or make it actually more interesting but a bit more balanced so these kind of continual talk between players and blizzard is kind of what has defined them actually in actually most games in starcraft but also in world of warcraft they would do that there are several classes and it would be not good that everyone plays absolutely the same race and so on right so i think they do care about balancing of course and they do a fair amount of testing but its also beautiful to also see how players get creative anyways and i mean whether ai can be more creative at this point i dont think so right i mean its just sometimes something so amazing happens like i remember back in the days like you have these drop ships that could drop the rivers and that was actually not thought about that you could drop this unit that has this whats called splash damage that would basically eliminate all the enemies workers at once no one thought that you could actually put them in really early game do that kind of damage and then things change in the game but i dont know i think its quite an amazing exploration process from both sides players and blizzard alike well its almost like a reinforcement learning exploration but the scale of humans that play blizzard games is almost on the scale of a large scale deep mind rl experiment i mean if you look at the numbers i mean youre talking about i dont know how many games but hundreds of thousands of games probably a month yeah i mean so its almost the same as running rl agents what aspect of the problem of starcraft do you think is the hardest is it the like you said the imperfect information is it the fact they have to do longterm planning is it the real time aspects we have to do stuff really quickly is it the fact that a large action space so you can do so many possible things or is it you know in the game theoretic sense there is no nash equilibrium or at least you dont know what the optimal strategy is because theres way too many options right is there something that stands out as just like the hardest the most annoying thing so when we sort of looked at the problem and start to define like the parameters of it right what are the observations what are the actions it became very apparent that you know the very first barrier that one would hit in starcraft would be because of the action space being so large and as not being able to search like you could in chess or go even though the search space is vast the main problem that we identified was that of exploration right so without any sort of human knowledge or human prior if you think about starcraft and you know how deep reinforcement learnings algorithm work which is essentially by issuing random actions and hoping that they will get some wins sometimes so they could learn so if you think of the action space in starcraft almost anything you can do in the early game is bad because any action involves taking workers which are mining minerals for free thats something that the game does automatically sends them to mine and you would immediately just take them out of mining and send them around so just thinking how is it gonna be possible to get to understand these concepts but even more like expanding right theres these buildings you can place in other locations in the map to gather more resources but the location of the building is important and you have to select a worker send it walking to that location build the building wait for the building to be built and then put extra workers there so they start mining that feels like impossible if you just randomly click to produce that state desirable state that then you could hope to learn from because eventually that may yield to an extra win right so for me the exploration problem and due to the action space and the fact that theres not really turns theres so many turns because the game essentially takes that 22 times per second i mean thats how they could discretize sort of time obviously you always have to discretize time but theres no such thing as real time but its really a lot of time steps of things that could go wrong and that definitely felt a priori like the hardest you mentioned many good ones i think partial observability and the fact that there is no perfect strategy because of the partial observability those are very interesting problems we start seeing more and more now in terms of as we solve the previous ones but the core problem to me was exploration and solving it has been basically kind of the focus and how we saw the first breakthroughs so exploration in a multi hierarchical way so like 22 times a second exploration has a very different meaning than it does in terms of should i gather resources early or should i wait or so on so how do you solve the longterm lets talk about the internals of alphastar so first of all how do you represent the state of the game as an input how do you then do the longterm sequence modeling how do you build a policy whats the architecture like so alphastar has obviously several components but everything passes through what we call the policy which is a neural network and thats kind of the beauty of it there is i could just now give you a neural network and some weights and if you fed the right observations and you understood the actions the same way we do you would have basically the agent playing the game theres absolutely nothing else needed other than those weights that were trained now the first step is observing the game and weve experimented with a few alternatives the one that we currently use mixes both spatial sort of images that you would process from the game that is the zoomed out version of the map and also a zoomed in version of the camera or the screen as we call it but also we give to the agent the list of units that it sees more of as a set of objects that it can operate on that is not necessarily required to use it and we have versions of the game that play well without this set vision that is a bit not like how humans perceive the game but it certainly helps a lot because its a very natural way to encode the game is by just looking at all the units that there are they have properties like health position type of unit whether its my unit or the enemies and that sort of is kind of the summary of the state of the game that list of units or set of units that you see all the time but thats pretty close to the way humans see the game why do you say its not isnt that youre saying the exactness of it is not similar to humans the exactness of it is perhaps not the problem i guess maybe the problem if you look at it from how actually humans play the game is that they play with a mouse and a keyboard and a screen and they dont see sort of a structured object with all the units what they see is what they see on the screen right so remember that theres a sorry to interrupt theres a plot that you showed with camera base where you do exactly that right you move around and that seems to converge to similar performance yeah i think thats what i were kind of experimenting with whats necessary or not but using the set so actually if you look at research in computer vision where it makes a lot of sense to treat images as two dimensional arrays theres actually a very nice paper from facebook i think i forgot who the authors are but i think its part of camings group and what they do is they take an image which is this two dimensional signal and they actually take pixel by pixel and scramble the image as if it was just a list of pixels crucially they encode the position of the pixels with the x y coordinates and this is just kind of a new architecture which we incidentally also use in starcraft called the transformer which is a very popular paper from last year which yielded very nice result in machine translation and if you actually believe in this kind of oh its actually a set of pixels as long as you encode x y its okay then you could argue that the list of units that we see is precisely that because we have each unit as a kind of pixel if you will and then their x y coordinates so in that perspective we without knowing it we use the same architecture that was shown to work very well on pascal and imagenet and so on so the interesting thing here is putting it in that way it starts to move it towards the way you usually work with language so what and especially with your expertise and work in language it seems like theres echoes of a lot of the way you would work with natural language in the way youve approached alphastar right whats does that help with the longterm sequence modeling there somehow exactly so now that we understand what an observation for a given time step is we need to move on to say well theres going to be a sequence of such observations and an agent will need to given all that its seen not only the current time step but all that its seen why because there is partial observability we must remember whether we saw a worker going somewhere for instance right because then there might be an expansion on the top right of the map so given that what you must then think about is there is the problem of given all the observations you have to predict the next action and not only given all the observations but given all the observations and given all the actions youve taken predict the next action and that sounds exactly like machine translation where and thats exactly how kind of i saw the problem especially when you are given supervised data or replays from humans because the problem is exactly the same youre translating essentially a prefix of observations and actions onto whats going to happen next which is exactly how you would train a model to translate or to generate language as well right do you have a certain prefix you must remember everything that comes in the past because otherwise you might start having noncoherent text and the same architectures were using lstms and transformers to operate on across time to kind of integrate all thats happened in the past those architectures that work so well in translation or language modeling are exactly the same than what the agent is using to issue actions in the game and the way we train it moreover for imitation which is step one of alphastar is take all the human experience and try to imitate it much like you try to imitate translators that translated many pairs of sentences from french to english say that sort of principle applies exactly the same its almost the same code except that instead of words you have a slightly more complicated objects which are the observations and the actions are also a bit more complicated than a word is there a self play component then too so once you run out of imitation right so indeed you can bootstrap from human replays but then the agents you get are actually not as good as the humans you imitated right so how do we imitate well we take humans from 3000 mmr and higher 3000 mmr is just a metric of human skill and 3000 mmr might be like 50 percentile right so its just average human whats that so maybe quick pause mmr is a ranking scale the matchmaking rating for players so its 3000 i remember theres like a master and a grand master whats 3000 so 3000 is pretty bad i think its kind of goals level it just sounds really good relative to chess i think oh yeah yeah no the ratings the best in the world are at 7000 mmr so 3000 its a bit like elo indeed right so 3500 just allows us to not filter a lot of the data so we like to have a lot of data in deep learning as you probably know so we take these kind of 3500 and above but then we do a very interesting trick which is we tell the neural network what level they are imitating so we say this replay youre gonna try to imitate to predict the next action for all the actions that youre gonna see is a 4000 mmr replay this one is a 6000 mmr replay and whats cool about this is then we take this policy that is being trained from human and then we can ask it to play like a 3000 mmr player by setting a beat saying well okay play like a 3000 mmr player or play like a 6000 mmr player and you actually see how the policy behaves differently it gets worse economy if you play like a goal level player it does less actions per minute which is the number of clicks or number of actions that you will issue in a whole minute and its very interesting to see that it kind of imitates the skill level quite well but if we ask it to play like a 6000 mmr player we tested of course these policies to see how well they do they actually beat all the built in ais that blizzard put in the game but theyre nowhere near 6000 mmr players right they might be maybe around goal level platinum perhaps so theres still a lot of work to be done for the policy to truly understand what it means to win so far we only asked them okay here is the screen and thats whats happened on the game until this point what would the next action be if we ask a pro to now say oh youre gonna click here or here or there and the point is experiencing wins and losses is very important to then start to refine otherwise the policy can get loose can just go off policy as we call it thats so interesting that you can at least hope eventually to be able to control a policy approximately to be at some mmr level thats so interesting especially given that you have ground truth for a lot of these cases can i ask you a personal question whats your mmr well i havent played starcraft ii so i am unranked which is the kind of lowest league so i used to play starcraft the first one but you havent seriously played starcraft ii so the best player we have at deepmind is about 5000 mmr which is high masters its not at grand master level grand master level will be the top 200 players in a certain region like europe or america or asia but for me it would be hard to say i am very bad at the game i actually played alphastar a bit too late and it beat me i remember the whole team was oh oreo you should play and i was oh it looks like its not so good yet and then i remember i kind of got busy and waited an extra week and i played and it really beat me very badly was that i mean how did that feel isnt that an amazing feeling thats amazing yeah i mean obviously i tried my best and i tried to also impress my because i actually played the first game so im still pretty good at micromanagement the problem is i just dont understand starcraft ii i understand starcraft and when i played starcraft i probably was consistently like for a couple of years top 32 in europe so i was decent but at the time we didnt have this kind of mmr system as well established so it would be hard to know what it was back then so whats the difference in interface between alphastar and starcraft and a human player in starcraft is there any significant differences between the way they both see the game i would say the way they see the game theres a few things that are just very hard to simulate the main one perhaps which is obvious in hindsight is whats called cloaked units which are invisible units so in starcraft you can make some units that you need to have a particular kind of unit to detect it so these units are invisible if you cannot detect them you cannot target them so they would just destroy your buildings or kill your workers but despite the fact you cannot target the unit theres a shimmer that as a human you observe i mean you need to train a little bit you need to pay attention but you would see this kind of space time distortion and you would know okay there are yeah yeah theres like a wave thing yeah its called shimmer space time distortion i like it thats really like the blizzard term is shimmer shimmer okay and so these shimmer professional players actually can see it immediately they understand it very well but its still something that requires certain amount of attention and its kind of a bit annoying to deal with whereas for alphastar in terms of vision its very hard for us to simulate sort of oh are you looking at this pixel in the screen and so on so the only thing we can do is there is a unit thats invisible over there so alphastar would know that immediately obviously still obeys the rules you cannot attack the unit you must have a detector and so on but its kind of one of the main things that it just doesnt feel theres a very proper way i mean you could imagine oh you dont have hypers maybe you dont know exactly where it is or sometimes you see it sometimes you dont but its just really really complicated to get it so that everyone would agree oh thats the best way to simulate this right it seems like a perception problem it is a perception problem so the only problem is people you ask oh whats the difference between how humans perceive the game i would say they wouldnt be able to tell a shimmer immediately as it appears on the screen whereas alphastar in principle sees it very sharply right it sees that the bit turned from zero to one meaning theres now a unit there although you dont know the unit or you know that you cannot attack it and so on so that from a vision standpoint that probably is the one that is kind of the most obvious one then there are things humans cannot do perfectly even professionals which is they might miss a detail or they might have not seen a unit and obviously as a computer if theres a corner of the screen that turns green because a unit enters the field of view that can go into the memory of the agent the lstm and persist there for a while and for however long is relevant right and in terms of action it seems like the rate of action from alphastar is comparative if not slower than professional players but its more precise is what i read so thats really probably the one that is causing us more issues for a couple of reasons right the first one is starcraft has been an ai environment for quite a few years in fact i mean i was participating in the very first competition back in 2010 and theres really not been a kind of a very clear set of rules how the actions per minute the rate of actions that you can issue is and as a result these agents or bots that people build in a kind of almost very cool way they do like 20000 40000 actions per minute now to put this in perspective a very good professional human might do 300 to 800 actions per minute they might not be as precise thats why the range is a bit tricky to identify exactly i mean 300 actions per minute precisely is probably realistic 800 is probably not but you see humans doing a lot of actions because they warm up and they kind of select things and spam and so on just so that when they need they have the accuracy so we came into this by not having kind of a standard way to say well how do we measure whether an agent is at human level or not on the other hand we had a huge advantage which is because we do imitation learning agents turned out to act like humans in terms of rate of actions even precisions and imprecisions of actions in the supervised policy you could see all these you could see how agents like to spam click to move here if you played especially diablo you wouldnt know what i mean i mean you just like spam oh move here move here move here youre doing literally like maybe five actions in two seconds but these actions are not very meaningful one would have sufficed so on the one hand we start from this imitation policy that is at the ballpark of the actions per minutes of humans because its actually statistically trying to imitate humans so we see these very nicely in the curves that we showed in the blog post theres these actions per minute and the distribution looks very human like but then of course as self play kicks in and thats the part we havent talked too much yet but of course the agent must play against itself to improve then theres almost no guarantees that these actions will not become more precise or even the rate of actions is going to increase over time so what we did and this is probably the first attempt that we thought was reasonable is we looked at the distribution of actions for humans for certain windows of time and just to give a perspective because i guess i mentioned that some of these agents that are programmatic lets call them they do 40000 actions per minute professionals as i said do 300 to 800 so what we looked is we look at the distribution over professional gamers and we took reasonably high actions per minute but we kind of identify certain cutoffs after which even if the agent wanted to act these actions would be dropped but the problem is this cutoff is probably set a bit too high and what ends up happening even though the games and when we ask the professionals and the gamers by and large they feel like its playing humanlike there are some agents that developed maybe slightly too high apms which is actions per minute combined with the precision which made people start discussing a very interesting issue which is should we have limited these should we just let it lose and see what cool things it can come up with right interesting so this is in itself an extremely interesting question but the same way that modeling the shimmer would be so difficult modeling absolutely all the details about muscles and precision and tiredness of humans would be quite difficult so were really here kind of innovating in this sense of ok what could be maybe the next iteration of putting more rules that makes the agents more humanlike in terms of restrictions yeah putting constraints that more constraints yeah thats really interesting thats really innovative so one of the constraints you put on yourself or at least focused in is on the protoss race as far as i understand can you tell me about the different races and how they so protoss terran and zerg how do they compare how do they interact why did you choose protoss yeah in the dynamics of the game seen from a strategic perspective so protoss so in starcraft there are three races indeed in the demonstration we saw only the protoss race so maybe lets start with that one protoss is kind of the most technologically advanced race it has units that are expensive but powerful so in general you want to kind of conserve your units as you go attack and then you want to utilize these tactical advantages of very fancy spells and so on and so forth and at the same time theyre kind of people say theyre a bit easier to play perhaps but that i actually didnt know i mean i just talked now a lot to the players that we work with tlo and mana and they said oh yeah protoss is actually people think is actually one of the easiest races so perhaps the easier that doesnt mean that its obviously professional players excel at the three races and theres never a race that dominates for a very long time anyway so if you look at the top i dont know 100 in the world is there one race that dominates that list it would be hard to know because it depends on the regions i think its pretty equal in terms of distribution and blizzard wants it to be equal they wouldnt want one race like protoss to not be representative in the top place so definitely they tried it to be balanced so then maybe the opposite race of protoss is zerg zerg is a race where you just kind of expand and take over as many resources as you can and they have a very high capacity to regenerate their units so if you have an army its not that valuable in terms of losing the whole army is not a big deal as zerg because you can then rebuild it and given that you generally accumulate a huge bank of resources zergs typically play by applying a lot of pressure maybe losing their whole army but then rebuilding it quickly so although of course every race i mean theres never i mean theyre pretty diverse i mean there are some units in zerg that are technologically advanced and they do some very interesting spells and theres some units in protoss that are less valuable and you could lose a lot of them and rebuild them and it wouldnt be a big deal all right so maybe im missing out maybe im going to say some dumb stuff but summary of strategy so first theres collection of a lot of resources thats one option the other one is expanding so building other bases then the other is obviously building units and attacking with those units and then i dont know what else there is maybe theres the different timing of attacks like do i attack early attack late what are the different strategies that emerged that youve learned about ive read that a bunch of people are super happy that you guys have apparently that alpha star apparently has discovered that its really good to what is it saturate oh yeah the mineral line yeah the mineral line yeah yeah and thats for greedy amateur players like myself thats always been a good strategy you just build up a lot of money and it just feels good to just accumulate and accumulate so thank you for discovering that and validating all of us but is there other strategies that you discovered that are interesting unique to this game yeah so if you look at the kind of not being a starcraft ii player but of course starcraft and starcraft ii and real time strategy games in general are very similar i would classify perhaps the openings of the game theyre very important and generally i would say theres two kinds of openings one thats a standard opening thats generally how players find sort of a balance between risk and economy and building some units early on so that they could defend but theyre not too exposed basically but also expanding quite quickly so this would be kind of a standard opening and within a standard opening then what you do choose generally is what technology are you aiming towards so theres a bit of rock paper scissors of you could go for spaceships or you could go for invisible units or you could go for i dont know like massive units that attack against certain kinds of units but theyre weak against others so standard openings themselves have some choices like rock paper scissors style of course if you scout and youre good at guessing what the opponent is doing then you can play as an advantage because if you know youre gonna play rock i mean im gonna play paper obviously so you can imagine that normal standard games in starcraft looks like a continuous rock paper scissors game where you guess what the distribution of rock paper and scissors is from the enemy and reacting accordingly to try to beat it or put the paper out before he kind of changes his mind from rock to scissors and then you would be in a weak position so sorry to pause on that i didnt realize this element because i know its true with poker i know i looked at labratus so youre also estimating trying to guess the distribution trying to better and better estimate the distribution of what the opponent is likely to be doing yeah i mean as a player you definitely wanna have a belief state over whats up on the other side of the map and when your belief state becomes inaccurate when you start having that serious doubts whether hes gonna play something that you must know thats when you scout you wanna then gather information right is improving the accuracy of the belief or improving the belief state part of the loss that youre trying to optimize or is it just a side effect its implicit but you could explicitly model it and it would be quite good at probably predicting whats on the other side of the map but so far its all implicit theres no additional reward for predicting the enemy so theres these standard openings and then theres what people call cheese which is very interesting and alphastar sometimes really likes this kind of cheese these cheeses what they are is kind of an all in strategy youre gonna do something sneaky youre gonna hide your own buildings close to the enemy base or youre gonna go for hiding your technological buildings so that you do invisible units and the enemy just cannot react to detect it and thus lose the game and theres quite a few of these cheeses and variants of them and there its where actually the belief state becomes even more important because if i scout your base and i see no buildings at all any human player knows somethings up they might know well youre hiding something close to my base should i build suddenly a lot of units to defend should i actually block my ramp with workers so that you cannot come and destroy my base so theres all this is happening and defending against cheeses is extremely important and in the alphastar league many agents actually develop some cheesy strategies and in the games we saw against tlo and mana two out of the 10 agents were actually doing these kind of strategies which are cheesy strategies and then theres a variant of cheesy strategy which is called all in so an all in strategy is not perhaps as drastic as oh im gonna build cannons on your base and then bring all my workers and try to just disrupt your base and game over or gg as we say in starcraft theres these kind of very cool things that you can align precisely at a certain time mark so for instance you can generate exactly 10 unit composition that is perfect like five of this type five of this other type and align the upgrade so that at four minutes and a half lets say you have these 10 units and the upgrade just finished and at that point that army is really scary and unless the enemy really knows whats going on if you push you might then have an advantage because maybe the enemy is doing something more standard it expanded too much it developed too much economy and it trade off badly against having defenses and the enemy will lose but its called all in because if you dont win then youre gonna lose so you see players that do these kinds of strategies if they dont succeed game is not over i mean they still have a base and they still gathering minerals but they will just gg out of the game because they know well game is over i gambled and i failed so if we start entering the game theoretic aspects of the game its really rich and its really thats why it also makes it quite entertaining to watch even if i dont play i still enjoy watching the game but the agents are trying to do this mostly implicitly but one element that we improved in self play is creating the alpha star league and the alpha star league is not pure self play its trying to create a different personalities of agents so that some of them will become cheesy agents some of them might become very economical very greedy like getting all the resources but then being maybe early on theyre gonna be weak but later on theyre gonna be very strong and by creating this personality of agents which sometimes it just happens naturally that you can see kind of an evolution of agents that given the previous generation they train against all of them and then they generate kind of the perfect counter to that distribution but these agents you must have them in the populations because if you dont have them youre not covered against these things you wanna create all sorts of the opponents that you will find in the wild so you can be exposed to these cheeses early aggression later aggression more expansions dropping units in your base from the side all these things and pure self play is getting a bit stuck at finding some subset of these but not all of these so the alpha star league is a way to kind of do an ensemble of agents that theyre all playing in a league much like people play on battlenet right they play you play against someone who does a new cool strategy and you immediately oh my god i wanna try it i wanna play again and this to me was another critical part of the problem which was can we create a battlenet for agents and thats kind of what the alpha star league really is thats fascinating and where they stick to their different strategies yeah wow thats really really interesting but that said you were fortunate enough or just skilled enough to win five zero and so how hard is it to win i mean thats not the goal i guess i dont know what the goal is the goal should be to win majority not five zero but how hard is it in general to win all matchups on a one v one so thats a very interesting question because once you see alpha star and superficially you think well okay it won lets if you sum all the games like 10 to one right it lost the game that it played with the camera interface you might think well thats done right its superhuman at the game and thats not really the claim we really can make actually the claim is we beat a professional gamer for the first time starcraft has really been a thing that has been going on for a few years but a moment like this had not occurred before yet but are these agents impossible to beat absolutely not right so thats a bit whats kind of the difference is the agents play at grandmaster level they definitely understand the game enough to play extremely well but are they unbeatable do they play perfect no and actually in starcraft because of these sneaky strategies its always possible that you might take a huge risk sometimes but you might get wins right out of this so i think that as a domain it still has a lot of opportunities not only because of course we wanna learn with less experience we would like to i mean if i learned to play protoss i can play terran and learn it much quicker than alpha star can right so there are obvious interesting research challenges as well but even as the raw performance goes really the claim here can be we are at pro level or at high grandmaster level but obviously the players also did not know what to expect right their prior distribution was a bit off because they played this kind of new like alien brain as they like to say it right and thats what makes it exciting for them but also i think if you look at the games closely you see there were weaknesses in some points maybe alpha star did not scout or if it had invisible units going against at certain points it wouldnt have known and it would have been bad so theres still quite a lot of work to do but its really a very exciting moment for us to be seeing wow a single neural net on a gpu is actually playing against these guys who are amazing i mean you have to see them play in life theyre really really amazing players yeah im sure there must be a guy in poland somewhere right now training his butt off to make sure that this never happens again with alpha star so thats really exciting in terms of alpha star having some holes to exploit which is great and then we build on top of each other and it feels like starcraft on let go even if you win its still not theres so many different dimensions in which you can explore so thats really really interesting do you think theres a ceiling to alpha star youve said that it hasnt reached you know this is a big wait let me actually just pause for a second how did it feel to come here to this point to beat a top professional player like that night i mean you know olympic athletes have their gold medal right this is your gold medal in a sense sure youre cited a lot youve published a lot of prestigious papers whatever but this is like a win how did it feel i mean it was for me it was unbelievable because first the win itself', 'the following is a conversation with chris latner currently hes a senior director at google working on several projects including cpu gpu tpu accelerators for tensorflow swift for tensorflow and all kinds of machine learning compiler magic going on behind the scenes hes one of the top experts in the world on compiler technologies which means he deeply understands the intricacies of how hardware and software come together to create efficient code he created the llvm compiler infrastructure project and the clang compiler he led major engineering efforts at apple including the creation of the swift programming language he also briefly spent time at tesla as vice president of autopilot software during the transition from autopilot hardware 1 to hardware 2 when tesla essentially started from scratch to build an in house software infrastructure for autopilot i could have easily talked to chris for many more hours compiling code down across the levels of abstraction is one of the most fundamental and fascinating aspects of what computers do and he is one of the world experts in this process its rigorous science and its messy beautiful art this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with chris ladner what was the first program youve ever written my first program back and when was it i think i started as a kid and my parents got a basic programming book and so when i started it was typing out programs from a book and seeing how they worked and then typing them in wrong and trying to figure out why they were not working right that kind of stuff so basic what was the first language that you remember yourself maybe falling in love with like really connecting with i dont know i mean i feel like ive learned a lot along the way and each of them have a different special thing about them so i started in basic and then went like gw basic which was the thing back in the dos days and then upgraded to qbasic and eventually quickbasic which are all slightly more fancy versions of microsoft basic made the jump to pascal and started doing machine language programming and assembly in pascal which was really cool turbo pascal was amazing for its day eventually got into c c and then kind of did lots of other weird things i feel like you took the dark path which is the you could have gone lisp yeah you could have gone higher level sort of functional philosophical hippie route instead you went into like the dark arts of the c it was straight into the machine straight to the machine so i started with basic pascal and then assembly and then wrote a lot of assembly and i eventually did smalltalk and other things like that but that was not the starting point but so what is this journey to c is that in high school is that in college that was in high school yeah and then that was really about trying to be able to do more powerful things than what pascal could do and also to learn a different world so he was really confusing to me with pointers and the syntax and everything and it took a while but pascals much more principled in various ways c is more i mean it has its historical roots but its not as easy to learn with pointers theres this memory management thing that you have to become conscious of is that the first time you start to understand that theres resources that youre supposed to manage well so you have that in pascal as well but in pascal like the caret instead of the star theres some small differences like that but its not about pointer arithmetic and in c you end up thinking about how things get laid out in memory a lot more and so in pascal you have allocating and deallocating and owning the memory but just the programs are simpler and you dont have to well for example pascal has a string type and so you can think about a string instead of an array of characters which are consecutive in memory so its a little bit of a higher level abstraction so lets get into it lets talk about llvm c lang and compilers sure so can you tell me first what llvm and c lang are and how is it that you find yourself the creator and lead developer one of the most powerful compiler optimization systems in use today sure so i guess theyre different things so lets start with what is a compiler is that a good place to start what are the phases of a compiler where are the parts yeah what is it so what is even a compiler used for so the way i look at this is you have a two sided problem of you have humans that need to write code and then you have machines that need to run the program that the human wrote and for lots of reasons the humans dont want to be writing in binary and want to think about every piece of hardware and so at the same time that you have lots of humans you also have lots of kinds of hardware and so compilers are the art of allowing humans to think at a level of abstraction that they want to think about and then get that program get the thing that they wrote to run on a specific piece of hardware and the interesting and exciting part of all this is that theres now lots of different kinds of hardware chips like x86 and powerpc and arm and things like that but also high performance accelerators for machine learning and other things like that are also just different kinds of hardware gpus these are new kinds of hardware and at the same time on the programming side of it you have basic you have c you have javascript you have python you have swift you have lots of other languages that are all trying to talk to the human in a different way to make them more expressive and capable and powerful and so compilers are the thing that goes from one to the other end to end from the very beginning to the very end end to end and so you go from what the human wrote and programming languages end up being about expressing intent not just for the compiler and the hardware but the programming languages job is really to capture an expression of what the programmer wanted that then can be maintained and adapted and evolved by other humans as well as interpreted by the compiler so when you look at this problem you have on the one hand humans which are complicated and you have hardware which is complicated and so compilers typically work in multiple phases and so the software engineering challenge that you have here is try to get maximum reuse out of the amount of code that you write because these compilers are very complicated and so the way it typically works out is that you have something called a front end or a parser that is language specific and so youll have a c parser and thats what clang is or c or javascript or python or whatever thats the front end then youll have a middle part which is often the optimizer and then youll have a late part which is hardware specific and so compilers end up theres many different layers often but these three big groups are very common in compilers and what llvm is trying to do is trying to standardize that middle and last part and so one of the cool things about llvm is that there are a lot of different languages that compile through to it and so things like swift but also julia rust clang for c c subjective c like these are all very different languages and they can all use the same optimization infrastructure which gets better performance and the same code generation infrastructure for hardware support and so llvm is really that layer that is common that all these different specific compilers can use and is it a standard like a specification or is it literally an implementation its an implementation and so i think theres a couple of different ways of looking at it right because it depends on which angle youre looking at it from llvm ends up being a bunch of code okay so its a bunch of code that people reuse and they build compilers with we call it a compiler infrastructure because its kind of the underlying platform that you build a concrete compiler on top of but its also a community and the llvm community is hundreds of people that all collaborate and one of the most fascinating things about llvm over the course of time is that weve managed somehow to successfully get harsh competitors in the commercial space to collaborate on shared infrastructure and so you have google and apple you have amd and intel you have nvidia and amd on the graphics side you have cray and everybody else doing these things and all these companies are collaborating together to make that shared infrastructure really really great and they do this not out of the goodness of their heart but they do it because its in their commercial interest of having really great infrastructure that they can build on top of and facing the reality that its so expensive that no one company even the big companies no one company really wants to implement it all themselves expensive or difficult both thats a great point because its also about the skill sets and the skill sets are very hard to find how big is the llvm it always seems like with open source projects the kind an llvm is open source yes its open source its about its 19 years old now so its fairly old it seems like the magic often happens within a very small circle of people yes at least their early birth and whatever yes so the llvm came from a university project and so i was at the university of illinois and there it was myself my advisor and then a team of two or three research students in the research group and we built many of the core pieces initially i then graduated and went to apple and at apple brought it to the products first in the opengl graphics stack but eventually to the c compiler realm and eventually built clang and eventually built swift and these things along the way building a team of people that are really amazing compiler engineers that helped build a lot of that and so as it was gaining momentum and as apple was using it being open source and public and encouraging contribution many others for example at google came in and started contributing and in some cases google effectively owns clang now because it cares so much about c and the evolution of that ecosystem and so its investing a lot in the c world and the tooling and things like that and so likewise nvidia cares a lot about cuda and so cuda uses clang and uses llvm for graphics and gpgpu and so when you first started as a masters project i guess did you think it was gonna go as far as it went were you crazy ambitious about it no it seems like a really difficult undertaking a brave one yeah no no no it was nothing like that so my goal when i went to the university of illinois was to get in and out with a non thesis masters in a year and get back to work so i was not planning to stay for five years and build this massive infrastructure i got nerd sniped into staying and a lot of it was because llvm was fun and i was building cool stuff and learning really interesting things and facing both software engineering challenges but also learning how to work in a team and things like that i had worked at many companies as interns before that but it was really a different thing to have a team of people that are working together and try and collaborate in version control and it was just a little bit different like i said i just talked to don knuth and he believes that 2 of the world population have something weird with their brain that theyre geeks they understand computers theyre connected with computers he put it at exactly 2 okay so hes a specific guy its very specific well he says i cant prove it but its very empirically there is there something that attracts you to the idea of optimizing code and he seems like thats one of the biggest coolest things about llvm yeah thats one of the major things it does so i got into that because of a person actually so when i was in my undergraduate i had an advisor or a professor named steve vegdahl and he i went to this little tiny private school there were like seven or nine people in my computer science department students in my class so it was a very tiny very small school it was kind of a wart on the side of the math department kind of a thing at the time i think its evolved a lot in the many years since then but steve vegdahl was a compiler guy and he was super passionate and his passion rubbed off on me and one of the things i like about compilers is that theyre large complicated software pieces and so one of the culminating classes that many computer science departments at least at the time did was to say that you would take algorithms and data structures and all these core classes but then the compilers class was one of the last classes you take because it pulls everything together and then you work on one piece of code over the entire semester and so you keep building on your own work which is really interesting and its also very challenging because in many classes if you dont get a project done you just forget about it and move on to the next one and get your b or whatever it is but here you have to live with the decisions you make and continue to reinvest in it and i really like that and so i did an extra study project with him the following semester and he was just really great and he was also a great mentor in a lot of ways and so from him and from his advice he encouraged me to go to graduate school i wasnt super excited about going to grad school i wanted the masters degree but i didnt want to be an academic but like i said i kind of got tricked into saying and was having a lot of fun and i definitely do not regret it what aspects of compilers were the things you connected with so llvm theres also the other part thats really interesting if youre interested in languages is parsing and just analyzing the language breaking it down parsing and so on was that interesting to you or were you more interested in optimization for me it was more so im not really a math person i could do math i understand some bits of it when i get into it but math is never the thing that attracted me and so a lot of the parser part of the compiler has a lot of good formal theories that don for example knows quite well im still waiting for his book on that but i just like building a thing and seeing what it could do and exploring and getting it to do more things and then setting new goals and reaching for them and in the case of llvm when i started working on that my research advisor that i was working for was a compiler guy and so he and i specifically found each other because we were both interested in compilers and so i started working with him and taking his class and a lot of llvm initially was its fun implementing all the standard algorithms and all the things that people had been talking about and were well known and they were in the curricula for advanced studies and compilers and so just being able to build that was really fun and i was learning a lot by instead of reading about it just building and so i enjoyed that so you said compilers are these complicated systems can you even just with language try to describe how you turn a c program into code like what are the hard parts why is it so hard so ill give you examples of the hard parts along the way so c is a very complicated programming language its something like 1400 pages in the spec so c by itself is crazy complicated can we just pause what makes the language complicated in terms of whats syntactically so its what they call syntax so the actual how the characters are arranged yes its also semantics how it behaves its also in the case of c theres a huge amount of history c is built on top of c you play that forward and then a bunch of suboptimal in some cases decisions were made and they compound and then more and more and more things keep getting added to c and it will probably never stop but the language is very complicated from that perspective and so the interactions between subsystems is very complicated theres just a lot there and when you talk about the front end one of the major challenges which clang as a project the c c compiler that i built i and many people built one of the challenges we took on was we looked at gcc gcc at the time was a really good industry standardized compiler that had really consolidated a lot of the other compilers in the world and was a standard but it wasnt really great for research the design was very difficult to work with and it was full of global variables and other things that made it very difficult to reuse in ways that it wasnt originally designed for and so with clang one of the things that we wanted to do is push forward on better user interface so make error messages that are just better than gccs and thats actually hard because you have to do a lot of bookkeeping in an efficient way to be able to do that we want to make compile time better and so compile time is about making it efficient which is also really hard when youre keeping track of extra information we wanted to make new tools available so refactoring tools and other analysis tools that gcc never supported also leveraging the extra information we kept but enabling those new classes of tools that then get built into ides and so thats been one of the areas that clang has really helped push the world forward in is in the tooling for c and c and things like that but c and the front end piece is complicated and you have to build syntax trees and you have to check every rule in the spec and you have to turn that back into an error message to the human that the human can understand when they do something wrong but then you start doing whats called lowering so going from c and the way that it represents code down to the machine and when you do that theres many different phases you go through often there are i think llvm has something like 150 different what are called passes in the compiler that the code passes through and these get organized in very complicated ways which affect the generated code and the performance and compile time and many other things what are they passing through so after you do the clang parsing whats the graph what does it look like whats the data structure here yeah so in the parser its usually a tree and its called an abstract syntax tree and so the idea is you have a node for the plus that the human wrote in their code or the function call youll have a node for call with the function that they call and the arguments they pass things like that this then gets lowered into whats called an intermediate representation and intermediate representations are like llvm has one and there its whats called a control flow graph and so you represent each operation in the program as a very simple like this is going to add two numbers this is going to multiply two things maybe well do a call but then they get put in what are called blocks and so you get blocks of these straight line operations where instead of being nested like in a tree its straight line operations and so theres a sequence and an ordering to these operations so within the block or outside the block thats within the block and so its a straight line sequence of operations within the block and then you have branches like conditional branches between blocks working on optimizing network transport of weights across the network originally and trying to find ways to compress that but then it got burned into silicon and its a key part of what makes tpu performance so amazing and great now tpus have many different aspects that are important but the co design between the low level compiler bits and the software bits and the algorithms is all super important and its this amazing trifecta that only google can do yeah thats super exciting so can you tell me about mlir project previously the secretive one yeah so mlir is a project that we announced at a compiler conference three weeks ago or something at the compilers for machine learning conference basically again if you look at tensorflow as a compiler stack it has a number of compiler algorithms within it it also has a number of compilers that get embedded into it and theyre made by different vendors for example google has xla which is a great compiler system nvidia has tensorrt intel has ngraph theres a number of these different compiler systems and theyre very hardware specific and theyre trying to solve different parts of the problems but theyre all kind of similar in a sense of they want to integrate with tensorflow now tensorflow has an optimizer and it has these different code generation technologies built in the idea of mlir is to build a common infrastructure to support all these different subsystems and initially its to be able to make it so that they all plug in together and they can share a lot more code and can be reusable but over time we hope that the industry will start collaborating and sharing code and instead of reinventing the same things over and over again that we can actually foster some of that working together to solve common problem energy that has been useful in the compiler field before beyond that mlir is some people have joked that its kind of llvm too it learns a lot about what llvm has been good and what llvm has done wrong and its a chance to fix that and also there are challenges in the llvm ecosystem as well where llvm is very good at the thing it was designed to do but 20 years later the world has changed and people are trying to solve higher level problems and we need some new technology and whats the future of open source in this context very soon so it is not yet open source but it will be hopefully in the next couple months so you still believe in the value of open source in these kinds of contexts oh yeah absolutely and i think that the tensorflow community at large fully believes in open source so i mean there is a difference between apple where you were previously and google now in spirit and culture and i would say the open source in tensorflow was a seminal moment in the history of software because heres this large company releasing a very large code base thats open sourcing what are your thoughts on that happy or not were you to see that kind of degree of open sourcing so between the two i prefer the google approach if thats what youre saying the apple approach makes sense given the historical context that apple came from but thats been 35 years ago and i think that apple is definitely adapting and the way i look at it is that theres different kinds of concerns in the space it is very rational for a business to care about making money that fundamentally is what a business is about but i think its also incredibly realistic to say its not your string library thats the thing thats going to make you money its going to be the amazing ui product differentiating features and other things like that that you built on top of your string library and so keeping your string library proprietary and secret and things like that is maybe not the important thing anymore where before platforms were different and even 15 years ago things were a little bit different but the world is changing so google strikes a very good balance i think and i think that tensorflow being open source really changed the entire machine learning field and caused a revolution in its own right and so i think its amazingly forward looking because i could have imagined and i wasnt at google at the time but i could imagine a different context and different world where a company says machine learning is critical to what were doing were not going to give it to other people and so that decision is a profoundly brilliant insight that i think has really led to the world being better and better for google as well and has all kinds of ripple effects i think it is really i mean you cant understate google deciding how profound that is for software its awesome well and again i can understand the concern about if we release our machine learning software our competitors could go faster but on the other hand i think that open sourcing tensorflow has been fantastic for google and im sure that decision was very nonobvious at the time but i think its worked out very well so lets try this real quick you were at tesla for five months as the vp of autopilot software you led the team during the transition from h hardware one to hardware two i have a couple of questions so one first of all to me thats one of the bravest engineering decisions undertaking really ever in the automotive industry to me software wise starting from scratch its a really brave engineering decision so my one question there is what was that like what was the challenge of that do you mean the career decision of jumping from a comfortable good job into the unknown or that combined so at the individual level you making that decision and then when you show up its a really hard engineering problem so you could just stay maybe slow down say hardware one or those kinds of decisions just taking it full on lets do this from scratch what was that like well so i mean i dont think tesla has a culture of taking things slow and seeing how it goes and one of the things that attracted me about tesla is its very much a gung ho lets change the world lets figure it out kind of a place and so i have a huge amount of respect for that tesla has done very smart things with hardware one in particular and the hardware one design was originally designed to be very simple automation features in the car for like traffic aware cruise control and things like that and the fact that they were able to effectively feature creep it into lane holding and a very useful driver assistance feature is pretty astounding particularly given the details of the hardware hardware two built on that in a lot of ways and the challenge there was that they were transitioning from a third party provided vision stack to an in house built vision stack and so for the first step which i mostly helped with was getting onto that new vision stack and that was very challenging and it was time critical for various reasons and it was a big leap but it was fortunate that it built on a lot of the knowledge and expertise and the team that had built hardware ones driver assistance features so you spoke in a collected and kind way about your time at tesla but it was ultimately not a good fit elon musk weve talked on this podcast several guests to the course elon musk continues to do some of the most bold and innovative engineering work in the world at times at the cost some of the members of the tesla team what did you learn about working in this chaotic world with elon yeah so i guess i would say that when i was at tesla i experienced and saw the highest degree of turnover id ever seen in a company which was a bit of a shock but one of the things i learned and i came to respect is that elons able to attract amazing talent because he has a very clear vision of the future and he can get people to buy into it because they want that future to happen and the power of vision is something that i have a tremendous amount of respect for and i think that elon is fairly singular in the world in terms of the things hes able to get people to believe in and there are many people that stand in the street corner and say ah were going to go to mars right but then there are a few people that can get others to buy into it and believe and build the path and make it happen and so i respect that i dont respect all of his methods but i have a huge amount of respect for that youve mentioned in a few places including in this context working hard what does it mean to work hard and when you look back at your life what were some of the most brutal periods of having to really put everything you have into something yeah good question so working hard can be defined a lot of different ways so a lot of hours and so that is true the thing to me thats the hardest is both being short term focused on delivering and executing and making a thing happen while also thinking about the longer term and trying to balance that because if you are myopically focused on solving a task and getting that done and only think about that incremental next step you will miss the next big hill you should jump over to and so ive been really fortunate that ive been able to kind of oscillate between the two and historically at apple for example that was made possible because i was able to work with some really amazing people and build up teams and leadership structures and allow them to grow in their careers and take on responsibility thereby freeing up me to be a little bit crazy and thinking about the next thing and so its a lot of that but its also about with experience you make connections that other people dont necessarily make and so i think thats a big part as well but the bedrock is just a lot of hours and thats ok with me theres different theories on work life balance and my theory for myself which i do not project onto the team but my theory for myself is that i want to love what im doing and work really hard and my purpose i feel like and my goal is to change the world and make it a better place and thats what im really motivated to do so last question llvm logo is a dragon you explain that this is because dragons have connotations of power speed intelligence it can also be sleek elegant and modular though you remove the modular part what is your favorite dragon related character from fiction video or movies so those are all very kind ways of explaining it do you want to know the real reason its a dragon yeah is that better so there is a seminal book on compiler design called the dragon book and so this is a really old now book on compilers and so the dragon logo for llvm came about because at apple we kept talking about llvm related technologies and theres no logo to put on a slide and so were like what do we do and somebodys like well what kind of logo should a compiler technology have and im like i dont know i mean the dragon is the best thing that weve got and apple somehow magically came up with the logo and it was a great thing and the whole community rallied around it and then it got better as other graphic designers got involved but thats originally where it came from the story is there dragons from fiction that you connect with that game of thrones lord of the rings that kind of thing lord of the rings is great i also like role playing games and things like computer role playing games and so dragons often show up in there but really it comes back to the book oh no we need a thing and hilariously one of the funny things about llvm is that my wife whos amazing runs the llvm foundation and she goes to grace hopper and is trying to get more women involved in the shes also a compiler engineer so shes trying to get other women to get interested in compilers and things like this and so she hands out the stickers and people like the llvm sticker because of game of thrones and so sometimes culture has this helpful effect to get the next generation of compiler engineers engaged with the cause ok awesome chris thanks so much for talking with us its been great talking with you and so when you write a loop for example in a syntax tree you would have a for node like for a for statement in a c like language youd have a for node and you have a pointer to the expression for the initializer a pointer to the expression for the increment a pointer to the expression for the comparison a pointer to the body and these are all nested underneath it in a control flow graph you get a block for the code that runs before the loop so the initializer code and you have a block for the body of the loop and so the body of the loop code goes in there but also the increment and other things like that and then you have a branch that goes back to the top and a comparison and a branch that goes out and so its more of an assembly level kind of representation but the nice thing about this level of representation is its much more language independent and so theres lots of different kinds of languages with different kinds of you know javascript has a lot of different ideas of what is false for example and all that can stay in the front end but then that middle part can be shared across all those how close is that intermediate representation to neural networks for example are they because everything you describe is a kind of echoes of a neural network graph are they neighbors or what theyre quite different in details but theyre very similar in idea so one of the things that neural networks do is they learn representations for data at different levels of abstraction and then they transform those through layers right so the compiler does very similar things but one of the things the compiler does is it has relatively few different representations where a neural network often as you get deeper for example you get many different representations in each layer or set of ops its transforming between these different representations in a compiler often you get one representation and they do many transformations to it and these transformations are often applied iteratively and for programmers theres familiar types of things for example trying to find expressions inside of a loop and pulling them out of a loop so they execute for times or find redundant computation or find constant folding or other simplifications turning two times x into x shift left by one and things like this are all the examples of the things that happen but compilers end up getting a lot of theorem proving and other kinds of algorithms that try to find higher level properties of the program that then can be used by the optimizer cool so whats the biggest bang for the buck with optimization today yeah well no not even today at the very beginning the 80s i dont know yeah so for the 80s a lot of it was things like register allocation so the idea of in a modern microprocessor what youll end up having is youll end up having memory which is relatively slow and then you have registers that are relatively fast but registers you dont have very many of them and so when youre writing a bunch of code youre just saying compute this put in a temporary variable compute this compute this compute this put in a temporary variable i have a loop i have some other stuff going on well now youre running on an x86 like a desktop pc or something well it only has in some cases some modes eight registers and so now the compiler has to choose what values get put in what registers at what points in the program and this is actually a really big deal so if you think about you have a loop an inner loop that executes millions of times maybe if youre doing loads and stores inside that loop then its going to be really slow but if you can somehow fit all the values inside that loop in registers now its really fast and so getting that right requires a lot of work because theres many different ways to do that and often what the compiler ends up doing is it ends up thinking about things in a different representation than what the human wrote you wrote into x well the compiler thinks about that as four different values each which have different lifetimes across the function that its in and each of those could be put in a register or memory or different memory or maybe in some parts of the code recomputed instead of stored and reloaded and there are many of these different kinds of techniques that can be used so its adding almost like a time dimension to its trying to optimize across time so its considering when youre programming youre not thinking in that way yeah absolutely and so the risc era made things so risc chips r i s c the risc chips as opposed to cisc chips the risc chips made things more complicated for the compiler because what they ended up doing is ending up adding pipelines to the processor where the processor can do more than one thing at a time but this means that the order of operations matters a lot so one of the classical compiler techniques that you use is called scheduling and so moving the instructions around so that the processor can keep its pipelines full instead of stalling and getting blocked and so theres a lot of things like that that are kind of bread and butter compiler techniques that have been studied a lot over the course of decades now but the engineering side of making them real is also still quite hard and you talk about machine learning this is a huge opportunity for machine learning because many of these algorithms are full of these hokey hand rolled heuristics which work well on specific benchmarks that dont generalize and full of magic numbers and i hear theres some techniques that are good at handling that so what would be the if you were to apply machine learning to this whats the thing youre trying to optimize is it ultimately the running time you can pick your metric and theres running time theres memory use theres lots of different things that you can optimize for code size is another one that some people care about in the embedded space is this like the thinking into the future or has somebody actually been crazy enough to try to have machine learning based parameter tuning for the optimization of compilers so this is something that is i would say research right now there are a lot of research systems that have been applying search in various forms and using reinforcement learning is one form but also brute force search has been tried for quite a while and usually these are in small problem spaces so find the optimal way to code generate a matrix multiply for a gpu something like that where you say there theres a lot of design space of do you unroll loops a lot do you execute multiple things in parallel and theres many different confounding factors here because graphics cards have different numbers of threads and registers and execution ports and memory bandwidth and many different constraints that interact in nonlinear ways and so search is very powerful for that and it gets used in certain ways but its not very structured this is something that we need we as an industry need to fix so you said 80s but like so have there been like big jumps in improvement and optimization yeah yeah since then whats the coolest thing its largely been driven by hardware so well its hardware and software so in the mid nineties java totally changed the world right and im still amazed by how much change was introduced by the way or in a good way so like reflecting back java introduced things like all at once introduced things like jit compilation none of these were novel but it pulled it together and made it mainstream and made people invest in it jit compilation garbage collection portable code safe code like memory safe code like a very dynamic dispatch execution model like many of these things which had been done in research systems and had been done in small ways in various places really came to the forefront really changed how things worked and therefore changed the way people thought about the problem javascript was another major world change based on the way it works but also on the hardware side of things multi core and vector instructions really change the problem space and are very they dont remove any of the problems that compilers faced in the past but they add new kinds of problems of how do you find enough work to keep a four wide vector busy right or if youre doing a matrix multiplication how do you do different columns out of that matrix at the same time and how do you maximally utilize the arithmetic compute that one core has and then how do you take it to multiple cores how did the whole virtual machine thing change the compilation pipeline yeah so what the java virtual machine does is it splits just like i was talking about before where you have a front end that parses the code and then you have an intermediate representation that gets transformed what java did was they said we will parse the code and then compile to whats known as java byte code and that byte code is now a portable code representation that is industry standard and locked down and cant change and then the back part of the compiler that does optimization and code generation can now be built by different vendors okay and java byte code can be shipped around across the wire its memory safe and relatively trusted and because of that it can run in the browser and thats why it runs in the browser right and so that way you can be in again back in the day you would write a java applet and as a web developer youd build this mini app that would run on a webpage well a user of that is running a web browser on their computer you download that java byte code which can be trusted and then you do all the compiler stuff on your machine so that you know that you trust that now is that a good idea or a bad idea its a great idea i mean its a great idea for certain problems and im very much a believer that technology is itself neither good nor bad its how you apply it you know this would be a very very bad thing for very low levels of the software stack but in terms of solving some of these software portability and transparency or portability problems i think its been really good now java ultimately didnt win out on the desktop and like there are good reasons for that but its been very successful on servers and in many places its been a very successful thing over decades so what has been llvms and c langs improvements and optimization that throughout its history what are some moments we had set back and really proud of whats been accomplished yeah i think that the interesting thing about llvm is not the innovations and compiler research it has very good implementations of various important algorithms no doubt and a lot of really smart people have worked on it but i think that the thing thats most profound about llvm is that through standardization it made things possible that otherwise wouldnt have happened okay and so interesting things that have happened with llvm for example sony has picked up llvm and used it to do all the graphics compilation in their movie production pipeline and so now theyre able to have better special effects because of llvm thats kind of cool thats not what it was designed for right but thats the sign of good infrastructure when it can be used in ways it was never designed for because it has good layering and software engineering and its composable and things like that which is where as you said it differs from gcc yes gcc is also great in various ways but its not as good as infrastructure technology its really a c compiler or its a fortran compiler its not infrastructure in the same way now you can tell i dont know what im talking about because i keep saying c lang you can always tell when a person has clues by the way to pronounce something i dont think have i ever used c lang entirely possible have you well so youve used code its generated probably so c lang and llvm are used to compile all the apps on the iphone effectively and the oss it compiles googles production server applications its used to build gamecube games and playstation 4 and things like that so as a user i have but just everything ive done that i experienced with linux has been i believe always gcc yeah i think linux still defaults to gcc and is there a reason for that or is it because i mean is there a reason for that its a combination of technical and social reasons many linux developers do use c lang but the distributions for lots of reasons use gcc historically and theyve not switched yeah because its just anecdotally online it seems that llvm has either reached the level of gcc or superseded on different features or whatever the way i would say it is that theyre so close it doesnt matter yeah exactly like theyre slightly better in some ways slightly worse than otherwise but it doesnt actually really matter anymore that level so in terms of optimization breakthroughs its just been solid incremental work yeah yeah which describes a lot of compilers the hard thing about compilers in my experience is the engineering the software engineering making it so that you can have hundreds of people collaborating on really detailed low level work and scaling that and thats really hard and thats one of the things i think llvm has done well and that kind of goes back to the original design goals with it to be modular and things like that and incidentally i dont want to take all the credit for this right i mean some of the best parts about llvm is that it was designed to be modular and when i started i would write for example a register allocator and then somebody much smarter than me would come in and pull it out and replace it with something else that they would come up with and because its modular they were able to do that and thats one of the challenges with gcc for example is replacing subsystems is incredibly difficult it can be done but it wasnt designed for that and thats one of the reasons that llvms been very successful in the research world as well but in a community sense guido van rossum right from python just retired from what is it benevolent dictator for life right so in managing this community of brilliant compiler folks is there did it for a time at least fall on you to approve things oh yeah so i mean i still have something like an order of magnitude more patches in llvm than anybody else and many of those i wrote myself but you still write i mean youre still close to the to the i dont know what the expression is to the metal you still write code yeah i still write code not as much as i was able to in grad school but thats an important part of my identity but the way that llvm has worked over time is that when i was a grad student i could do all the work and steer everything and review every patch and make sure everything was done exactly the way my opinionated sense felt like it should be done and that was fine but as things scale you cant do that right and so what ends up happening is llvm has a hierarchical system of whats called code owners these code owners are given the responsibility not to do all the work not necessarily to review all the patches but to make sure that the patches do get reviewed and make sure that the right things happening architecturally in their area and so what youll see is youll see that for example hardware manufacturers end up owning the hardware specific parts of their hardware thats very common leaders in the community that have done really good work naturally become the de facto owner of something and then usually somebody else is like how about we make them the official code owner and then well have somebody to make sure that all the patches get reviewed in a timely manner and then everybodys like yes thats obvious and then it happens right and usually this is a very organic thing which is great and so im nominally the top of that stack still but i dont spend a lot of time reviewing patches what i do is i help negotiate a lot of the technical disagreements that end up happening and making sure that the community as a whole makes progress and is moving in the right direction and doing that so we also started a nonprofit six years ago seven years ago times gone away and the llvm foundation nonprofit helps oversee all the business sides of things and make sure that the events that the llvm community has are funded and set up and run correctly and stuff like that but the foundation is very much stays out of the technical side of where the project is going right so it sounds like a lot of it is just organic yeah well llvm is almost 20 years old which is hard to believe somebody pointed out to me recently that llvm is now older than gcc was when llvm started right so time has a way of getting away from you but the good thing about that is it has a really robust really amazing community of people that are in their professional lives spread across lots of different companies but its a community of people that are interested in similar kinds of problems and have been working together effectively for years and have a lot of trust and respect for each other and even if they dont always agree that were able to find a path forward so then in a slightly different flavor of effort you started at apple in 2005 with the task of making i guess llvm production ready and then eventually 2013 through 2017 leading the entire developer tools department were talking about llvm xcode objective c to swift so in a quick overview of your time there what were the challenges first of all leading such a huge group of developers what was the big motivator dream mission behind creating swift the early birth of it from objective c and so on and xcode what are some challenges so these are different questions yeah i know but i wanna talk about the other stuff too ill stay on the technical side then we can talk about the big team pieces if thats okay so its to really oversimplify many years of hard work llvm started joined apple became a thing became successful and became deployed but then theres a question about how do we actually parse the source code so llvm is that back part the optimizer and the code generator and llvm was really good for apple as it went through a couple of harder transitions i joined right at the time of the intel transition for example and 64 bit transitions and then the transition to arm with the iphone and so llvm was very useful for some of these kinds of things but at the same time theres a lot of questions around developer experience and so if youre a programmer pounding out at the time objective c code the error message you get the compile time the turnaround cycle the tooling and the ide were not great were not as good as they could be and so as i occasionally do im like well okay how hard is it to write a c compiler and so im not gonna commit to anybody im not gonna tell anybody im just gonna just do it nights and weekends and start working on it and then i built up in c theres this thing called the preprocessor which people dont like but its actually really hard and complicated and includes a bunch of really weird things like trigraphs and other stuff like that that are really nasty and its the crux of a bunch of the performance issues in the compiler started working on the parser and kind of got to the point where im like ah you know what we could actually do this everybodys saying that this is impossible to do but its actually just hard its not impossible and eventually told my manager about it and hes like oh wow this is great we do need to solve this problem oh this is great we can get you one other person to work with you on this you know and slowly a team is formed and it starts taking off and c for example huge complicated language people always assume that its impossible to implement and its very nearly impossible but its just really really hard and the way to get there is to build it one piece at a time incrementally and that was only possible because we were lucky to hire some really exceptional engineers that knew various parts of it very well and could do great things swift was kind of a similar thing so swift came from we were just finishing off the first version of c support in clang and c is a very formidable and very important language but its also ugly in lots of ways and you cant influence c without thinking there has to be a better thing right and so i started working on swift again with no hope or ambition that would go anywhere just lets see what could be done lets play around with this thing it was me in my spare time not telling anybody about it kind of a thing and it made some good progress im like actually it would make sense to do this at the same time i started talking with the senior vp of software at the time a guy named bertrand serlet and bertrand was very encouraging he was like well lets have fun lets talk about this and he was a little bit of a language guy and so he helped guide some of the early work and encouraged me and got things off the ground and eventually told my manager and told other people and it started making progress the complicating thing with swift was that the idea of doing a new language was not obvious to anybody including myself and the tone at the time was that the iphone was successful because of objective c oh interesting not despite of or just because of and you have to understand that at the time apple was hiring software people that loved objective c and it wasnt that they came despite objective c they loved objective c and thats why they got hired and so you had a software team that the leadership in many cases went all the way back to next where objective c really became real and so they quote unquote grew up writing objective c and many of the individual engineers all were hired because they loved objective c and so this notion of ok lets do new language was kind of heretical in many ways meanwhile my sense was that the outside community wasnt really in love with objective c some people were and some of the most outspoken people were but other people were hitting challenges because it has very sharp corners and its difficult to learn and so one of the challenges of making swift happen that was totally non technical is the social part of what do we do if we do a new language which at apple many things happen that dont ship so if we ship it what is the metrics of success why would we do this why wouldnt we make objective c better if objective c has problems lets file off those rough corners and edges and one of the major things that became the reason to do this was this notion of safety memory safety and the way objective c works is that a lot of the object system and everything else is built on top of pointers in c objective c is an extension on top of c and so pointers are unsafe and if you get rid of the pointers its not objective c anymore and so fundamentally that was an issue that you could not fix safety or memory safety without fundamentally changing the language and so once we got through that part of the mental process and the thought process it became a design process of saying ok well if were going to do something new what is good how do we think about this and what do we like and what are we looking for and that was a very different phase of it so what are some design choices early on in swift like were talking about braces are you making a typed language or not all those kinds of things yeah so some of those were obvious given the context so a typed language for example objective c is a typed language and going with an untyped language wasnt really seriously considered we wanted the performance and we wanted refactoring tools and other things like that that go with typed languages quick dumb question was it obvious i think this would be a dumb question but was it obvious that the language has to be a compiled language yes thats not a dumb question earlier i think late 90s apple had seriously considered moving its development experience to java but swift started in 2010 which was several years after the iphone it was when the iphone was definitely on an upward trajectory and the iphone was still extremely and is still a bit memory constrained and so being able to compile the code and then ship it and then having standalone code that is not jit compiled is a very big deal and is very much part of the apple value system now javascripts also a thing i mean its not that this is exclusive and technologies are good depending on how theyre applied but in the design of swift saying how can we make objective c better objective c is statically compiled and that was the contiguous natural thing to do just skip ahead a little bit and well go right back just as a question as you think about today in 2019 in your work at google tensorflow and so on is again compilations static compilation still the right thing yeah so the funny thing after working on compilers for a really long time is that and this is one of the things that llvm has helped with is that i dont look at compilations being static or dynamic or interpreted or not this is a spectrum and one of the cool things about swift is that swift is not just statically compiled its actually dynamically compiled as well and it can also be interpreted though nobodys actually done that and so what ends up happening when you use swift in a workbook for example in colab or in jupyter is its actually dynamically compiling the statements as you execute them and so this gets back to the software engineering problems where if you layer the stack properly you can actually completely change how and when things get compiled because you have the right abstractions there and so the way that a colab workbook works with swift is that when you start typing into it it creates a process a unix process and then each line of code you type in it compiles it through the swift compiler the front end part and then sends it through the optimizer jit compiles machine code and then injects it into that process and so as youre typing new stuff its like squirting in new code and overwriting and replacing and updating code in place and the fact that it can do this is not an accident swift was designed for this but its an important part of how the language was set up and how its layered and this is a nonobvious piece and one of the things with swift that was for me a very strong design point is to make it so that you can learn it very quickly and so from a language design perspective the thing that i always come back to is this ui principle of progressive disclosure of complexity and so in swift you can start by saying print quote hello world quote and theres no slash n just like python one line of code no main no header files no public static class void blah blah blah string like java has one line of code and you can teach that and it works great then you can say well lets introduce variables and so you can declare a variable with var so var x equals 4 what is a variable you can use x x plus 1 this is what it means then you can say well how about control flow well this is what an if statement is this is what a for statement is this is what a while statement is then you can say lets introduce functions and many languages like python have had this kind of notion of lets introduce small things and then you can add complexity then you can introduce classes and then you can add generics in the case of swift and then you can build in modules and build out in terms of the things that youre expressing but this is not very typical for compiled languages and so this was a very strong design point and one of the reasons that swift in general is designed with this factoring of complexity in mind so that the language can express powerful things you can write firmware in swift if you want to but it has a very high level feel which is really this perfect blend because often you have very advanced library writers that want to be able to use the nitty gritty details but then other people just want to use the libraries and work at a higher abstraction level its kind of cool that i saw that you can just interoperability i dont think i pronounced that word enough but you can just drag in python its just strange you can import like i saw this in the demo how do you make that happen whats up with that is that as easy as it looks or is it yes as easy as it looks thats not a stage magic hack or anything like that i dont mean from the user perspective i mean from the implementation perspective to make it happen so its easy once all the pieces are in place the way it works so if you think about a dynamically typed language like python you can think about it in two different ways you can say it has no types which is what most people would say or you can say it has one type and you can say it has one type and its the python object and the python object gets passed around and because theres only one type its implicit and so what happens with swift and python talking to each other swift has lots of types it has arrays and it has strings and all classes and that kind of stuff but it now has a python object type so there is one python object type and so when you say import numpy what you get is a python object which is the numpy module and then you say nparray it says ok hey python object i have no idea what you are give me your array member ok cool and it just uses dynamic stuff talks to the python interpreter and says hey python whats thearray member in that python object it gives you back another python object and now you say parentheses for the call and the arguments youre going to pass and so then it says hey a python object that is the result of nparray call with these arguments again calling into the python interpreter to do that work and so right now this is all really simple and if you dive into the code what youll see is that the python module in swift is something like 1200 lines of code or something its written in pure swift its super simple and its built on top of the c interoperability because it just talks to the python interpreter but making that possible required us to add two major language features to swift to be able to express these dynamic calls and the dynamic member lookups and so what weve done over the last year is weve proposed implement standardized and contributed new language features to the swift language in order to make it so it is really trivial and this is one of the things about swift that is critical to the swift for tensorflow work which is that we can actually add new language features and the bar for adding those is high but its what makes it possible so youre now at google doing incredible work on several things including tensorflow so tensorflow 20 or whatever leading up to 20 has by default in 20 has eager execution and yet in order to make code optimized for gpu or tpu or some of these systems computation needs to be converted to a graph so whats that process like what are the challenges there yeah so i am tangentially involved in this but the way that it works with autograph is that you mark your function with a decorator and when python calls it that decorator is invoked and then it says before i call this function you can transform it and so the way autograph works is as far as i understand is it actually uses the python parser to go parse that turn it into a syntax tree and now apply compiler techniques to again transform this down into tensorflow graphs and so you can think of it as saying hey i have an if statement im going to create an if node in the graph like you say tfcond you have a multiply well ill turn that into a multiply node in the graph and it becomes this tree transformation so where does the swift for tensorflow come in which is parallels for one swift is an interface like python is an interface to tensorflow but it seems like theres a lot more going on in just a different language interface theres optimization methodology so the tensorflow world has a couple of different what id call front end technologies and so swift and python and go and rust and julia and all these things share the tensorflow graphs and all the runtime and everything thats later and so swift for tensorflow is merely another front end for tensorflow just like any of these other systems are theres a major difference between i would say three camps of technologies here theres python which is a special case because the vast majority of the community effort is going to the python interface and python has its own approaches for automatic differentiation it has its own apis and all this kind of stuff theres swift which ill talk about in a second and then theres kind of everything else and so the everything else are effectively language bindings so they call into the tensorflow runtime but they usually dont have automatic differentiation or they usually dont provide anything other than apis that call the c apis in tensorflow and so theyre kind of wrappers for that swift is really kind of special and its a very different approach swift for tensorflow that is is a very different approach because there were saying lets look at all the problems that need to be solved in the full stack of the tensorflow compilation process if you think about it that way because tensorflow is fundamentally a compiler it takes models and then it makes them go fast on hardware thats what a compiler does and it has a front end it has an optimizer and it has many back ends and so if you think about it the right way or if you look at it in a particular way it is a compiler and so swift is merely another front end but its saying and the design principle is saying lets look at all the problems that we face as machine learning practitioners and what is the best possible way we can do that given the fact that we can change literally anything in this entire stack and python for example where the vast majority of the engineering and effort has gone into is constrained by being the best possible thing you can do with a python library there are no python language features that are added because of machine learning that im aware of they added a matrix multiplication operator with that but thats as close as you get and so with swift its hard but you can add language features to the language and theres a community process for that and so we look at these things and say well what is the right division of labor between the human programmer and the compiler and swift has a number of things that shift that balance so because it has a type system for example that makes certain things possible for analysis of the code and the compiler can automatically build graphs for you without you thinking about them thats a big deal for a programmer you just get free performance you get clustering and fusion and optimization things like that without you as a programmer having to manually do it because the compiler can do it for you automatic differentiation is another big deal and i think one of the key contributions of the swift tensorflow project is that theres this entire body of work on automatic differentiation that dates back to the fortran days people doing a tremendous amount of numerical computing in fortran used to write these what they call source to source translators where you take a bunch of code shove it into a mini compiler and it would push out more fortran code but it would generate the backwards passes for your functions for you the derivatives and so in that work in the 70s a tremendous number of optimizations a tremendous number of techniques for fixing numerical instability and other kinds of problems were developed but theyre very difficult to port into a world where in eager execution you get an op by op at a time you need to be able to look at an entire function and be able to reason about whats going on and so when you have a language integrated automatic differentiation which is one of the things that the swift project is focusing on you can open all these techniques and reuse them in familiar ways but the language integration piece has a bunch of design room in it and its also complicated the other piece of the puzzle here thats kind of interesting is tpus at google so were in a new world with deep learning it constantly is changing and i imagine without disclosing anything i imagine youre still innovating on the tpu front too indeed so how much interplay is there between software and hardware in trying to figure out how to together move towards an optimized solution theres an incredible amount so were on our third generation of tpus which are now 100 petaflops in a very large liquid cooled box virtual box with no cover and as you might imagine were not out of ideas yet the great thing about tpus is that theyre a perfect example of hardware software co design and so its about saying what hardware do we build to solve certain classes of machine learning problems well the algorithms are changing the hardware takes some cases years to produce and so you have to make bets and decide what is going to happen and what is the best way to spend the transistors to get the maximum performance per watt or area per cost or whatever it is that youre optimizing for and so one of the amazing things about tpus is this numeric format called bfloat16 bfloat16 is a compressed 16 bit floating point format but it puts the bits in different places and in numeric terms it has a smaller mantissa and a larger exponent that means that its less precise but it can represent larger ranges of values which in the machine learning context is really important and useful because sometimes you have very small gradients you want to accumulate and very very small numbers that are important to move things as youre learning but sometimes you have very large magnitude numbers as well and bfloat16 is not as precise the mantissa is small but it turns out the machine learning algorithms actually want to generalize and so theres theories that this actually increases the ability for the network to generalize across data sets and regardless of whether its good or bad its much cheaper at the hardware level to implement because the area and time of a multiplier is n squared in the number of bits in the mantissa but its linear with size of the exponent and youre connected to both efforts here both on the hardware and the software side yeah and so that was a breakthrough coming from the research side and people', 'the following is a conversation with rajat manga hes an engineer and director of google leading the tensorflow team tensorflow is an open source library at the center of much of the work going on in the world in deep learning both the cutting edge research and the large scale application of learning based approaches but its quickly becoming much more than a software library its now an ecosystem of tools for the deployment of machine learning in the cloud on the phone in the browser on both generic and specialized hardware tpu gpu and so on plus theres a big emphasis on growing a passionate community of developers rajat jeff dean and a large team of engineers at google brain are working to define the future of machine learning with tensorflow 20 which is now in alpha i think the decision to open source tensorflow is a definitive moment in the tech industry it showed that open innovation can be successful and inspire many companies to open source their code to publish and in general engage in the open exchange of ideas this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with rajat manga you were involved with google brain since its start in 2011 with jeff dean it started with this belief the proprietary machine learning library and turned into tensorflow in 2014 the open source library so what were the early days of google brain like what were the goals the missions how do you even proceed forward once theres so much possibilities before you it was interesting back then when i started or when you were even just talking about it the idea of deep learning was interesting and intriguing in some ways it hadnt yet taken off but it held some promise it had shown some very promising and early results i think the idea where andrew and jeff had started was what if we can take this work people are doing in research and scale it to what google has in terms of the compute power and also put that kind of data together what does it mean and so far the results had been if you scale the compute scale the data it does better and would that work and so that was the first year or two can we prove that out and with this belief when we started the first year we got some early wins which is always great what were the wins like what was the wins where you were theres some problems to this this is going to be good i think there are two early wins where one was speech that we collaborated very closely with the speech research team who was also getting interested in this and the other one was on images where the cat paper as we call it that was covered by a lot of folks and the birth of google brain was around neural networks so it was deep learning from the very beginning that was the whole mission so what would in terms of scale what was the sort of dream of what this could become were there echoes of this open source tensorflow community that might be brought in was there a sense of tpus was there a sense of machine learning is now going to be at the core of the entire company is going to grow into that direction yeah i think so that was interesting and if i think back to 2012 or 2011 and first was can we scale it in the year or so we had started scaling it to hundreds and thousands of machines in fact we had some runs even going to 10000 machines and all of those shows great promise in terms of machine learning at google the good thing was googles been doing machine learning for a long time deep learning was new but as we scaled this up we showed that yes that was possible and it was going to impact lots of things like we started seeing real products wanting to use this again speech was the first there were image things that photos came out of and then many other products as well so that was exciting as we went into that a couple of years externally also academia started to there was lots of push on okay deep learning is interesting we should be doing more and so on and so by 2014 we were looking at okay this is a big thing its going to grow and not just internally externally as well yes maybe googles ahead of where everybody is but theres a lot to do so a lot of this started to make sense and come together so the decision to open source i was just chatting with chris glatner about this the decision to go open source with tensorflow i would say sort of for me personally seems to be one of the big seminal moments in all of software engineering ever i think thats when a large company like google decides to take a large project that many lawyers might argue has a lot of ip just decide to go open source with it and in so doing lead the entire world and saying you know what open innovation is a pretty powerful thing and its okay to do that was i mean thats an incredible moment in time so do you remember those discussions happening whether open source should be happening what was that like i would say i think so the initial idea came from jeff who was a big proponent of this i think it came off of two big things one was research wise we were a research group we were putting all our research out there if you wanted to we were building on others research and we wanted to push the state of the art forward and part of that was to share the research thats how i think deep learning and machine learning has really grown so fast so the next step was okay now would software help with that and it seemed like they were existing a few libraries out there tiano being one torch being another and a few others but they were all done by academia and so the level was significantly different the other one was from a software perspective google had done lots of software or that we used internally you know and we published papers often there was an open source project that came out of that that somebody else picked up that paper and implemented and they were very successful back then it was like okay theres hadoop which has come off of tech that weve built we know the tech weve built is way better for a number of different reasons weve invested a lot of effort in that and turns out we have google cloud and we are now not really providing our tech but we are saying okay we have bigtable which is the original thing we are going to now provide h base apis on top of that which isnt as good but thats what everybodys used to so theres like can we make something that is better and really just provide helps the community in lots of ways but also helps push a good standard forward so how does cloud fit into that theres a tensorflow open source library and how does the fact that you can use so many of the resources that google provides and the cloud fit into that strategy so tensorflow itself is open and you can use it anywhere right and we want to make sure that continues to be the case on google cloud we do make sure that theres lots of integrations with everything else and we want to make sure that it works really really well there youre leading the tensorflow effort can you tell me the history and the timeline of tensorflow project in terms of major design decisions so like the open source decision but really what to include and not theres this incredible ecosystem that id like to talk about theres all these parts but what if just some sample moments that defined what tensorflow eventually became through its i dont know if youre allowed to say history when its just but in deep learning everything moves so fast and just a few years is already history yes yes so looking back we were building tensorflow i guess we open sourced it in 2015 november 2015 we started on it in summer of 2014 i guess and somewhere like three to six late 2014 by then we had decided that okay theres a high likelihood well open source it so we started thinking about that and making sure were heading down that path at that point by that point we had seen a few lots of different use cases at google so there were things like okay yes you wanna run it at large scale in the data center yes we need to support different kind of hardware we had gpus at that point we had our first gpu at that point or was about to come out roughly around that time so the design sort of included those we had started to push on mobile so we were running models on mobile at that point people were customizing code so we wanted to make sure tensorflow could support that as well so that sort of became part of that overall design when you say mobile you mean like a pretty complicated algorithms running on the phone thats correct so when you have a model that you deploy on the phone and run it there right so already at that time there was ideas of running machine learning on the phone thats correct we already had a couple of products that were doing that by then and in those cases we had basically customized handcrafted code or some internal libraries that were using so i was actually at google during this time in a parallel i guess universe but we were using theano and caffe was there some degree to which you were bouncing like trying to see what caffe was offering people trying to see what theano was offering that you want to make sure youre delivering on whatever that is perhaps the python part of thing maybe did that influence any design decisions totally so when we built this belief and some of that was in parallel with some of these libraries coming up i mean theano itself is older but we were building this belief focused on our internal thing because our systems were very different by the time we got to this we looked at a number of libraries that were out there theano there were folks in the group who had experience with torch with lua there were folks here who had seen caffe i mean actually yang jing was here as well theres what other libraries i think we looked at a number of things might even have looked at jnr back then im trying to remember if it was there in fact yeah we did discuss ideas around okay should we have a graph or not so putting all these together was definitely they were key decisions that we wanted we had seen limitations in our prior disbelief things a few of them were just in terms of research was moving so fast we wanted the flexibility the hardware was changing fast we expected to change that so that those probably were two things and yeah i think the flexibility in terms of being able to express all kinds of crazy things was definitely a big one then so what the graph decisions though with moving towards tensorflow 20 theres more by default therell be eager execution so sort of hiding the graph a little bit because its less intuitive in terms of the way people develop and so on what was that discussion like in terms of using graphs it seemed its kind of the theano way did it seem the obvious choice so i think where it came from was our disbelief had a graph like thing as well a much more simple it wasnt a general graph it was more like a straight line thing more like what you might think of cafe i guess in that sense but the graph was and we always cared about the production stuff like even with disbelief we were deploying a whole bunch of stuff in production so graph did come from that when we thought of okay should we do that in python and we experimented with some ideas where it looked a lot simpler to use but not having a graph meant okay how do you deploy now so that was probably what tilted the balance for us and eventually we ended up with a graph and i guess the question there is did you i mean so production seems to be the really good thing to focus on but did you even anticipate the other side of it where there could be what is it what are the numbers its been crazy 41 million downloads yep i mean was that even like a possibility in your mind that it would be as popular as it became so i think we did see a need for this a lot from the research perspective and like early days of deep learning in some ways 41 million no i dont think i imagined this number then it seemed like theres a potential future where lots more people would be doing this and how do we enable that i would say this kind of growth i probably started seeing somewhat after the open sourcing where it was like okay deep learning is actually growing way faster for a lot of different reasons and we are in just the right place to push on that and leverage that and deliver on lots of things that people want so what changed once you open sourced like how this incredible amount of attention from a global population of developers how did the project start changing i dont even actually remember during those times i know looking now theres really good documentation theres an ecosystem of tools theres a community theres a blog theres a youtube channel now right yeah its very community driven back then i guess 01 version is that the version i think we call it 06 or five something like that i forget what changed leading into 10 its interesting i think weve gone through a few things there when we started out when we first came out people loved the documentation we have because it was just a huge step up from everything else because all of those were academic projects people doing who dont think about documentation i think what that changed was instead of deep learning being a research thing some people who were just developers could now suddenly take this out and do some interesting things with it right who had no clue what machine learning was before then and that i think really changed how things started to scale up in some ways and pushed on it over the next few months as we looked at how do we stabilize things as we look at not just researchers now we want stability people want to deploy things thats how we started planning for 10 and there are certain needs for that perspective and so again documentation comes up designs more kinds of things to put that together and so that was exciting to get that to a stage where more and more enterprises wanted to buy in and really get behind that and i think post 10 and over the next few releases that enterprise adoption also started to take off i would say between the initial release and 10 it was okay researchers of course then a lot of hobbies and early interest people excited about this who started to get on board and then over the 1x thing lots of enterprises i imagine anything thats below 10 gives pressure to be the enterprise probably wants something thats stable exactly and do you have a sense now that tensorflow is stable like it feels like deep learning in general is extremely dynamic field so much is changing and tensorflow has been growing incredibly do you have a sense of stability at the helm of it i mean i know youre in the midst of it but yeah i think in the midst of it its often easy to forget what an enterprise wants and what some of the people on that side want there are still people running models that are three years old four years old so inception is still used by tons of people even resnet 50 is what couple of years old now or more but there are tons of people who use that and theyre fine they dont need the last couple of bits of performance or quality they want some stability in things that just work and so there is value in providing that with that kind of stability and making it really simpler because that allows a lot more people to access it and then theres the research crowd which wants okay they wanna do these crazy things exactly like youre saying right not just deep learning in the straight up models that used to be there they want rnns and even rnns are maybe old they are transformers now and now it needs to combine with rl and gans and so on so theres definitely that area that like the boundary thats shifting and pushing the state of the art but i think theres more and more of the past thats much more stable and even stuff that was two three years old is very very usable by lots of people so that part makes it a lot easier so i imagine maybe you can correct me if im wrong one of the biggest use cases is essentially taking something like resnet 50 and doing some kind of transfer learning on a very particular problem that you have its basically probably what majority of the world does and you wanna make that as easy as possible so i would say for the hobbyist perspective thats the most common case right in fact the apps and phones and stuff that youll see the early ones thats the most common case i would say there are a couple of reasons for that one is that everybody talks about that it looks great on slides thats a presentation yeah exactly what enterprises want is that is part of it but thats not the big thing enterprises really have data that they wanna make predictions on this is often what they used to do with the people who were doing ml was just regression models linear regression logistic regression linear models or maybe gradient booster trees and so on some of them still benefit from deep learning but they want thats the bread and butter or like the structured data and so on so depending on the audience you look at theyre a little bit different and they just have i mean the best of enterprise probably just has a very large data set or deep learning can probably shine thats correct thats right and then i think the other pieces that they wanted again with 20 the developer summit we put together is the whole tensorflow extended piece which is the entire pipeline they care about stability across doing their entire thing they want simplicity across the entire thing i dont need to just train a model i need to do that every day again over and over again i wonder to which degree you have a role in i dont know so i teach a course on deep learning i have people like lawyers come up to me and say or is there still a balance to where its less deadline you had the dev summit today that came together incredibly looked like theres a lot of moving pieces and so on so did that deadline make people rise to the occasion releasing tensorflow 20 alpha im sure that was done last minute as well i mean up to the last point again its one of those things that you need to strike the good balance theres some value that deadlines bring that does bring a sense of urgency to get the right things together instead of getting the perfect thing out you need something thats good and works well and the team definitely did a great job in putting that together so i was very amazed and excited by everything how that came together that said across the year we try not to put out official deadlines we focus on key things that are important figure out how much of its important and we are developing in the open both internally and externally everythings available to everybody so you can pick and look at where things are we do releases at a regular cadence so fine if something doesnt necessarily end up this month itll end up in the next release in a month or two and thats okay but we want to keep moving as fast as we can in these different areas because we can iterate and improve on things sometimes its okay to put things out that arent fully ready well make sure its clear that okay this is experimental but its out there if you want to try and give feedback thats very very useful i think that quick cycle and quick iteration is important thats what we often focus on rather than heres a deadline where you get everything else is 20 is there pressure to make that stable or like for example wordpress 50 just came out and there was no pressure to it was a lot of build updates delivered way too late but and they said okay well but were gonna release a lot of updates really quickly to improve it do you see tensorflow 20 in that same kind of way or is there this pressure to once it hits 20 once you get to the release candidate and then you get to the final thats gonna be the stable thing so its gonna be stable in just like when nodex was where every api thats there is gonna remain in work it doesnt mean we cant change things under the covers it doesnt mean we cant add things so theres still a lot more for us to do and well continue to have more releases so in that sense theres still i dont think well be done in like two months when we release this i dont know if you can say but is there theres not external deadlines for tensorflow 20 but is there internal deadlines the artificial or otherwise that youre trying to set for yourself or is it whenever its ready so we want it to be a great product right and thats a big important piece for us tensorflows already out there we have 41 million downloads for 10 x so its not like we have to have this yeah exactly so its not like a lot of the features that weve really polishing and putting them together are there we dont have to rush that just because so in that sense we wanna get it right and really focus on that that said we have said that we are looking to get this out in the next few months in the next quarter and as far as possible well definitely try to make that happen yeah my favorite line was spring is a relative concept i love it yes spoken like a true developer so something im really interested in and your previous line of work is before tensorflow you led a team at google on search ads i think this is a very interesting topic on every level on a technical level because at their best ads connect people to the things they want and need so and at their worst theyre just these things that annoy the heck out of you to the point of ruining the entire user experience of whatever youre actually doing so they have a bad rep i guess and on the other end so that this connecting users to the thing they need and want is a beautiful opportunity for machine learning to shine like huge amounts of data thats personalized and you kind of map to the thing they actually want wont get annoyed so what have you learned from this google thats leading the world in this aspect what have you learned from that experience and what do you think is the future of ads take you back to that yeah yes its been a while but i totally agree with what you said i think the search ads the way it was always looked at and i believe it still is is its an extension of what search is trying to do and the goal is to make the information and make the worlds information accessible thats its not just information but maybe products or other things that people care about and so its really important for them to align with what the users need and in search ads theres a minimum quality level before that ad would be shown if you dont have an ad that hits that quality but it will not be shown even if we have it and okay maybe we lose some money there thats fine that is really really important and i think that that is something i really liked about being there advertising is a key part i mean as a model its been around for ages right its not a new model its been adapted to the web and became a core part of search and many other search engines across the world and i do hope like you said there are aspects of ads that are annoying and i go to a website and if it just keeps popping an ad in my face not to let me read thats gonna be annoying clearly so i hope we can strike that balance between showing a good ad where its valuable to the user and provides the monetization to the service and this might be search this might be a website all of these they do need the monetization for them to provide that service but if its done in a good balance between showing just some random stuff thats distracting versus showing something thats actually valuable so do you see it moving forward as to continue being a model that funds businesses like google thats a significant revenue stream because thats one of the most exciting things but also limiting things in the internet is nobody wants to pay for anything and advertisements again coupled at their best are actually really useful and not annoying do you see that continuing and growing and improving or is there do you see sort of more netflix type models where you have to start to pay for content i think its a mix i think its gonna take a long while for everything to be paid on the internet if at all probably not i mean i think theres always gonna be things that are sort of monetized with things like ads but over the last few years i would say weve definitely seen that transition towards more paid services across the web and people are willing to pay for them because they do see the value i mean netflix is a great example i mean we have youtube doing things people pay for the apps they buy more people i find are willing to pay for newspaper content for the good news websites across the web that wasnt the case a few years even a few years ago i would say and i just see that change in myself as well and just lots of people around me so definitely hopeful that well transition to that mix model where maybe you get to try something out for free maybe with ads but then theres a more clear revenue model that sort of helps go beyond that so speaking of revenue how is it that a person can use the tpu in a google call app for free so whats the i guess the question is whats the future of tensorflow in terms of empowering say a class of 300 students and im asked by mit what is going to be the future of them being able to do their homework in tensorflow like where are they going to train these networks right whats that future look like with tpus with cloud services and so on i think a number of things there i mean any tensorflow open source you can run it wherever you can run it on your desktop and your desktops always keep getting more powerful so maybe you can do more my phone is like i dont know how many times more powerful than my first desktop youll probably train it on your phone though yeah thats true right so in that sense the power you have in your hands is a lot more clouds are actually very interesting from say students or courses perspective because they make it very easy to get started i mean colab the great thing about it is go to a website and it just works no installation needed nothing to youre just there and things are working thats really the power of cloud as well and so i do expect that to grow again colab is a free service its great to get started to play with things to explore things that said with free you can only get so much youd be yeah so just like we were talking about free versus paid yeah there are services you can pay for and get a lot more great so if im a complete beginner interested in machine learning and tensorflow what should i do probably start with going to our website and playing there so just go to tensorfloworg and start clicking on things yep check out tutorials and guides theres stuff you can just click there and go to a colab and do things no installation needed you can get started right there okay awesome rajit thank you so much for talking today thank you lex it was great when is machine learning gonna enter legal the legal realm the same thing in all kinds of disciplines immigration insurance often when i see what it boils down to is these companies are often a little bit old school in the way they organize the data so the data is just not ready yet its not digitized do you also find yourself being in the role of an evangelist for like lets get organize your data folks and then youll get the big benefit of tensorflow do you get those have those conversations yeah yeah you know i get all kinds of questions there from okay what do i need to make this work right do we really need deep learning i mean there are all these things i already use this linear model why would this help i dont have enough data lets say or i wanna use machine learning but i have no clue where to start so it varies that to all the way to the experts to why support very specific things its interesting is there a good answer it boils down to oftentimes digitizing data so whatever you want automated whatever data you want to make prediction based on you have to make sure that its in an organized form like within the tensorflow ecosystem theres now youre providing more and more data sets and more and more pre trained models are you finding yourself also the organizer of data sets yes i think the tensorflow data sets that we just released thats definitely come up where people want these data sets can we organize them and can we make that easier so thats definitely one important thing the other related thing i would say is i often tell people you know what dont think of the most fanciest thing that the newest model that you see make something very basic work and then you can improve it theres just lots of things you can do with it yeah start with the basics true one of the big things that makes tensorflow even more accessible was the appearance whenever that happened of keras the keras standard sort of outside of tensorflow i think it was keras on top of tiano at first only and then keras became on top of tensorflow do you know when keras chose to also add tensorflow as a backend who was the was it just the community that drove that initially do you know if there was discussions conversations yeah so francois started the keras project before he was at google and the first thing was tiano i dont remember if that was after tensorflow was created or way before and then at some point when tensorflow started becoming popular there were enough similarities that he decided to create this interface and put tensorflow as a backend i believe that might still have been before he joined google so we werent really talking about that he decided on his own and thought that was interesting and relevant to the community in fact i didnt find out about him being at google until a few months after he was here he was working on some research ideas and doing keras on his nights and weekends project oh interesting he wasnt like part of the tensorflow he didnt join initially he joined research and he was doing some amazing research he has some papers on that and research so hes a great researcher as well and at some point we realized oh hes doing this good stuff people seem to like the api and hes right here so we talked to him and he said okay why dont i come over to your team and work with you for a quarter and lets make that integration happen and we talked to his manager and he said sure quarters fine and that quarters been something like two years now and so hes fully on this so keras got integrated into tensorflow in a deep way and now with 20 tensorflow 20 sort of keras is kind of the recommended way for a beginner to interact with tensorflow which makes that initial sort of transfer learning or the basic use cases even for an enterprise super simple right thats correct thats right so what was that decision like that seems like its kind of a bold decision as well we did spend a lot of time thinking about that one we had a bunch of apis some built by us there was a parallel layers api that we were building and when we decided to do keras in parallel so there were like okay two things that we are looking at and the first thing we was trying to do is just have them look similar like be as integrated as possible share all of that stuff there were also like three other apis that others had built over time because we didnt have a standard one but one of the messages that we kept hearing from the community okay which one do we use and they kept seeing like okay heres a model in this one and heres a model in this one which should i pick so thats sort of like okay we had to address that straight on with 20 the whole idea was we need to simplify we had to pick one based on where we were we were like okay lets see what are the people like and keras was clearly one that lots of people loved there were lots of great things about it so we settled on that organically thats kind of the best way to do it it was great it was surprising nevertheless to sort of bring in an outside i mean there was a feeling like keras might be almost like a competitor in a certain kind of to tensorflow and in a sense it became an empowering element of tensorflow thats right yeah its interesting how you can put two things together which can align in this case i think francois the team and a bunch of us have chatted and i think we all want to see the same kind of things we all care about making it easier for the huge set of developers out there and that makes a difference so python has guido van rossum who until recently held the position of benevolent dictator for life all right so theres a huge successful open source project like tensorflow need one person who makes a final decision so youve did a pretty successful tensorflow dev summit just now last couple of days theres clearly a lot of different new features being incorporated an amazing ecosystem so on whos how are those design decisions made is there a bdfl in tensorflow or is it more distributed and organic i think its somewhat different i would say ive always been involved in the key design directions but there are lots of things that are distributed where there are a number of people martin wick being one who has really driven a lot of our open source stuff a lot of the apis and there are a number of other people whove been you know pushed and been responsible for different parts of it we do have regular design reviews over the last year weve had a lot of weve really spent a lot of time opening up to the community and adding transparency were setting more processes in place so rfcs special interest groups to really grow that community and scale that i think the kind of scale that ecosystem is in i dont think we could scale with having me as the lone point of decision maker i got it so yeah the growth of that ecosystem maybe you can talk about it a little bit first of all it started with andrej karpathy when he first did comnetjs the fact that you can train and youll network in the browser was in javascript was incredible so now tensorflowjs is really making that a serious like a legit thing a way to operate whether its in the backend or the front end then theres the tensorflow extended like you mentioned theres tensorflow lite for mobile and all of it as far as i can tell its really converging towards being able to save models in the same kind of way you can move around you can train on the desktop and then move it to mobile and so on thats right so theres that cohesiveness so can you maybe give me whatever i missed a bigger overview of the mission of the ecosystem thats trying to be built and where is it moving forward yeah so in short the way i like to think of this is our goals to enable machine learning and in a couple of ways you know one is we have lots of exciting things going on in ml today we started with deep learning but we now support a bunch of other algorithms too so one is to on the research side keep pushing on the state of the art can we you know how do we enable researchers to build the next amazing thing so bert came out recently you know its great that people are able to do new kinds of research and there are lots of amazing research that happens across the world so thats one direction the other is how do you take that across all the people outside who want to take that research and do some great things with it and integrate it to build real products to have a real impact on people and so if thats the other axes in some ways you know at a high level one way i think about it is there are a crazy number of compute devices across the world and we often used to think of ml and training and all of this as okay something you do either in the workstation or the data center or cloud but we see things running on the phones we see things running on really tiny chips i mean we had some demos at the developer summit and so the way i think about this ecosystem is how do we help get machine learning on every device that has a compute capability and that continues to grow and so in some ways this ecosystem is looked at you know various aspects of that and grown over time to cover more of those and we continue to push the boundaries in some areas weve built more tooling and things around that to help you i mean the first tool we started was tensorboard you wanted to learn just the training piece the effects or tensorflow extended to really do your entire ml pipelines if youre you know care about all that production stuff but then going to the edge going to different kinds of things and its not just us now we are a place where there are lots of libraries being built on top so there are some for research maybe things like tensorflow agents or tensorflow probability that started as research things or for researchers for focusing on certain kinds of algorithms but theyre also being deployed or used by you know production folks and some have come from within google just teams across google who wanted to build these things others have come from just the community because there are different pieces that different parts of the community care about and i see our goal as enabling even that right its not we cannot and wont build every single thing that just doesnt make sense but if we can enable others to build the things that they care about and theres a broader community that cares about that and we can help encourage that and thats great that really helps the entire ecosystem not just those one of the big things about 20 that were pushing on is okay we have these so many different pieces right how do we help make all of them work well together so there are a few key pieces there that were pushing on one being the core format in there and how we share the models themselves through save model and tensorflow hub and so on and a few of the pieces that we really put this together i was very skeptical that thats you know when tensorflowjs came out it didnt seem or deep learning js as it was earlier yeah that was the first it seems like technically very difficult project as a standalone its not as difficult but as a thing that integrates into the ecosystem it seems very difficult so i mean theres a lot of aspects of this youre making look easy but and the technical side how many challenges have to be overcome here a lot and still have to be overcome thats the question here too there are lots of steps to it right and weve iterated over the last few years so theres a lot weve learned i yeah and often when things come together well things look easy and thats exactly the point it should be easy for the end user but there are lots of things that go behind that if i think about still challenges ahead there are you know we have a lot more devices coming on board for example from the hardware perspective how do we make it really easy for these vendors to integrate with something like tensorflow right so theres a lot of compiler stuff that others are working on there are things we can do in terms of our apis and so on that we can do as we you know tensorflow started as a very monolithic system and to some extent it still is there are less lots of tools around it but the core is still pretty large and monolithic one of the key challenges for us to scale that out is how do we break that apart with clearer interfaces its you know in some ways its software engineering 101 but for a system thats now four years old i guess or more and thats still rapidly evolving and that were not slowing down with its hard to change and modify and really break apart its sort of like as people say right its like changing the engine with a car running or trying to fix that thats exactly what were trying to do so theres a challenge here because the downside of so many people being excited about tensorflow and coming to rely on it in many of their applications is that youre kind of responsible like its the technical debt youre responsible for previous versions to some degree still working so when youre trying to innovate i mean its probably easier to just start from scratch every few months absolutely so do you feel the pain of that 20 does break some back compatibility but not too much it seems like the conversion is pretty straightforward do you think thats still important given how quickly deep learning is changing can you just the things that youve learned can you just start over or is there pressure to not its a tricky balance so if it was just a researcher writing a paper who a year later will not look at that code again sure it doesnt matter there are a lot of production systems that rely on tensorflow both at google and across the world and people worry about this i mean these systems run for a long time so it is important to keep that compatibility and so on and yes it does come with a huge cost theres we have to think about a lot of things as we do new things and make new changes i think its a trade off right you can you might slow certain kinds of things down but the overall value youre bringing because of that is much bigger because its not just about breaking the person yesterday its also about telling the person tomorrow that you know what this is how we do things were not gonna break you when you come on board because there are lots of new people who are also gonna come on board and you know one way i like to think about this and i always push the team to think about it as well when you wanna do new things you wanna start with a clean slate design with a clean slate in mind and then well figure out how to make sure all the other things work and yes we do make compromises occasionally but unless you design with the clean slate and not worry about that youll never get to a good place oh thats brilliant so even if you are responsible when youre in the idea stage when youre thinking of new just put all that behind you okay thats really really well put so i have to ask this because a lot of students developers ask me how i feel about pytorch versus tensorflow so ive recently completely switched my research group to tensorflow i wish everybody would just use the same thing and tensorflow is as close to that i believe as we have but do you enjoy competition so tensorflow is leading in many ways on many dimensions in terms of ecosystem in terms of number of users momentum power production levels so on but a lot of researchers are now also using pytorch do you enjoy that kind of competition or do you just ignore it and focus on making tensorflow the best that it can be so just like research or anything people are doing its great to get different kinds of ideas and when we started with tensorflow like i was saying earlier one it was very important for us to also have production in mind we didnt want just research right and thats why we chose certain things now pytorch came along and said you know what i only care about research this is what im trying to do whats the best thing i can do for this and it started iterating and said okay i dont need to worry about graphs let me just run things and i dont care if its not as fast as it can be but let me just make this part easy and there are things you can learn from that right they again had the benefit of seeing what had come before but also exploring certain different kinds of spaces and they had some good things there building on say things like jnr and so on before that so competition is definitely interesting it made us you know this is an area that we had thought about like i said way early on over time we had revisited this a couple of times should we add this again at some point we said you know what it seems like this can be done well so lets try it again and thats how we started pushing on eager execution how do we combine those two together which has finally come very well together in 20 but it took us a while to get all the things together and so on so let me ask put another way i think eager execution is a really powerful thing that was added do you think it wouldnt have been you know muhammad ali versus frasier right do you think it wouldnt have been added as quickly if pytorch wasnt there it might have taken longer no longer yeah it was i mean we had tried some variants of that before so im sure it would have happened but it might have taken longer im grateful that tensorflow is finally in the way they did its doing some incredible work last couple years what other things that we didnt talk about are you looking forward in 20 that comes to mind so we talked about some of the ecosystem stuff making it easily accessible to keras eager execution is there other things that we missed yeah so i would say one is just where 20 is and you know with all the things that weve talked about i think as we think beyond that there are lots of other things that it enables us to do and that were excited about so what its setting us up for okay here are these really clean apis weve cleaned up the surface for what the users want what it also allows us to do a whole bunch of stuff behind the scenes once we are ready with 20 so for example in tensorflow with graphs and all the things you could do you could always get a lot of good performance if you spent the time to tune it right and weve clearly shown that lots of people do that with 20 with these apis where we are we can give you a lot of performance just with whatever you do you know because we see these its much cleaner we know most people are gonna do things this way we can really optimize for that and get a lot of those things out of the box and it really allows us you know both for single machine and distributed and so on to really explore other spaces behind the scenes after 20 in the future versions as well so right now the teams really excited about that that over time i think well see that the other piece that i was talking about in terms of just restructuring the monolithic thing into more pieces and making it more modular i think thats gonna be really important for a lot of the other people in the ecosystem other organizations and so on that wanted to build things can you elaborate a little bit what you mean by making tensorflow ecosystem more modular so the way its organized today is theres one there are lots of repositories in the tensorflow organization at github the core one where we have tensorflow it has the execution engine it has the key backends for cpus and gpus it has the work to do distributed stuff and all of these just work together in a single library or binary theres no way to split them apart easily i mean there are some interfaces but theyre not very clean in a perfect world you would have clean interfaces where okay i wanna run it on my fancy cluster with some custom networking just implement this and do that i mean we kind of support that but its hard for people today i think as we are starting to see more interesting things in some of these spaces having that clean separation will really start to help and again going to the large size of the ecosystem and the different groups involved there enabling people to evolve and push on things more independently just allows it to scale better and by people you mean individual developers and and organizations and organizations thats right so the hope is that everybody sort of major i dont know pepsi or something uses like major corporations go to tensorflow to this kind of yeah if you look at enterprises like pepsi or these i mean a lot of them are already using tensorflow they are not the ones that do the development or changes in the core some of them do but a lot of them dont i mean they touch small pieces there are lots of these some of them being lets say hardware vendors who are building their custom hardware and they want their own pieces or some of them being bigger companies say ibm i mean theyre involved in some of our special interest groups and they see a lot of users who want certain things and they want to optimize for that so folks like that often autonomous vehicle companies perhaps exactly yes so yeah like i mentioned tensorflow has been downloaded 41 million times 50000 commits almost 10000 pull requests and 1800 contributors so im not sure if you can explain it but what does it take to build a community like that in retrospect what do you think what is the critical thing that allowed for this growth to happen and how does that growth continue yeah yeah thats an interesting question i wish i had all the answers there i guess so you could replicate it i think there are a number of things that need to come together right one just like any new thing it is about theres a sweet spot of timing whats needed does it grow with whats needed so in this case for example tensorflows not just grown because it was a good tool its also grown with the growth of deep learning itself so those factors come into play other than that though i think just hearing listening to the community what they do what they need being open to like in terms of external contributions weve spent a lot of time in making sure we can accept those contributions well we can help the contributors in adding those putting the right process in place getting the right kind of community welcoming them and so on like over the last year weve really pushed on transparency thats important for an open source project people wanna know where things are going and were like okay heres a process where you can do that here are our rfcs and so on so thinking through there are lots of community aspects that come into that you can really work on as a small project its maybe easy to do because theres like two developers and you can do those as you grow putting more of these processes in place thinking about the documentation thinking about what two developers care about what kind of tools would they want to use all of these come into play i think so one of the big things i think that feeds the tensorflow fire is people building something on tensorflow and implement a particular architecture that does something cool and useful and they put that on github and so it just feeds this growth do you have a sense that with 20 and 10 that there may be a little bit of a partitioning like there is with python 2 and 3 that therell be a code base and in the older versions of tensorflow they will not be as compatible easily or are you pretty confident that this kind of conversion is pretty natural and easy to do so were definitely working hard to make that very easy to do theres lots of tooling that we talked about at the developer summit this week and well continue to invest in that tooling its you know when you think of these significant version changes thats always a risk and we are really pushing hard to make that transition very very smooth so i think so at some level people wanna move and they see the value in the new thing they dont wanna move just because its a new thing and some people do but most people want a really good thing and i think over the next few months as people start to see the value well definitely see that shift happening so im pretty excited and confident that we will see people moving as you said earlier this field is also moving rapidly so thatll help because we can do more things and all the new things will clearly happen in 2x so people will have lots of good reasons to move so what do you think tensorflow 30 looks like is there are things happening so crazily that even at the end of this year seems impossible to plan for or is it possible to plan for the next five years i think its tricky there are some things that we can expect in terms of okay change yes change is gonna happen are there some things gonna stick around and some things not gonna stick around i would say the basics of deep learning the you know say convolution models or the basic kind of things theyll probably be around in some form still in five years will rl and gan stay very likely based on where they are will we have new things probably but those are hard to predict and some directionally some things that we can see is you know in things that were starting to do right with some of our projects right now is just 20 combining eager execution and graphs where were starting to make it more like just your natural programming language youre not trying to program something else similarly with swift for tensorflow were taking that approach can you do something ground up right so some of those ideas seem like okay thats the right direction in five years we expect to see more in that area other things we dont know is will hardware accelerators be the same will we be able to train with four bits instead of 32 bits and i think the tpu side of things is exploring that i mean tpu is already on version three it seems that the evolution of tpu and tensorflow are sort of theyre coevolving almost in terms of both are learning from each other and from the community and from the applications where the biggest benefit is achieved thats right youve been trying to sort of with eager with keras to make tensorflow as accessible and easy to use as possible what do you think for beginners is the biggest thing they struggle with have you encountered that or is basically what keras is solving is that eager like we talked about yeah for some of them like you said right the beginners want to just be able to take some image model they dont care if its inception or resnet or something else and do some training or transfer learning on their kind of model being able to make that easy is important so in some ways if you do that by providing them simple models with say in hub or so on they dont care about whats inside that box but they want to be able to use it so were pushing on i think different levels if you look at just a component that you get which has the layers already smooshed in the beginners probably just want that then the next step is okay look at building layers with keras if you go out to research then they are probably writing custom layers themselves or doing their own loops so theres a whole spectrum there and then providing the pre trained models seems to really decrease the time from you trying to start you could basically in a colab notebook achieve what you need so im basically answering my own question because i think what tensorflow delivered on recently is trivial for beginners so i was just wondering if there was other pain points youre trying to ease but im not sure there would no those are probably the big ones i see high schoolers doing a whole bunch of things now which is pretty amazing its both amazing and terrifying yes in a sense that when they grow up its some incredible ideas will be coming from them so theres certainly a technical aspect to your work but you also have a management aspect to your role with tensorflow leading the project a large number of developers and people so what do you look for in a good team what do you think google has been at the forefront of exploring what it takes to build a good team and tensorflow is one of the most cutting edge technologies in the world so in this context what do you think makes for a good team its definitely something i think a favorite about i think in terms of the team being able to deliver something well one of the things thats important is a cohesion across the team so being able to execute together in doing things thats not an end like at this scale an individual engineer can only do so much theres a lot more that they can do together even though we have some amazing superstars across google and in the team but theres you know often the way i see it as the product of what the team generates is way larger than the whole or the individual put together and so how do we have all of them work together the culture of the team itself hiring good people is important but part of that is its not just that okay we hire a bunch of smart people and throw them together and let them do things its also people have to care about what theyre building people have to be motivated for the right kind of things thats often an important factor and you know finally how do you put that together with a somewhat unified vision of where we wanna go so are we all looking in the same direction or each of us going all over and sometimes its a mix googles a very bottom up organization in some sense also research even more so and thats how we started but as weve become this larger product and ecosystem i think its also important to combine that well with a mix of okay heres the direction we wanna go in there is exploration well do around that but lets keep staying in that direction not just all over the place and is there a way you monitor the health of the team sort of like is there a way you know you did a good job the team is good like i mean youre sort of youre saying nice things but its sometimes difficult to determine how aligned yes because its not binary its not like theres tensions and complexities and so on and the other element of the mission of superstars theres so much even at google such a large percentage of work is done by individual superstars too so theres a and sometimes those superstars can be against the dynamic of a team and those tensions i mean im sure in tensorflow it might be a little bit easier because the mission of the project is so sort of beautiful youre at the cutting edge so its exciting but have you had struggle with that has there been challenges there are always people challenges in different kinds of ways that said i think weve been whats good about getting people who care and are you know have the same kind of culture and thats google in general to a large extent but also like you said given that the project has had so many exciting things to do theres been room for lots of people to do different kinds of things and grow which does make the problem a bit easier i guess and it allows people depending on what theyre doing if theres room around them then thats fine but yes we do care about whether a superstar or not that they need to work well with the team across google thats interesting to hear so its like superstar or not the productivity broadly is about the team yeah yeah i mean they might add a lot of value but if theyre hurting the team then thats a problem so in hiring engineers its so interesting right the hiring process what do you look for how do you determine a good developer or a good member of a team from just a few minutes or hours together again no magic answers im sure yeah i mean google has a hiring process that weve refined over the last 20 years i guess and that youve probably heard and seen a lot about so we do work with the same hiring process and thats really helped for me in particular i would say in addition to the core technical skills what does matter is their motivation in what they wanna do because if that doesnt align well with where we wanna go thats not gonna lead to long term success for either them or the team and i think that becomes more important the more senior the person is but its important at every level like even the junior most engineer if theyre not motivated to do well at what theyre trying to do however smart they are its gonna be hard for them to succeed does the google hiring process touch on that passion so like trying to determine because i think as far as i understand maybe you can speak to it that the google hiring process sort of helps in the initial like determines the skill set there is your puzzle solving ability problem solving ability good but like im not sure but it seems that the determining whether the person is like fire inside them that burns to do anything really it doesnt really matter its just some cool stuff im gonna do it is that something that ultimately ends up when they have a conversation with you or once it gets closer to the team so one of the things we do have as part of the process is just a culture fit like part of the interview process itself in addition to just the technical skills and each engineer or whoever the interviewer is is supposed to rate the person on the culture and the culture fit with google and so on so that is definitely part of the process now there are various kinds of projects and different kinds of things so there might be variants and of the kind of culture you want there and so on and yes that does vary so for example tensorflow has always been a fast moving project and we want people who are comfortable with that but at the same time now for example we are at a place where we are also very full fledged product and we wanna make sure things that work really really work right you cant cut corners all the time so balancing that out and finding the people who are the right fit for those is important and i think those kinds of things do vary a bit across projects and teams and product areas across google and so youll see some differences there in the final checklist but a lot of the core culture it comes along with just the engineering excellence and so on what is the hardest part of your job ill take your pick i guess its fun i would say right hard yes i mean lots of things at different times i think that does vary so let me clarify that difficult things are fun when you solve them right so its fun in that sense i think the key to a successful thing across the board and in this case its a large ecosystem now but even a small product is striking that fine balance across different aspects of it sometimes its how fast do you go versus how perfect it is sometimes its how do you involve this huge community who do you involve or do you decide okay now is not a good time to involve them because its not the right fit sometimes its saying no to certain kinds of things those are often the hard decisions some of them you make quickly because you dont have the time some of them you get time to think about them but theyre always hard so both choices are pretty good those decisions what about deadlines is this do you find tensorflow to be driven by deadlines to a degree that a product might', 'the following is a conversation with gavin miller hes the head of adobe research adobe has empowered artists designers and creative minds from all professions working in the digital medium for over 30 years with software such as photoshop illustrator premiere after effects indesign audition software that work with images video and audio adobe research is working to define the future evolution of these products in a way that makes the life of creatives easier automates the tedious tasks and gives more and more time to operate in the idea space instead of pixel space this is where the cutting edge deep learning methods of the past decade can really shine more than perhaps any other application gavin is the embodiment of combining tech and creativity outside of adobe research he writes poetry and builds robots both things that are near and dear to my heart as well this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lux friedman spelled f r i d and now heres my conversation with gavin miller youre head of adobe research leading a lot of innovative efforts and applications of ai creating images video audio language but youre also yourself an artist a poet a writer and even a roboticist so while i promised to everyone listening that i will not spend the entire time we have together reading your poetry which i love i have to sprinkle it in at least a little bit so some of them are pretty deep and profound and some are light and silly lets start with a few lines from the silly variety you write in je ne vinaigrette rien a poem that beautifully parodies both edith piafs je ne vinaigrette rien and my way by frank sinatra so it opens with and now dessert is near its time to pay the final total ive tried to slim all year but my diets have been anecdotal so where does that love for poetry come from for you and if we dissect your mind how does it all fit together in the bigger puzzle of dr gavin miller oh well interesting you chose that one that was a poem i wrote when id been to my doctor and he said you really need to lose some weight and go on a diet and whilst the rational part of my brain wanted to do that the irrational part of my brain was protesting and sort of embraced the opposite idea i regret nothing hence yes exactly taken to an extreme i thought it would be funny obviously its a serious topic for some people but i think for me ive always been interested in writing since i was in high school as well as doing technology and invention and sometimes there are parallel strands in your life that carry on and one is more about your private life and ones more about your technological career and then at sort of happy moments along the way sometimes the two things touch one idea informs the other and we can talk about that as we go do you think your writing the art the poetry contribute indirectly or directly to your research to your work in adobe well sometimes it does if i say imagine a future in a science fiction kind of way and then once it exists on paper i think well why shouldnt i just build that there was an example where when realistic voice synthesis first started in the 90s at apple where i worked in research it was done by a friend of mine i sort of sat down and started writing a poem which each line i would enter into the voice synthesizer and see how it sounded and sort of wrote it for that voice and at the time the agents werent very sophisticated so theyd sort of add random intonation and i kind of made up the poem to sort of match the tone of the voice and it sounded slightly sad and depressed so i pretended it was a poem written by an intelligent agent sort of telling the user to go home and leave them alone but at the same time they were lonely and wanted to have company and learn from what the user was saying and at the time it was way beyond anything that ai could possibly do but since then its becoming more within the bounds of possibility and then at the same time i had a project at home where i did sort of a smart home this was probably 93 94 and i had the talking voice whod remind me when i walked in the door of what things i had to do i had buttons on my washing machine because i was a bachelor and id leave the clothes in there for three days and they got moldy so as i got up in the morning it would say dont forget the washing and so on i made photo albums that use light sensors to know which page you were looking at would send that over wireless radio to the agent who would then play sounds that match the image you were looking at in the book so i was kind of in love with this idea of magical realism and whether it was possible to do that with technology so that was a case where the sort of the agent sort of intrigued me from a literary point of view and became a personality i think more recently ive also written plays and when plays you write dialogue and obviously you write a fixed set of dialogue that follows a linear narrative but with modern agents as you design a personality or a capability for conversation youre sort of thinking of i kind of have imaginary dialogue in my head and then i think what would it take not only to have that be real but for it to really know what its talking about so its easy to fall into the uncanny valley with ai where it says something it doesnt really understand but it sounds good to the person but you rapidly realize that its kind of just stimulus response it doesnt really have real world knowledge about the thing its describing and so when you get to that point it really needs to have multiple ways of talking about the same concept so it sounds as though it really understands it now what really understanding means is in the eye of the beholder right but if it only has one way of referring to something it feels like its a canned response but if it can reason about it or you can go at it from multiple angles and give a similar kind of response that people would then it starts to seem more like theres something there thats sentient you can say the same thing multiple things from different perspectives i mean with the automatic image captioning that ive seen the work that youre doing theres elements of that right being able to generate different kinds of statements about the same picture right so in my team theres a lot of work on turning a medium from one form to another whether its auto tagging imagery or making up full sentences about whats in the image then changing the sentence finding another image that matches the new sentence or vice versa and in the modern world of gans you sort of give it a description and it synthesizes an asset that matches the description so ive sort of gone on a journey my early days in my career were about 3d computer graphics the sort of pioneering work sort of before movies had special effects done with 3d graphics and sort of rode that revolution and that was very much like the renaissance where people would model light and color and shape and everything and now were kind of in another wave where its more impressionistic and its sort of the idea of something can be used to generate an image directly which is sort of the new frontier in computer image generation using ai algorithms so the creative process is more in the space of ideas or becoming more in the space of ideas versus in the raw pixels well its interesting it depends i think at adobe we really want to span the entire range from really really good what you might call low level tools by low level as close to say analog workflows as possible so what we do there is we make up systems that do really realistic oil paint and watercolor simulations so if you want every bristle to behave as it would in the real world and leave a beautiful analog trail of water and then flow after youve made the brushstroke you can do that and thats really important for people who want to create something really expressive or really novel because they have complete control and then as certain other tasks become automated it frees the artists up to focus on the inspiration and less of the perspiration so thinking about different ideas obviously once you finish the design theres a lot of work to say do it for all the different aspect ratio of phones or websites and so on and that used to take up an awful lot of time for artists it still does for many what we call content velocity and one of the targets of ai is actually to reason about from the first example of what are the likely intent for these other formats maybe if you change the language to german and the words are longer how do you reflow everything so that it looks nicely artistic in that way and so the person can focus on the really creative bit in the middle which is what is the look and style and feel and whats the message and whats the story and the human element so i think creativity is changing so thats one way in which were trying to just make it easier and faster and cheaper to do so that there can be more of it more demand because its less expensive so everyone wants beautiful artwork for everything from a school website to hollywood movie on the other side as some of these things have automatic versions of them people will possibly change role from being the hands on artisan to being either the art director or the conceptual artist and then the computer will be a partner to help create polished examples of the idea that theyre exploring lets talk about adobe products ai and adobe products just so you know where im coming from im a huge fan of photoshop for images premiere for video audition for audio ill probably use photoshop to create the thumbnail for this video premiere to edit the video audition to do the audio that said everything i do is really manually and i set up i use this old school kinesis keyboard and i have auto hotkey that just its really about optimizing the flow of just making sure theres as few clicks as possible so just being extremely efficient something you started to speak to so before we get into the fun sort of awesome deep learning things where does ai if you could speak a little more to it ai or just automation in general do you see in the coming months and years or in general prior in 2018 fitting into making the life the low level pixel work flow easier yeah thats a great question so we have a very rich array of algorithms already in photoshop just classical procedural algorithms as well as ones based on data in some cases they end up with a large number of sliders and degrees of freedom so one way in which ai can help is just an auto button which comes up with default settings based on the content itself rather than default values for the tool at that point you then start tweaking so thats a very kind of make life easier for people whilst making use of common sense from other example images so like smart defaults smart defaults absolutely another one is something weve spent a lot of work over the last 20 years ive been at adobe or 19 thinking about selection for instance where you know with quick select you would look at color boundaries and figure out how to sort of flood fill into regions that you thought were physically connected in the real world but that algorithm had no visual common sense about what a cat looks like or a dog it would just do it based on rules of thumb which were applied to graph theory and it was a big improvement over the previous work where you had sort of almost click everything by hand or if it just did similar colors it would do little tiny regions that wouldnt be connected but in the future using neural nets to actually do a great job with say a single click or even in the case of well known categories like people or animals no click where you just say select the object and it just knows the dominant object is a person in the middle of the photograph those kinds of things are really valuable if they can be robust enough to give you good quality results or they can be a great start for like tweaking it so for example background removal correct like one thing ill in a thumbnail ill take a picture of you right now and essentially remove the background behind you and i want to make that as easy as possible you dont have flowing hair like rich at the moment i had it in the past it may come again in the future so that sometimes makes it a little more challenging to remove the background how difficult do you think is that problem for ai for basically making the quick selection tool smarter and smarter and smarter well we have a lot of research on that already if you want a sort of quick cheap and cheerful look im pretending im in hawaii but its sort of a joke then you dont need perfect boundaries and you can do that today with a single click with the algorithms we have we have other algorithms where with a little bit more guidance on the boundaries like you might need to touch it up a little bit we have other algorithms that can pull a nice mat from a crude selection so we have combinations of tools that can do all of that and at our recent max conference at adobe max we demonstrated how very quickly just by drawing a simple polygon around the object of interest we could not only do it for a single still but we could pull a mat well pull at least a selection mask from a moving target like a person dancing in front of a brick wall or something and so its going from hours to a few seconds for workflows that are really nice and then you might go in and touch up a little so thats a really interesting question you mentioned the word robust you know theres like a journey for an idea right and what you presented probably at max has elements of just sort of it inspires the concept it can work pretty well in a majority of cases but how do you make something that works well in majority of cases how do you make something that works maybe in all cases or it becomes a robust tool that can well there are a couple of things so that really touches on the difference between academic research and industrial research so in academic research its really about whos the person to have the great new idea that shows promise and we certainly love to be those people too but we have sort of two forms of publishing one is academic peer review which we do a lot of and we have great success there as much as some universities but then we also have shipping which is a different type of and then we get customer review as well as you know product critics and that might be a case where its not about being perfect every single time but perfect enough of the time plus a mechanism to intervene and recover where you do have mistakes so we have the luxury of very talented customers we dont want them to be overly taxed doing it every time but if they can go in and just take it from 99 to 100 with the touch of a mouse or something then for the professional end thats something that we definitely want to support as well and for them it went from having to do that tedious task all the time to much less often so i think that gives us an out if it had to be 100 automatic all the time then that would delay the time at which we could get to market so on that thread maybe you can untangle something again im sort of just speaking to my own experience maybe that is the most useful absolutely so i think photoshop as an example or premiere has a lot of amazing features that i havent touched and so in terms of ai helping make my life or the life of creatives easier this collaboration between human and machine how do you learn to collaborate better how do you learn the new algorithms is it something where you have to watch tutorials and you have to watch videos and so on or do you think about the experience itself through exploration being the teacher we absolutely do so im glad that you brought this up we sort of think about two things one is helping the person in the moment to do the task that they need to do but the other is thinking more holistically about their journey learning a tool and when its like think of it as adobe university where you use the tool long enough you become an expert and not necessarily an expert in everything its like living in a city you dont necessarily know every street but you know the important ones you need to get to so we have projects in research which actually look at the thousands of hours of tutorials online and try to understand whats being taught in them and then we had one publication at chi where it was looking at given the last three or four actions you did what did other people in tutorials do next so if you want some inspiration for what you might do next or you just want to watch the tutorial and see learn from people who are doing similar workflows to you you can without having to go and search on keywords and everything so really trying to use the context of your use of the app to make intelligent suggestions either about choices that you might make or in a more assistive way where it could say if you did this next we could show you and thats basically the frontier that were exploring now which is if we really deeply understand the domain in which designers and creative people work can we combine that with ai and pattern matching of behavior to make intelligent suggestions either through you know verbal possibilities or just showing the results of if you try this and thats really the sort of you know i was in a meeting today thinking about these things well its still a grand challenge you know wed all love an artist over one shoulder and a teacher over the other right and we hope to get there and the right thing to do is to give enough at each stage that its useful in itself but it builds a foundation for the next stage give enough at each stage that its useful in itself but it builds a foundation for the next level of expectation are you aware of this gigantic medium of youtube thats creating just a bunch of creative people both artists and teachers of different kinds absolutely and the more we can understand those media types both visually and in terms of transcripts and words the more we can bring the wisdom that they embody into the guidance thats embedded in the tool that would be brilliant to remove the barrier from having to yourself type in the keyword searching so on absolutely and then in the longer term an interesting discussion is does it ultimately not just assist with learning the interface we have but does it modify the interface to be simpler or do you fragment into a variety of tools each of which has a different level of visibility of build a real one and so then started what turned out to be like a 15 year obsession with trying to build better snake robots and the first one that i built just sort of slithered sideways but didnt actually go forward then i added wheels and building things in real life makes you honest about the friction the thing that appeals to me is i love creating the illusion of life which is what drove me to animation and if you have a robot with enough degrees of coordinated freedom that move in a kind of biological way then it starts to cross the ancani valley and to seem like a creature rather than a thing and i certainly got that with the early snakes by s3 i had it able to sidewind as well as go directly forward my wife to be suggested that it would be the ring bearer at our wedding so it actually went down the aisle carrying the rings and got in the local paper for that which was really fun and this was all done as a hobby and then i at the time that can onboard compute was incredibly limited it was sort of yeah so you should explain that these things the whole idea is that you would youre trying to run it autonomously autonomously on board right and so the very first one i actually built the controller from discrete logic cause i used to do lsi you know circuits and things when i was a teenager and then the second and third one the eight bit microprocessors were available with like the whole 256 bytes of ram which you could just about squeeze in so they were radio controlled rather than autonomous and really were more about the physicality and coordinated motion ive occasionally taken a sidestep into if only i could make it cheaply enough bake a great toy which has been a lesson in how clockwork is its own magical realm that you venture into and learn things about backlash and other things you dont take into account as a computer scientist which is why what seemed like a good idea doesnt work so it was quite humbling and then more recently ive been building s9 which is a much better engineered version of s3 where the motors wore out and it doesnt work anymore and you cant buy replacements which is sad given that it was such a meaningful one s5 was about twice as long and looked much more biologically inspired unlike the typical roboticist i taper my snakes there are good mechanical reasons to do that but it also makes them look more biological although it means every segments unique rather than a repetition which is why most engineers dont do it it actually saves weight and leverage and everything and that one is currently on display at the international spy museum in washington dc not that its done any spying it was on youtube and it got its own conspiracy theory where people thought that it wasnt real because i work at adobe it must be fake graphics and people would write to me tell me its real you know they say the background doesnt move and its like its on a tripod you know so that one but you can see the real thing so it really is true and then the latest one is the first one where i could put a raspberry pi which leads to all sorts of terrible jokes about pythons and things but this one can have on board compute and then where my hobby work and my work work are converging is you can now add vision accelerator chips which can evaluate neural nets and do object recognition and everything so both for the snakes and more recently for the spider that ive been working on having you know desktop level compute is now opening up a whole world of true autonomy with onboard compute onboard batteries and still having that sort of biomimetic quality that appeals to children in particular they are really drawn to them and adults think they look creepy but children actually think they look charming and i gave a series of lectures at girls who code to encourage people to take an interest in technology and at the moment id say theyre still more expensive than the value that they add which is why theyre a great hobby for me but theyre not really a great product it makes me think about doing that very early thing i did at alias with changing the muscle rest lengths if i could do that with a real artificial muscle material then the next snake ideally would use that rather than motors and gearboxes and everything it would be lighter much stronger and more continuous and smooth so its i like to say being in research is a license to be curious and i have the same feeling with my hobby it forced me to read biology and be curious about things that otherwise would have just been you know a national geographic special suddenly im thinking how does that snake move can i copy it i look at the trails that sidewinding snakes leave in sand and see if my snake robots would do the same thing so out of something inanimate i like why you put it try to bring life into it and beauty absolutely and then ultimately give it a personality which is where the intelligent agent research will converge with the vision and voice synthesis to give it a sense of having not necessarily human level intelligence i think the turing test is such a high bar its a little bit self defeating but having one that you can have a meaningful conversation with especially if you have a reasonably good sense of what you can say so not trying to have it so a stranger could walk up and have one but so as a pet owner or a robot pet owner you could know what it thinks about and what it can reason about or sometimes just the meaningful interaction if you have the kind of interaction you have with the dog sometimes you might have a conversation but its usually one way absolutely and nevertheless it feels like a meaningful and meaningful connection and one of the things that im trying to do in the sample audio that will play you is beginning to get towards the point where the reasoning system can explain why it knows something or why it thinks something and that again creates the sense that it really does know what its talking about but also for debugging as you get more and more elaborate behavior its like why did you decide to do that you know how do you know that i think the robots really my muse for helping me think about the future of ai and what to invent next so even at adobe thats mostly operating in digital world correct do you ever do you see a future where adobe even expands into the more physical world perhaps so bringing life not into animations but bringing life into physical objects with whether its well id have to say at the moment its a twinkle in my eye i think the more likely thing is that we will bring virtual objects into the physical world through augmented reality and many of the ideas that might take five years to build a robot to do you can do in a few weeks with digital assets so i think when really intelligent robots finally become commonplace they wont be that surprising because well have been living with those personalities for in the virtual sphere for a long time and then theyll just say oh its you know siri with legs or alexa alexa on hooves or something so i can see that world coming and for now its still an adventure still an adventure and we dont know quite what the experience will be like and its really exciting to sort of see all of these different strands of my career converge yeah in interesting ways and it is definitely a fun adventure so let me end with my favorite poem the last few lines of my favorite poem of yours that ponders mortality and in some sense immortality you know as our ideas live through the ideas of others through the work of others it ends with do not weep or mourn it was enough the little enemies permitted just a single dance scattered them as deep as your eyes can see im content theyll have another chance sweeping more centered parts along to join a jostling lifting throng as others danced in me beautiful poem beautiful way to end it gavin thank you so much for talking today and thank you for inspiring and empowering millions of people like myself for creating amazing stuff oh thank you great conversation the functionality i like to say that if you add a feature to a gui you have to have yet more visual complexity confronting the new user whereas if you have an assistant with a new skill if you know they have it so you know to ask for it then its sort of additive without being more intimidating so we definitely think about new users and how to onboard them many actually value the idea of being able to master that complex interface and keyboard shortcuts like you were talking about earlier because with great familiarity it becomes a musical instrument for expressing your visual ideas and other people just want to get something done quickly in the simplest way possible and thats where a more assistive version of the same technology might be useful maybe on a different class of device which is more in context for captcha say whereas somebody whos in a deep post production workflow maybe want to be on a laptop or a big screen desktop and have more knobs and dials to really express the subtlety of what they want to do so theres so many exciting applications of computer vision and machine learning that adobe is working on like scene stitching sky replacement foreground background removal spatial object based image search automatic image captioning like we mentioned project cloak project deep fill filling in parts of the images project scribbler style transform video style transform faces and video with project puppetron best name ever can you talk through a favorite or some of them or examples that popped in mind im sure ill be able to provide links to other ones we dont talk about because theres visual elements to all of them that are exciting why theyre interesting for different reasons might be a good way to go so i think sky replace is interesting because we talked about selection being sort of an atomic operation its almost like if you think of an assembly language its like a single instruction whereas sky replace is a compound action where you automatically select the sky you look for stock content that matches the geometry of the scene you try to have variety in your choices so that you do coverage of different moods it then mats in the sky behind the foreground but then importantly it uses the foreground of the other image that you just searched on to recolor the foreground of the image that youre editing so if you say go from a midday sky to an evening sky it will actually add sort of an orange glow to the foreground objects as well i was a big fan in college of magritte and he has a number of paintings where its surrealism because hell like do a composite but the foreground building will be at night and the sky will be during the day theres one called the empire of light which was on my wall in college and were trying not to do surrealism it can be a choice but wed rather have it be natural by default rather than it looking fake and then you have to do a whole bunch of post production to fix it so thats a case where were kind of capturing an entire workflow into a single action and doing it in about a second rather than a minute or two and when you do that you can not just do it once but you can do it for say like 10 different backgrounds and then youre almost back to this inspiration idea of i dont know quite what i want but ill know it when i see it and you can just explore the design space as close to final production value as possible and then when you really pick one you might go back and slightly tweak the selection mask just to make it perfect and do that kind of polish that professionals like to bring to their work so then theres this idea of you mentioned the sky replacing it to different stock images of the sky but in general you have this idea or it could be on your disc or whatever disc right but making even more intelligent choices about ways to search stock images which is really interesting its kind of spatial absolutely right so that was something we called concept canvas so normally when you do a say an image search you would i assuming its just based on text you would give the keywords of the things you want to be in the image and it would find the nearest one that had those tags for many tasks you really want you know to be able to say i want a big person in the middle or in a dog to the right and umbrella above the left because you want to leave space for the text or whatever for the and so concept canvas lets you assign spatial regions to the keywords and then weve already pre indexed the images to know where the important concepts are in the picture so we then go through that index matching to assets and even though its just another form of search because youre doing spatial design or layout it starts to feel like design you sort of feel oddly responsible for the image that comes back as if you invented it yeah so its its a its a good example where giving enough control starts to make people have a sense of ownership over the outcome of the event and then we also have technologies in photoshop we physically can move the dog in post as well but for concept canvas it was just a very fast way to sort of loop through and be able to lay things out and in terms of being able to remove objects from a scene and fill in the background right automatically i so thats extremely exciting and thats so neural networks are stepping in there i just talked this week ian goodfellow so the gans for doing that is definitely one approach so that is that is that a really difficult problem is it as difficult as it looks again to take it to a robust product level well there are certain classes of image for which the traditional algorithms like content aware fill work really well like if you have a naturalistic texture like a gravel path or something because its patch based it will make up a very plausible looking intermediate thing and fill in the hole and then we use some algorithms to sort of smooth out the lighting so you dont see any brightness contrast in that region or youve gradually ramped from one from dark to light if it straddles the boundary where it gets complicated as if you have to infer invisible structure behind behind the person in front and that really requires a common sense knowledge of the world to know what you know if i see three quarters of a house do i have a rough sense of what the rest of the house looks like if you just fill it in with patches it can end up sort of doing things that make sense locally but you look at the global structure and it looks like its just sort of crumpled or messed up and so what gans and neural nets bring to the table is this common sense learned from the training set and the challenge right now is that the generative methods that can make up missing holes using that kind of technology are still only stable at low resolutions and so you either need to then go from a low resolution to a high resolution using some other algorithm or we need to push the state of the art and its still in research to get to that point of course if you show it something say its trained on houses and then you show it an octopus its not going to do a very good job of showing common sense about octopuses so again youre asking about how you know that its ready for primetime you really need a very diverse training set of images and ultimately that may be a case where you put it out there with some guardrails where you might do a detector which looks at the image and sort of estimates its own competence of how well a job could this algorithm do so eventually there may be this idea of what we call an ensemble of experts where any particular expert is specialized in certain things and then theres sort of a either they vote to say how confident they are about what to do this is sort of more future looking or theres some dispatcher which says youre good at houses youre good at trees so i mean all this adds up to a lot of work because each of those models will be a whole bunch of work but i think over time youd gradually fill out the set and initially focus on certain workflows and then sort of branch out as you get more capable you mentioned workflows and have you considered maybe looking far into the future first of all using the fact that there is a huge amount of people that use photoshop for example and have certain workflows being able to collect the information by which they you know basically get information about their workflows about what they need the ways to help them whether it is houses or octopus that people work on more you know like basically getting a beat on what kind of data is needed to be annotated and collected for people to build tools that actually work well for people right absolutely and this is a big topic in the whole world of ai is what data can you gather and why right at one level a way to think about it is we not only want to train our customers in how to use our products but we want them to teach us whats important and whats useful at the same time we want to respect their privacy and obviously we wouldnt do things without their explicit permission and i think the modern spirit of the age around this is you have to demonstrate to somebody how theyre benefiting from sharing their data with the tool either its helping in the short term to understand their intent so you can make better recommendations or if theyre friendly to your cause or your tool or they want to help you evolve quickly because they depend on you for their livelihood they may be willing to share some of their workflows or choices with the data set to be then trained there are technologies for looking at learning without necessarily storing all the information permanently so that you can sort of learn on the fly but not keep a record of what somebody did so were definitely exploring all of those possibilities and i think adobe exists in a space where photoshop like if i look at the data ive created and own you know im less comfortable sharing data with social networks than i am with adobe because theres a just exactly as you said theres an obvious benefit for sharing for sharing the data that i use to create in photoshop because its helping improve the workflow in the future as opposed to its not clear what the benefit is in social networks its nice for you to say that i mean i think there are some professional workflows where people might be very protective of what theyre doing such as if i was preparing evidence for a legal case i wouldnt want any of that you know phoning home to help train the algorithm or anything there may be other cases where people are say having a trial version or theyre doing some im not saying were doing this today but theres a future scenario where somebody has a more permissive relationship with adobe where they explicitly say im fine im only doing hobby projects or things which are non confidential and in exchange for some benefit tangible or otherwise im willing to share very fine grained data so another possible scenario is to capture relatively crude high level things from more people and then more detailed knowledge from people who are willing to participate we do that today with explicit customer studies where you know we go and visit somebody and ask them to try the tool and we human observe what theyre doing in the future to be able to do that enough to be able to train an algorithm wed need a more systematic process but wed have to do it very consciously because is one of the things people treasure about adobe is a sense of trust and we dont want to endanger that through overly aggressive data collection so we have a chief privacy officer and its definitely front and center of thinking about ai rather than an afterthought well when you start that program sign me up okay happy to is there other projects that you wanted to mention that that i didnt perhaps that pop into mind well you covered the number i think you mentioned project puppetron i think that one is interesting because its you might think of adobe as only thinking in 2d and thats a good example where were actually thinking more three dimensionally about how to assign features to faces so that we can you know if you take so what puppet run does it takes either a still or a video of a person talking and then it can take a painting of somebody else and then apply the style of the painting to the person whos talking in the video and its unlike a sort of screen door post filter effect that you sometimes see online it really looks as though its sort of somehow attached or reflecting the motion of the face and so thats the case where even to do a 2d workflow like stylization you really need to infer more about the 3d structure of the world and i think as 3d computer vision algorithms get better initially theyll focus on particular domains like faces where you have a lot of prior knowledge about structure and you can maybe have a parameterized template that you fit to the image but over time this should be possible for more general content and it might even be invisible to the user that youre doing 3d reconstruction but under the hood but it might then let you do edits much more reliably or correctly than you would otherwise and you know the face is a very important application right absolutely so making things work and a very sensitive one if you do something uncanny its very disturbing thats right you have to get it right so in the space of augmented reality and virtual reality what do you think is the role of ar and vr and in the content we consume as people as consumers and the content we create as creators now thats a great question we think about this a lot too so i think vr and ar serve slightly different purposes so vr can really transport you to an entire immersive world no matter what your personal situation is to that extent its a bit like a really really widescreen television where it sort of snaps you out of your context and puts you in a new one and i think its still evolving in terms of the hardware i actually worked on vr in the 90s trying to solve the latency and sort of nausea problem which we did but it was very expensive and a bit early theres a new wave of that now i think and increasingly those devices are becoming all in one rather than something thats tethered to a box i think the market seems to be bifurcating into things for consumers and things for professional use cases like for architects and people designing where your product is a building and you really want to experience it better than looking at a scale model or a drawing i think or even than a video so i think for that where you need a sense of scale and spatial relationships its great i think ar holds the promise of sort of taking digital assets off the screen and putting them in context in the real world on the table in front of you on the wall behind you and that has the corresponding need that the assets need to adapt to the physical context in which theyre being placed i mean its a bit like having a live theater troupe come to your house and put on hamlet my mother had a friend who used to do this at stately homes in england for the national trust and they would adapt the scenes and even theyd walk the audience through the rooms to see the action based on the country house they found themselves in for two days and i think ar will have the same issue that you know if you have a tiny table and a big living room or something itll try to figure out what can you change and whats fixed and theres a little bit of a tension between fidelity where if you captured say nureyev doing a fantastic ballet youd want it to be sort of exactly reproduced and maybe all you could do is scale it down whereas somebody telling you a story might be walking around the room doing some gestures and that could adapt to the room in which they were telling the story and do you think fidelity is that important in that space or is it more about the storytelling i think it may depend on the characteristic of the media if its a famous celebrity then it may be that you want to catch every nuance and they dont want to be reanimated by some algorithm it could be that if its really you know a lovable frog telling you a story and its about a princess and a frog then it doesnt matter if the frog moves in a different way i think a lot of the ideas that have sort of grown up in the game world will now come into the broader commercial sphere once theyre needing adaptive characters in ar are you thinking of engineering tools that allow creators to create in the augmented world basically making a photoshop for the augmented world well we have shown a few demos of sort of taking a photoshop layer stack and then expanding it into 3d thats actually been shown publicly as one example in ar where were particularly excited at the moment is in 3d 3d design is still a very challenging space and we believe that its a worthwhile experiment to try to figure out if ar or immersive makes 3d design more spontaneous can you give me an example of 3d design just like applications literally a simple one would be laying out objects right so on a conventional screen youd sort of have a plan view and a side view and a perspective view and youd sort of be dragging it around with a mouse and if youre not careful it would go through the wall and all that whereas if you were really laying out objects say in a vr headset you could literally move your head to see a different viewpoint theyd be in stereo so youd have a sense of depth because youre already wearing the depth glasses right so it would be those sort of big gross motor move things around kind of skills seem much more spontaneous just like they are in the real world the frontier for us i think is whether that same medium can be used to do fine grained design tasks like very accurate constraints on say a cad model or something that may be better done on a desktop but it may just be a matter of inventing the right ui so were hopeful that because there will be this potential explosion of demand for 3d assets driven by ar and more real time animation on conventional screens that those tools will also help with or those devices will help with designing the content as well youve mentioned quite a few interesting sort of new ideas and at the same time theres old timers like me that are stuck in their old ways and are well i think im the old timer okay all right all right but the opposed all change at all costs yes when youre thinking about creating new interfaces do you feel the burden of just this giant user base that loves the current product so anything new you do any new idea comes at a cost that youll be resisted well i think if you have to trade off control for convenience then our existing user base would definitely be offended by that i think if there are some things where you have more convenience and just as much control that may be more welcome we do think about not breaking well known metaphors for things so things should sort of make sense photoshop has never been a static target its always been evolving and growing and to some extent theres been a lot of brilliant thought along the way of how it works today so we dont want to just throw all that out if theres a fundamental breakthrough like a single click is good enough to select an object rather than having to do lots of strokes that actually fits in quite nicely to the existing toolset either as an optional mode or as a starting point i think where were looking at radical simplicity where you could encapsulate an entire workflow with a much simpler ui then sometimes thats easier to do in the context of either a different device like a mobile device where the affordances are naturally different or in a tool thats targeted at a different workflow where its about spontaneity and velocity rather than precision and we have projects like rush which can let you do professional quality video editing for a certain class of media output that is targeted very differently in terms of users and the experience and ideally people would go if im feeling like doing premiere big project im doing a four part television series thats definitely a premiere thing but if i want to do something to show my recent vacation maybe ill just use rush because i can do it in the half an hour i have free at home rather than the four hours i need to do it at work and for the use cases which we can do well it really is much faster to get the same output but the more professional tools obviously have a much richer toolkit and more flexibility in what they can do and then at the same time with the flexibility and control i like this idea of smart defaults of using ai to coach you to like what google has im feeling lucky button or one button kind of gives you a pretty good set of settings and then thats almost an educational tool to show because sometimes when you have all this control youre not sure about the correlation between the different bars that control different elements of the image and so on and sometimes theres a degree of you dont know what the optimal is and then some things are sort of on demand like help right where im stuck i need to know what to look for im not quite sure what its called and something that was proactively making helpful suggestions or you could imagine a make a suggestion button where youd use all of that knowledge of workflows and everything to maybe suggest something to go and learn about or just to try or show the answer and maybe its not one intelligent default but its like a variety of defaults and then you go i like that one yeah yeah several options so back to poetry ah yes were going to interleave so first few lines of a recent poem of yours before i ask the next question this is about the smartphone today i left my phone at home and went down to the sea the sand was soft the ocean glass but i was still just me this is a poem about you leaving your phone behind and feeling quite liberated because of it so this is kind of a difficult topic and lets see if we can talk about it figure it out but so with the help of ai more and more we can create sort of versions of ourselves versions of reality that are in some ways more beautiful than actual reality and some of the creative ways that we can do that some of the creative effort there is part of creating this illusion so of course this is inevitable but how do you think we should adjust as human beings to live in this digital world thats partly artificial thats better than the world that we lived in a hundred years ago when you didnt have instagram and facebook versions of ourselves and the online oh this is sort of showing off better versions of ourselves were using the tooling of modifying the images or even with artificial intelligence ideas of deep fakes and creating adjusted or fake versions of ourselves and reality i think its an interesting question youre all sort of historical bent on this so i actually wonder if 18th century aristocrats who commissioned famous painters to paint portraits of them had portraits that were slightly nicer than they actually looked in practice so human desire to put your best foot forward has always been true i think its interesting you sort of framed it in two ways one is if we can imagine alternate realities and visualize them is that a good or bad thing in the old days you do it with storytelling and words and poetry which still resides sometimes on websites but weve become a very visual culture in particular in the 19th century were very much a text based culture people would read long tracks political speeches were very long nowadays everythings very kind of quick and visual and snappy i think it depends on how harmless your intent a lot of its about intent so if you have a somewhat flattering photo that you pick out of the photos that you have in your inbox to say this is what i look like its probably fine if someones going to judge you by how you look then theyll decide soon enough when they meet you whether the reality you know yeah right i think where it can be harmful is if people hold themselves up to an impossible standard which they then feel bad about themselves for not meeting i think that definitely can be an issue but i think the ability to imagine and visualize an alternate reality which sometimes you then go off and build later can be a wonderful thing too people can imagine architectural styles which they then you know have a startup make a fortune and then build a house that looks like their favorite video game is that a terrible thing i think i used to worry about exploration actually that part of the joy of going to the moon when i was a tiny child i remember it in grainy black and white was to know what it would look like when you got there and i think now we have such good graphics for visualizing the experience before it happens that i slightly worry that it may take the edge off actually wanting to go you know what i mean because weve seen it on tv we kind of oh you know by the time we finally get to mars well go yeah yeah so its mars thats what it looks like but then you know the outer exploration i mean i think pluto was a fantastic recent discovery where nobody had any idea what it looked like and it was just breathtakingly varied and beautiful so i think expanding the ability of the human toolkit to imagine and communicate on balance is a good thing i think there are abuses we definitely take them seriously and try to discourage them i think theres a parallel side where the public needs to know whats possible through events like this right so that you dont believe everything you read in print anymore and it may over time become true of images as well or you need multiple sets of evidence to really believe something rather than a single media asset so i think its a constantly evolving thing its been true forever theres a famous story about anne of cleves and henry viii where luckily for anne they didnt get married right so or they got married and broke up in it whats the story oh so holbein went and painted a picture and then henry viii wasnt pleased and you know history doesnt record whether anne was pleased but i think she was pleased not to be married more than a day or something so i mean this has gone on for a long time but i think its just a part of the magnification of human capability youve kind of built up an amazing research environment here research culture research lab and youve written that the secret to a thriving research lab is interns can you unpack that a little bit oh absolutely so a couple of reasons as you see looking at my personal history there are certain ideas you bond with at a certain stage of your career and you tend to keep revisiting them through time if youre lucky you pick one that doesnt just get solved in the next five years and then youre sort of out of luck so i think a constant influx of new people brings new ideas with it from the point of view of industrial research because a big part of what we do is really taking those ideas to the point where they can ship as very robust features you end up investing a lot in a particular idea and if youre not careful people can get too conservative in what they choose to do next knowing that the product teams will want it and interns let you explore the more fanciful or unproven ideas in a relatively lightweight way ideally leading to new publications for the intern and for the researcher and it gives you then a portfolio from which to draw which idea am i going to then try to take all the way through to being robust in the next year or two to ship so it sort of becomes part of the funnel its also a great way for us to identify future full time researchers many of our greatest researchers were former interns it builds a bridge to university departments so we can get to know and build an enduring relationship with the professors whom we often do academic give funds to as well as an acknowledgement of the value the interns add in their own collaborations so its sort of a virtuous cycle and then the long term legacy of a great research lab hopefully will be not only the people who stay but the ones who move through and then go off and carry that same model to other companies and so we believe strongly in industrial research and how it can complement academia and we hope that this model will continue to propagate and be invested in by other companies which makes it harder for us to recruit of course but thats a sign of success and a rising tide lifts all ships in that sense and wheres the idea born with the interns is there brainstorming is there discussions about you know like what where do the ideas come from yeah as im asking the question i realize how dumb it is but im hoping you have a better answer a question i ask at the beginning of every summer so what will happen is well send out a call for interns theyll well have a number of resumes come in people will contact the candidates talk to them about their interests theyll usually try to find some somebody who has a reasonably good match to what theyre already doing or just has a really interesting domain that theyve been pursuing in their phd and we think wed love to do one of those projects too and then the intern stays in touch with the mentor as we call them and then they come and at the end of two weeks they have to decide so theyll often have a general sense by the time they arrive and well have internal discussions about what are all the general ideas that were wanting to pursue to see whether two people have the same idea and maybe they should talk and all that but then once the intern actually arrives sometimes the idea goes linearly and sometimes it takes a giant left turn and we go that sounded good but when we thought about it theres this other project or its already been done and we found this paper we were scooped but we have this other great idea so its pretty pretty flexible at the beginning one of the questions for research labs is whos deciding what to do and then whos to blame if it goes wrong who gets the credit if it goes right and so in adobe we push the needle very much towards freedom of choice of projects by the researchers and the interns but then we reward people based on impact so if the projects ultimately end up impacting the products and having papers and so on and so your alternative model just to be clear is that you have one lab director who thinks hes a genius and tells everybody what to do takes all the credit if it goes well blames everybody else if it goes badly so we dont want that model and this helps new ideas percolate up the art of running such a lab is that there are strategic priorities for the company and there are areas where we do want to invest and pressing problems and so its a little bit of a trickle down and filter up meets in the middle and so you dont tell people you have to do x but you say x would be particularly appreciated this year and then people reinterpret x through the filter of things they want to do and theyre interested in and miraculously it usually comes together very well one thing that really helps is adobe has a really broad portfolio of products so if we have a good idea theres usually a product team that is intrigued or interested so it means we dont have to qualify things too much ahead of time once in a while the product teams sponsor extra intern because they have a particular problem that they really care about in which case its a little bit more we really need one of these and then we sort of say great i get an extra intern we find an intern who thinks thats a great problem but thats not the typical model thats sort of the icing on the cake as far as the budget is concerned and all of the above end up being important its really hard to predict at the beginning of the summer which we all have high hopes of all of the intern projects but ultimately some of them pay off and some of them sort of are a nice paper but dont turn into a feature others turn out not to be as novel as we thought but theyd be a great feature but not a paper and then others we make a little bit of progress and we realize how much we dont know and maybe we revisit that problem several years in a row until it finally we have a breakthrough and then it becomes more on track to impact a product jumping back to a big overall view of adobe research what are you looking forward to in 2019 and beyond what is you mentioned theres a giant suite of products a giant suite of ideas new interns a large team of researchers what do you think the future holds in terms of the technological breakthroughs technological breakthroughs especially ones that will make it into product will get to impact the world so i think the creative or the analytics assistants that we talked about where theyre constantly trying to figure out what youre trying to do and how can they be helpful and make useful suggestions is a really hot topic and its very unpredictable as to when itll be ready but im really looking forward to seeing how much progress we make against that i think some of the core technologies like generative adversarial networks are immensely promising and seeing how quickly those become practical for mainstream use cases at high resolution with really good quality is also exciting and they also have this sort of strange way of even the things they do oddly are odd in an interesting way so it can look like dreaming or something so thats fascinating i think internally we have a sensei platform which is a way in which were pulling our neural nets and other intelligence models into a central platform which can then be leveraged by multiple product teams at once so were in the middle of transitioning from once you have a good idea you pick a product team to work with and they sort of hand design it for that use case to a more sort of henry ford standard up in a standard way which can be accessed in a standard way which should mean that the time between a good idea and impacting our products will be greatly shortened and when one product has a good idea many of the other products can just leverage it too so its sort of an economy of scale so thats more about the how than the what but that combination of this sort of renaissance in ai theres a comparable one in graphics with real time ray tracing and other really exciting emerging technologies and when these all come together youll sort of basically be dancing with light right where youll have real time shadows reflections and as if its a real world in front of you but then with all these magical properties brought by ai where it sort of anticipates or modifies itself in ways that make sense based on how it understands the creative task youre trying to do thats a really exciting future for creative for myself to the creator so first of all i work in autonomous vehicles im a roboticist i love robots and i think you have a fascination with snakes both natural and artificial robots i share your fascination i mean their movement is beautiful adaptable the adaptability is fascinating there are i looked it up 2900 species of snakes in the world wow 875 venomous some are tiny some are huge i saw that theres one thats 25 feet in some cases so whats the most interesting thing that you connect with in terms of snakes both natural and artificial what was the connection with robotics ai and this particular form of a robot well it actually came out of my work in the 80s on computer animation where i started doing things like cloth simulation and other kind of soft body simulation and youd sort of drop it and it would bounce and then it would just sort of stop moving and i thought well what if you animate the spring lengths and simulate muscles and the simplest object i could do that for was an earthworm so i actually did a paper in 1988 called the motion dynamics of snakes and worms and i read the physiology literature on both how snakes and worms move and then did some of the early computer animation examples of that and so your interest in robotics came out of simulation and graphics when i moved from alias to apple we actually did a movie called her majestys secret serpent which is about a secret agent snake that parachutes in and captures a film canister from a satellite which tells you how old fashioned we were thinking back then sort of classic 1950s or 60s bond movie kind of thing and at the same time id always made radio controlled chips when i was a child and from scratch and i thought well how can it be to', 'the following is a conversation with rosalind picard shes a professor at mit director of the effective computing research group at the mit media lab and cofounder of two companies affectiva and empatica over two decades ago she launched a field of effective computing with her book of the same name this book described the importance of emotion in artificial and natural intelligence the vital role of emotional communication has to the relationship between people in general and human robot interaction i really enjoy talking with ros over so many topics including emotion ethics privacy wearable computing and her recent research in epilepsy and even love and meaning this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with rosalind picard more than 20 years ago youve coined the term effective computing and led a lot of research in this area since then as i understand the goal is to make the machine detect and interpret the emotional state of a human being and adapt the behavior of the machine based on the emotional state so how is your understanding of the problem space defined by effective computing changed in the past 24 years so its the scope the applications the challenges whats involved how has that evolved over the years yeah actually originally when i defined the term affective computing it was a bit broader than just recognizing and responding intelligently to human emotion although those are probably the two pieces that weve worked on the hardest the original concept also encompassed machines that would have mechanisms that functioned like human emotion does inside them it would be any computing that relates to arises from or deliberately influences human emotion so the human computer interaction part is the part that people tend to see like if im really ticked off at my computer and im scowling at it and im cursing at it and it just keeps acting smiling and happy like that little paperclip used to do dancing winking that kind of thing just makes you even more frustrated right and i thought that stupid thing needs to see my affect and if its gonna be intelligent which microsoft researchers had worked really hard on it actually had some of the most sophisticated ai in it at the time that things gonna actually be smart it needs to respond to me and you and we can send it very different signals so by the way just a quick interruption the clippy maybe its in word 95 98 i dont remember when it was born but many people do you find yourself with that reference that people recognize what youre talking about still to this point i dont expect the newest students to these days but ive mentioned it to a lot of audiences like how many of you know this clippy thing and still the majority of people seem to know it so clippy kind of looks at maybe natural language processing where you were typing and tries to help you complete i think i dont even remember what clippy was except annoying yeah some people actually liked it i would hear those stories you miss it well i miss the annoyance they felt like theres an element someone was there somebody was there and we were in it together and they were annoying its like a puppy that just doesnt get it they keep stripping up the couch kind of thing and in fact they could have done it smarter like a puppy if they had done like if when you yelled at it or cursed at it if it had put its little ears back in its tail down and shrugged off probably people would have wanted it back right but instead when you yelled at it what did it do it smiled it winked it danced right if somebody comes to my office and i yell at them they start smiling winking and dancing im like i never want to see you again so bill gates got a standing ovation when he said it was going away because people were so ticked it was so emotionally unintelligent right it was intelligent about whether you were writing a letter what kind of help you needed for that context it was completely unintelligent about hey if youre annoying your customer dont smile in their face when you do it so that kind of mismatch was something the developers just didnt think about and intelligence at the time was really all about math and language and chess and games problems that could be pretty well defined social emotional interaction is much more complex than chess or go or any of the games that people are trying to solve and in order to understand that required skills that most people in computer science actually were lacking personally well lets talk about computer science have things gotten better since the work since the message since youve really launched the field with a lot of research work in this space i still find as a person like yourself whos deeply passionate about human beings and yet am in computer science there still seems to be a lack of sorry to say empathy in as computer scientists yeah well or hasnt gotten better lets just say theres a lot more variety among computer scientists these days computer scientists are a much more diverse group today than they were 25 years ago and thats good we need all kinds of people to become computer scientists so that computer science reflects more what society needs and theres brilliance among every personality type so it need not be limited to people who prefer computers to other people how hard do you think it is your view of how difficult it is to recognize emotion or to create a deeply emotionally intelligent interaction has it gotten easier or harder as youve explored it further and how far away are we from cracking this if you think of the turing test solving the intelligence looking at the turing test for emotional intelligence i think it is as difficult as i thought it was gonna be i think my prediction of its difficulty is spot on i think the time estimates are always hard because theyre always a function of societys love and hate of a particular topic if society gets excited and you get thousands of researchers working on it for a certain application that application gets solved really quickly the general intelligence the computers complete lack of ability to have awareness of what its doing the fact that its not conscious the fact that theres no signs of it becoming conscious the fact that it doesnt read between the lines those kinds of things that we have to teach it explicitly what other people pick up implicitly we dont see that changing yet there arent breakthroughs yet that lead us to believe that thats gonna go any faster which means that its still gonna be kind of stuck with a lot of limitations where its probably only gonna do the right thing in very limited narrow prespecified contexts where we can prescribe pretty much whats gonna happen there so i dont see the its hard to predict a date because when people dont work on it its infinite when everybody works on it you get a nice piece of it well solved in a short amount of time i actually think theres a more important issue right now than the difficulty of it and thats causing some of us to put the brakes on a little bit usually were all just like step on the gas lets go faster this is causing us to pull back and put the brakes on and thats the way that some of this technology is being used in places like china right now and that worries me so deeply that its causing me to pull back myself on a lot of the things that we could be doing and try to get the community to think a little bit more about okay if were gonna go forward with that how can we do it in a way that puts in place safeguards that protects people so the technology were referring to is just when a computer senses the human being like the human face right so theres a lot of exciting things there like forming a deep connection with the human being so what are your worries how that could go wrong is it in terms of privacy is it in terms of other kinds of more subtle things but lets dig into privacy so here in the us if im watching a video of say a political leader and in the us were quite free as we all know to even criticize the president of the united states right here thats not a shocking thing it happens about every five seconds right but in china what happens if you criticize the leader of the government right and so people are very careful not to do that however what happens if youre simply watching a video and you make a facial expression that shows a little bit of skepticism right well and here were completely free to do that in fact were free to fly off the handle and say anything we want usually i mean there are some restrictions when the athlete does this as part of the national broadcast maybe the teams get a little unhappy about picking that forum to do it right but thats more a question of judgment we have these freedoms and in places that dont have those freedoms what if our technology can read your underlying affective state what if our technology can read it even noncontact what if our technology can read it without your prior consent and here in the us in my first company we started affectiva we have worked super hard to turn away money and opportunities that try to read peoples affect without their prior informed consent and even the software that is licensable you have to sign things saying you will only use it in certain ways which essentially is get peoples buy in right dont do this without people agreeing to it there are other countries where theyre not interested in peoples buy in theyre just gonna use it theyre gonna inflict it on you and if you dont like it you better not scowl in the direction of any censors so one let me just comment on a small tangent do you know with the idea of adversarial examples and deep fakes and so on what you bring up is actually in that one sense deep fakes provide a comforting protection that you can no longer really trust that the video of your face was legitimate and therefore you always have an escape clause if a government is trying if a stable balanced ethical government is trying to accuse you of something at least you have protection you can say it was fake news as is a popular term now yeah thats the general thinking of it we know how to go into the video and see for example your heart rate and respiration and whether or not theyve been tampered with and we also can put like fake heart rate and respiration in your video now too we decided we needed to do that after we developed a way to extract it we decided we also needed a way to jam it and so the fact that we took time to do that other step too that was time that i wasnt spending making the machine more affectively intelligent and theres a choice in how we spend our time which is now being swayed a little bit less by this goal and a little bit more like by concern about whats happening in society and what kind of future do we wanna build and as we step back and say okay we dont just build ai to build ai to make elon musk more money or to make amazon jeff bezos more money good gosh you know thats the wrong ethic why are we building it what is the point of building ai it used to be it was driven by researchers in academia to get papers published and to make a career for themselves and to do something cool right like cause maybe it could be done now we realize that this is enabling rich people to get vastly richer the poor are the divide is even larger and is that the kind of future that we want maybe we wanna think about maybe we wanna rethink ai maybe we wanna rethink the problems in society that are causing the greatest inequity and rethink how to build ai thats not about a general intelligence but thats about extending the intelligence and capability of the have nots so that we close these gaps in society do you hope that kind of stepping on the brake happens organically because i think still majority of the force behind ai is the desire to publish papers is to make money without thinking about the why do you hope it happens organically is there room for regulation yeah yeah yeah great questions i prefer the you know they talk about the carrot versus the stick i definitely prefer the carrot to the stick and you know in our free world we theres only so much stick right youre gonna find a way around it i generally think less regulation is better that said even though my position is classically carrot no stick no regulation i think we do need some regulations in this space i do think we need regulations around protecting people with their data that you own your data not amazon not google i would like to see people own their own data i would also like to see the regulations that we have right now around lie detection being extended to emotion recognition in general that right now you cant use a lie detector on an employee when youre on a candidate when youre interviewing them for a job i think similarly we need to put in place protection around reading peoples emotions without their consent and in certain cases like characterizing them for a job and other opportunities so im also i also think that when were reading emotion thats predictive around mental health that that should even though its not medical data that that should get the kinds of protections that our medical data gets what most people dont know yet is right now with your smartphone use and if youre wearing a sensor and you wanna learn about your stress and your sleep and your physical activity and how much youre using your phone and your social interaction all of that nonmedical data when we put it together with machine learning now called ai even though the founders of ai wouldnt have called it that that capability can not only tell that youre calm right now or that youre getting a little stressed but it can also predict how youre likely to be tomorrow if youre likely to be sick or healthy happy or sad stressed or calm especially when youre tracking data over time especially when were tracking a week of your data or more do you have an optimism towards you know a lot of people on our phones are worried about this camera thats looking at us for the most part on balance are you optimistic about the benefits that can be brought from that camera thats looking at billions of us or should we be more worried i think we should be a little bit more worried about whos looking at us and listening to us the device sitting on your countertop in your kitchen whether its you know alexa or google home or apple siri these devices want to listen while they say ostensibly to help us and i think there are great people in these companies who do want to help people let me not brand them all bad im a user of products from all of these companies im naming all the a companies alphabet apple amazon they are awfully big companies right they have incredible power and you know what if china were to buy them right and suddenly all of that data were not part of free america but all of that data were part of somebody who just wants to take over the world and you submit to them and guess what happens if you so much as smirk the wrong way when they say something that you dont like well they have reeducation camps right thats a nice word for them by the way they have a surplus of organs for people who have surgery these days they dont have an organ donation problem because they take your blood and they know youre a match and the doctors are on record of taking organs from people who are perfectly healthy and not prisoners theyre just simply not the favored ones of the government and you know thats a pretty freaky evil society and we can use the word evil there i was born in the soviet union i can certainly connect to the worry that youre expressing at the same time probably both you and i and you very much so you know theres an exciting possibility that you can have a deep connection with a machine yeah yeah right so those of us ive admitted students who say that they you know when you list like who do you most wish you could have lunch with or dinner with right and theyll write like i dont like people i just like computers and one of them said to me once when i had this party at my house i want you to know this is my only social event of the year my one social event of the year like okay now this is a brilliant machine learning person right and we need that kind of brilliance in machine learning and i love that computer science welcomes people who love people and people who are very awkward around people i love that this is a field that anybody could join we need all kinds of people and you dont need to be a social person im not trying to force people who dont like people to suddenly become social at the same time if most of the people building the ais of the future are the kind of people who dont like people weve got a little bit of a problem well hold on a second so let me push back on that so dont you think a large percentage of the world can you know theres loneliness there is a huge problem with loneliness thats growing and so theres a longing for connection do you if youre lonely youre part of a big and growing group yes so were in it together i guess if youre lonely join the group youre not alone youre not alone thats a good line but do you think theres you talked about some worry but do you think theres an exciting possibility that something like alexa and these kinds of tools can alleviate that loneliness in a way that other humans cant yeah yeah definitely i mean a great book can kind of alleviate loneliness because you just get sucked into this amazing story and you cant wait to go spend time with that character and theyre not a human character there is a human behind it but yeah it can be an incredibly delightful way to pass the hours and it can meet needs even you know i dont read those trashy romance books but somebody does right and what are they getting from this well probably some of that feeling of being there right being there in that social moment that romantic moment or connecting with somebody ive had a similar experience reading some science fiction books right and connecting with the character orson scott card you know just amazing writing and enders game and speaker for the dead terrible title but those kind of books that pull you into a character and you feel like youre you feel very social its very connected even though its not responding to you and a computer of course can respond to you so it can deepen it right you can have a very deep connection much more than the movie her you know plays up right well much more i mean movie her is already a pretty deep connection right well but its just a movie right its scripted its just you know but i mean like there can be a real interaction where the character can learn and you can learn you could imagine it not just being you and one character you could imagine a group of characters you can imagine a group of people and characters human and ai connecting where maybe a few people cant sort of be friends with everybody but the few people and their ais can befriend more people there can be an extended human intelligence in there where each human can connect with more people that way but its still very limited but there are just what i mean is there are many more possibilities than whats in that movie so theres a tension here so one you expressed a really serious concern about privacy about how governments can misuse the information and theres the possibility of this connection so lets look at alexa so personal assistance for the most part as far as im aware they ignore your emotion they ignore even the context or the existence of you the intricate beautiful complex aspects of who you are except maybe aspects of your voice that help it recognize for speech recognition do you think they should move towards trying to understand your emotion all of these companies are very interested in understanding human emotion they want more people are telling siri every day they want to kill themselves apple wants to know the difference between if a person is really suicidal versus if a person is just kind of fooling around with siri right the words may be the same the tone of voice and what surrounds those words is pivotal to understand if they should respond in a very serious way bring help to that person or if they should kind of jokingly tease back ah you just want to sell me for something else right like how do you respond when somebody says that well you do want to err on the side of being careful and taking it seriously people want to know if the person is happy or stressed in part well so let me give you an altruistic reason and a business profit motivated reason and there are people in companies that operate on both principles the altruistic people really care about their customers and really care about helping you feel a little better at the end of the day and it would just make those people happy if they knew that they made your life better if you came home stressed and after talking with their product you felt better there are other people who maybe have studied the way affect affects decision making and prices people pay and they know i dont know if i should tell you like the work of jen lerner on heartstrings and purse strings you know if we manipulate you into a slightly sadder mood youll pay more right youll pay more to change your situation youll pay more for something you dont even need to make yourself feel better so you know if they sound a little sad maybe i dont want to cheer them up maybe first i want to help them get something a little shopping therapy right that helps them which is really difficult for a company thats primarily funded on advertisement so theyre encouraged to get you to offer you products or amazon thats primarily funded on you buying things from their store so i think we should be you know maybe we need regulation in the future to put a little bit of a wall between these agents that have access to our emotion and agents that want to sell us stuff maybe there needs to be a little bit more of a firewall in between those so maybe digging in a little bit on the interaction with alexa you mentioned of course a really serious concern about like recognizing emotion if somebody is speaking of suicide or depression and so on but what about the actual interaction itself do you think so if i you know you mentioned clippy and being annoying what is the objective function were trying to optimize is it minimize annoyingness or minimize or maximize happiness or if we look at human to human relations i think that push and pull the tension the dance you know the annoying the flaws thats what makes it fun so is there a room for like what is the objective function there are times when you want to have a little push and pull i think of kids sparring right you know i see my sons and they one of them wants to provoke the other to be upset and thats fun and its actually healthy to learn where your limits are to learn how to self regulate you can imagine a game where its trying to make you mad and youre trying to show self control and so if were doing a ai human interaction thats helping build resilience and self control whether its to learn how to not be a bully or how to turn the other cheek or how to deal with an abusive person in your life then you might need an ai that pushes your buttons right but in general do you want an ai that pushes your buttons probably depends on your personality i dont i want one thats respectful that is there to serve me and that is there to extend my ability to do things im not looking for a rival im looking for a helper and thats the kind of ai id put my money on your sense is for the majority of people in the world in order to have a rich experience thats what theyre looking for as well so theyre not looking if you look at the movie her spoiler alert i believe the program that the woman in the movie her leaves the person for somebody else says they dont wanna be dating anymore right like do you your sense is if alexa said you know what im actually had enough of you for a while so im gonna shut myself off you dont see that as id say youre trash cause i paid for you right you weve got to remember and this is where this blending human ai as if were equals is really deceptive because ai is something at the end of the day that my students and i are making in the lab and were choosing what its allowed to say when its allowed to speak what its allowed to listen to what its allowed to act on given the inputs that we choose to expose it to what outputs its allowed to have its all something made by a human and if we wanna make something that makes our lives miserable fine i wouldnt invest in it as a business unless its just there for self regulation training but i think we need to think about what kind of future we want and actually your question i really like the what is the objective function is it to calm people down sometimes is it to always make people happy and calm them down well there was a book about that right the brave new world make everybody happy take your soma if youre unhappy take your happy pill and if you refuse to take your happy pill well well threaten you by sending you to iceland to live there i lived in iceland three years its a great place dont take your soma then go to iceland a little tv commercial there now i was a child there for a few years its a wonderful place so that part of the book never scared me but really like do we want ai to manipulate us into submission into making us happy well if you are a you know like a power obsessed sick dictator individual who only wants to control other people to get your jollies in life then yeah you wanna use ai to extend your power and your scale to force people into submission if you believe that the human race is better off being given freedom and the opportunity to do things that might surprise you then you wanna use ai to extend peoples ability to build you wanna build ai that extends human intelligence that empowers the weak and helps balance the power between the weak and the strong not that gives more power to the strong so in this process of empowering people and sensing people what is your sense on emotion in terms of recognizing emotion the difference between emotion that is shown and emotion that is felt so yeah emotion that is expressed on the surface through your face your body and various other things and whats actually going on deep inside on the biological level on the neuroscience level or some kind of cognitive level yeah yeah whoa no easy questions here well yeah im sure theres no definitive answer but whats your sense how far can we get by just looking at the face were very limited when we just look at the face but we can get further than most people think we can get people think hey i have a great poker face therefore all youre ever gonna get from me is neutral well thats naive we can read with the ordinary camera on your laptop or on your phone we can read from a neutral face if your heart is racing we can read from a neutral face if your breathing is becoming irregular and showing signs of stress we can read under some conditions that maybe i wont give you details on how your heart rate variability power is changing that could be a sign of stress even when your heart rate is not necessarily accelerating so sorry from physio sensors or from the face from the color changes that you cannot even see but the camera can see thats amazing so you can get a lot of signal but so we get things people cant see using a regular camera and from that we can tell things about your stress so if you were just sitting there with a blank face thinking nobody can read my emotion well youre wrong right so thats really interesting but thats from sort of visual information from the face thats almost like cheating your way to the physiological state of the body by being very clever with what you can do with vision with signal processing with signal processing so thats really impressive but if you just look at the stuff we humans can see the poker the smile the smirks the subtle all the facial actions so then you can hide that on your face for a limited amount of time now if youre just going in for a brief interview and youre hiding it thats pretty easy for most people if you are however surveilled constantly everywhere you go then its gonna say gee you know lex used to smile a lot and now im not seeing so many smiles and roz used to laugh a lot and smile a lot very spontaneously and now im only seeing these not so spontaneous looking smiles and only when shes asked these questions you know thats somethings changed here probably not getting enough sleep we could look at that too so now i have to be a little careful too when i say we you think we cant read your emotion and we can its not that binary what were reading is more some physiological changes that relate to your activation now that doesnt mean that we know everything about how you feel in fact we still know very little about how you feel your thoughts are still private your nuanced feelings are still completely private we cant read any of that so theres some relief that we cant read that even brain imaging cant read that wearables cant read that however as we read your body state changes and we know whats going on in your environment and we look at patterns of those over time we can start to make some inferences about what you might be feeling and that is where its not just the momentary feeling but its more your stance toward things and that could actually be a little bit more scary with certain kinds of governmental control freak people who want to know more about are you on their team or are you not and getting that information through over time so youre saying theres a lot of signal by looking at the change over time yeah so youve done a lot of exciting work both in computer vision and physiological sense like wearables what do you think is the best modality for whats the best window into the emotional soul is it the face is it the voice depends what you want to know it depends what you want to know it depends what you want to know everything is informative everything we do is informative so for health and wellbeing and things like that do you find the wearable physiotechnical measuring physiological signals is the best for health based stuff so here im going to answer empirically with data and studies weve been doing weve been doing studies now these are currently running with lots of different kinds of people but where weve published data and i can speak publicly to it the data are limited right now to new england college students so thats a small group among new england college students when they are wearing a wearable like the empathic embrace here thats measuring skin conductance movement temperature and when they are using a smartphone that is collecting their time of day of when theyre texting who theyre texting their movement around it their gps the weather information based upon their location and when its using machine learning and putting all of that together and looking not just at right now but looking at your rhythm of behaviors over about a week when we look at that we are very accurate at forecasting tomorrows stress mood and happy sad mood and health and when we look at which pieces of that are most useful first of all if you have all the pieces you get the best results if you have only the wearable you get the next best results and thats still better than 80 accurate at forecasting tomorrows levels isnt that exciting because the wearable stuff with physiological information it feels like it violates privacy less than the noncontact face based methods yeah its interesting i think what people sometimes dont its funny in the early days people would say oh wearing something or giving blood is invasive right whereas a camera is less invasive because its not touching you i think on the contrary the things that are not touching you are maybe the scariest because you dont know when theyre on or off and you dont know whos behind it right a wearable depending upon whats happening to the data on it if its just stored locally or if its streaming and what it is being attached to in a sense you have the most control over it because its also very easy to just take it off right now its not sensing me so if im uncomfortable with what its sensing now im free right if im comfortable with what its sensing then and i happen to know everything about this one and what its doing with it so im quite comfortable with it then i have control im comfortable control is one of the biggest factors for an individual in reducing their stress if i have control over it if i know all there is to know about it then my stress is a lot lower and im making an informed choice about whether to wear it or not or when to wear it or not i wanna wear it sometimes maybe not others right so that control yeah im with you that control even if yeah the ability to turn it off that is a really important thing its huge and we need to maybe if theres regulations maybe thats number one to protect is peoples ability to its easy to opt out as to opt in right so youve studied a bit of neuroscience as well how have looking at our own minds sort of the biological stuff or the neurobiological the neuroscience to get the signals in our brain helped you understand the problem and the approach of effective computing so originally i was a computer architect and i was building hardware and computer designs and i wanted to build ones that worked like the brain so ive been studying the brain as long as ive been studying how to build computers have you figured out anything yet very little its so amazing you know they used to think like oh if you remove this chunk of the brain and you find this function goes away well thats the part of the brain that did it and then later they realized if you remove this other chunk of the brain that function comes back and oh no we really dont understand it brains are so interesting and changing all the time and able to change in ways that will probably continue to surprise us when we were measuring stress you may know the story where we found an unusual big skin conductance pattern on one wrist in one of our kids with autism and in trying to figure out how on earth you could be stressed on one wrist and not the other like how can you get sweaty on one wrist right when you get stressed with that sympathetic fight or flight response like you kind of should like sweat more in some places than others but not more on one wrist than the other that didnt make any sense we learned that what had actually happened was a part of his brain had unusual electrical activity and that caused an unusually large sweat response on one wrist and not the other and since then weve learned that seizures cause this unusual electrical activity and depending where the seizure is if its in one place and its staying there you can have a big electrical response we can pick up with a wearable at one part of the body you can also have a seizure that spreads over the whole brain generalized grand mal seizure and that response spreads and we can pick it up pretty much anywhere as we learned this and then later built embrace thats now fda cleared for seizure detection we have also built relationships with some of the most amazing doctors in the world who not only help people with unusual brain activity or epilepsy but some of them are also surgeons and theyre going in and theyre implanting electrodes not just to momentarily read the strange patterns of brain activity that wed like to see return to normal but also to read out continuously whats happening in some of these deep regions of the brain during most of life when these patients are not seizing most of the time theyre not seizing most of the time theyre fine and so we are now working on mapping those deep brain regions that you cant even usually get with eeg scalp electrodes because the changes deep inside dont reach the surface but interesting when some of those regions are activated we see a big skin conductance response who would have thunk it right like nothing here but something here in fact right after seizures that we think are the most dangerous ones that precede whats called sudep sudden unexpected death and epilepsy theres a period where the brainwaves go flat and it looks like the persons brain has stopped but it hasnt the activity has gone deep into a region that can make the cortical activity look flat like a quick shutdown signal here it can unfortunately cause breathing to stop if it progresses long enough before that happens we see a big skin conductance response in the data that we have the longer this flattening the bigger our response here so we have been trying to learn you know initially like why are we getting a big response here when theres nothing here well it turns out theres something much deeper so we can now go inside the brains of some of these individuals fabulous people who usually arent seizing and get this data and start to map it so thats the active research that were doing right now with top medical partners so this wearable sensor thats looking at skin conductance can capture sort of the ripples of the complexity of whats going on in our brain so this little device you have a hope that you can start to get the signal from the interesting things happening in the brain yeah weve already published the strong correlations between the size of this response and the flattening that happens afterwards and unfortunately also in a real sudep case where the patient died because the well we dont know why we dont know if somebody was there it would have definitely prevented it but we know that most sudeps happen when the persons alone and in this case a sudep is an acronym s u d e p and it stands for the number two cause of years of life lost actually among all neurological disorders stroke is number one sudep is number two but most people havent heard of it actually ill plug my ted talk its on the front page of ted right now that talks about this and we hope to change that i hope everybody whos heard of sids and stroke will now hear of sudep because we think in most cases its preventable if people take their meds and arent alone when they have a seizure not guaranteed to be preventable there are some exceptions but we think most cases probably are so you had this embrace now in the version two wristband right for epilepsy management thats the one thats fda approved yes which is kind of a clear fda cleared they say sorry no its okay it essentially means its approved for marketing got it just a side note how difficult is that to do its essentially getting fda approval for computer science technology its so agonizing its much harder than publishing multiple papers in top medical journals yeah weve published peer reviewed top medical journal neurology best results and thats not good enough for the fda is that system so if we look at the peer review of medical journals theres flaws theres strengths is the fda approval process how does it compare to the peer review process does it have the strength ill take peer review over fda any day but is that a good thing is that a good thing for fda youre saying does it stop some amazing technology from getting through yeah it does the fda performs a very important good role in keeping people safe they keep things they put you through tons of safety testing and thats wonderful and thats great im all in favor of the safety testing but sometimes they put you through additional testing that they dont have to explain why they put you through it and you dont understand why youre going through it and it doesnt make sense and thats very frustrating and maybe they have really good reasons and they just would it would do people a service to articulate those reasons be more transparent be more transparent so as part of empatica you have sensors so what kind of problems can we crack what kind of things from seizures to autism to i think ive heard you mentioned depression what kind of things can we alleviate can we detect whats your hope of what how we can make the world a better place with this wearable tech i would really like to see my fellow brilliant researchers step back and say what are the really hard problems that we dont know how to solve that come from people maybe we dont even see in our normal life because theyre living in the poor places theyre stuck on the bus they cant even afford the uber or the lyft or the data plan or all these other wonderful things we have that we keep improving on meanwhile theres all these folks left behind in the world and theyre struggling with horrible diseases with depression with epilepsy with diabetes with just awful stuff that maybe a little more time and attention hanging out with them and learning what are their challenges in life what are their needs how do we help them have job skills how do we help them have a hope and a future and a chance to have the great life that so many of us building technology have and then how would that reshape the kinds of ai that we build how would that reshape the new apps that we build or the maybe we need to focus on how to make things more low cost and green instead of thousand dollar phones i mean come on why cant we be thinking more about things that do more with less for these folks quality of life is not related to the cost of your phone its not something that its been shown that what about 75000 of income and happiness is the same okay however i can tell you you get a lot of happiness from helping other people you get a lot more than 75000 buys so how do we connect up the people who have real needs with the people who have the ability to build the future and build the kind of future that truly improves the lives of all the people that are currently being left behind so let me return just briefly on a point maybe in the movie her so do you think if we look farther into the future you said so much of the benefit from making our technology more empathetic to us human beings would make them better tools empower us make our lives better well if we look farther into the future do you think well ever create an ai system that we can fall in love with that we can fall in love with and loves us back on a level that is similar to human to human interaction like in the movie her or beyond i think we can simulate it in ways that could you know sustain engagement for a while would it be as good as another person i dont think so if youre used to like good people now if youve just grown up with nothing but abuse and you cant stand human beings can we do something that helps you there that gives you something through a machine yeah but thats pretty low bar right if youve only encountered pretty awful people if youve encountered wonderful amazing people were nowhere near building anything like that and i would not bet on building it i would bet instead on building the kinds of ai that helps kind of raise all boats that helps all people be better people helps all people figure out if theyre getting sick tomorrow and helps give them what they need to stay well tomorrow thats the kind of ai i wanna build that improves human lives not the kind of ai that just walks on the tonight show and people go wow look how smart that is really and then it goes back in a box you know so on that point if we continue looking a little bit into the future do you think an ai thats empathetic and does improve our lives need to have a physical presence a body and even let me cautiously say the c word consciousness and even fear of mortality so some of those human characteristics do you think it needs to have those aspects or can it remain simply a machine learning tool that learns from data of behavior that learns to make us based on previous patterns feel better or does it need those elements of consciousness it depends on your goals if youre making a movie it needs a body it needs a gorgeous body it needs to act like it has consciousness it needs to act like it has emotion right because thats what sells thats whats gonna get me to show up and enjoy the movie okay in real life does it need all that well if youve read orson scott card enders game speaker of the dead it could just be like a little voice in your earring right and you could have an intimate relationship and it could get to know you and it doesnt need to be a robot but that doesnt make this compelling of a movie right i mean we already think its kind of weird when a guy looks like hes talking to himself on the train even though its earbuds so we have these embodied is more powerful embodied when you compare interactions with an embodied robot versus a video of a robot versus no robot the robot is more engaging the robot gets our attention more the robot when you walk in your house is more likely to get you to remember to do the things that you asked it to do because its kind of got a physical presence you can avoid it if you dont like it it could see youre avoiding it theres a lot of power to being embodied there will be embodied ais they have great power and opportunity and potential there will also be ais that arent embodied that just are little software assistants that help us with different things that may get to know things about us will they be conscious there will be attempts to program them to make them appear to be conscious we can already write programs that make it look like oh what do you mean of course im aware that youre there right i mean its trivial to say stuff like that its easy to fool people but does it actually have conscious experience like we do nobody has a clue how to do that yet that seems to be something that is beyond what any of us knows how to build now will it have to have that i think you can get pretty far with a lot of stuff without it but will we accord it rights well thats more a political game than it is a question of real consciousness yeah can you go to jail for turning off alexa is the question for an election maybe a few decades from now well sophia robots already been given rights as a citizen in saudi arabia right even before women have full rights then the robot was still put back in the box to be shipped to the next place where it would get a paid appearance right yeah its dark and almost comedic if not absurd so ive heard you speak about your journey in finding faith sure and how you discovered some wisdoms about life and beyond from reading the bible and ive also heard you say that you said scientists too often assume that nothing exists beyond what can be currently measured yeah materialism materialism and scientism yeah so in some sense this assumption enables the near term scientific method assuming that we can uncover the mysteries of this world by the mechanisms of measurement that we currently have but we easily forget that weve made this assumption so what do you think we miss out on by making that assumption its fine to limit the scientific method to things we can measure and reason about and reproduce thats fine i think we have to recognize that sometimes we scientists also believe in things that happen historically like i believe the holocaust happened i cant prove events from past history scientifically you prove them with historical evidence right with the impact they had on people with eyewitness testimony and things like that so a good thinker recognizes that science is one of many ways to get knowledge its not the only way and theres been some really bad philosophy and bad thinking recently you can call it scientism where people say science is the only way to get to truth and its not it just isnt there are other ways that work also like knowledge of love with someone you dont prove your love through science right so history philosophy love a lot of other things in life show us that theres more ways to gain knowledge and truth if youre willing to believe there is such a thing and i believe there is than science i do i am a scientist however and in my science i do limit my science to the things that the scientific method can do but i recognize that its myopic to say that thats all there is right theres just like you listed theres all the why questions and really we know if were being honest with ourselves the percent of what we really know is basically zero relative to the full mystery of the measure theory a set of measure zero if i have a finite amount of knowledge which i do so you said that you believe in truth so let me ask that old question what do you think this thing is all about whats the life on earth life the universe and everything and everything whats the meaning i cant quote douglas adams 42 its my favorite number by the way thats my street address my husband and i guessed the exact same number for our house we got to pick it and theres a reason we picked 42 yeah so is it just 42 or is there do you have other words that you can put around it well i think theres a grand adventure and i think this life is a part of it i think theres a lot more to it than meets the eye and the heart and the mind and the soul here i think we see but through a glass dimly in this life we see only a part of all there is to know if people havent read the bible they should if they consider themselves educated and you could read proverbs and find tremendous wisdom in there that cannot be scientifically proven but when you read it theres something in you like a musician knows when the instruments played right and its beautiful theres something in you that comes alive and knows that theres a truth there that its like your strings are being plucked by the master instead of by me right playing when i pluck it but probably when you play it sounds spectacular right and when you encounter those truths theres something in you that sings and knows that there is more than what i can prove mathematically or program a computer to do dont get me wrong the math is gorgeous the computer programming can be brilliant its inspiring right we wanna do more none of this squashes my desire to do science or to get knowledge through science im not dissing the science at all i grow even more in awe of what the science can do because im more in awe of all there is we dont know and really at the heart of science you have to have a belief that theres truth that theres something greater to be discovered and some scientists may not wanna use the faith word but its faith that drives us to do science its faith that there is truth that theres something to know that we dont know that its worth knowing that its worth working hard and that there is meaning that there is such a thing as meaning which by the way science cant prove either we have to kind of start with some assumptions that theres things like truth and meaning and these are really questions philosophers own right this is their space of philosophers and theologians at some level so these are things science when people claim that science will tell you all truth theres a name for that its its own kind of faith its scientism and its very myopic yeah theres a much bigger world out there to be explored in ways that science may not at least for now allow us to explore yeah and theres meaning and purpose and hope and joy and love and all these awesome things that make it all worthwhile too i dont think theres a better way to end it roz thank you so much for talking today thanks lex what a pleasure great questions', 'the following is a conversation with jeff hawkins hes the founder of the redwood center for theoretical neuroscience in 2002 and numenta in 2005 in his 2004 book titled on intelligence and in the research before and after he and his team have worked to reverse engineer the neural cortex and propose artificial intelligence architectures approaches and ideas that are inspired by the human brain these ideas include hierarchical tupperware memory htm from 2004 and new work the thousand brains theory of intelligence from 2017 18 and 19 jeffs ideas have been an inspiration to many who have looked for progress beyond the current machine learning approaches but they have also received criticism for lacking a body of empirical evidence supporting the models this is always a challenge when seeking more than small incremental steps forward in ai jeff is a brilliant mind and many of the ideas he has developed and aggregated from neuroscience are worth understanding and thinking about there are limits to deep learning as it is currently defined forward progress in ai is shrouded in mystery my hope is that conversations like this can help provide an inspiring spark for new ideas this is the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at lex friedman spelled f r i d and now heres my conversation with jeff hawkins are you more interested in understanding the human brain or in creating artificial systems that have many of the same qualities but dont necessarily require that you actually understand the underpinning workings of our mind so theres a clear answer to that question my primary interest is understanding the human brain no question about it but i also firmly believe that we will not be able to create fully intelligent machines until we understand how the human brain works so i dont see those as separate problems i think theres limits to what can be done with machine intelligence if you dont understand the principles by which the brain works and so i actually believe that studying the brain is actually the fastest way to get to machine intelligence and within that let me ask the impossible question how do you not define but at least think about what it means to be intelligent so i didnt try to answer that question first we said lets just talk about how the brain works and lets figure out how certain parts of the brain mostly the neocortex but some other parts too the parts of the brain most associated with intelligence and lets discover the principles by how they work because intelligence isnt just like some mechanism and its not just some capabilities its like okay we dont even know where to begin on this stuff and so now that weve made a lot of progress on this after weve made a lot of progress on how the neocortex works and we can talk about that i now have a very good idea whats gonna be required to make intelligent machines i can tell you today some of the things are gonna be necessary i believe to create intelligent machines well so well get there well get to the neocortex and some of the theories of how the whole thing works and youre saying as we understand more and more about the neocortex about our own human mind well be able to start to more specifically define what it means to be intelligent its not useful to really talk about that until i dont know if its not useful look theres a long history of ai as you know and theres been different approaches taken to it and who knows maybe theyre all useful so the good old fashioned ai the expert systems the current convolutional neural networks they all have their utility they all have a value in the world but i would think almost everyone agree that none of them are really intelligent in a sort of a deep way that humans are and so its just the question of how do you get from where those systems were or are today to where a lot of people think were gonna go and theres a big big gap there a huge gap and i think the quickest way of bridging that gap is to figure out how the brain does that and then we can sit back and look and say oh which of these principles that the brain works on are necessary and which ones are not clearly we dont have to build this in and intelligent machines arent gonna be built out of organic living cells but theres a lot of stuff that goes on the brain thats gonna be necessary so let me ask maybe before we get into the fun details let me ask maybe a depressing or a difficult question do you think its possible that we will never be able to understand how our brain works that maybe theres aspects to the human mind like we ourselves cannot introspectively get to the core that theres a wall you eventually hit yeah i dont believe thats the case i have never believed thats the case theres not been a single thing humans have ever put their minds to that weve said oh we reached the wall we cant go any further its just people keep saying that people used to believe that about life alain vital right theres like whats the difference between living matter and nonliving matter something special that we never understand we no longer think that so theres no historical evidence that suggests this is the case and i just never even consider thats a possibility i would also say today we understand so much about the neocortex weve made tremendous progress in the last few years that i no longer think of it as an open question the answers are very clear to me the pieces we dont know are clear to me but the framework is all there and its like oh okay were gonna be able to do this this is not a problem anymore just takes time and effort but theres no mystery a big mystery anymore so then lets get into it for people like myself who are not very well versed in the human brain except my own can you describe to me at the highest level what are the different parts of the human brain and then zooming in on the neocortex the parts of the neocortex and so on a quick overview yeah sure the human brain we can divide it roughly into two parts theres the old parts lots of pieces and then theres the new part the new part is the neocortex its new because it didnt exist before mammals the only mammals have a neocortex and in humans in primates its very large in the human brain the neocortex occupies about 70 to 75 of the volume of the brain its huge and the old parts of the brain are theres lots of pieces there theres the spinal cord and theres the brain stem and the cerebellum and the different parts of the basal ganglia and so on in the old parts of the brain you have the autonomic regulation like breathing and heart rate you have basic behaviors so like walking and running are controlled by the old parts of the brain all the emotional centers of the brain are in the old part of the brain so when you feel anger or hungry lust or things like that those are all in the old parts of the brain and we associate with the neocortex all the things we think about as sort of high level perception and cognitive functions anything from seeing and hearing and touching things to language to mathematics and engineering and science and so on those are all associated with the neocortex and theyre certainly correlated our abilities in those regards are correlated with the relative size of our neocortex compared to other mammals so thats like the rough division and you obviously cant understand the neocortex completely isolated but you can understand a lot of it with just a few interfaces to the old parts of the brain and so it gives you a system to study the other remarkable thing about the neocortex compared to the old parts of the brain is the neocortex is extremely uniform its not visibly or anatomically its very i always like to say its like the size of a dinner napkin about two and a half millimeters thick and it looks remarkably the same everywhere everywhere you look in that two and a half millimeters is this detailed architecture and it looks remarkably the same everywhere and thats across species a mouse versus a cat and a dog and a human where if you look at the old parts of the brain theres lots of little pieces do specific things so its like the old parts of our brain evolved like this is the part that controls heart rate and this is the part that controls this and this is this kind of thing and thats this kind of thing and these evolved for eons a long long time and they have their specific functions and all of a sudden mammals come along and they got this thing called the neocortex and it got large by just replicating the same thing over and over and over again this is like wow this is incredible so all the evidence we have and this is an idea that was first articulated in a very cogent and beautiful argument by a guy named vernon malcastle in 1978 i think it was that the neocortex all works on the same principle so language hearing touch vision engineering all these things are basically underlying are all built on the same computational substrate theyre really all the same problem so the low level of the building blocks all look similar yeah and theyre not even that low level were not talking about like neurons were talking about this very complex circuit that exists throughout the neocortex its remarkably similar its like yes you see variations of it here and there more of the cell less and less and so on but what malcastle argued was he says you know if you take a section of neocortex why is one a visual area and one is a auditory area or why is and his answer was its because one is connected to eyes and one is connected to ears literally you mean just its most closest in terms of number of connections to the sensor literally literally if you took the optic nerve and attached it to a different part of the neocortex that part would become a visual region this actually this experiment was actually done by merkankasur in developing i think it was lemurs i cant remember what it was some animal and theres a lot of evidence to this you know if you take a blind person a person whos born blind at birth theyre born with a visual neocortex it doesnt may not get any input from the eyes because of some congenital defect or something and that region becomes does something else it picks up another task so and its so its this very complex thing its not like oh theyre all built on neurons no theyre all built in this very complex circuit and somehow that circuit underlies everything and so this is the its called the common cortical algorithm if you will some scientists just find it hard to believe and they just i cant believe thats true but the evidence is overwhelming in this case and so a large part of what it means to figure out how the brain creates intelligence and what is intelligence in the brain is to understand what that circuit does if you can figure out what that circuit does as amazing as it is then you can then you understand what all these other cognitive functions are so if you were to sort of put neocortex outside of your book on intelligence you look if you wrote a giant tome a textbook on the neocortex and you look maybe a couple of centuries from now how much of what we know now would still be accurate two centuries from now so how close are we in terms of understanding i have to speak from my own particular experience here so i run a small research lab here its like any other research lab im sort of the principal investigator theres actually two of us and theres a bunch of other people and this is what we do we study the neocortex and we publish our results and so on so about three years ago we had a real breakthrough in this field just tremendous breakthrough weve now published i think three papers on it and so i have a pretty good understanding of all the pieces and what were missing i would say that almost all the empirical data weve collected about the brain which is enormous if you dont know the neuroscience literature its just incredibly big and its for the most part all correct its facts and experimental results and measurements and all kinds of stuff but none of that has been really assimilated into a theoretical framework its data without in the language of thomas kuhn the historian would be a sort of a pre paradigm science lots of data but no way to fit it together i think almost all of thats correct theres just gonna be some mistakes in there and for the most part there arent really good cogent theories about it how to put it together its not like we have two or three competing good theories which ones are right and which ones are wrong its like nah people are just scratching their heads some people have given up on trying to figure out what the whole thing does in fact theres very very few labs that we do that focus really on theory and all this unassimilated data and trying to explain it so its not like weve got it wrong its just that we havent got it at all so its really i would say pretty early days in terms of understanding the fundamental theorys forces of the way our mind works i dont think so i would have said thats true five years ago so as i said we had some really big breakthroughs on this recently and we started publishing papers on this so well get to that but so i dont think its im an optimist and from where i sit today most people would disagree with this but from where i sit today from what i know its not super early days anymore we are the way these things go is its not a linear path right you dont just start accumulating and get better and better and better no all this stuff youve collected none of it makes sense all these different things are just sort of around and then youre gonna have some breaking points where all of a sudden oh my god now we got it right thats how it goes in science and i personally feel like we passed that little thing about a couple of years ago all that big thing a couple of years ago so we can talk about that time will tell if im right but i feel very confident about it thats why im willing to say it on tape like this at least very optimistic so lets before those few years ago lets take a step back to htm the hierarchical temporal memory theory which you first proposed on intelligence and went through a few different generations can you describe what it is how it evolved through the three generations since you first put it on paper yeah so one of the things that neuroscientists just sort of missed for many many years and especially people who were thinking about theory was the nature of time in the brain brains process information through time the information coming into the brain is constantly changing the patterns from my speech right now if you were listening to it at normal speed would be changing on your ears about every 10 milliseconds or so youd have a change this constant flow when you look at the world your eyes are moving constantly three to five times a second and the inputs completely changing if i were to touch something like a coffee cup as i move my fingers the input changes so this idea that the brain works on time changing patterns is almost completely or was almost completely missing from a lot of the basic theories like fears of vision and so on its like oh no were gonna put this image in front of you and flash it and say what is it convolutional neural networks work that way today right classify this picture but thats not what vision is like vision is this sort of crazy time based pattern thats going all over the place and so is touch and so is hearing so the first part of hierarchical temporal memory was the temporal part its to say you wont understand the brain nor will you understand intelligent machines unless youre dealing with time based patterns the second thing was the memory component of it was is to say that we arent just processing input we learn a model of the world and the memory stands for that model the point of the brain the part of the neocortex it learns a model of the world we have to store things our experiences in a form that leads to a model of the world so we can move around the world we can pick things up and do things and navigate and know how its going on so thats what the memory referred to and many people just they were thinking about like certain processes without memory at all theyre just like processing things and then finally the hierarchical component was a reflection to that the neocortex although its this uniform sheet of cells different parts of it project to other parts which project to other parts and there is a sort of rough hierarchy in terms of that so the hierarchical temporal memory is just saying look we should be thinking about the brain as time based model memory based and hierarchical processing and that was a placeholder for a bunch of components that we would then plug into that we still believe all those things i just said but we now know so much more that im stopping to use the word hierarchical temporal memory yet because its insufficient to capture the stuff we know so again its not incorrect but its i now know more and i would rather describe it more accurately yeah so youre basically we could think of htm as emphasizing that theres three aspects of intelligence that are important to think about whatever the eventual theory it converges to so in terms of time how do you think of nature of time across different time scales so you mentioned things changing sensory inputs changing every 10 20 minutes what about every few minutes every few months and years well if you think about a neuroscience problem the brain problem neurons themselves can stay active for certain periods of time parts of the brain where they stay active for minutes you could hold a certain perception or an activity for a certain period of time but most of them dont last that long and so if you think about your thoughts are the activity of neurons if youre gonna wanna involve something that happened a long time ago even just this morning for example the neurons havent been active throughout that time so you have to store that so if i ask you what did you have for breakfast today that is memory that is youve built into your model the world now you remember that and that memory is in the synapses is basically in the formation of synapses and so youre sliding into what you know its the different timescales theres timescales of which we are like understanding my language and moving about and seeing things rapidly and over time thats the timescales of activities of neurons but if you wanna get in longer timescales then its more memory and we have to invoke those memories to say oh yes well now i can remember what i had for breakfast because i stored that someplace i may forget it tomorrow but id store it for now so does memory also need to have so the hierarchical aspect of reality is not just about concepts its also about time do you think of it that way yeah time is infused in everything its like you really cant separate it out if i ask you what is your you know hows the brain learn a model of this coffee cup here i have a coffee cup and im at the coffee cup i say well time is not an inherent property of the model i have of this cup whether its a visual model or a tactile model i can sense it through time but the model itself doesnt really have much time if i asked you if i said well what is the model of my cell phone my brain has learned a model of the cell phone so if you have a smartphone like this and i said well this has time aspects to it i have expectations when i turn it on whats gonna happen what or how long its gonna take to do certain things if i bring up an app what sequences and so i have and its like melodies in the world you know melody has a sense of time so many things in the world move and act one way to think about it is we have all these models of the world okay and we model everything and as i said earlier i kind of snuck it in there our models are actually we build composite structure so every object is composed of other objects which are composed of other objects and they become members of other objects so this room has chairs and a table and a room and walls and so on now we can just arrange these things in a certain way and go oh thats the nomenclature conference room so and what we do is when we go around the world and we experience the world by walking into a room for example the first thing i do is i can say oh im in this room do i recognize the room then i can say oh look theres a table here and by attending to the table im then assigning this table in the context of the room then i can say oh on the table theres a coffee cup oh and on the table theres a logo and in the logo theres the word nementa oh and look in the logo theres the letter e oh and look it has an unusual serif and it doesnt actually but i pretended to serif so the point is your attention is kind of drilling deep in and out of these nested structures and i can pop back up and i can pop back down i can pop back up and i can pop back down so when i attend to the coffee cup i havent lost the context of everything else but its sort of theres this sort of nested structure so the attention filters the reference frame information for that particular period of time yes it basically moment to moment you attend the sub components and then you can attend the sub components to sub components and you can move up and down you can move up and down we do that all the time youre not even now that im aware of it im very conscious of it but until but most people dont even think about this you just walk in a room and you dont say oh i looked at the chair and i looked at the board and looked at that word on the board and i looked over here whats going on right so what percent of your day are you deeply aware of this and what part can you actually relax and just be jeff me personally like my personal day yeah unfortunately im afflicted with too much of the former well unfortunately or unfortunately yeah you dont think its useful oh it is useful totally useful i think about this stuff almost all the time and one of my primary ways of thinking is when im in sleep at night i always wake up in the middle of the night and then i stay awake for at least an hour with my eyes shut in sort of a half sleep state thinking about these things i come up with answers to problems very often in that sort of half sleeping state i think about it on my bike ride i think about it on walks im just constantly thinking about this i have to almost schedule time to not think about this stuff because its very its mentally taxing are you when youre thinking about this stuff are you thinking introspectively like almost taking a step outside of yourself and trying to figure out what is your mind doing right now i do that all the time but thats not all i do im constantly observing myself so as soon as i started thinking about grid cells for example and getting into that i started saying oh well grid cells can have my place of sense in the world thats where you know where you are and its interesting we always have a sense of where we are unless were lost and so i started at night when i got up to go to the bathroom i would start trying to do it completely with my eyes closed all the time and i would test my sense of grid cells i would walk five feet and say okay i think im here am i really there whats my error and then i would calculate my error again and see how the errors could accumulate so even something as simple as getting up in the middle of the night to go to the bathroom im testing these theories out its kind of fun i mean the coffee cup is an example of that too so i find that these sort of everyday introspections are actually quite helpful it doesnt mean you can ignore the science i mean i spend hours every day reading ridiculously complex papers thats not nearly as much fun but you have to sort of build up those constraints and the knowledge about the field and whos doing what and what exactly they think is happening here and then you can sit back and say okay lets try to piece this all together lets come up with some im very in this group here people they know they do i do this all the time i come in with these introspective ideas and say well have you ever thought about this now watch well lets all do this together and its helpful its not as long as you dont all you did was that then youre just making up stuff but if youre constraining it by the reality of the neuroscience then its really helpful so lets talk a little bit about deep learning and the successes in the applied space of neural networks ideas of training model on data and these simple computational units artificial neurons that with backpropagation statistical ways of being able to generalize from the training set onto data thats similar to that training set so where do you think are the limitations of those approaches what do you think are its strengths relative to your major efforts of constructing a theory of human intelligence well im not an expert in this field im somewhat knowledgeable so but im not some of it is in just your intuition what are your well i have a little bit more than intuition but i just want to say like you know one of the things that you asked me do i spend all my time thinking about neuroscience i do thats to the exclusion of thinking about things like convolutional neural networks but i try to stay current so look i think its great the progress theyve made its fantastic and as i mentioned earlier its very highly useful for many things the models that we have today are actually derived from a lot of neuroscience principles there are distributed processing systems and distributed memory systems and thats how the brain works they use things that we might call them neurons but theyre really not neurons at all so we can just theyre not really neurons so theyre distributed processing systems and that nature of hierarchy that came also from neuroscience and so theres a lot of things the learning rules basically not back prop but other you know sort of heavy on top of that id be curious to say theyre not neurons at all can you describe in which way i mean some of it is obvious but id be curious if you have specific ways in which you think are the biggest differences yeah we had a paper in 2016 called why neurons have thousands of synapses and if you read that paper youll know what im talking about here a real neuron in the brain is a complex thing and lets just start with the synapses on it which is a connection between neurons real neurons can have everywhere from five to 30000 synapses on them the ones near the cell body the ones that are close to the soma of the cell body those are like the ones that people model in artificial neurons there is a few hundred of those maybe they can affect the cell they can make the cell become active 95 of the synapses cant do that theyre too far away so if you activate one of those synapses it just doesnt affect the cell body enough to make any difference any one of them individually any one of them individually or even if you do a mass of them what real neurons do is the following if you activate or you get 10 to 20 of them active at the same time meaning theyre all receiving an input at the same time and those 10 to 20 synapses or 40 synapses within a very short distance on the dendrite like 40 microns a very small area so if you activate a bunch of these right next to each other at some distant place what happens is it creates whats called the dendritic spike and the dendritic spike travels through the dendrites and can reach the soma or the cell body now when it gets there it changes the voltage which is sort of like gonna make the cell fire but never enough to make the cell fire its sort of what we call it says we depolarize the cell you raise the voltage a little bit but not enough to do anything its like well what good is that and then it goes back down again so we propose a theory which im very confident in basics are is that whats happening there is those 95 of the synapses are recognizing dozens to hundreds of unique patterns they can write about 10 20 synapses at a time and theyre acting like predictions so the neuron actually is a predictive engine on its own it can fire when it gets enough what they call proximal input from those ones near the cell fire but it can get ready to fire from dozens to hundreds of patterns that it recognizes from the other guys and the advantage of this to the neuron is that when it actually does produce a spike in action potential it does so slightly sooner than it would have otherwise and so what could is slightly sooner well the slightly sooner part is it all the excitatory neurons in the brain are surrounded by these inhibitory neurons and theyre very fast the inhibitory neurons these basket cells and if i get my spike out a little bit sooner than someone else i inhibit all my neighbors around me right and what you end up with is a different representation you end up with a reputation that matches your prediction its a sparser representation meaning fewer neurons are active but its much more specific and so we showed how networks of these neurons can do very sophisticated temporal prediction basically so this summarize this real neurons in the brain are time based prediction engines and theres no concept of this at all in artificial what we call point neurons i dont think you can build a brain without them i dont think you can build intelligence without them because its where a large part of the time comes from these are predictive models and the time is theres a prior and a prediction and an action and its inherent through every neuron in the neocortex so i would say that point neurons sort of model a piece of that and not very well at that either but like for example synapses are very unreliable and you cannot assign any precision to them so even one digit of precision is not possible so the way real neurons work is they dont add these they dont change these weights accurately like artificial neural networks do they basically form new synapses and so what youre trying to always do is detect the presence of some 10 to 20 active synapses at the same time as opposed and theyre almost binary its like because you cant really represent anything much finer than that so these are the kind of and i think thats actually another essential component because the brain works on sparse patterns and all that mechanism is based on sparse patterns and i dont actually think you could build real brains or machine intelligence without incorporating some of those ideas its hard to even think about the complexity that emerges from the fact that the timing of the firing matters in the brain the fact that you form new synapses and i mean everything you just mentioned in the past couple minutes trust me if you spend time on it you can get your mind around it its not like its no longer a mystery to me no but sorry as a function in a mathematical way can you start getting an intuition about what gets it excited what not and what kind of representation yeah its not as easy as theres many other types of neural networks that are more amenable to pure analysis especially very simple networks oh i have four neurons and theyre doing this can we describe to them mathematically what theyre doing type of thing even the complexity of convolutional neural networks today its sort of a mystery they cant really describe the whole system and so its different my colleague subitai ahmad he did a nice paper on this you can get all this stuff on our website if youre interested talking about sort of the mathematical properties of sparse representations and so what we can do is we can show mathematically for example why 10 to 20 synapses to recognize a pattern is the correct number is the right number youd wanna use and by the way that matches biology we can show mathematically some of these concepts about the show why the brain is so robust to noise and error and fallout and so on we can show that mathematically as well as empirically in simulations but the system cant be analyzed completely any complex system cant and so thats out of the realm but there is mathematical benefits and intuitions that can be derived from mathematics and we try to do that as well most of our papers have a section about that so i think its refreshing and useful for me to be talking to you about deep neural networks because your intuition basically says that we cant achieve anything like intelligence with artificial neural networks well not in the current form not in the current form im sure we can do it in the ultimate form sure so let me dig into it and see what your thoughts are there a little bit so im not sure if you read this little blog post called bitter lesson by rich sutton recently hes a reinforcement learning pioneer im not sure if youre familiar with him his basic idea is that all the stuff weve done in ai in the past 70 years hes one of the old school guys the biggest lesson learned is that all the tricky things weve done they benefit in the short term but in the long term what wins out is a simple general method that just relies on moores law on computation getting faster and faster this is what hes saying this is what has worked up to now this is what has worked up to now if youre trying to build a system if were talking about hes not concerned about intelligence hes concerned about a system that works in terms of making predictions on applied narrow ai problems right thats what this discussion is about that you just try to go as general as possible and wait years or decades for the computation to make it actually is he saying that as a criticism or is he saying this is a prescription of what we ought to be doing well its very difficult hes saying this is what has worked and yes a prescription but its a difficult prescription because it says all the fun things you guys are trying to do we are trying to do hes part of the community hes saying its only going to be short term gains so this all leads up to a question i guess on artificial neural networks and maybe our own biological neural networks is do you think if we just scale things up significantly so take these dumb artificial neurons the point neurons i like that term if we just have a lot more of them do you think some of the elements that we see in the brain may start emerging no i dont think so we can do bigger problems of the same type i mean its been pointed out by many people that todays convolutional neural networks arent really much different than the ones we had quite a while ago theyre bigger and train more and we have more labeled data and so on but i dont think you can get to the kind of things i know the brain can do and that we think about as intelligence by just scaling it up so that may be its a good description of whats happened in the past whats happened recently with the reemergence of artificial neural networks it may be a good prescription for whats gonna happen in the short term but i dont think thats the path ive said that earlier theres an alternate path i should mention to you by the way that weve made sufficient progress on the whole cortical theory in the last few years that last year we decided to start actively pursuing how do we get these ideas embedded into machine learning well thats again being led by my colleague subed tariman and hes more of a machine learning guy im more of a neuroscience guy so this is now i wouldnt say our focus but it is now an equal focus here because we need to proselytize what weve learned and we need to show how its beneficial to the machine learning layer so were putting we have a plan in place right now in fact we just did our first paper on this i can tell you about that but one of the reasons i wanna talk to you is because im trying to get more people in the machine learning community to say i need to learn about this stuff and maybe we should just think about this a bit more about what weve learned about the brain and what are those team at nimenta what have they done is that useful for us yeah so is there elements of all the cortical theory that things weve been talking about that may be useful in the short term yes in the short term yes this is the sorry to interrupt but the open question is it certainly feels from my perspective that in the long term some of the ideas weve been talking about will be extremely useful the question is whether in the short term well this is always what i would call the entrepreneurs dilemma so you have this long term vision oh were gonna all be driving electric cars or were all gonna have computers or were all gonna whatever and youre at some point in time and you say i can see that long term vision im sure its gonna happen how do i get there without killing myself without going out of business right thats the challenge thats the dilemma thats the really difficult thing to do so were facing that right now so ideally what youd wanna do is find some steps along the way that you can get there incrementally you dont have to like throw it all out and start over again the first thing that weve done is we focus on the sparse representations so just in case you dont know what that means or some of the listeners dont know what that means in the brain if i have like 10000 neurons what you would see is maybe 2 of them active at a time you dont see 50 you dont see 30 you might see 2 and its always like that for any set of sensory inputs it doesnt matter if anything doesnt matter any part of the brain but which neurons differs which neurons are active yeah so lets say i take 10000 neurons that are representing something theyre sitting there in a little block together its a teeny little block of neurons 10000 neurons and theyre representing a location theyre representing a cup theyre representing the input from my sensors i dont know it doesnt matter its representing something the way the representations occur its always a sparse representation meaning its a population code so which 200 cells are active tells me whats going on its not individual cells arent that important at all its the population code that matters and when you have sparse population codes then all kinds of beautiful properties come out of them so the brain uses sparse population codes weve written and described these benefits in some of our papers so they give this tremendous robustness to the systems brains are incredibly robust neurons are dying all the time and spasming and synapses are falling apart all the time and it keeps working so what sibutai and louise one of our other engineers here have done have shown theyre introducing sparseness into convolutional neural networks now other people are thinking along these lines but were going about it in a more principled way i think and were showing that if you enforce sparseness throughout these convolutional neural networks in both the act which sort of which neurons are active and the connections between them that you get some very desirable properties so one of the current hot topics in deep learning right now are these adversarial examples so you know you give me any deep learning network and i can give you a picture that looks perfect and youre going to call it you know youre going to say the monkey is you know an airplane so thats a problem and darpa just announced some big thing theyre trying to you know have some contest for this but if you enforce sparse representations here many of these problems go away theyre much more robust and theyre not easy to fool so weve already shown some of those results just literally in january or february just like last month we did that and you can i think its on biorxiv right now or on irxiv you can read about it but so thats like a baby step okay thats taking something from the brain we know about sparseness we know why its important we know what it gives the brain so lets try to enforce that onto this whats your intuition why sparsity leads to robustness because it feels like it would be less robust why would you feel the rest robust to you so it just feels like if the fewer neurons are involved the more fragile the representation but i didnt say there was lots of few neurons i said lets say 200 thats a lot theres still a lot its just so heres an intuition for it this is a bit technical so for engineers machine learning people this will be easy but all the listeners maybe not if youre trying to classify something youre trying to divide some very high dimensional space into different pieces a and b and youre trying to create some point where you say all these points in this high dimensional space are a and all these points in this high dimensional space are b and if you have points that are close to that line its not very robust it works for all the points you know about but its not very robust because you can just move a little bit and youve crossed over the line when you have sparse representations imagine i pick im gonna pick 200 cells active out of 10000 okay so i have 200 cells active now lets say i pick randomly another a different representation 200 the overlap between those is gonna be very small just a few i can pick millions of samples randomly of 200 neurons and not one of them will overlap more than just a few so one way to think about it is if i wanna fool one of these representations to look like one of those other representations i cant move just one cell or two cells or three cells or four cells i have to move 100 cells and that makes them robust in terms of further so you mentioned sparsity what would be the next thing yeah okay so we have we picked one we dont know if its gonna work well yet so again were trying to come up with incremental ways to moving from brain theory to add pieces to machine learning current machine learning world and one step at a time so the next thing were gonna try to do is sort of incorporate some of the ideas of the thousand brains theory that you have many many models that are voting now that idea is not new theres a mixture of models thats been around for a long time but the way the brain does it is a little different and the way it votes is different and the kind of way it represents uncertainty is different so were just starting this work but were gonna try to see if we can sort of incorporate some of the principles of voting or principles of the thousand brain theory like lots of simple models that talk to each other in a certain way and can we build more machines systems that learn faster and also well mostly are multimodal and robust to multimodal type of issues so one of the challenges there is the machine learning computer vision community has certain sets of benchmarks sets of tests based on which they compete and i would argue especially from your perspective that those benchmarks arent that useful for testing the aspects that the brain is good at or intelligence theyre not really testing intelligence theyre very fine and its been extremely useful for developing specific mathematical models but its not useful in the long term for creating intelligence so you think you also have a role in proposing better tests yeah this is a very youve identified a very serious problem first of all the tests that they have are the tests that they want not the tests of the other things that were trying to do right you know what are the so on the second thing is sometimes these to be competitive in these tests you have to have huge data sets and huge computing power and so you know and we dont have that here we dont have it as well as other big teams that big companies do so theres numerous issues there you know we come out you know where our approach to this is all based on in some sense you might argue elegance were coming at it from like a theoretical base that we think oh my god this is so clearly elegant this is how brains work this is what intelligence is but the machine learning world has gotten in this phase where they think it doesnt matter doesnt matter what you think as long as you do you know 01 better on this benchmark thats what thats all that matters and thats a problem you know we have to figure out how to get around that thats a challenge for us thats one of the challenges that we have to deal with so i agree youve identified a big issue its difficult for those reasons but you know part of the reasons im talking to you here today is i hope im gonna get some machine learning people to say im gonna read those papers those might be some interesting ideas im tired of doing this 01 improvement stuff you know well thats why im here as well because i think machine learning now as a community is at a place where the next step needs to be orthogonal to what has received success in the past well you see other leaders saying this machine learning leaders you know jeff hinton with his capsules idea many people have gotten up to say you know were gonna hit road map maybe we should look at the brain you know things like that so hopefully that thinking will occur organically and then were in a nice position for people to come and look at our work and say well what can we learn from these guys yeah mit is launching a billion dollar computing college thats centered around this idea so is it on this idea of what well the idea that you know the humanities psychology and neuroscience have to work all together to get to build the s yeah i mean stanford just did this human centered ai center im a little disappointed in these initiatives because you know theyre focusing on sort of the human side of it and it could very easily slip into how humans interact with intelligent machines which is nothing wrong with that but thats not that is orthogonal to what were trying to do were trying to say like what is the essence of intelligence i dont care in fact i wanna build intelligent machines that arent emotional that dont smile at you that you know that arent trying to tuck you in at night yeah there is that pattern that you when you talk about understanding humans is important for understanding intelligence that you start slipping into topics of ethics or yeah like you said the interactive elements as opposed to no no no we have to zoom in on the brain study what the human brain the baby the lets study what a brain does does and then we can decide which parts of that we wanna recreate in some system but until you have that theory about what the brain does whats the point you know its just youre gonna be wasting time i think right just to break it down on the artificial neural network side maybe you could speak to this on the biological neural network side the process of learning versus the process of inference maybe you can explain to me is there a difference between you know in artificial neural networks theres a difference between the learning stage and the inference stage do you see the brain as something different one of the big distinctions that people often say i dont know how correct it is is artificial neural networks need a lot of data theyre very inefficient learning do you see that as a correct distinction from the biology of the human brain that the human brain is very efficient or is that just something we deceive ourselves no it is efficient obviously we can learn new things almost instantly and so what elements do you think are useful yeah i can talk about that you brought up two issues there so remember i talked early about the constraints we always feel well one of those constraints is the fact that brains are continually learning thats not something we said oh we can add that later thats something that was upfront had to be there from the start made our problems harder but we showed going back to the 2016 paper on sequence memory we showed how that happens how the brains infer and learn at the same time and our models do that and theyre not two separate phases or two separate sets of time i think thats a big big problem in ai at least for many applications not for all so i can talk about that there are some it gets detailed there are some parts of the neocortex in the brain where actually whats going on theres these cycles of activity in the brain and theres very strong evidence that youre doing more of inference on one part of the phase and more of learning on the other part of the phase so the brain can actually sort of separate different populations of cells or going back and forth like this but in general i would say thats an important problem we have all of our networks that weve come up with do both and theyre continuous learning networks and you mentioned benchmarks earlier well there are no benchmarks about that so we have to we get in our little soapbox and hey by the way this is important and heres a mechanism for doing that but until you can prove it to someone in some commercial system or something its a little harder so yeah one of the things i had to linger on that is in some ways to learn the concept of a coffee cup you only need this one coffee cup and maybe some time alone in a room with it well the first thing is imagine i reach my hand into a black box and im reaching im trying to touch something i dont know upfront if its something i already know or if its a new thing and i have to im doing both at the same time i dont say oh lets see if its a new thing oh lets see if its an old thing i dont do that as i go my brain says oh its new or its not new and if its new i start learning what it is and by the way it starts learning from the get go even if its gonna recognize it so theyre not separate problems and so thats the thing there the other thing you mentioned was the fast learning so i was just talking about continuous learning but theres also fast learning literally i can show you this coffee cup and i say heres a new coffee cup its got the logo on it take a look at it done youre done you can predict what its gonna look like you know in different positions so i can talk about that too in the brain the way learning occurs i mentioned this earlier but ill mention it again the way learning occurs imagine i am a section of a dendrite of a neuron and im gonna learn something new doesnt matter what it is im just gonna learn something new i need to recognize a new pattern so what im gonna do is im gonna form new synapses new synapses were gonna rewire the brain onto that section of the dendrite once ive done that everything else that neuron has learned is not affected by it thats because its isolated to that small section of the dendrite theyre not all being added together like a point neuron so if i learn something new on this segment here it doesnt change any of the learning that occur anywhere else in that neuron so i can add something without affecting previous learning and i can do it quickly now lets talk we can talk about the quickness how its done in real neurons you might say well doesnt it take time to form synapses yes it can take maybe an hour to form a new synapse we can form memories quicker than that and i can explain that how it happens too if you want but its getting a bit neurosciencey thats great but is there an understanding of these mechanisms at every level yeah so from the short term memories and the forming so this idea of synaptogenesis the growth of new synapses thats well described its well understood and thats an essential part of learning that is learning that is learning okay going back many many years people you know it was whats his name the psychologist who proposed hebb donald hebb he proposed that learning was the modification of the strength of a connection between two neurons people interpreted that as the modification of the strength of a synapse he didnt say that he just said theres a modification between the effect of one neuron and another so synaptogenesis is totally consistent with what donald hebb said but anyway theres these mechanisms the growth of new synapses you can go online you can watch a video of a synapse growing in real time its literally you can see this little thing going boop its pretty impressive so those mechanisms are known now theres another thing that weve speculated and weve written about which is consistent with known neuroscience but its less proven and this is the idea how do i form a memory really really quickly like instantaneous if it takes an hour to grow a synapse like thats not instantaneous so there are types of synapses called silent synapses they look like a synapse but they dont do anything theyre just sitting there its like if an action potential comes in it doesnt release any neurotransmitter some parts of the brain have more of these than others for example the hippocampus has a lot of them which is where we associate most short term memory with so what we speculated again in that 2016 paper we proposed that the way we form very quick memories very short term memories or quick memories is that we convert silent synapses into active synapses its like saying a synapse has a zero weight and a one weight but the longterm memory has to be formed by synaptogenesis so you can remember something really quickly by just flipping a bunch of these guys from silent to active its not from 01 to 015 its like it doesnt do anything till it releases transmitter and if i do that over a bunch of these ive got a very quick short term memory so i guess the lesson behind this is that most neural networks today are fully connected every neuron connects every other neuron from layer to layer thats not correct in the brain we dont want that we actually dont want that its bad you want a very sparse connectivity so that any neuron connects to some subset of the neurons in the other layer and it does so on a dendrite by dendrite segment basis so its a very some parcelated out type of thing and that then learning is not adjusting all these weights but learning is just saying okay connect to these 10 cells here right now in that process you know with artificial neural networks its a very simple process of backpropagation that adjusts the weights the process of synaptogenesis synaptogenesis synaptogenesis its even easier its even easier its even easier backpropagation requires something that really cant happen in brains this backpropagation of this error signal that really cant happen people are trying to make it happen in brains but it doesnt happen in brains this is pure hebbian learning well synaptogenesis is pure hebbian learning its basically saying theres a population of cells over here that are active right now and theres a population of cells over here active right now how do i form connections between those active cells and its literally saying this guy became active these 100 neurons here became active before this neuron became active so form connections to those ones thats it theres no propagation of error nothing all the networks we do all the models we have work on almost completely on hebbian learning but on dendritic segments and multiple synapses at the same time so now lets sort of turn the question that you already answered and maybe you can answer it again if you look at the history of artificial intelligence where do you think we stand how far are we from solving intelligence you said you were very optimistic can you elaborate on that yeah its always the crazy question to ask because no one can predict the future absolutely so ill tell you a story i used to run a different neuroscience institute called the redwood neuroscience institute and we would hold these symposiums and wed get like 35 scientists from around the world to come together and i used to ask them all the same question i would say well how long do you think itll be before we understand how the neocortex works and everyone went around the room and they had introduced the name and they have to answer that question so i got the typical answer was 50 to 100 years some people would say 500 years some people said never i said why are you a neuroscientist its never gonna its a good pay its interesting so you know but it doesnt work like that as i mentioned earlier these are not these are step functions things happen and then bingo they happen you cant predict that i feel ive already passed a step function so if i can do my job correctly over the next five years then meaning i can proselytize these ideas i can convince other people theyre right we can show that other people machine learning people should pay attention to these ideas then were definitely in an under 20 year timeframe if i can do those things if im not successful in that and this is the last time anyone talks to me and no one reads our papers and you know and im wrong or something like that then i dont know but its not 50 years think about electric cars how quickly are they gonna populate the world it probably takes about a 20 year span itll be something like that but i think if i can do what i said were starting it and of course there could be other you said step functions it could be everybody gives up on your ideas for 20 years and then all of a sudden somebody picks it up again wait that guy was onto something yeah so that would be a failure on my part right think about charles babbage charles babbage hes the guy who invented the computer back in the 18 something 1800s and everyone forgot about it until 100 years later and say hey this guy figured this stuff out a long time ago but he was ahead of his time i dont think as i said i recognize this is part of any entrepreneurs challenge i use entrepreneur broadly in this case im not meaning like im building a business or trying to sell something i mean im trying to sell ideas and this is the challenge as to how you get people to pay attention to you how do you get them to give you positive or negative feedback how do you get the people to act differently based on your ideas so well see how well we do on that so you know that theres a lot of hype behind artificial intelligence currently do you as you look to spread the ideas that are of neocortical theory the things youre working on do you think theres some possibility well hit an ai winter once again yeah its certainly a possibility no question about it is that something you worry about yeah well i guess do i worry about it i havent decided yet if thats good or bad for my mission thats true thats very true because its almost like you need the winter to refresh the palette yeah its like i want heres what you wanna have it is you want like to the extent that everyone is so thrilled about the current state of machine learning and ai and they dont imagine they need anything else it makes my job harder if everything crashed completely and every student left the field and there was no money for anybody to do anything and it became an embarrassment to talk about machine intelligence and ai that wouldnt be good for us either you want sort of the soft landing approach right you want enough people the senior people in ai and machine learning to say you know we need other approaches we really need other approaches damn we need other approaches maybe we should look to the brain okay lets look to the brain whos got some brain ideas okay lets start a little project on the side here trying to do brain idea related stuff thats the ideal outcome we would want so i dont want a total winter and yet i dont want it to be sunny all the time either so what do you think it takes to build a system with human level intelligence where once demonstrated you would be very impressed so does it have to have a body does it have to have the c word we used before consciousness as an entirety in a holistic sense first of all i dont think the goal is to create a machine that is human level intelligence i think its a false goal back to turing i think it was a false statement we want to understand what intelligence is and then we can build intelligent machines of all different scales all different capabilities a dog is intelligent i dont need thatd be pretty good to have a dog but what about something that doesnt look like an animal at all in different spaces so my thinking about this is that we want to define what intelligence is agree upon what makes an intelligent system we can then say okay were now gonna build systems that work on those principles or some subset of them and we can apply them to all different types of problems and the kind the idea its not computing we dont ask if i take a little one chip computer i dont say well thats not a computer because its not as powerful as this big server over here no no because we know that what the principles of computing are and i can apply those principles to a small problem or into a big problem and same intelligence needs to get there we have to say these are the principles i can make a small one a big one i can make them distributed i can put them on different sensors they dont have to be human like at all now you did bring up a very interesting question about embodiment does it have to have a body it has to have some concept of movement it has to be able to move through these reference frames i talked about earlier whether its physically moving like i need if im gonna have an ai that understands coffee cups its gonna have to pick up the coffee cup and touch it and look at it with its eyes and hands or something equivalent to that if i have a mathematical ai maybe it needs to move through mathematical spaces i could have a virtual ai that lives in the internet and its movements are traversing links and digging into files but its got a location that its traveling through some space you cant have an ai that just take some flash thing input we call it flash inference heres a pattern done no its movement pattern movement pattern movement pattern attention digging building structure figuring out the model of the world so some sort of embodiment whether its physical or not has to be part of it so self awareness and the way to be able to answer where am i well youre bringing up self thats a different topic self awareness no the very narrow definition of self meaning knowing a sense of self enough to know where am i in the space where its actually yeah basically the system needs to know its location or each component of the system needs to know where it is in the world at that point in time so self awareness and consciousness do you think one from the perspective of neuroscience and neurocortex these are interesting topics solvable topics do you have any ideas of why the heck it is that we have a subjective experience at all yeah i have a lot of thoughts on that and is it useful or is it just a side effect of us its interesting to think about i dont think its useful as a means to figure out how to build intelligent machines its something that systems do and we can talk about what it is that are like well if i build a system like this then it would be self aware or if i build it like this it wouldnt be self aware so thats a choice i can have its not like oh my god its self aware i cant turn i heard an interview recently with this philosopher from yale i cant remember his name i apologize for that but he was talking about well if these computers are self aware then it would be a crime to unplug them and im like oh come on thats not i unplug myself every night i go to sleep is that a crime i plug myself in again in the morning and there i am so people get kind of bent out of shape about this i have very definite very detailed understanding or opinions about what it means to be conscious and what it means to be self aware i dont think its that interesting a problem youve talked to christoph koch he thinks thats the only problem i didnt actually listen to your interview with him but i know him and i know thats the thing he cares about he also thinks intelligence and consciousness are disjoint so i mean its not you dont have to have one or the other so he is i disagree with that i just totally disagree with that so wheres your thoughts and consciousness where does it emerge from because it is so then we have to break it down to the two parts okay because consciousness isnt one thing thats part of the problem with that term is it means different things to different people and theres different components of it there is a concept of self awareness okay that can be very easily explained you have a model of your own body the neocortex models things in the world and it also models your own body and then it has a memory it can remember what youve done okay so it can remember what you did this morning can remember what you had for breakfast and so on and so i can say to you okay lex were you conscious this morning when you had your bagel and youd say yes i was conscious now what if i could take your brain and revert all the synapses back to the state they were this morning and then i said to you lex were you conscious when you ate the bagel and you said no i wasnt conscious i said heres a video of eating the bagel and you said i wasnt there thats not possible because i mustve been unconscious at that time so we can just make this one to one correlation between memory of your bodys trajectory through the world over some period of time a memory and the ability to recall that memory is what you would call conscious i was conscious of that its a self awareness and any system that can recall memorize what its done recently and bring that back and invoke it again would say yeah im aware i remember what i did all right i got it thats an easy one although some people think thats a hard one the more challenging part of consciousness is this one thats sometimes used going by the word of qualia which is why does an object seem red or what is pain and why does pain feel like something why do i feel redness or why do i feel painness and then i could say well why does sight seems different than hearing its the same problem its really these are all just neurons and so how is it that why does looking at you feel different than hearing you it feels different but theres just neurons in my head theyre all doing the same thing so thats an interesting question the best treatise ive read about this is by a guy named oregon he wrote a book called why red doesnt sound like a bell its a little its not a trade book easy to read but it and its an interesting question take something like color color really doesnt exist in the world its not a property of the world property of the world that exists is light frequency and that gets turned into we have certain cells in the retina that respond to different frequencies different than others and so when they enter the brain you just have a bunch of axons that are firing at different rates and from that we perceive color but there is no color in the brain i mean theres no color coming in on those synapses its just a correlation between some axons and some property of frequency and that isnt even color itself frequency doesnt have a color its just what it is so then the question is well why does it even appear to have a color at all just as youre describing it there seems to be a connection to those ideas of reference frames i mean it just feels like consciousness having the subject assigning the feeling of red to the actual color or to the wavelength is useful for intelligence yeah i think thats a good way of putting it its useful as a predictive mechanism or useful as a generalization idea its a way of grouping things together to say its useful to have a model like this so think about the well known syndrome that people whove lost a limb experience called phantom limbs and what they claim is they can have their arm is removed but they feel their arm that not only feel it they know its there its there i know its there theyll swear to you that its there and then they can feel pain in their arm and theyll feel pain in their finger and if they move their non existent arm behind their back then they feel the pain behind their back so this whole idea that your arm exists is a model of your brain it may or may not really exist and just like but its useful to have a model of something that sort of correlates to things in the world so you can make predictions about what would happen when those things occur its a little bit of a fuzzy but i think youre getting quite towards the answer there its useful for the model to express things certain ways that we can then map them into these reference frames and make predictions about them i need to spend more time on this topic it doesnt bother me do you really need to spend more time yeah i know it does feel special that we have subjective experience but im yet to know why im just personally curious its not necessary for the work were doing here i dont think i need to solve that problem to build intelligent machines at all not at all but there is sort of the silly notion that you described briefly that doesnt seem so silly to us humans is if youre successful building intelligent machines it feels wrong to then turn them off because if youre able to build a lot of them it feels wrong to then be able to turn off the well why lets break that down a bit as humans why do we fear death theres two reasons we fear death well first of all ill say when youre dead it doesnt matter at all who cares youre dead so why do we fear death we fear death for two reasons one is because we are programmed genetically to fear death thats a survival and pop beginning of the genes thing and we also are programmed to feel sad when people we know die we dont feel sad for someone we dont know dies theres people dying right now theyre only just gonna say i dont feel bad about them because i dont know them but if i knew them id feel really bad so again these are old brain genetically embedded things that we fear death its outside of those uncomfortable feelings theres nothing else to worry about well wait hold on a second do you know the denial of death by becker no theres a thought that death is our whole conception of our world model kind of assumes immortality and then death is this terror that underlies it all so like some peoples world model not mine but okay so what becker would say is that youre just living in an illusion youve constructed an illusion for yourself because its such a terrible terror the fact that this whats the illusion the illusion that death doesnt matter youre still not coming to grips with the illusion of what that death is going to happen oh like its not gonna happen youre actually operating you havent even though you said youve accepted it you havent really accepted the notion that youre gonna die is what you say so it sounds like you disagree with that notion yeah yeah totally i literally every night i go to bed its like dying like little deaths its little deaths and if i didnt wake up it wouldnt matter to me only if i knew that was gonna happen would it be bothersome if i didnt know it was gonna happen how would i know then i would worry about my wife so imagine i was a loner and i lived in alaska and i lived out there and there was no animals nobody knew i existed i was just eating these roots all the time and nobody knew i was there and one day i didnt wake up what pain in the world would there exist well so most people that think about this problem would say that youre just deeply enlightened or are completely delusional one of the two but i would say thats a very enlightened way to see the world thats the rational one as well its rational thats right but the fact is we dont i mean we really dont have an understanding of why the heck it is were born and why we die and what happens after we die well maybe there isnt a reason maybe there is so im interested in those big problems too right you interviewed max tegmark and theres people like that right im interested in those big problems as well and in fact when i was young i made a list of the biggest problems i could think of first why does anything exist second why do we have the laws of physics that we have third is life inevitable and why is it here fourth is intelligence inevitable and why is it here i stopped there because i figured if you can make a truly intelligent system that will be the quickest way to answer the first three questions im serious and so i said my mission you asked me earlier my first mission is to understand the brain but i felt that is the shortest way to get to true machine intelligence and i wanna get to true machine intelligence because even if it doesnt occur in my lifetime other people will benefit from it because i think itll occur in my lifetime but 20 years you never know but that will be the quickest way for us to we can make super mathematicians we can make super space explorers we can make super physicist brains that do these things and that can run experiments that we cant run we dont have the abilities to manipulate things and so on but we can build intelligent machines that do all those things with the ultimate goal of finding out the answers to the other questions let me ask you another depressing and difficult question which is once we achieve that goal of creating no of understanding intelligence do you think we would be happier more fulfilled as a species the understanding intelligence or understanding the answers to the big questions understanding intelligence oh totally totally it would be far more fun place to live you think so oh yeah why not i mean just put aside this terminator nonsense and just think about you can think about we can talk about the risks of ai if you want id love to so lets talk about but i think the world would be far better knowing things were always better than know things do you think its better is it a better place to live in that i know that our planet is one of many in the solar system and the solar systems one of many in the galaxy i think its a more i dread i sometimes think like god what would it be like to live 300 years ago id be looking up at the sky i cant understand anything oh my god id be like going to bed every night going whats going on here well i mean in some sense i agree with you but im not exactly sure so im also a scientist so i share your views but im not were like rolling down the hill together whats down the hill i feel like were climbing a hill whatever were getting closer to enlightenment and youre going down the hill were climbing were getting pulled up a hill by our curiosity our curiosity is were pulling ourselves up the hill by our curiosity yeah sisyphus was doing the same thing with the rock yeah yeah yeah yeah but okay our happiness aside do you have concerns about you talk about sam harris elon musk of existential threats of intelligent systems no im not worried about existential threats at all there are some things we really do need to worry about even todays ai we have things we have to worry about we have to worry about privacy and about how it impacts false beliefs in the world and we have real problems and things to worry about with todays ai and that will continue as we create more intelligent systems theres no question the whole issue about making intelligent armaments and weapons is something that really we have to think about carefully i dont think of those as existential threats i think those are the kind of threats we always face and well have to face them here and well have to deal with them we could talk about what people think are the existential threats but when i hear people talking about them they all sound hollow to me theyre based on ideas theyre based on people who really have no idea what intelligence is and if they knew what intelligence was they wouldnt say those things so those are not experts in the field yeah so theres two right so one is like super intelligence so a system that becomes far far superior in reasoning ability than us humans how is that an existential threat then so theres a lot of ways in which it could be one way is us humans are actually irrational inefficient and get in the way of not happiness but whatever the objective function is of maximizing that objective function super intelligent the paperclip problem and things like that so the paperclip problem but with the super intelligent yeah yeah yeah yeah so we already face this threat in some sense theyre called bacteria these are organisms in the world that would like to turn everything into bacteria and theyre constantly morphing theyre constantly changing to evade our protections and in the past they have killed huge swaths of populations of humans on this planet so if you wanna worry about something thats gonna multiply endlessly we have it and im far more worried in that regard im far more worried that some scientists in the laboratory will create a super virus or a super bacteria that we cannot control that is a more of an existential threat putting an intelligence thing on top of it actually seems to make it less existential to me its like it limits its power it limits where it can go it limits the number of things it can do in many ways a bacteria is something you cant even see so thats only one of those problems yes exactly so the other one just in your intuition about intelligence when you think about intelligence of us humans do you think of that as something if you look at intelligence on a spectrum from zero to us humans do you think you can scale that to something far far superior to all the mechanisms weve been talking about i wanna make another point here lex before i get there intelligence is the neocortex it is not the entire brain the goal is not to make a human the goal is not to make an emotional system the goal is not to make a system that wants to have sex and reproduce why would i build that if i wanna have a system that wants to reproduce and have sex make bacteria make computer viruses those are bad things dont do that those are really bad dont do those things regulate those but if i just say i want an intelligent system why does it have to have any of the human like emotions why does it even care if it lives why does it even care if it has food it doesnt care about those things its just you know its just in a trance thinking about mathematics or its out there just trying to build the space for it on mars thats a choice we make dont make human like things dont make replicating things dont make things that have emotions just stick to the neocortex so thats a view actually that i share but not everybody shares in the sense that you have faith and optimism about us as engineers of systems humans as builders of systems to not put in stupid not so this is why i mentioned the bacteria one because you might say well some persons gonna do that well some person today could create a bacteria thats resistant to all the known antibacterial agents so we already have that threat we already know this is going on its not a new threat so just accept that and then we have to deal with it right yeah so my point is nothing to do with intelligence intelligence is a separate component and theres a sense of time related to them some dont but most things do actually so its sort of infused throughout the models of the world you build a model of the world youre learning the structure of the objects in the world and youre also learning how those things change through time okay so it really is just a fourth dimension thats infused deeply and you have to make sure that your models of intelligence incorporate it so like you mentioned the state of neuroscience is deeply empirical a lot of data collection its you know thats where it is you mentioned thomas kuhn right yeah and then youre proposing a theory of intelligence and which is really the next step the really important step to take but why is htm or what well talk about soon the right theory so is it more in the is it backed by intuition is it backed by evidence is it backed by a mixture of both is it kind of closer to where string theory is in physics where theres mathematical components which show that you know what it seems that this it fits together too well for it not to be true which is where string theory is is that where youre kind of seeing its a mixture of all those things although definitely where we are right now is definitely much more on the empirical side than lets say string theory the way this goes about were theorists right so we look at all this data and were trying to come up with some sort of model that explains it basically and theres unlike string theory theres vast more amounts of empirical data here that i think than most physicists deal with and so our challenge is to sort through that and figure out what kind of constructs would explain this and when we have an idea you come up with a theory of some sort you have lots of ways of testing it first of all there are 100 years of assimilated assimilated unassimilated empirical data from neuroscience so we go back and read papers and we say oh did someone find this already we can predict x y and z and maybe no ones even talked about it since 1972 or something but we go back and find that and we say oh either it can support the theory or it can invalidate the theory and we say okay we have to start over again oh no its supportive lets keep going with that one so the way i kind of view it when we do our work we look at all this empirical data and what i call it is a set of constraints were not interested in something thats biologically inspired were trying to figure out how the actual brain works so every piece of empirical data is a constraint on a theory in theory if you have the correct theory it needs to explain every pin right so we have this huge number of constraints on the problem which initially makes it very very difficult if you dont have many constraints you can make up stuff all the day you can say oh heres an answer on how you can do this you can do that you can do this but if you consider all biology as a set of constraints all neuroscience as a set of constraints and even if youre working in one little part of the neocortex for example there are hundreds and hundreds of constraints these are empirical constraints that its very very difficult initially to come up with a theoretical framework for that but when you do and it solves all those constraints at once you have a high confidence that you got something close to correct its just mathematically almost impossible not to be so thats the curse and the advantage of what we have the curse is we have to solve we have to meet all these constraints which is really hard but when you do meet them then you have a great confidence that youve discovered something in addition then we work with scientific labs so well say oh theres something we cant find we can predict something but we cant find it anywhere in the literature so we will then we have people weve collaborated with well say sometimes theyll say you know what i have some collected data which i didnt publish but we can go back and look at it and see if we can find that which is much easier than designing a new experiment you know neuroscience experiments take a long time years so although some people are doing that now too so but between all of these things i think its a reasonable actually a very very good approach we are blessed with the fact that we can test our theories out the yin yang here because theres so much unassimilar data and we can also falsify our theories very easily which we do often so its kind of reminiscent to whenever that was with copernicus you know when you figure out that the suns at the center of the solar system as opposed to earth the pieces just fall into place yeah i think thats the general nature of aha moments is and its copernicus it could be you could say the same thing about darwin you could say the same thing about you know about the double helix that people have been working on a problem for so long and have all this data and they cant make sense of it they cant make sense of it but when the answer comes to you and everything falls into place its like oh my gosh thats it thats got to be right i asked both jim watson and francis crick about this i asked them you know when you were working on trying to discover the structure of the double helix and when you came up with the sort of the structure that ended up being correct but it was sort of a guess you know it wasnt really verified yet i said did you know that it was right and they both said absolutely so we absolutely knew it was right and it doesnt matter if other people didnt believe it or not we knew it was right theyd get around to thinking it and agree with it eventually anyway and thats the kind of thing you hear a lot with scientists who really are studying a difficult problem and i feel that way too about our work have you talked to crick or watson about the problem youre trying to solve the of finding the dna of the brain yeah in fact francis crick was very interested in this in the latter part of his life and in fact i got interested in brains by reading an essay he wrote in 1979 called thinking about the brain and that was when i decided im gonna leave my profession of computers and engineering and become a neuroscientist just reading that one essay from francis crick i got to meet him later in life i spoke at the salk institute and he was in the audience and then i had a tea with him afterwards he was interested in a different problem he was focused on consciousness the easy problem right well i think its the red herring and so we werent really overlapping a lot there jim watson whos still alive is also interested in this problem and he was when he was director of the cold spring harbor laboratories he was really sort of behind moving in the direction of neuroscience there and so he had a personal interest in this field and i have met with him numerous times and in fact the last time was a little bit over a year ago i gave a talk at cold spring harbor labs about the progress we were making in our work and it was a lot of fun because he said well you wouldnt be coming here unless you had something important to say so im gonna go attend your talk so he sat in the very front row next to him was the director of the lab bruce stillman so these guys are in the front row of this auditorium nobody else in the auditorium wants to sit in the front row because theres jim watson and theres the director and i gave a talk and then i had dinner with him afterwards but theres a great picture of my colleague subitai amantak where im up there sort of like screaming the basics of this new framework we have and jim watsons on the edge of his chair hes literally on the edge of his chair like intently staring up at the screen and when he discovered the structure of dna the first public talk he gave was at cold spring harbor labs and theres a picture theres a famous picture of jim watson standing at the whiteboard with an overrated thing pointing at something pointing at the double helix with his pointer and it actually looks a lot like the picture of me so there was a sort of funny theres arian talking about the brain and theres jim watson staring intently at it and of course there with whatever 60 years earlier he was standing pointing at the double helix thats one of the great discoveries in all of whatever biology science all science and dna so its funny that theres echoes of that in your presentation do you think in terms of evolutionary timeline and history the development of the neocortex was a big leap or is it just a small step so like if we ran the whole thing over again from the birth of life on earth how likely would we develop the mechanism of the neocortex okay well those are two separate questions one is was it a big leap and one was how likely it is okay theyre not necessarily related maybe correlated maybe correlated maybe not and we dont really have enough data to make a judgment about that i would say definitely it was a big leap and i can tell you why i dont think it was just another incremental step i dont get that at the moment i dont really have any idea how likely it is if we look at evolution we have one data point which is earth right life formed on earth billions of years ago whether it was introduced here or it created it here or someone introduced it we dont really know but it was here early it took a long long time to get to multicellular life and then for multicellular life it took a long long time to get the neocortex that you might apply to a system that wants to reproduce and do stupid things lets not do that yeah in fact it is a mystery why people havent done that yet my dad is a physicist believes that the reason he says for example nuclear weapons havent proliferated amongst evil people so one belief that i share is that theres not that many evil people in the world that would use whether its bacteria or nuclear weapons or maybe the future ai systems to do bad so the fraction is small and the second is that its actually really hard technically so the intersection between evil and competent is small in terms of and thats the and by the way to really annihilate humanity youd have to have sort of the nuclear winter phenomenon which is not one person shooting or even 10 bombs youd have to have some automated system that detonates a million bombs or whatever many thousands we have so extreme evil combined with extreme competence and to start with building some stupid system that would automatically dr strangelove type of thing you know i mean look we could have some nuclear bomb go off in some major city in the world i think thats actually quite likely even in my lifetime i dont think thats an unlikely thing and itd be a tragedy but it wont be an existential threat and its the same as you know the virus of 1917 whatever it was you know the influenza these bad things can happen and the plague and so on we cant always prevent them we always try but we cant but theyre not existential threats until we combine all those crazy things together so on the spectrum of intelligence from zero to human do you have a sense of whether its possible to create several orders of magnitude or at least double that of human intelligence talking about neuro context i think its the wrong thing to say double the intelligence break it down into different components can i make something thats a million times fast than a human brain yes i can do that could i make something that is has a lot more storage than the human brain yes i could do that more common more copies of common can i make something that attaches to different sensors than human brain yes i can do that could i make something thats distributed so these people yeah we talked early about the departure of the neocortex voting they dont have to be co located like you know they can be all around the place i could do that too those are the levers i have but is it more intelligent well it depends what i train it on what is it doing if its well so heres the thing so lets say larger neocortex and or whatever size that allows for higher and higher hierarchies to form were talking about reference frames and concepts could i have something thats a super physicist or a super mathematician yes and the question is once you have a super physicist will they be able to understand something do you have a sense that it will be orders of math like us compared to ants could we ever understand it yeah most people cannot understand general relativity its a really hard thing to get i mean yeah you can paint it in a fuzzy picture stretchy space you know but the field equations to do that and the deep intuitions are really really hard and ive tried im unable to do it like its easy to get special relativity but general relativity man thats too much and so we already live with this to some extent the vast majority of people cant understand actually what the vast majority of other people actually know were just either we dont have the effort to or we cant or we dont have time or just not smart enough whatever but we have ways of communicating einstein has spoken in a way that i can understand hes given me analogies that are useful i can use those analogies from my own work and think about concepts that are similar its not stupid its not like hes existing some other plane and theres no connection with my plane in the world here so that will occur it already has occurred thats what my point of this story is it already has occurred we live it every day one could argue that when we create machine intelligence that think a million times faster than us that itll be so far we cant make the connections but you know at the moment everything that seems really really hard to figure out in the world when you actually figure it out its not that hard you know almost everyone can understand the multiverses almost everyone can understand quantum physics almost everyone can understand these basic things even though hardly any people could figure those things out yeah but really understand but you dont need to really only a few people really understand you need to only understand the projections the sprinkles of the useful insights from that that was my example of einstein right his general theory of relativity is one thing that very very very few people can get and what if we just said those other few people are also artificial intelligences how bad is that in some sense they are right yeah they say already i mean einstein wasnt a really normal person he had a lot of weird quirks and so did the other people who worked with him so you know maybe they already were sort of this astral plane of intelligence that we live with it already its not a problem its still useful and you know so do you think we are the only intelligent life out there in the universe i would say that intelligent life has and will exist elsewhere in the universe ill say that there was a question about contemporaneous intelligence life which is hard to even answer when we think about relativity and the nature of space time cant say what exactly is this time someplace else in the world but i think its you know i do worry a lot about the filter idea which is that perhaps intelligent species dont last very long and so we havent been around very long and as a technological species weve been around for almost nothing you know what 200 years something like that and we dont have any data a good data point on whether its likely that well survive or not so do i think that there have been intelligent life elsewhere in the universe almost certainly of course in the past in the future yes does it survive for a long time i dont know this is another reason im excited about our work is our work meaning the general world of ai i think we can build intelligent machines that outlast us you know they dont have to be tied to earth they dont have to you know im not saying theyre recreating you know aliens im just saying if i asked myself and this might be a good point to end on here if i asked myself you know whats special about our species were not particularly interesting physically we dont fly were not good swimmers were not very fast were not very strong you know its our brain thats the only thing and we are the only species on this planet thats built the model of the world that extends beyond what we can actually sense were the only people who know about the far side of the moon and the other universes and i mean other galaxies and other stars and about what happens in the atom theres no that knowledge doesnt exist anywhere else its only in our heads cats dont do it dogs dont do it monkeys dont do it its just on and that is what weve created thats unique not our genes its knowledge and if i asked me what is the legacy of humanity what should our legacy be it should be knowledge we should preserve our knowledge in a way that it can exist beyond us and i think the best way of doing that in fact you have to do it is it has to go along with intelligent machines that understand that knowledge its a very broad idea but we should be thinking i call it a state planning for humanity we should be thinking about what we wanna leave behind when as a species were no longer here and thatll happen sometime sooner or later its gonna happen and understanding intelligence and creating intelligence gives us a better chance to prolong it does give us a better chance to prolong life yes it gives us a chance to live on other planets but even beyond that i mean our solar system will disappear one day just given enough time so i dont know i doubt well ever be able to travel to other things but we could tell the stars but we could send intelligent machines to do that so you have an optimistic a hopeful view of our knowledge of the echoes of human civilization living through the intelligent systems we create oh totally well i think the intelligent systems we create are in some sense the vessel for bringing them beyond earth or making them last beyond humans themselves how do you feel about that that they wont be human quote unquote who cares human what is human our species are changing all the time human today is not the same as human just 50 years ago what is human do we care about our genetics why is that important as i point out our genetics are no more interesting than a bacteriums genetics its no more interesting than a monkeys genetics what we have whats unique and whats valuable is our knowledge what weve learned about the world and that is the rare thing thats the thing we wanna preserve its who cares about our genes thats not its the knowledge its the knowledge thats a really good place to end thank you so much for talking to me no it was fun and weve only had the neocortex for a few 100000 years so thats like nothing okay so is it likely well it certainly isnt something that happened right away on earth and there were multiple steps to get there so i would say its probably not gonna be something that would happen instantaneously on other planets that might have life it might take several billion years on average is it likely i dont know but youd have to survive for several billion years to find out probably is it a big leap yeah i think it is a qualitative difference in all other evolutionary steps i can try to describe that if youd like sure in which way yeah i can tell you how pretty much lets start with a little preface many of the things that humans are able to do do not have obvious survival advantages precedent we could create music is that is there a really survival advantage to that maybe maybe not what about mathematics is there a real survival advantage to mathematics well you could stretch it you can try to figure these things out right but most of evolutionary history everything had immediate survival advantages to it so ill tell you a story which i like may or may not be true but the story goes as follows organisms have been evolving for since the beginning of life here on earth and adding this sort of complexity onto that and this sort of complexity onto that and the brain itself is evolved this way in fact theres old parts and older parts and older older parts of the brain that kind of just keeps calming on new things and we keep adding capabilities when we got to the neocortex initially it had a very clear survival advantage in that it produced better vision and better hearing and better touch and maybe and so on but what i think happens is that evolution discovered it took a mechanism and this is in our recent theories but it took a mechanism evolved a long time ago for navigating in the world for knowing where you are these are the so called grid cells and place cells of an old part of the brain and it took that mechanism for building maps of the world and knowing where you are on those maps and how to navigate those maps and turns it into a sort of a slimmed down idealized version of it and that idealized version could now apply to building maps of other things maps of coffee cups and maps of phones maps of mathematics concepts almost concepts yes and not just almost exactly and so and it just started replicating this stuff right you just think more and more and more so we went from being sort of dedicated purpose neural hardware to solve certain problems that are important to survival to a general purpose neural hardware that could be applied to all problems and now its escaped the orbit of survival we are now able to apply it to things which we find enjoyment but arent really clearly survival characteristics and that it seems to only have happened in humans to the large extent and so thats whats going on where we sort of have weve sort of escaped the gravity of evolutionary pressure in some sense in the neocortex and it now does things which are not that are really interesting discovering models of the universe which may not really help us does it matter how does it help us surviving knowing that there might be multiverses or that there might be the age of the universe or how do various stellar things occur it doesnt really help us survive at all but we enjoy it and thats what happened or at least not in the obvious way perhaps it is required if you look at the entire universe in an evolutionary way its required for us to do interplanetary travel and therefore survive past our own sun but you know lets not get too yeah but evolution works at one time frame its survival if you think of survival of the phenotype survival of the individual what youre talking about there is spans well beyond that so theres no genetic im not transferring any genetic traits to my children that are gonna help them survive better on mars totally different mechanism thats right so lets get into the new as youve mentioned this idea of the i dont know if you have a nice name thousand we call it the thousand brain theory of intelligence i like it can you talk about this idea of a spatial view of concepts and so on yeah so can i just describe sort of the theres an underlying core discovery which then everything comes from that thats a very simple this is really what happened we were deep into problems about understanding how we build models of stuff in the world and how we make predictions about things and i was holding a coffee cup just like this in my hand and my finger was touching the side my index finger and then i moved it to the top and i was gonna feel the rim at the top of the cup and i asked myself a very simple question i said well first of all i say i know that my brain predicts what its gonna feel before it touches it you can just think about it and imagine it and so we know that the brains making predictions all the time so the question is what does it take to predict that and theres a very interesting answer first of all it says the brain has to know its touching a coffee cup it has to have a model of a coffee cup it needs to know where the finger currently is on the cup relative to the cup because when i make a movement it needs to know where its going to be on the cup after the movement is completed relative to the cup and then it can make a prediction about what its gonna sense so this told me that the neocortex which is making this prediction needs to know that its sensing its touching a cup and it needs to know the location of my finger relative to that cup in a reference frame of the cup it doesnt matter where the cup is relative to my body it doesnt matter its orientation none of that matters its where my finger is relative to the cup which tells me then that the neocortex has a reference frame thats anchored to the cup because otherwise i wouldnt be able to say the location and i wouldnt be able to predict my new location and then we quickly very instantly can say well every part of my skin could touch this cup and therefore every part of my skin is making predictions and every part of my skin must have a reference frame that its using to make predictions so the big idea is that throughout the neocortex there are everything is being stored and referenced in reference frames you can think of them like xyz reference frames but theyre not like that we know a lot about the neural mechanisms for this but the brain thinks in reference frames and as an engineer if youre an engineer this is not surprising youd say if i wanted to build a cad model of the coffee cup well i would bring it up and some cad software and i would assign some reference frame and say this features at this locations and so on but the fact that this the idea that this is occurring throughout the neocortex everywhere it was a novel idea and then a zillion things fell into place after that a zillion so now we think about the neocortex as processing information quite differently than we used to do it we used to think about the neocortex as processing sensory data and extracting features from that sensory data and then extracting features from the features very much like a deep learning network does today but thats not how the brain works at all the brain works by assigning everything every input everything to reference frames and there are thousands hundreds of thousands of them active at once in your neocortex its a surprising thing to think about but once you sort of internalize this you understand that it explains almost every almost all the mysteries weve had about this structure so one of the consequences of that is that every small part of the neocortex say a millimeter square and theres 150000 of those so its about 150000 square millimeters if you take every little square millimeter of the cortex its got some input coming into it and its gonna have reference frames where its assigned that input to and each square millimeter can learn complete models of objects so what do i mean by that if im touching the coffee cup well if i just touch it in one place i cant learn what this coffee cup is because im just feeling one part but if i move it around the cup and touch it at different areas i can build up a complete model of the cup because im now filling in that three dimensional map which is the coffee cup i can say oh what am i feeling at all these different locations thats the basic idea its more complicated than that but so through time and we talked about time earlier through time even a single column which is only looking at or a single part of the cortex which is only looking at a small part of the world can build up a complete model of an object and so if you think about the part of the brain which is getting input from all my fingers so theyre spread across the top of your head here this is the somatosensory cortex theres columns associated with all the different areas of my skin and what we believe is happening is that all of them are building models of this cup every one of them or things theyre not all building not every column or every part of the cortex builds models of everything but theyre all building models of something and so you have so when i touch this cup with my hand there are multiple models of the cup being invoked if i look at it with my eyes there are again many models of the cup being invoked because each part of the visual system the brain doesnt process an image thats a misleading idea its just like your fingers touching the cup so different parts of my retina are looking at different parts of the cup and thousands and thousands of models of the cup are being invoked at once and theyre all voting with each other trying to figure out whats going on so thats why we call it the thousand brains theory of intelligence because there isnt one model of a cup there are thousands of models of this cup there are thousands of models of your cellphone and about cameras and microphones and so on its a distributed modeling system which is very different than the way people have thought about it and so thats a really compelling and interesting idea i have two first questions so one on the ensemble part of everything coming together you have these thousand brains how do you know which one has done the best job of forming the great question let me try to explain it theres a problem thats known in neuroscience called the sensor fusion problem yes and so the idea is theres something like oh the image comes from the eye theres a picture on the retina and then it gets projected to the neocortex oh by now its all spread out all over the place and its kind of squirrely and distorted and pieces are all over the it doesnt look like a picture anymore when does it all come back together again or you might say well yes but i also have sounds or touches associated with the cup so im seeing the cup and touching the cup how do they get combined together again so its called the sensor fusion problem as if all these disparate parts have to be brought together into one model someplace thats the wrong idea the right idea is that youve got all these guys voting theres auditory models of the cup theres visual models of the cup theres tactile models of the cup in the vision system there might be ones that are more focused on black and white and ones focusing on color it doesnt really matter theres just thousands and thousands of models of this cup and they vote they dont actually come together in one spot just literally think of it this way imagine you have these columns that are like about the size of a little piece of spaghetti like a two and a half millimeters tall and about a millimeter in wide theyre not physical but you could think of them that way and each ones trying to guess what this thing is or touching now they can do a pretty good job if theyre allowed to move over time so i can reach my hand into a black box and move my finger around an object and if i touch enough spaces i go okay now i know what it is but often we dont do that often i can just reach and grab something with my hand all at once and i get it or if i had to look through the world through a straw so im only invoking one little column i can only see part of something because i have to move the straw around but if i open my eyes i see the whole thing at once so what we think is going on is all these little pieces of spaghetti if you will all these little columns in the cortex are all trying to guess what it is that theyre sensing theyll do a better guess if they have time and can move over time so if i move my eyes i move my fingers but if they dont they have a poor guess its a probabilistic guess of what they might be touching now imagine they can post their probability at the top of a little piece of spaghetti each one of them says i think and its not really a probability distribution its more like a set of possibilities in the brain it doesnt work as a probability distribution it works as more like what we call a union so you could say and one column says i think it could be a coffee cup a soda can or a water bottle and another column says i think it could be a coffee cup or a telephone or a camera or whatever right and all these guys are saying what they think it might be and theres these long range connections in certain layers in the cortex so theres in some layers in some cells types in each column send the projections across the brain and thats the voting occurs and so theres a simple associative memory mechanism weve described this in a recent paper and weve modeled this that says they can all quickly settle on the only or the one best answer for all of them if there is a single best answer they all vote and say yep its gotta be the coffee cup and at that point they all know its a coffee cup and at that point everyone acts as if its a coffee cup theyre like yep we know its a coffee even though ive only seen one little piece of this world i know its a coffee cup im touching or im seeing or whatever and so you can think of all these columns are looking at different parts in different places different sensory input different locations theyre all different but this layer thats doing the voting it solidifies its just like it crystallizes and says oh we all know what were doing and so you dont bring these models together in one model you just vote and theres a crystallization of the vote great thats at least a compelling way to think about the way you form a model of the world now you talk about a coffee cup do you see this as far as i understand you are proposing this as well that this extends to much more than coffee cups yeah it does or at least the physical world it expands to the world of concepts yeah it does and well first the primary thing is evidence for that is that the regions of the neocortex that are associated with language or high level thought or mathematics or things like that they look like the regions of the neocortex that process vision hearing and touch they dont look any different or they look only marginally different and so one would say well if vernon mountcastle who proposed that all the parts of the neocortex do the same thing if hes right then the parts that are doing language or mathematics or physics are working on the same principle they must be working on the principle of reference frames so thats a little odd thought but of course we had no prior idea how these things happen so lets go with that and we in our recent paper we talked a little bit about that ive been working on it more since i have better ideas about it now im sitting here very confident that thats whats happening and i can give you some examples that help you think about that its not we understand it completely but i understand it better than ive described it in any paper so far so but we did put that idea out there it says okay this is its a good place to start you know and the evidence would suggest its how its happening and then we can start tackling that problem one piece at a time like what does it mean to do high level thought what does it mean to do language how would that fit into a reference frame framework yeah so theres a i dont know if you could tell me if theres a connection but theres an app called anki that helps you remember different concepts and they talk about like a memory palace that helps you remember completely random concepts by trying to put them in a physical space in your mind and putting them next to each other its called the method of loci loci yeah for some reason that seems to work really well now thats a very narrow kind of application of just remembering some facts but thats a very very telling one yes exactly so this seems like youre describing a mechanism why this seems to work so basically the way what we think is going on is all things you know all concepts all ideas words everything you know are stored in reference frames and so if you want to remember something you have to basically navigate through a reference frame the same way a rat navigates through a maze and the same way my finger navigates to this coffee cup you are moving through some space and so if you have a random list of things you were asked to remember by assigning them to a reference frame youve already know very well to see your house right and the idea of the method of loci is you can say okay in my lobby im going to put this thing and then the bedroom i put this one i go down the hall i put this thing and then you want to recall those facts or recall those things you just walk mentally you walk through your house youre mentally moving through a reference frame that you already had and that tells you theres two things that are really important about that it tells us the brain prefers to store things in reference frames and that the method of recalling things or thinking if you will is to move mentally through those reference frames you could move physically through some reference frames like i could physically move through the reference frame of this coffee cup i can also mentally move through the reference frame of the coffee cup imagining me touching it but i can also mentally move my house and so now we can ask yourself or are all concepts stored this way there was some recent research using human subjects in fmri and im going to apologize for not knowing the name of the scientists who did this but what they did is they put humans in this fmri machine which is one of these imaging machines and they gave the humans tasks to think about birds so they had different types of birds and birds that look big and small and long necks and long legs things like that and what they could tell from the fmri was a very clever experiment you get to tell when humans were thinking about the birds that the birds the knowledge of birds was arranged in a reference frame similar to the ones that are used when you navigate in a room that these are called grid cells and there are grid cell like patterns of activity in the neocortex when they do this so its a very clever experiment and what it basically says that even when youre thinking about something abstract and youre not really thinking about it as a reference frame it tells us the brain is actually using a reference frame and its using the same neural mechanisms these grid cells are the basic same neural mechanism that we propose that grid cells which exist in the old part of the brain the entorhinal cortex that that mechanism is now similar mechanism is used throughout the neocortex its the same nature to preserve this interesting way of creating reference frames and so now they have empirical evidence that when you think about concepts like birds that youre using reference frames that are built on grid cells so thats similar to the method of loci but in this case the birds are related so they create their own reference frame which is consistent with bird space and when you think about something you go through that you can make the same example lets take mathematics lets say you wanna prove a conjecture what is a conjecture a conjecture is a statement you believe to be true but you havent proven it and so it might be an equation i wanna show that this is equal to that and you have some places you start with you say well i know this is true and i know this is true and i think that maybe to get to the final proof i need to go through some intermediate results what i believe is happening is literally these equations or these points are assigned to a reference frame a mathematical reference frame and when you do mathematical operations a simple one might be multiply or divide but you might be a little plus transform or something else that is like a movement in the reference frame of the math and so youre literally trying to discover a path from one location to another location in a space of mathematics and if you can get to these intermediate results then you know your map is pretty good and you know youre using the right operations much of what we think about is solving hard problems is designing the correct reference frame for that problem figuring out how to organize the information and what behaviors i wanna use in that space to get me there yeah so if you dig in an idea of this reference frame whether its the math you start a set of axioms to try to get to proving the conjecture can you try to describe maybe take a step back how you think of the reference frame in that context is it the reference frame that the axioms are happy in is it the reference frame that might contain everything is it a changing thing as you you have many many reference frames i mean in fact the way the theory the thousand brain theory of intelligence says that every single thing in the world has its own reference frame so every word has its own reference frames and we can talk about this the mathematics work out this is no problem for neurons to do this but how many reference frames does a coffee cup have well its on a table lets say you ask how many reference frames could a column in my finger thats touching the coffee cup have because there are many many copy there are many many models of the coffee cup so the coffee there is no one model of a coffee cup there are many models of a coffee cup and you could say well how many different things can my finger learn is this the question you want to ask imagine i say every concept every idea everything youve ever know about that you can say i know that thing has a reference frame associated with it and what we do when we build composite objects we assign reference frames to point another reference frame so my coffee cup has multiple components to it its got a limb its got a cylinder its got a handle and those things have their own reference frames and theyre assigned to a master reference frame which is called this cup and now i have this numenta logo on it well thats something that exists elsewhere in the world its its own thing so it has its own reference frame so we now have to say how can i assign the numenta logo reference frame onto the cylinder or onto the coffee cup so its all we talked about this in the paper that came out in december of this last year the idea of how you can assign reference frames to reference frames how neurons could do this so well my question is even though you mentioned reference frames a lot i almost feel its really useful to dig into how you think of what a reference frame is i mean it was already helpful for me to understand that you think of reference frames as something there is a lot of okay so lets just say that were gonna have some neurons in the brain not many actually 10000 20000 are gonna create a whole bunch of reference frames what does it mean what is a reference frame first of all these reference frames are different than the ones you might be used to we know lots of reference frames for example we know the cartesian coordinates x y z thats a type of reference frame we know longitude and latitude thats a different type of reference frame if i look at a printed map you might have columns a through m and rows one through 20 thats a different type of reference frame its kind of a cartesian coordinate reference frame the interesting thing about the reference frames in the brain and we know this because these have been established through neuroscience studying the entorhinal cortex so im not speculating here okay this is known neuroscience in an old part of the brain the way these cells create reference frames they have no origin so what its more like you have a point a point in some space and you given a particular movement you can then tell what the next point should be and you can then tell what the next point would be and so on you can use this to calculate how to get from one point to another so how do i get from my house to my home or how do i get my finger from the side of my cup to the top of the cup how do i get from the axioms to the conjecture so its a different type of reference frame and i can if you want i can describe in more detail i can paint a picture of how you might want to think about that its really helpful to think its something you can move through but is there is it helpful to think of it as spatial in some sense or is there something thats more no its definitely spatial its spatial in a mathematical sense how many dimensions can it be a crazy number of dimensions well thats an interesting question in the old part of the brain the entorhinal cortex they studied rats and initially it looks like oh this is just two dimensional its like the rat is in some box in the maze or whatever and they know where the rat is using these two dimensional reference frames to know where it is in the maze we said well okay but what about bats thats a mammal and they fly in three dimensional space how do they do that they seem to know where they are right so this is a current area of active research and it seems like somehow the neurons in the entorhinal cortex can learn three dimensional space we just two members of our team along with elif fett from mit just released a paper this literally last week its on biorxiv where they show that you can if you the way these things work and i wont get unless you want to i wont get into the detail but grid cells can represent any n dimensional space its not inherently limited you can think of it this way if you had two dimensional the way it works is you had a bunch of two dimensional slices thats the way these things work theres a whole bunch of two dimensional models and you can just you can slice up any n dimensional space with two dimensional projections so and you could have one dimensional models so theres nothing inherent about the mathematics about the way the neurons do this which constrain the dimensionality of the space which i think was important so obviously i have a three dimensional map of this cup maybe its even more than that i dont know but its clearly a three dimensional map of the cup i dont just have a projection of the cup but when i think about birds or when i think about mathematics perhaps its more than three dimensions who knows so in terms of each individual column building up more and more information over time do you think that mechanism is well understood in your mind youve proposed a lot of architectures there is that a key piece or is it is the big piece the thousand brain theory of intelligence the ensemble of it all well i think theyre both big i mean clearly the concept as a theorist the concept is most exciting right the high level concept the high level concept this is a totally new way of thinking about how the neocortex works so that is appealing it has all these ramifications and with that as a framework for how the brain works you can make all kinds of predictions and solve all kinds of problems now were trying to work through many of these details right now okay how do the neurons actually do this well it turns out if you think about grid cells and place cells in the old parts of the brain theres a lot thats known about them but theres still some mysteries theres a lot of debate about exactly the details how these work and what are the signs and we have that still that same level of detail that same level of concern what we spend here most of our time doing is trying to make a very good list of the things we dont understand yet thats the key part here what are the constraints its not like oh this thing seems to work were done no its like okay it kind of works but these are other things we know it has to do and its not doing those yet i would say were well on the way here were not done yet theres a lot of trickiness to this system but the basic principles about how different layers in the neocortex are doing much of this we understand but theres some fundamental parts that we dont understand as well so what would you say is one of the harder open problems or one of the ones that have been bothering you keeping you up at night the most oh well right now this is a detailed thing that wouldnt apply to most people okay sure but you want me to answer that question yeah please weve talked about as if oh to predict what youre going to sense on this coffee cup i need to know where my finger is gonna be on the coffee cup that is true but its insufficient think about my finger touches the edge of the coffee cup my finger can touch it at different orientations i can rotate my finger around here and that doesnt change i can make that prediction and somehow so its not just the location theres an orientation component of this as well this is known in the old parts of the brain too theres things called head direction cells which way the rat is facing its the same kind of basic idea so if my finger were a rat you know in three dimensions i have a three dimensional orientation and i have a three dimensional location if i was a rat i would have a you might think of it as a two dimensional location a two dimensional orientation a one dimensional orientation like just which way is it facing so how the two components work together how it is that i combine orientation the orientation of my sensor as well as the location is a tricky problem and i think ive made progress on it so at a bigger version of that so perspective is super interesting but super specific yeah i warned you no no no thats really good but theres a more general version of that do you think context matters the fact that were in a building in north america that we in the day and age where we have mugs i mean theres all this extra information that you bring to the table about everything else in the room thats outside of just the coffee cup how does it get connected do you think yeah and that is another really interesting question im gonna throw that under the rubric or the name of attentional problems first of all we have this model i have many many models and also the question does it matter well it matters for certain things of course it does maybe what we think of that as a coffee cup in another part of the world is viewed as something completely different or maybe our logo which is very benign in this part of the world it means something very different in another part of the world so those things do matter i think the way to think about it is the following', 'the following is a conversation with sean carroll hes a theoretical physicist at caltech specializing in quantum mechanics gravity and cosmology hes the author of several popular books one on the arrow of time called from eternity to here one on the higgs boson called particle at the end of the universe and one on science and philosophy called the big picture on the origins of life meaning and the universe itself he has an upcoming book on quantum mechanics that you can preorder now called something deeply hidden he writes one of my favorite blogs on his website preposterousuniversecom i recommend clicking on the greatest hits link that lists accessible interesting posts on the arrow of time dark matter dark energy the big bang general relativity string theory quantum mechanics and the big meta questions about the philosophy of science god ethics politics academia and much much more finally and perhaps most famously hes the host of a podcast called mindscape that you should subscribe to and support on patreon along with the joe rogan experience sam harriss making sense and dan carlins hardcore history seans mindscape podcast is one of my favorite ways to learn new ideas or explore different perspectives and ideas that i thought i understood it was truly an honor to meet and spend a couple hours with sean its a bit heartbreaking to say that for the first time ever the audio recorder for this podcast died in the middle of our conversation theres technical reasons for this having to do with phantom power that i now understand and will avoid it took me one hour to notice and fix the problem so much like the universe is 68 dark energy roughly the same amount from this conversation was lost except in the memories of the two people involved and in my notes im sure well talk again and continue this conversation on this podcast or on seans and of course i look forward to it this is the artificial intelligence podcast if you enjoy it subscribe on youtube itunes support it on patreon or simply connect with me on twitter at lex friedman and now heres my conversation with sean carroll what do you think is more interesting and impactful understanding how the universe works at a fundamental level or understanding how the human mind works you know of course this is a crazy meaningless unanswerable question in some sense because theyre both very interesting and theres no absolute scale of interestingness that we can rate them on theres a glib answer that says the human brain is part of the universe right and therefore understanding the universe is more fundamental than understanding the human brain but do you really believe that once we understand the fundamental way the universe works at the particle level the forces we would be able to understand how the mind works no certainly not we cannot understand how ice cream works just from understanding how particles work right so im a big believer in emergence im a big believer that there are different ways of talking about the world beyond just the most fundamental microscopic one you know when we talk about tables and chairs and planets and people were not talking the language of particle physics and cosmology so but understanding the universe you didnt say just at the most fundamental level right so understanding the universe at all levels is part of that i do think you know to be a little bit more fair to the question there probably are general principles of complexity biology information processing memory knowledge creativity that go beyond just the human brain right and maybe one could count understanding those as part of understanding the universe the human brain as far as we know is the most complex thing in the universe so theres its certainly absurd to think that by understanding the fundamental laws of particle physics you get any direct insight on how the brain works but then theres this step from the fundamentals of particle physics to information processing which a lot of physicists and philosophers may be a little bit carelessly take when they talk about artificial intelligence do you think of the universe as a kind of a computational device no to be like the honest answer there is no theres a sense in which the universe processes information clearly theres a sense in which the universe is like a computer clearly but in some sense i think i tried to say this once on my blog and no one agreed with me but the universe is more like a computation than a computer because the universe happens once a computer is a general purpose machine right that you can ask it different questions even a pocket calculator right and its set up to answer certain kinds of questions the universe isnt that so information processing happens in the universe but its not what the universe is and i know your mit colleague seth lloyd feels very differently about this right well youre thinking of the universe as a closed system i am so what makes a computer more like a pc like a computing machine is that theres a human that every once comes up to it and moves the mouse around so input gives it input gives it input and thats why youre saying its just a computation a deterministic thing thats just unrolling but the immense complexity of it is nevertheless like processing theres a state and then it changes with good rules and theres a sense for a lot of people that if the brain operates the human brain operates within that world then its simply just a small subset of that and so theres no reason we cant build arbitrarily great intelligences yeah do you think of intelligence in this way intelligence is tricky i dont have a definition of it offhand so i remember this panel discussion that i saw on youtube i wasnt there but seth lloyd was on the panel and so was martin rees the famous astrophysicist and seth gave his shtick for why the universe is a computer and explained this and martin rees said so what is not a computer and seth was like oh thats a good question im not sure because if you have a sufficiently broad definition of what a computer is then everything is right and the simile or the analogy gains force when it excludes some things you know is the moon going around the earth performing a computation i can come up with definitions in which the answer is yes but its not a very useful computation i think that its absolutely helpful to think about the universe in certain situations certain contexts as an information processing device im even guilty of writing a paper called quantum circuit cosmology where we modeled the whole universe as a quantum circuit as a circuit as a circuit yeah with qubits kind of thing with qubits basically right yeah so and qubits becoming more and more entangled so do we wanna digress a little bit lets do it its kind of fun so heres a mystery about the universe that is so deep and profound that nobody talks about it space expands right and we talk about in a certain region of space a certain number of degrees of freedom a certain number of ways that the quantum fields and the particles in that region can arrange themselves that number of degrees of freedom in a region of space is arguably finite we actually dont know how many there are but theres a very good argument that says its a finite number so as the universe expands and space gets bigger are there more degrees of freedom if its an infinite number it doesnt really matter infinity times two is still infinity but if its a finite number then theres more space so theres more degrees of freedom so where did they come from that would mean the universe is not a closed system theres more degrees of freedom popping into existence so what we suggested was that there are more degrees of freedom and its not that theyre not there to start but theyre not entangled to start so the universe that you and i know of the three dimensions around us that we see we said those are the entangled degrees of freedom making up space time and as the universe expands there are a whole bunch of qubits in their zero state that become entangled with the rest of space time through the action of these quantum circuits so what does it mean that theres now more degrees of freedom as they become more entangled yeah so as the universe expands thats right so theres more and more degrees of freedom that are entangled that are playing part playing the role of part of the entangled space time structure so the basic the underlying philosophy is that space time itself arises from the entanglement of some fundamental quantum degrees of freedom wow okay so at which point is most of the entanglement happening are we talking about close to the big bang are we talking about throughout the time of the life throughout history yeah so the idea is that at the big bang almost all the degrees of freedom that the universe could have were there but they were unentangled with anything else and thats a reflection of the fact that the big bang had a low entropy it was a very simple very small place and as space expands more and more degrees of freedom become entangled with the rest of the world well i have to ask john carroll what do you think of the thought experiment from nick bostrom that were living in a simulation so i think let me contextualize that a little bit more i think people dont actually take this thought experiments i think its quite interesting its not very useful but its quite interesting from the perspective of ai a lot of the learning that can be done usually happens in simulation from artificial examples and so its a constructive question to ask how difficult is our real world to simulate right which is kind of a dual part of if were living in a simulation and somebody built that simulation if you were to try to do it yourself how hard would it be so obviously we could be living in a simulation if you just want the physical possibility then i completely agree that its physically possible i dont think that we actually are so take this one piece of data into consideration you know we live in a big universe okay theres two trillion galaxies in our observable universe with 200 billion stars in each galaxy et cetera it would seem to be a waste of resources to have a universe that big going on just to do a simulation so in other words i want to be a good bayesian i want to ask under this hypothesis what do i expect to see so the first thing i would say is i wouldnt expect to see a universe that was that big okay the second thing is i wouldnt expect the resolution of the universe to be as good as it is so its always possible that if our superhuman simulators only have finite resources that they dont render the entire universe right that the part that is out there the two trillion galaxies isnt actually being simulated fully okay but then the obvious extrapolation of that is that only i am being simulated fully like the rest of you are just non player characters right im the only thing that is real the rest of you are just chat bots beyond this wall i see the wall but there is literally nothing on the other side of the wall that is sort of the bayesian prediction thats what it would be like to do an efficient simulation of me so like none of that seems quite realistic i dont see i hear the argument that its just possible and easy to simulate lots of things i dont see any evidence from what we know about our universe that we look like a simulated universe now maybe you can say well we dont know what it would look like but thats just abandoning your bayesian responsibilities like your job is to say under this theory heres what you would expect to see yeah so certainly if you think about simulation as a thing thats like a video game where only a small subset is being rendered but say the entire all the laws of physics the entire closed system of the quote unquote universe it had a creator yeah its always possible right so thats not useful to think about when youre thinking about physics the way nick bostrom phrases it if its possible to simulate a universe eventually well do it right you can use that by the way for a lot of things well yeah but i guess the question is how hard is it to create a universe i wrote a little blog post about this and maybe im missing something but theres an argument that says not only that it might be possible to simulate a universe but probably if you imagine that you actually attribute consciousness and agency to the little things that were simulating to our little artificial beings theres probably a lot more of them than there are ordinary organic beings in the universe or there will be in the future right so theres an argument that not only is being a simulation possible its probable because in the space of all living consciousnesses most of them are being simulated right most of them are not at the top level i think that argument must be wrong because it follows from that argument that if were simulated but we can also simulate other things well but if we can simulate other things they can simulate other things right if we give them enough power and resolution and ultimately well reach a bottom because the laws of physics in our universe have a bottom were made of atoms and so forth so there will be the cheapest possible simulations and if you believe the original argument you should conclude that we should be in the cheapest possible simulation because thats where most people are but we dont look like that it doesnt look at all like were at the edge of resolution that were 16 bit things it seems much easier to make much lower level things than we are and also i questioned the whole approach to the anthropic principle that says we are typical observers in the universe i think that thats not actually i think that theres a lot of selection that we can do that were typical within things we already know but not typical within all of the universe so do you think theres intelligent life however you would like to define intelligent life out there in the universe my guess is that there is not intelligent life in the observable universe other than us simply on the basis of the fact that the likely number of other intelligent species in the observable universe theres two likely numbers zero or billions and if there had been billions you would have noticed already for there to be literally like a small number like you know star trek theres a dozen intelligent civilizations in our galaxy but not a billion thats weird thats sort of bizarre to me its easy for me to imagine that there are zero others because theres just a big bottleneck to making multicellular life or technological life or whatever its very hard for me to imagine that theres a whole bunch out there that have somehow remained hidden from us the question id like to ask is what would intelligent life look like what i mean by that question and where its going is what if intelligent life is just in some very big ways different than the one that has on earth that theres all kinds of intelligent life that operates at different scales of both size and temporal right thats a great possibility because i think we should be humble about what intelligence is what life is we dont even agree on what life is much less what intelligent life is right so thats an argument for humility saying there could be intelligent life of a very different character right like you could imagine the dolphins are intelligent but never invent space travel because they live in the ocean and they dont have thumbs right so they never invent technology they never invent smelting maybe the universe is full of intelligent species that just dont make technology right thats compatible with the data i think and i think maybe what youre pointing at is even more out there versions of intelligence intelligence in intermolecular clouds or on the surface of a neutron star or in between the galaxies in giant things where the equivalent of a heartbeat is 100 million years on the one hand yes we should be very open minded about those things on the other hand all of us share the same laws of physics there might be something about the laws of physics even though we dont currently know exactly what that thing would be that makes meters and years the right length and timescales for intelligent life maybe not but were made of atoms atoms have a certain size we orbit stars or stars have a certain lifetime its not impossible to me that theres a sweet spot for intelligent life that we find ourselves in so im open minded either way im open minded either being humble and theres all sorts of different kinds of life or no theres a reason we just dont know it yet why life like ours is the kind of life thats out there yeah im of two minds too but i often wonder if our brains is just designed to quite obviously to operate and see the world in these timescales and were almost blind and the tools weve created for detecting things are blind to the kind of observation needed to see intelligent life at other scales well im totally open to that but so heres another argument i would make we have looked for intelligent life but weve looked at for it in the dumbest way we can by turning radio telescopes to the sky and why in the world would a super advanced civilization randomly beam out radio signals wastefully in all directions into the universe that just doesnt make any sense especially because in order to think that you would actually contact another civilization you would have to do it forever you have to keep doing it for millions of years that sounds like a waste of resources if you thought that there were other solar systems with planets around them where maybe intelligent life didnt yet exist but might someday you wouldnt try to talk to it with radio waves you would send a spacecraft out there and you would park it around there and it would be like from our point of view itd be like 2001 where there was a monolith monolith there could be an artifact in fact the other way works also right there could be artifacts in our solar system that have been put there by other technologically advanced civilizations and thats how we will eventually contact them we just havent explored the solar system well enough yet to find them the reason why we dont think about that is because were young and impatient right like it would take more than my lifetime to actually send something to another star system and wait for it and then come back so but if we start thinking on hundreds of thousands of years or million year time scales thats clearly the right thing to do are you excited by the thing that elon musk is doing with spacex in general space but the idea of space exploration even though your or your species is young and impatient yeah no i do think that space travel is crucially important long term even to other star systems and i think that many people overestimate the difficulty because they say look if you travel 1 the speed of light to another star system well be dead before we get there right and i think that its much easier and therefore when they write their science fiction stories they imagine wed go faster than the speed of light because otherwise theyre too impatient right were not gonna go faster than the speed of light but we could easily imagine that the human lifespan gets extended to thousands of years and once you do that then the stars are much closer effectively right and then whats a hundred year trip right so i think that thats gonna be the future the far future not my lifetime once again but baby steps unless your lifetime gets extended well its in a race against time right a friend of mine who actually thinks about these things said you know you and i are gonna die but i dont know about our grandchildren thats i dont know predicting the future is hard but thats at least a plausible scenario and so yeah no i think that as we discussed earlier there are threats to the earth known and unknown right having spread humanity and biology elsewhere is a really important longterm goal what kind of questions can science not currently answer but might soon when you think about the problems and the mysteries before us that may be within reach of science i think an obvious one is the origin of life we dont know how that happened theres a difficulty in knowing how it happened historically actually you know literally on earth but starting life from non life is something i kind of think were close to right were really you really think so like how difficult is it to start life well ive talked to people including on the podcast about this you know life requires three things life as we know it so theres a difference with life which who knows what it is and life as we know it which we can talk about with some intelligence so life as we know it requires compartmentalization you need like a little membrane around your cell metabolism you need to take in food and eat it and let that make you do things and then replication okay so you need to have some information about who you are that you pass down to future generations in the lab compartmentalization seems pretty easy not hard to make lipid bilayers that come into little cellular walls pretty easily metabolism and replication are hard but replication were close to people have made rna like molecules in the lab that i think the state of the art is theyre not able to make one molecule that reproduces itself but theyre able to make two molecules that reproduce each other so thats okay thats pretty close metabolism is harder believe it or not even though its sort of the most obvious thing but you want some sort of controlled metabolism and the actual cellular machinery in our bodies is quite complicated its hard to see it just popping into existence all by itself it probably took a while but were making progress and in fact i dont think were spending nearly enough money on it if i were the nsf i would flood this area with money because it would change our view of the world if we could actually make life in the lab and understand how it was made originally here on earth and im sure itd have some ripple effects that help cure disease and so on i mean just that understanding so synthetic biology is a wonderful big frontier where were making cells right now the best way to do that is to borrow heavily from existing biology right well craig venter several years ago created an artificial cell but all he did was not all he did it was a tremendous accomplishment but all he did was take out the dna from a cell and put in entirely new dna and let it boot up and go what about the leap to creating intelligent life on earth yeah again we define intelligence of course but lets just even say homo sapiens the modern intelligence in our human brain do you have a sense of whats involved in that leap and how big of a leap that is so ai would count in this or do you really want life do you want really an organism in some sense ai would count i think okay yeah of course of course ai would count well lets say artificial consciousness right so i do not think we are on the threshold of creating artificial consciousness i think its possible im not again very educated about how close we are but my impression is not that were really close because we understand how little we understand of consciousness and what it is so if we dont have any idea what it is its hard to imagine were on the threshold of making it ourselves but its doable its possible i dont see any obstacles in principle so yeah i would hold out some interest in that happening eventually i think in general consciousness i think we would be just surprised how easy consciousness is once we create intelligence i think consciousness is a thing thats just something we all fake well good no actually i like this idea that in fact consciousness is way less mysterious than we think because were all at every time at every moment less conscious than we think we are right we can fool things and i think that plus the idea that you not only have artificial intelligent systems but you put them in a body right give them a robot body that will help the faking a lot yeah i think creating consciousness in artificial consciousness is as simple as asking a roomba to say im conscious and refusing to be talked out of it could be it could be and i mean im almost being silly but thats what we do thats what we do with each other this is the kind of that consciousness is also a social construct and a lot of our ideas of intelligence is a social construct and so reaching that bar involves something thats beyond that doesnt necessarily involve the fundamental understanding of how you go from electrons to neurons to cognition no actually i think that is an extremely good point and in fact what it suggests is so yeah you referred to kate darling who i had on the podcast and who does these experiments with very simple robots but they look like animals and they can look like theyre experiencing pain and we human beings react very negatively to these little robots looking like theyre experiencing pain and what you wanna say is yeah but theyre just robots its not really pain right its just some electrons going around but then you realize you and i are just electrons going around and thats what pain is also and so what i would have an easy time imagining is that there is a spectrum between these simple little robots that kate works with and a human being where there are things that sort of by some strict definition turing test level thing are not conscious but nevertheless walk and talk like theyre conscious and it could be that the future is i mean siri is close right and so it might be the future has a lot more agents like that and in fact rather than someday going aha we have consciousness well just creep up on it with more and more accurate reflections of what we expect and in the future maybe the present for example we havent met before and youre basically assuming that im human as its a high probability at this time because the yeah but in the future there might be question marks around that right yeah no absolutely certainly videos are almost to the point where you shouldnt trust them already photos you cant trust right videos is easier to trust but were getting worse that were getting better at faking them right yeah so physical embodied people whats so hard about faking that so this is very depressing this conversation were having right now so i mean to me its exciting to me youre doing it so its exciting to you but its a sobering thought were very bad right at imagining what the next 50 years are gonna be like when were in the middle of a phase transition as we are right now yeah and i in general im not blind to all the threats i am excited by the power of technology to solve to protect us against the threats as they evolve im not as much as steven pinker optimistic about the world but in everything ive seen all of the brilliant people in the world that ive met are good people so the army of the good in terms of the development of technology is large okay youre way more optimistic than i am i think that goodness and badness are equally distributed among intelligent and unintelligent people i dont see much of a correlation there interesting neither of us have proof yeah exactly again opinions are free right nor definitions of good and evil we come without definitions or without data opinions so what kind of questions can science not currently answer and may never be able to answer in your view well the obvious one is what is good and bad what is right and wrong i think that there are questions that science tells us what happens what the world is and what it does it doesnt say what the world should do or what we should do because were part of the world but we are part of the world and we have the ability to feel like somethings right somethings wrong and to make a very long story very short i think that the idea of moral philosophy is systematizing our intuitions of what is right and what is wrong and science might be able to predict ahead of time what we will do but it wont ever be able to judge whether we should have done it or not so youre kind of unique in terms of scientists listen it doesnt have to do with podcasts but even just reaching out i think you referred to as sort of doing interdisciplinary science so you reach out and talk to people that are outside of your discipline which i always hope thats what science was for in fact i was a little disillusioned when i realized that academia is very siloed yeah and so the question is how at your own level how do you prepare for these conversations how do you think about these conversations how do you open your mind enough to have these conversations and it may be a little bit broader how can you advise other scientists to have these kinds of conversations not at the podcast the fact that youre doing a podcast is awesome other people get to hear them but its also good to have it without mics in general its a good question but a tough one to answer i think about a guy i know whos a personal trainer and he was asked on a podcast how do we psych ourselves up to do a workout how do we make that discipline to go and work out and hes like why are you asking me i cant stop working out i dont need to psych myself up so and likewise he asked me how do you get to have interdisciplinary conversations on all sorts of different things all sorts of different people im like thats what makes me go right like thats i couldnt stop doing that i did that long before any of them were recorded in fact a lot of the motivation for starting recording it was making sure i would read all these books that i had purchased right like all these books i wanted to read not enough time to read them and now if i have the motivation cause im gonna interview pat churchland im gonna finally read her book you know and its absolutely true that academia is extraordinarily siloed right we dont talk to people we rarely do and in fact when we do its punished you know like the people who do it successfully generally first became very successful within their little siloed discipline and only then did they start expanding out if youre a young person you know i have graduate students i try to be very very candid with them about this that its you know most graduate students are to not become faculty members right its a tough road and so live the life you wanna live but do it with your eyes open about what it does to your job chances and the more broad you are and the less time you spend hyper specializing in your field the lower your job chances are thats just an academic reality its terrible i dont like it but its a reality and for some people thats fine like theres plenty of people who are wonderful scientists who have zero interest in branching out and talking to things to anyone outside their field but it is disillusioning to me some of the you know romantic notion i had of the intellectual academic life is belied by the reality of it the idea that we should reach out beyond our discipline and that is a positive good is just so rare in universities that it may as well not exist at all but that said even though youre saying youre doing it like the personal trainer because you just cant help it youre also an inspiration to others like i could speak for myself you know i also have a career im thinking about right and without your podcast i may have not have been doing this at all right so it makes me realize that these kinds of conversations is kind of what science is about in many ways the reason we write papers this exchange of ideas is its much harder to do interdisciplinary papers i would say and conversations are easier so conversations is the beginning and in the field of ai its obvious that we should think outside of pure computer vision competitions on a particular data sets we should think about the broader impact of how this can be you know reaching out to physics to psychology to neuroscience and having these conversations so that youre an inspiration and so never know how the world changes i mean the fact that this stuff is out there and ive a huge number of people come up to me grad students really loving the podcast inspired by it and they will probably have that theyll be ripple effects when they become faculty and so on and so on we can end on a balance between pessimism and optimism and sean thank you so much for talking to me it was awesome no lex thank you very much for this conversation it was great', 'the following is a conversation with kai fu lee hes the chairman and ceo of cinovation ventures that manages a 2 billion dual currency investment fund with a focus on developing the next generation of chinese high tech companies hes the former president of google china and the founder of what is now called microsoft research asia an institute that trained many of the artificial intelligence leaders in china including ctos or ai execs at baidu tencent alibaba lenovo and huawei he was named one of the 100 most influential people in the world by time magazine hes the author of seven bestselling books in chinese and most recently the new york times bestseller called ai superpowers china silicon valley and the new world order he has unparalleled experience in working across major tech companies and governments and applications of ai and so he has a unique perspective on global innovation and the future of ai that i think is important to listen to and think about this is the artificial intelligence podcast if you enjoy it subscribe on youtube and itunes support it on patreon or simply connect with me on twitter at lex friedman and now heres my conversation with kaifu li i immigrated from russia to us when i was 13 you immigrated to us at about the same age the russian people the american people the chinese people each have a certain soul a spirit that permeates throughout the generations so maybe its a little bit of a poetic question but could you describe your sense of what defines the chinese soul i think the chinese soul of people today right were talking about people who have had centuries of burden because of the poverty that the country has gone through and suddenly shined with hope of prosperity in the past 40 years as china opened up and embraced market economy and undoubtedly there are two sets of pressures on the people that of the tradition that of facing difficult situations and that of hope of wanting to be the first to become successful and wealthy so thats a very strong hunger and a strong desire and strong work ethic that drives china forward and is there roots to not just this generation but before thats deeper than just the new economic developments is there something thats unique to china that you could speak to thats in the people yeah well the chinese tradition is about excellence dedication and results and the chinese exams and study subjects in schools have traditionally started from memorizing 10000 characters not an easy task to start with and further by memorizing his historic philosophers literature poetry so it really is probably the strongest rote learning mechanism created to make sure people had good memory and remember things extremely well thats i think at the same time suppresses the breakthrough innovation and also enhances the speed execution get results and that i think characterizes the historic basis of china thats interesting because theres echoes of that in russian education as well as rote memorization so you have to memorize a lot of poetry i mean theres just an emphasis on perfection in all forms thats not conducive to perhaps what youre speaking to which is creativity but you think that kind of education holds back the innovative spirit that you might see in the united states well it holds back the breakthrough innovative spirits that we see in the united states but it does not hold back the valuable execution oriented result oriented value creating engines which we see china being very successful so is there a difference between a chinese ai engineer today and an american ai engineer perhaps rooted in the culture that we just talked about or the education or the very soul of the people or no and what would your advice be to each if theres a difference well theres a lot thats similar because ai is about mastering sciences about using known technologies and trying new things but its also about picking from many parts of possible networks to use and different types of parameters to tune and that part is somewhat rote and it is also as anyone whos built ai products can tell you a lot about cleansing the data because ai runs better with more data and data is generally unstructured errorful and unclean and the effort to clean the data is immense so i think the better part of american engineering ai engineering process is to try new things to do things people havent done before and to use technology to solve most if not all problems so to make the algorithm work despite not so great data find error tolerant ways to deal with the data the chinese way would be to basically enumerate to the fullest extent all the possible ways by a lot of machines try lots of different ways to get it to work and spend a lot of resources and money and time cleaning up data that means the ai engineer may be writing data cleansing algorithms working with thousands of people who label or correct or do things with the data that is the incredible hard work that might lead to better results so the chinese engineer would rely on and ask for more and more and more data and find ways to cleanse them and make them work in the system and probably less time thinking about new algorithms that can overcome data or other issues so wheres your intuition where do you think the biggest impact in the next 10 years lies is it in some breakthrough algorithms or is it in just this at scale rigor a rigorous approach to data cleaning data organizing data onto the same algorithms what do you think the big impact in the applied world is well if youre really in the company and you have to deliver results using known techniques and enhancing data seems like the more expedient approach thats very low risk and likely to generate better and better results and thats why the chinese approach has done quite well now there are a lot of more challenging startups and problems such as autonomous vehicles medical diagnosis that existing algorithms probably wont solve and that would put the chinese approach more challenged and give them more breakthrough innovation approach more of an edge on those kinds of problems so let me talk to that a little more so my intuition personally is that data can take us extremely far so you brought up autonomous vehicles and medical diagnosis so your intuition is that huge amounts of data might not be able to completely help us solve that problem right so breaking that down further in autonomous vehicle i think huge amounts of data probably will solve trucks driving on highways which will deliver a significant value and china will probably lead in that and full l5 autonomous is likely to require new technologies we dont yet know and that might require academia and great industrial research both innovating and working together and in that case us has an advantage so the interesting question there is i dont know if youre familiar on the autonomous vehicle space and the developments with tesla and elon musk i am where they are in fact full steam ahead into this mysterious complex world of full autonomy l5 l4 l5 and theyre trying to solve that purely with data so the same kind of thing that youre saying is just for highway which is what a lot of people share your intuition theyre trying to solve with data so just to linger on that moment further do you think possible for them to achieve success with simply just a huge amount of this training on edge cases and difficult cases in urban environments not just highway and so on i think it would be very hard one could characterize teslas approach as kind of a chinese strength approach right gather all the data you can and hope that will overcome the problems but in autonomous driving clearly a lot of the decisions arent merely solved by aggregating data and having feedback loop there are things that are more akin to human thinking and how would those be integrated and built there has not yet been a lot of success integrating human intelligence or call it expert systems if you will even though thats a taboo word with the machine learning and the integration of the two types of thinking hasnt yet been demonstrated and the question is how much can you push a purely machine learning approach and of course tesla also has an additional constraint that they dont have all the sensors i know that they think its foolish to use lidars but thats clearly a one less very valuable and reliable source of input that theyre foregoing which may also have consequences i think the advantage of course is capturing data that no one has ever seen before and in some cases such as computer vision and speech recognition i have seen chinese companies accumulate data thats not seen anywhere in the western world and they have delivered superior results but then speech recognition and object recognition are relatively suitable problems for deep learning and dont have the potentially need for the human intelligence analytical planning elements and the same on the speech recognition side your intuition that speech recognition and the machine learning approaches to speech recognition wont take us to a conversational system that can pass the turing test which is sort of maybe akin to what driving is so it needs to have something more than just simply simple language understanding simple language generation roughly right i would say that based on purely machine learning approaches its hard to imagine it could lead to a full conversational experience across arbitrary domains which is akin to l5 im a little hesitant to use the word turing test because the original definition was probably too easy we probably do that yeah the spirit of the turing test is what i was referring to of course so youve had major leadership research positions at apple microsoft google so continuing on the discussion of america russia chinese seoul and culture and so on what is the culture of silicon valley in contrast to china and maybe us broadly and what is the unique culture of each of these three major companies in your view i think in aggregate silicon valley companies and we could probably include microsoft in that even though theyre not in the valley is really dream big and have visionary goals and believe that technology will conquer all and also the self confidence and the self entitlement that whatever they produce the whole world should use and must use and those are historically important i think steve jobs famous quote that he doesnt do focus groups he looks in the mirror and asks the person in the mirror what do you want and that really is an inspirational comment that says the great company shouldnt just ask users what they want but develop something that users will know they want when they see it but they could never come up with themselves i think that is probably the most exhilarating description of what the essence of silicon valley is that this brilliant idea could cause you to build something that couldnt come out of the focus groups or ab tests and iphone would be an example of that no one in the age of blackberry would write down they want an iphone or multi touch a browser might be another example no one would say they want that in the days of ftp but once they see it they want it so i think that is what silicon valley is best at but it also comes with it came with a lot of success these products became global platforms and there were basically no competitors anywhere and that has also led to a belief that these are the only things that one should do that companies should not tread on other companies territory so that a groupon and a yelp and then opentable and the grubhub would each feel okay im not gonna do the other companys business because that would not be the pride of innovating what each of these four companies have innovated but i think the chinese approach is do whatever it takes to win and its a winner take all market and in fact in the internet space the market leader will get predominantly all the value extracted out of the system so and the system isnt just defined as one narrow category but gets broader and broader so its amazing ambition for success and domination of increasingly larger product categories leading to clear market winner status and the opportunity to extract tremendous value and that develops a practical result oriented ultra ambitious winner take all gladiatorial mentality and if what it takes is to build what the competitors built essentially a copycat that can be done without infringing laws if what it takes is to satisfy a foreign countrys need by forking the code base and building something that looks really ugly and different theyll do it so its contrasted very sharply with the silicon valley approach and i think the flexibility and the speed and execution has helped the chinese approach and i think the silicon valley approach is potentially challenged if every chinese entrepreneur is learning from the whole world us and china and the american entrepreneurs only look internally and write off china as a copycat and the second part of your question about the three companies the unique elements of the three companies perhaps yeah i think apple represents while the user please the user and the essence of design and brand and its the one company and perhaps the only tech company that draws people with a strong serious desire for the product and the willingness to pay a premium because of the halo effect of the brand which came from the attention to detail and great respect for user needs microsoft represents a platform approach that builds giant products that become very strong modes that others cant do because its well architected at the bottom level and the work is efficiently delegated to individuals and then the whole product is built by adding small parts that sum together so its probably the most effective high tech assembly line that builds a very difficult product that and the whole process of doing that is kind of a differentiation and something competitors cant easily repeat are there elements of the chinese approach in the way microsoft went about assembling those little pieces and dominating essentially dominating the market for a long time or do you see those as distinct i think there are elements that are the same i think the three american companies that had or have chinese characteristics and obviously as well as american characteristics are microsoft facebook and amazon yes thats right amazon because these are companies that will tenaciously go after adjacent markets build up strong product offering and find ways to extract greater value from a sphere thats ever increasing and they understand the value of the platforms so thats the similarity and then with google i think its a genuinely value oriented company that does have a heart and soul and that wants to do great things for the world by connecting information and that has also very strong technology genes and wants to use technology and has found out of the box ways to use technology to deliver incredible value to the end user if you can look at google for example you mentioned heart and soul there seems to be an element where google is after making the world better theres a more positive view they used to have the slogan dont be evil and facebook a little bit more has a negative tend to it at least in the perception of privacy and so on do you have a sense of how these different companies can achieve because youve talked about how much we can make the world better in all these kinds of ways with ai what is it about a company that can make give it a heart and soul gain the trust of the public would be very dangerous because should two countries rely on ai to make certain decisions and they dont even talk to each other they do their own scenario planning then something could easily go wrong i think engagement interaction some protocols to avoid inadvertent disasters is actually needed so its natural for each country to want to be the best whether its in nuclear technologies or ai or bio but i think its important to realize if each country has a black box ai and dont talk to each other that probably presents greater challenges to humanity than if they interacted i think there can still be competition but with some degree of protocol for interaction just like when there was a nuclear competition there were some protocol for deterrence among us russia and china and i think that engagement is needed so of course were still far from ai presenting that kind of danger but what i worry the most about is the level of engagement seems to be coming down the level of distrust seems to be going up especially from the us towards other large countries such as china and of course and russia yes is there a way to make that better so lets beautifully put level of engagement and even just basic trust and communication as opposed to sort of making artificial enemies out of particular countries do you have a sense how we can make it better actionable items that as a society we can take on im not an expert at geopolitics but i would say that we look pretty foolish as humankind when we are faced with the opportunity to create 16 trillion for humanity and yet were not solving fundamental problems with parts of the world still in poverty and for the first time we have the resources to overcome poverty and hunger were not using it on that but were fueling competition among superpowers and thats a very unfortunate thing if we become utopian for a moment imagine a benevolent world government that has this 16 trillion and maybe some ai to figure out how to use it to deal with diseases and problems and hate and things like that world would be a lot better off so what is wrong with the current world i think the people with more skill than i should think about this and then the geopolitics issue with superpower competition is one side of the issue theres another side which i worry maybe even more which is as the 16 trillion all gets made by us and china and a few of the other developed countries the poorer country will get nothing because they dont have technology and the wealth disparity and inequality will increase so a poorer country with a large population will not only benefit from the ai boom or other technology booms but they will have their workers who previously had hoped they could do the china model and do outsource manufacturing or the india model so they could do the outsource process or call center well all those jobs are gonna be gone in 10 or 15 years so the individual citizen may be a net liability i mean financially speaking to a poorer country and not an asset to claw itself out of poverty so in that kind of situation these large countries with not much tech are going to be facing a downward spiral and its unclear what could be done and then when we look back and say theres 16 trillion being created and its all being kept by us china and other developed countries it just doesnt feel right so i hope people who know about geopolitics can find solutions thats beyond my expertise so different countries that weve talked about have different value systems if you look at the united states to an almost extreme degree there is an absolute desire for freedom of speech if you look at a country where i was raised that desire just amongst the people is not as elevated as it is to basically fundamental level to the essence of what it means to be america right and the same is true with china theres different value systems theres some censorship of internet content that china and russia and many other countries undertake do you see that having effects on innovation other aspects of some of the tech stuff ai development we talked about and maybe from another angle do you see that changing in different ways over the next 10 years 20 years 50 years as china continues to grow as it does now in its tech innovation theres a common belief that full freedom of speech and expression is correlated with creativity which is correlated with entrepreneurial success i think empirically we have seen that is not true and china has been successful thats not to say the fundamental values are not right or not the best but its just that perfect correlation isnt there its hard to read the tea leaves on opening up or not in any country and ive not been very good at that in my past predictions but i do believe every country shares a lot of fundamental values for the longterm so china is drafting its privacy policy for individual citizens and they dont look that different from the american or european ones so people do want to protect their privacy and have the opportunity to express and i think the fundamental values are there the question is in the execution and timing how soon or when will that start to open up so as long as each government knows ultimately people want that kind of protection there should be a plan to move towards that as to when or how and im not an expert on the point of privacy to me its really interesting so ai needs data to create a personalized awesome experience right im just speaking generally in terms of products and then we have currently depending on the age and depending on the demographics of who were talking about some people are more or less concerned about the amount of data they hand over so in your view how do we get this balance right that we provide an amazing experience to people that use products you look at facebook the more facebook knows about you yes its scary to say the better it can probably better experience it can probably create so in your view how do we get that balance right yes i think a lot of people have a misunderstanding that its okay and possible to just rip all the data out from a provider and give it back to you so you can deny them access to further data and still enjoy the services we have if we take back all the data all the services will give us nonsense well no longer be able to use products that function well in terms of right ranking right products right user experience so yet i do understand we dont want to permit misuse of the data from legal policy standpoint i think there can be severe punishment for those who have egregious misuse of the data thats i think a good first step actually china in this side on this aspect has very strong laws about people who sell or give data to other companies and that over the past few years since that law came into effect pretty much eradicated the illegal distribution sharing of data additionally i think giving i think technology is often a very good way to solve technology misuse so can we come up with new technologies that will let us have our cake and eat it too people are looking into homomorphic encryption which is letting you keep the data have it encrypted and train on encrypted data of course we havent solved that one yet but that kind of direction may be worth pursuing also federated learning which would allow one hospital to train on its hospitals patient data fully because they have a license for that and then hospitals would then share their models not data but models to create a super ai and that also maybe has some promise so i would want to encourage us to be open minded and think of this as not just the policy binary yes no but letting the technologists try to find solutions to let us have our cake and eat it too or have most of our cake and eat most of it too finally i think giving each end user a choice is important and having transparency is important also i think thats universal but the choice you give to the user should not be at a granular level that the user cannot understand gdpr today causes all these popups of yes no will you give this site this right to use this part of your data i dont think any user understands what theyre saying yes or no to and i suspect most are just saying yes because they dont understand it so while gdpr in its current implementation has lived up to its promise of transparency and user choice it implemented it in such a way that really didnt deliver the spirit of gdpr it fit the letter but not the spirit so again i think we need to think about is there a way to fit the spirit of gdpr by using some kind of technology can we have a slider thats an ai trying to figure out how much you want to slide between perfect protection security of your personal data versus a high degree of convenience with some risks of not having full privacy each user should have some preference and that gives you the user choice but maybe we should turn the problem on its head and ask can there be an ai algorithm that can customize this because we can understand the slider but we sure cannot understand every popup question and i think getting that right requires getting the balance between what we talked about earlier which is heart and soul versus profit driven decisions and strategy i think from my perspective the best way to make a lot of money in the long term is to keep your heart and soul intact i think getting that slider right in the short term may feel like youll be sacrificing profit but in the long term youll be gaining user trust and providing a great experience do you share that kind of view in general yes absolutely i sure would hope there is a way we can do long term projects that really do the right thing i think a lot of people who embrace gdpr their hearts in the right place i think they just need to figure out how to build a solution ive heard utopians talk about solutions that get me excited but im not sure how in the current funding environment they can get started people talk about imagine this crowdsourced data collection that we all trust and then we have these agents that we ask the trusted agent to that agent only that platform so a trusted joint platform that we all believe is trustworthy that can give us all the closed loop personal suggestions by the new social network new search engine new ecommerce engine that has access to even more of our data but not directly but indirectly so i think that general concept of licensing to some trusted engine and finding a way to trust that engine seems like a great idea but if you think how long its gonna take to implement and tweak and develop it right as well as to collect all the trusts and the data from the people its beyond the current cycle of venture capital so how do you do that is a big question youve recently had a fight with cancer stage four lymphoma and in a sort of deep personal level what did it feel like in the darker moments to face your own mortality well ive been the workaholic my whole life and ive basically worked nine nine six nine am to nine pm six days a week roughly and i didnt really pay a lot of attention to my family friends and people who loved me and my life revolved around optimizing for work while my work was not routine my optimization really what made my life basically very mechanical process but i got a lot of highs out of it because of accomplishments that i thought were really important and dear and the highest priority to me but when i faced mortality and the possible death in matter of months i suddenly realized that this really meant nothing to me that i didnt feel like working for another minute that if i had six months left in my life i would spend it all with my loved ones and thanking them giving them love back and apologizing to them that i lived my life the wrong way so that moment of reckoning caused me to really rethink that why we exist in this world is something that we might be too much shaped by the society to think that success and accomplishments is why we live but while that can get you periodic successes and satisfaction its really in the facing death you see whats truly important to you so as a result of going through the challenges with cancer ive resolved to live a more balanced lifestyle im now in remission knock on wood and im spending more time with my family my wife travels with me when my kids need me i spend more time with them and before i used to prioritize everything around work when i had a little bit of time i would dole it out to my family now when my family needs something really needs something i drop everything at work and go to them and then in the time remaining i allocate to work but ones family is very understanding its not like they will take 50 hours a week from me so im actually able to still work pretty hard maybe 10 hours less per week so i realized the most important thing in my life is really love and the people i love and i give that the highest priority it isnt the only thing i do but when that is needed i put that at the top priority and i feel much better and i feel much more balanced and i think this also gives a hint as to a life of routine work a life of pursuit of numbers while my job was not routine it was in pursuit of numbers pursuit of can i make more money can i fund more great companies can i raise more money can i make sure our vc is ranked higher and higher every year this competitive nature of driving for bigger numbers and better numbers became a endless pursuit thats mechanical and bigger numbers really didnt make me happier and faced with death i realized bigger numbers really meant nothing and what was important is that people who have given their heart and their love to me deserve for me to do the same so theres deep profound truth in that that everyone should hear and internalize i mean thats really powerful for you to say that i have to ask sort of a difficult question here so ive competed in sports my whole life looking historically id like to challenge some aspect of that a little bit on the point of hard work that it feels that there are certain aspects that is the greatest the most beautiful aspects of human nature is the ability to become obsessed of becoming extremely passionate to the point where yes flaws are revealed and just giving yourself fully to a task that is in another sense you mentioned love being important but in another sense this kind of obsession this pure exhibition of passion and hard work is truly what it means to be human what lessons should we take thats deeper because youve accomplished incredible things you say it chasing numbers but really theres some incredible work there so how do you think about that when you look back in your 20s your 30s what would you do differently would you really take back some of the incredible hard work i would but its in percentages right were both computer scientists so i think when one balances ones life when one is younger you might give a smaller percentage to family but you would still give them high priority and when you get older you would give a larger percentage to them and still the high priority and when youre near retirement you give most of it to them and the highest priority so i think the key point is not that we would work 20 hours less for the whole life and just spend it aimlessly with the family but thats when the family has a need when your wife is having a baby when your daughter has a birthday or when theyre depressed or when theyre celebrating something or when they have a get together or when we have family time that its important for us to put down our phone and pc and be a hundred percent with them and that priority on the things that really matter isnt going to be so taxing that it would eliminate or even dramatically reduce our accomplishments it might have some impact but it might also have other impact because if you have a happier family maybe you fight less if you fight less you dont spend time taking care of all the aftermath of a fight so its unclear that it would take more time and if it did id be willing to take that reduction and its not a dramatic number but its a number that i think would give me a greater degree of happiness and knowing that ive done the right thing and still have plenty of hours to get the success that i want to get so given the many successful companies that youve launched and much success throughout your career what advice would you give to young people today looking or it doesnt have to be young but people today looking to launch and to create the next 1 billion tech startup or even ai based startup i would suggest that people understand technology waves move quickly what worked two years ago may not work today and that is very much case in point for ai i think two years ago or maybe three years ago you certainly could say i have a couple of super smart phds and were not sure what were gonna do but heres how were gonna start and get funding for a very high valuation those days are over because ai is going from rocket science towards mainstream not yet commodity but more mainstream so first the creation of any company to a venture capitalists has to be creation of business value and monetary value and when you have a very scarce commodity vcs may be willing to accept greater uncertainty but now the number of people who have the equivalent of phd three years ago because that can be learned more quickly platforms are emerging the cost to become a ai engineer is much lower and there are many more ai engineers so the market is different so i would suggest someone who wants to build an ai company be thinking about the normal business questions what customer cases are you trying to address what kind of pain are you trying to address how does that translate to value how will you extract value and get paid through what channel and how much business value will get created that today needs to be thought about much earlier upfront than it did three years ago the scarcity question of ai talent has changed the number of ai talent has changed so now you need not just ai but also understanding of business customer and the marketplace so i also think you should have a more reasonable valuation expectation and growth expectation theres gonna be more competition but the good news though is that ai technologies are now more available in open source tensorflow pytorch and such tools are much easier to use so you should be able to experiment and get results iteratively faster than before so take more of a business mindset to this think less of this as a laboratory taken into a company because weve gone beyond that stage the only exception is if you truly have a breakthrough in some technology that really no one has then the old way still works but i think thats harder and harder now so i know you believe as many do that were far from creating an artificial general intelligence system but say once we do and you get to ask her one question what would that question be what is it that differentiates you and me beautifully put kaifu thank you so much for your time today thank you and just actually just not be evil and do good for the world its really hard and i think google has struggled with that first the dont do evil mantra is very dangerous because every employees definition of evil is different and that has led to some difficult employee situations for them so i dont necessarily think thats a good value statement but just watching the kinds of things google or its parent company alphabet does in new areas like healthcare like eradicating mosquitoes things that are really not in the business of a internet tech company i think that shows that theres a heart and soul and desire to do good and willingness to put in the resources to do something when they see its good they will pursue it that doesnt necessarily mean it has all the trust of the users i realize while most people would view facebook as the primary target of their recent unhappiness about silicon valley companies many would put google in that category and some have named googles business practices as predatory also so its kind of difficult to have the two parts of a body the brain wants to do what its supposed to do for a shareholder maximize profit and then the heart and soul wants to do good things that may run against what the brain wants to do so in this complex balancing that these companies have to do youve mentioned that youre concerned about a future where too few companies like google facebook amazon are controlling our data or controlling too much of our digital lives can you elaborate on this concern and perhaps do you have a better way forward i think im hardly the most vocal complainer of this sure of course there are a lot louder complainers out there i do observe that having a lot of data does perpetuate their strength and limits competition in many spaces but i also believe ai is much broader than the internet space so the entrepreneurial opportunities still exists in using ai to empower financial retail manufacturing education applications so i dont think its quite a case of full monopolistic dominance that totally stifles innovation but i do believe in their areas of strength its hard to dislodge them i dont know if i have a good solution probably the best solution is let the entrepreneurial vc ecosystem work well and find all the places that can create the next google the next facebook so there will always be increasing number of challengers in some sense that has happened a little bit you see uber airbnb having emerged despite the strength of the big three and i think china as an environment may be more interesting for the emergence because if you look at companies between lets say 50 to 300 billion china has emerged more of such companies than the us in the last three to four years because of the larger marketplace because of the more fearless nature of the entrepreneurs and the chinese giants are just as powerful as american ones tencent alibaba are very strong but bytedance has emerged worth 75 billion and financial while its alibaba affiliated its nevertheless independent and worth 150 billion and so i do think if we start to extend to traditional businesses we will see very valuable companies so its probably not the case that in five or 10 years well still see the whole world with these five companies having such dominance so youve mentioned a couple of times this fascinating world of entrepreneurship in china of the fearless nature of the entrepreneur so can you maybe talk a little bit about what it takes to be an entrepreneur in china what are the strategies that are undertaken what are the ways to achieve success what is the dynamic of vcf funding of the way the government helps companies and so on what are the interesting aspects here that are distinct from that are different from the silicon valley world of entrepreneurship well many of the listeners probably still would brand chinese entrepreneur as copycats and no doubt 10 years ago that would not be an inaccurate description back 10 years ago an entrepreneur probably could not get funding if he or she could not describe what product he or she is copying from the us the first question is who has proven this business model which is a nice way of asking who are you copying and that reason is understandable because china had a much lower internet penetration and didnt have enough indigenous experience to build innovative products and secondly internet was emerging link startup was the way to do things building a first minimally viable product and then expanding was the right way to go and the american successes have given a shortcut that if you built your minimally viable product based on an american product its guaranteed to be a decent starting point then you tweak it afterwards so as long as there are no ip infringement which as far as i know there hasnt been in the mobile and ai spaces thats a much better shortcut and i think silicon valley would view that as still not very honorable because thats not your own idea to start with but you cant really at the same time believe every idea must be your own and believe in the link startup methodology because link startup is intended to try many many things and then converge when that works and its meant to be iterated and changed so finding a decent starting point without legal violations there should be nothing morally dishonorable about that yeah so just a quick pause on that its fascinating that thats why is that not honorable right its exactly as you formulated it seems like a perfect start for business is to take look at amazon and say okay well do exactly what amazon is doing lets start there in this particular market and then lets out innovate them from that starting point come up with new ways i mean is it wrong to be except the word copycat just sounds bad but is it wrong to be a copycat it just seems like a smart strategy but yes it doesnt have a heroic nature to it that like steve jobs elon musk sort of in something completely coming up with something completely new yeah i like the way you describe it its a nonheroic acceptable way to start the company and maybe more expedient so thats i think a baggage for silicon valley that if it doesnt let go then it may limit the ultimate ceiling of the company take snapchat as an example i think you know evans brilliant he built a great product but hes very proud that he wants to build his own features not copy others while facebook was more willing to copy his features and you see what happens in the competition so i think putting that handcuff on the company would limit its ability to reach the maximum potential so back to the chinese environment copying was merely a way to learn from the american masters just like we if we learned to play piano or painting you start by copying you dont start by innovating when you dont have the basic skill sets so very amazingly the chinese entrepreneurs about six years ago started to branch off with these lean startups built on american ideas to build better products than american products but they did start from the american idea and today wechat is better than whatsapp weibo is better than twitter zhihu is better than quora and so on so that i think is chinese entrepreneurs going to step two and then step three is once these entrepreneurs have done one or two of these companies they now look at the chinese market and the opportunities and come up with ideas that didnt exist elsewhere so products like ant financial under which includes alipay which is mobile payments and also the financial products for loans built on that and also in education vipkid and in social video social network tiktok and in social ecommerce pinduoduo and then in ride sharing mobike these are all chinese innovated products that now are being copied elsewhere so an additional interesting observation is some of these products are built on unique chinese demographics which may not work in the us but may work very well in southeast asia africa and other developing worlds that are a few years behind china and a few of these products maybe are universal and are getting traction even in the united states such as tiktok so this whole ecosystem is supported by vcs as a virtuous cycle because a large market with innovative entrepreneurs will draw a lot of money and then invest in these companies as the market gets larger and larger the china market is easily three four times larger than the us they will create greater value and greater returns for the vcs thereby raising even more money so at sinovation ventures our first fund was 15 million our last fund was 500 million so it reflects the valuation of the companies and our us going multi stage and things like that it also has government support but not in the way most americans would think of it the government actually leaves the entrepreneurial space as a private enterprise sort of self regulating and the government would build infrastructures that would around it to make it work better for example the mass entrepreneur mass innovation plan builds 8000 incubators so the pipeline is very strong to the vcs for autonomous vehicles the chinese government is building smart highways with sensors smart cities that separate pedestrians from cars that may allow initially an inferior autonomous vehicle company to launch a car without increasing with lower casualty because the roads or the city is smart and the chinese government at local levels would have these guiding funds acting as lps passive lps to funds and when the fund makes money part of the money made is given back to the gps and potentially other lps to increase everybodys return at the expense of the governments return so thats an interesting incentive that entrusts the task of choosing entrepreneurs to vcs who are better at it than the government by letting some of the profits move that way so this is really fascinating right so i look at the russian government as a case study where let me put it this way theres no such government driven large scale support of entrepreneurship and probably the same is true in the united states but the entrepreneurs themselves kind of find a way so maybe in a form of advice or explanation how did the chinese government arrive to be this way so supportive on entrepreneurship to be in this particular way so forward thinking at such a large scale and also perhaps how can we copy it in other countries how can we encourage other governments like even the united states government to support infrastructure for autonomous vehicles in that same kind of way perhaps yes so these techniques are the result of several key things some of which may be learnable some of which may be very hard one is just trial and error and watching what everyone else is doing i think its important to be humble and not feel like you know all the answers the guiding funds idea came from singapore which came from israel and china made a few tweaks and turned it into a because the chinese cities and government officials kind of compete with each other because they all want to make their city more successful so they can get the next level in their political career and its somewhat competitive so the central government made it a bit of a competition everybody has a budget they can put it on ai or they can put it on bio or they can put it on energy and then whoever gets the results the city shines the people are better off the mayor gets a promotion so the tools is kind of almost like an entrepreneurial environment for local governments to see who can do a better job and also many of them try different experiments some have given award to very smart researchers just give them money and hope theyll start a company some have given money to academic research labs maybe government research labs to see if they can spin off some companies from the science lab or something like that some have tried to recruit overseas chinese to come back and start companies and theyve had mixed results the one that worked the best was the guiding funds so its almost like a lean startup idea where people try different things and what works sticks and everybody copies so now every city has a guiding fund so thats how that came about the autonomous vehicle and the massive spending in highways and smart cities thats a chinese way its about building infrastructure to facilitate its a clear division of the governments responsibility from the market the market should do everything in a private freeway but there are things the market cant afford to do like infrastructure so the government always appropriates large amounts of money for infrastructure building this happens with not only autonomous vehicle and ai but happened with the 3g and 4g youll find that the chinese wireless reception is better than the us because massive spending that tries to cover the whole country whereas in the us it may be a little spotty its a government driven because i think they view the coverage of cell access and 3g 4g access to be a governmental infrastructure spending as opposed to capitalistic so thats of course the state owned enterprises are also publicly traded but they also carry a government responsibility to deliver infrastructure to all so its a different way of thinking that may be very hard to inject into western countries to say starting tomorrow bandwidth infrastructure and highways are gonna be governmental spending with some characteristics whats your sense and sorry to interrupt but because its such a fascinating point do you think on the autonomous vehicle space its possible to solve the problem of full autonomy without significant investment in infrastructure well thats really hard to speculate i think its not a yes no question but how long does it take question 15 years 30 years 45 years clearly with infrastructure augmentation whether its road the city or whole city planning building a new city im sure that will accelerate the day of the l5 im not knowledgeable enough and its hard to predict even when were knowledgeable because a lot of it is speculative but in the us i dont think people would consider building a new city the size of chicago to make it the ai slash autonomous city there are smaller ones being built im aware of that but is infrastructure spend really impossible for us or western countries i dont think so the us highway system was built was that during president eisenhower or kennedy eisenhower yeah so maybe historians can study how the president eisenhower get the resources to build this massive infrastructure that surely gave us a tremendous amount of prosperity over the next decade if not century if i may comment on that then it takes us to artificial intelligence a little bit because in order to build infrastructure it creates a lot of jobs so ill be actually interested if you would say that you talk in your book about all kinds of jobs that could and could not be automated i wonder if building infrastructure is one of the jobs that would not be easily automated something you could think about because i think youve mentioned somewhere in the talk or that there might be as jobs are being automated a role for government to create jobs that cant be automated yes i think thats a possibility back in the last financial crisis china put a lot of money to basically give this economy a boost and a lot of it went into infrastructure building and i think thats a legitimate way at the government level to deal with the employment issues as well as build out the infrastructure as long as the infrastructures are truly needed and as long as there is an employment problem which no we dont know so maybe taking a little step back if youve been a leader and a researcher in ai for several decades at least 30 years so how has ai changed in the west and the east as youve observed as youve been deep in it over the past 30 years well ai began as the pursuit of understanding human intelligence and the term itself represents that but it kind of drifted into the one sub area that worked extremely well which is machine intelligence and thats actually more using pattern recognition techniques to basically do incredibly well on a limited domain large amount of data but relatively simple kinds of planning tasks and not very creative so we didnt end up building human intelligence we built a different machine that was a lot better than us some problems but nowhere close to us on other problems so today i think a lot of people still misunderstand when we say artificial intelligence and what various products can do people still think its about replicating human intelligence but the products out there really are closer to having invented the internet or the spreadsheet or the database and getting broader adoption and speaking further to the fears near term fears that people have about ai so youre commenting on the sort of general intelligence that people in the popular culture from sci fi movies have a sense about ai but theres practical fears about ai the narrow ai that youre talking about of automating particular kinds of jobs and you talk about them in the book so what are the kinds of jobs in your view that you see in the next five 10 years beginning to be automated by ai systems algorithms yes this is also maybe a little bit counterintuitive because its the routine jobs that will be displaced the soonest and they may not be displaced entirely maybe 50 80 of a job but when the workload drops by that much employment will come down and also another part of misunderstanding is most people think of ai replacing routine jobs than they think of the assembly line the workers well that will have some effect but its actually the routine white collar workers thats easiest to replace because to replace a white collar worker you just need software to replace a blue collar worker you need robotics mechanical excellence and the ability to deal with dexterity and maybe even unknown environments very very difficult so if we were to categorize the most dangerous white collar jobs they would be things like back office people who copy and paste and deal with simple computer programs and data and maybe paper and ocr and they dont make strategic decisions they basically facilitate the process these softwares and paper systems dont work so you have people dealing with new employee orientation searching for past lawsuits and financial documents and doing reference check so basic searching and management of data thats the most endangered being lost in addition to the white collar repetitive work a lot of simple interaction work can also be taken care of such as telesales telemarketing customer service as well as many physical jobs that are in the same location and dont require a high degree of dexterity so fruit picking dishwashing assembly line inspection are jobs in that category so altogether back office is a big part and the blue collar may be smaller initially but over time ai will get better and when we start to get to over the next 15 20 years the ability to actually have the dexterity of doing assembly line thats a huge chunk of jobs and when autonomous vehicles start to work initially starting with truck drivers but eventually to all drivers thats another huge group of workers so i see modest numbers in the next five years but increasing rapidly after that on the worry of the jobs that are in danger and the gradual loss of jobs im not sure if youre familiar with andrew yang yes i am so theres a candidate for president of the united states whose platform andrew yang is based around in part around job loss due to automation and also in addition the need perhaps of universal basic income to support jobs that are folks who lose their job due to automation and so on and in general support people under complex unstable job market so what are your thoughts about his concerns him as a candidate his ideas in general i think his thinking is generally in the right direction but his approach as a presidential candidate may be a little bit ahead of the time and i think the displacements will happen but will they happen soon enough for people to agree to vote for him the unemployment numbers are not very high yet and i think he and i have the same challenge if i want to theoretically convince people this is an issue and he wants to become the president people have to see how can this be the case when unemployment numbers are low so that is the challenge and i think i do agree with him on the displacement issue on universal basic income at a very vanilla level i dont agree with it because i think the main issue is retraining so people need to be incented not by just giving a monthly 2000 check or 1000 check and do whatever they want because they dont have the know how to know what to retrain to go into what type of a job and guidance is needed and retraining is needed because historically when technology revolutions when routine jobs were displaced new routine jobs came up so there was always room for that but with ai and automation the whole point is replacing all routine jobs eventually so there will be fewer and fewer routine jobs and ai will create jobs but it wont create routine jobs because if it creates routine jobs why wouldnt ai just do it so therefore the people who are losing the jobs are losing routine jobs the jobs that are becoming available are non routine jobs so the social stipend needs to be put in place is for the routine workers who lost their jobs to be retrained maybe in six months maybe in three years takes a while to retrain on the non routine job and then take on a job that will last for that persons lifetime now having said that if you look deeply into andrews document he does cater for that so im not disagreeing with what hes trying to do but for simplification sometimes he just says ubi but simple ubi wouldnt work and i think youve mentioned elsewhere that the goal isnt necessarily to give people enough money to survive or live or even to prosper the point is to give them a job that gives them meaning that meaning is extremely important that our employment at least in the united states and perhaps it carries across the world provides something thats forgive me for saying greater than money it provides meaning so now what kind of jobs do you think cant be automated can you talk a little bit about creativity and compassion in your book what aspects do you think its difficult to automate for an ai system because an ai system is currently merely optimizing its not able to reason plan or think creatively or strategically its not able to deal with complex problems it cant come up with a new problem and solve it a human needs to find the problem and pose it as an optimization problem then have the ai work at it so an ai would have a very hard time discovering a new drug or discovering a new style of painting or dealing with complex tasks such as managing a company that isnt just about optimizing the bottom line but also about employee satisfaction corporate brand and many many other things so that is one category of things and because these things are challenging creative complex doing them creates a high degree of satisfaction and therefore appealing to our desire for working which isnt just to make the money make the ends meet but also that weve accomplished something that others maybe cant do or cant do as well another type of job that is much numerous would be compassionate jobs jobs that require compassion empathy human touch human trust ai cant do that because ai is cold calculating and even if it can fake that to some extent it will make errors and that will make it look very silly and also i think even if ai did okay people would want to interact with another person whether its for some kind of a service or a teacher or a doctor or a concierge or a masseuse or a bartender there are so many jobs where people just dont want to interact with a cold robot or software ive had an entrepreneur who built an elderly care robot and they found that the elderly really only use it for customer service and not but not to service the product but they click on customer service and the video of a person comes up and then the person says how come my daughter didnt call me let me show you a picture of her grandkids so people yearn for that people people interaction so even if robots improved people just dont want it and those jobs are going to be increasing because ai will create a lot of value 16 trillion to the world in the next 10 years next 11 years according to pwc and that will give people money to enjoy services whether its eating a gourmet meal or tourism and traveling or having concierge services the services revolving around every dollar of that 16 trillion will be tremendous it will create more opportunities that are to service the people who did well through ai with things but even at the same time the entire society is very much short in need of many service oriented compassionate oriented jobs the best example is probably in healthcare services theres going to be 2 million new jobs not counting replacement just brand new incremental jobs in the next six years in healthcare services that includes nurses orderly in the hospital elderly care and also at home care is particularly lacking and those jobs are not likely to be filled so theres likely to be a shortage and the reason theyre not filled is simply because they dont pay very well and that the social status of these jobs are not very good so they pay about half as much as a heavy equipment operator which will be replaced a lot sooner and they pay probably comparably to someone on the assembly line and so if we ignoring all the other issues and just think about satisfaction from ones job someone repetitively doing the same manual action at an assembly line that cant create a lot of job satisfaction but someone taking care of a sick person and getting a hug and thank you from that person and the family i think is quite satisfying so if only we could fix the pay for service jobs there are plenty of jobs that require some training or a lot of training for the people coming off the routine jobs to take we can easily imagine someone who was maybe a cashier at the grocery store as stores become automated learns to become a nurse or an at home care i also do want to point out the blue collar jobs are going to stay around a bit longer some of them quite a bit longer ai cannot be told go clean an arbitrary home thats incredibly hard arguably its an l5 level of difficulty right and then ai cannot be a good plumber because plumber is almost like a mini detective that has to figure out where the leak came from so yet ai probably can be an assembly line and auto mechanic and so on so one has to study which blue collar jobs are going away and facilitate retraining for the people to go into the ones that wont go away or maybe even will increase i mean it is fascinating that its easier to build a world champion chess player than it is to build a mediocre plumber yes right very true and to ai and that goes counterintuitive to a lot of peoples understanding of what artificial intelligence is so it sounds i mean youre painting a pretty optimistic picture about retraining about the number of jobs and actually the meaningful nature of those jobs once we automate the repetitive tasks so overall are you optimistic about the future where much of the repetitive tasks are automated that there is a lot of room for humans for the compassionate for the creative input that only humans can provide i am optimistic if we start to take action if we have no action in the next five years i think its going to be hard to deal with the devastating losses that will emerge so if we start thinking about retraining maybe with the low hanging fruits explaining to vocational schools why they should train more plumbers than auto mechanics maybe starting with some government subsidy for corporations to have more training positions we start to explain to people why retraining is important we start to think about what the future of education how that needs to be tweaked for the era of ai if we start to make incremental progress and the greater number of people understand then theres no reason to think we cant deal with this because this technological revolution is arguably similar to what electricity industrial revolutions and internet brought about do you think theres a role for policy for governments to step in to help with policy to create a better world absolutely and the governments dont have to believe an employment will go up and they dont have to believe automation will be this fast to do something revamping vocational school would be one example another is if theres a big gap in healthcare service employment and we know that a countrys population is growing older more longevity living older because people over 80 require five times as much care as those under 80 then it is a good time to incent training programs for elderly care to find ways to improve the pay maybe one way would be to offer as part of medicare or the equivalent program for people over 80 to be entitled to a few hours of elderly care at home and then that might be reimbursable and that will stimulate the service industry around the policy do you have concerns about large entities whether its governments or companies controlling the future of ai development in general so we talked about companies do you have a better sense that governments can better represent the interests of the people than companies or do you believe companies are better at representing the interests of the people or is there no easy answer i dont think theres an easy answer because its a double edged sword the companies and governments can provide better services with more access to data and more access to ai but that also leads to greater power which can lead to uncontrollable problems whether its monopoly or corruption in the government so i think one has to be careful to look at how much data that companies and governments have and some kind of checks and balances would be helpful so again i come from russia theres something called the cold war so let me ask a difficult question here looking at conflict steven pinker written a great book that conflict all over the world is decreasing in general but do you have a sense that having written the book ai superpowers do you see a major international conflict potentially arising between major nations whatever they are whether its russia china european nations united states or others in the next 10 20 50 years around ai around the digital space cyberspace do you worry about that is that something we need to think about and try to alleviate or prevent i believe in greater engagement a lot of the worries about more powerful ai are based on a arms race metaphor and when you extrapolate into military kinds of scenarios ai can automate and autonomous weapons that needs to be controlled somehow and autonomous decision making can lead to not enough time to fix international crises so i actually believe a cold war mentality', 'the following is a conversation with chris sampson he was a cto of the google self driving car team a key engineer and leader behind the carnegie mellon university autonomous vehicle entries in the darpa grand challenges and the winner of the darpa urban challenge today hes the ceo of aurora innovation an autonomous vehicle software company he started with sterling anderson who was the former director of tesla autopilot and drew back now ubers former autonomy and perception lead chris is one of the top roboticists and autonomous vehicle experts in the world and a longtime voice of reason in a space that is shrouded in both mystery and hype he both acknowledges the incredible challenges involved in solving the problem of autonomous driving and is working hard to solve it this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with chris sampson you were part of both the darpa grand challenge and the darpa urban challenge teams at cmu with red whitaker what technical or philosophical things have you learned from these races i think the high order bit was that it could be done i think that was the thing that was incredible about the first of the grand challenges that i remember i was a grad student at carnegie mellon and there was kind of this dichotomy of it seemed really hard so that would be cool and interesting but at the time we were the only robotics institute around and so if we went into it and fell on our faces that would be embarrassing so i think just having the will to go do it to try to do this thing that at the time was marked as darn near impossible and then after a couple of tries be able to actually make it happen i think that was really exciting but at which point did you believe it was possible did you from the very beginning did you personally because youre one of the lead engineers you actually had to do a lot of the work yeah i was the technical director there and did a lot of the work along with a bunch of other really good people did i believe it could be done yeah of course why would you go do something you thought was completely impossible we thought it was going to be hard we didnt know how we were going to be able to do it we didnt know if wed be able to do it the first time turns out we couldnt that yeah i guess you have to i think theres a certain benefit to naivete right that if you dont know how hard something really is you try different things and it gives you an opportunity that others who are wiser maybe dont have what were the biggest pain points mechanical sensors hardware software algorithms for mapping localization just general perception control like hardware software first of all i think thats the joy of this field is that its all hard and that you have to be good at each part of it so for the urban challenges if i look back at it from today it should be easy today that it was a static world there werent other actors moving through it is what that means it was out in the desert so you get really good gps so that went and we could map it roughly and so in retrospect now its within the realm of things we could do back then just actually getting the vehicle and the theres a bunch of engineering work to get the vehicle so that we could control it and drive it thats still a pain today but it was even more so back then and then the uncertainty of exactly what they wanted us to do was part of the challenge as well right you didnt actually know the track heading in here you knew approximately but you didnt actually know the route that was going to be taken thats right we didnt know the route we didnt even really the way the rules had been described you had to kind of guess so if you think back to that challenge the idea was that the government would give us the darpa would give us a set of waypoints and kind of the width that you had to stay within between the line that went between each of those waypoints and so the most devious thing they could have done is set a kilometer wide corridor across a field of scrub brush and rocks and said go figure it out fortunately it really it turned into basically driving along a set of trails which is much more relevant to the application they were looking for but no it was a hell of a thing back in the day so the legend red was kind of leading that effort in terms of just broadly speaking so youre a leader now what have you learned from red about leadership i think theres a couple things one is go and try those really hard things thats where there is an incredible opportunity i think the other big one though is to see people for who they can be not who they are its one of the things that i actually one of the deepest lessons i learned from red was that he would look at undergraduates or graduate students and empower them to be leaders to have responsibility to do great things that i think another person might look at them and think oh well thats just an undergraduate student what could they know and so i think that kind of trust but verify have confidence in what people can become i think is a really powerful thing so through that lets just fast forward through the history can you maybe talk through the technical evolution of autonomous vehicle systems from the first two grand challenges to the urban challenge to today are there major shifts in your mind or is it the same kind of technology just made more robust i think theres been some big big steps so for the grand challenge the real technology that unlocked that was hd mapping prior to that a lot of the off road robotics work had been done without any real prior model of what the vehicle was going to encounter and so that innovation that the fact that we could get decimeter resolution models was really a big deal and that allowed us to kind of bound the complexity of the driving problem the vehicle had and allowed it to operate at speed because we could assume things about the environment that it was going to encounter so that was the big step there for the urban challenge one of the big technological innovations there was the multi beam lidar and being able to generate high resolution mid to long range 3d models of the world and use that for understanding the world around the vehicle and that was really kind of a game changing technology in parallel with that we saw a bunch of other technologies that had been kind of converging half their day in the sun so bayesian estimation had been slam had been a big field in robotics you would go to a conference a couple of years before that and every paper would effectively have slam somewhere in it and so seeing that the bayesian estimation techniques play out on a very visible stage i thought that was pretty exciting to see and mostly slam was done based on lidar at that time yeah and in fact we werent really doing slam per se in real time because we had a model ahead of time we had a roadmap but we were doing localization and we were using the lidar or the cameras depending on who exactly was doing it to localize to a model of the world and i thought that was a big step from kind of naively trusting gps ins before that and again lots of work had been going on in this field certainly this was not doing anything particularly innovative in slam or in localization but it was seeing that technology necessary in a real application on a big stage i thought was very cool so for the urban challenge those are already maps constructed offline in general and did people do that individually did individual teams do it individually so they had their own different approaches there or did everybody kind of share that information at least intuitively so darpa gave all the teams a model of the world a map and then one of the things that we had to figure out back then was and its still one of these things that trips people up today is actually the coordinate system so you get a latitude longitude and to so many decimal places you dont really care about kind of the ellipsoid of the earth thats being used but when you want to get to 10 centimeter or centimeter resolution you care whether the coordinate system is nads 83 or wgs 84 or these are different ways to describe both the kind of non sphericalness of the earth but also kind of the i think i cant remember which one the tectonic shifts that are happening and how to transform the global datum as a function of that so getting a map and then actually matching it to reality to centimeter resolution that was kind of interesting and fun back then so how much work was the perception doing there so how much were you relying on localization based on maps without using perception to register to the maps and i guess the question is how advanced was perception at that point its certainly behind where we are today right were more than a decade since the urban challenge but the core of it was there that we were tracking vehicles we had to do that at 100 plus meter range because we had to merge with other traffic we were using again bayesian estimates for state of these vehicles we had to deal with a bunch of the problems that you think of today of predicting where that vehicles going to be a few seconds into the future we had to deal with the fact that there were multiple hypotheses for that because a vehicle at an intersection might be going right or it might be going straight or it might be making a left turn and we had to deal with the challenge of the fact that our behavior was going to impact the behavior of that other operator and we did a lot of that in relatively naive ways but it kind of worked still had to have some kind of solution and so where does that 10 years later where does that take us today from that artificial city construction to real cities to the urban environment yeah i think the biggest thing is that the actors are truly unpredictable that most of the time the drivers on the road the other road users are out there behaving well but every once in a while theyre not the variety of other vehicles is you have all of them in terms of behavior in terms of perception or both both back then we didnt have to deal with cyclists we didnt have to deal with pedestrians didnt have to deal with traffic lights the scale over which that you have to operate is now is much larger than the air base that we were thinking about back then so what easy question what do you think is the hardest part about driving easy question yeah no im joking im sure nothing really jumps out at you as one thing but in the jump from the urban challenge to the real world is there something thats a particular you foresee as very serious difficult challenge i think the most fundamental difference is that were doing it for real that in that environment it was both a limited complexity environment because certain actors werent there because the roads were maintained there were barriers keeping people separate from robots at the time and it only had to work for 60 miles which looking at it from 2006 it had to work for 60 miles right looking at it from now we want things that will go and drive for half a million miles and its just a different game so how important you said lidar came into the game early on and its really the primary driver of autonomous vehicles today as a sensor so how important is the role of lidar in the sensor suite in the near term so i think its essential i believe but i also believe that cameras are essential and i believe the radar is essential i think that you really need to use the composition of data from these different sensors if you want the thing to really be robust the question i wanna ask lets see if we can untangle it is what are your thoughts on the elon musk provocative statement that lidar is a crutch that its a kind of i guess growing pains and that much of the perception task can be done with cameras so i think it is undeniable that people walk around without lasers in their foreheads and they can get into vehicles and drive them and so theres an existence proof that you can drive using passive vision no doubt cant argue with that in terms of sensors yeah so theres proof yeah in terms of sensors right so theres an example that we all go do it many of us every day in terms of lidar being a crutch sure but in the same way that the combustion engine was a crutch on the path to an electric vehicle in the same way that any technology ultimately gets replaced by some superior technology in the future and really the way that i look at this is that the way we get around on the ground the way that we use transportation is broken and that we have this i think the number i saw this morning 37000 americans killed last year on our roads and thats just not acceptable and so any technology that we can bring to bear that accelerates this self driving technology coming to market and saving lives is technology we should be using and it feels just arbitrary to say well im not okay with using lasers because thats whatever but i am okay with using an eight megapixel camera or a 16 megapixel camera these are just bits of technology and we should be taking the best technology from the tool bin that allows us to go and solve a problem the question i often talk to well obviously you do as well to sort of automotive companies and if theres one word that comes up more often than anything its cost and trying to drive costs down so while its true that its a tragic number the 37000 the question is and im not the one asking this question because i hate this question but we want to find the cheapest sensor suite that creates a safe vehicle so in that uncomfortable trade off do you foresee lidar coming down in cost in the future or do you see a day where level four autonomy is possible without lidar i see both of those but its really a matter of time and i think really maybe i would talk to the question you asked about the cheapest sensor i dont think thats actually what you want what you want is a sensor suite that is economically viable and then after that everything is about margin and driving costs out of the system what you also want is a sensor suite that works and so its great to tell a story about how it would be better to have a self driving system with a 50 sensor instead of a 500 sensor but if the 500 sensor makes it work and the 50 sensor doesnt work who cares so long as you can actually have an economic opportunity theres an economic opportunity there and the economic opportunity is important because thats how you actually have a sustainable business and thats how you can actually see this come to scale and be out in the world and so when i look at lidar i see a technology that has no underlying fundamentally expense to it fundamental expense to it its going to be more expensive than an imager because cmos processes or fap processes are dramatically more scalable than mechanical processes but we still should be able to drive costs down substantially on that side and then i also do think that with the right business model you can absorb more certainly more cost on the bill of materials yeah if the sensor suite works extra value is provided thereby you dont need to drive costs down to zero its the basic economics youve talked about your intuition that level two autonomy is problematic because of the human factor of vigilance decrement complacency over trust and so on just us being human we over trust the system we start doing even more so partaking in the secondary activities like smartphones and so on have your views evolved on this point in either direction can you speak to it so and i want to be really careful because sometimes this gets twisted in a way that i certainly didnt intend so active safety systems are a really important technology that we should be pursuing and integrating into vehicles and theres an opportunity in the near term to reduce accidents reduce fatalities and we should be pushing on that level two systems are systems where the vehicle is controlling two axes so braking and throttle slash steering and i think there are variants of level two systems that are supporting the driver that absolutely we should encourage to be out there where i think theres a real challenge is in the human factors part around this and the misconception from the public around the capability set that that enables and the trust that they should have in it and that is where i kind of im actually incrementally more concerned around level three systems and how exactly a level two system is marketed and delivered and how much effort people have put into those human factors so i still believe several things around this one is people will overtrust the technology weve seen over the last few weeks a spate of people sleeping in their tesla i watched an episode last night of trevor noah talking about this and him this is a smart guy who has a lot of resources at his disposal describing a tesla as a self driving car and that why shouldnt people be sleeping in their tesla and its like well because its not a self driving car and it is not intended to be and these people will almost certainly die at some point or hurt other people and so we need to really be thoughtful about how that technology is described and brought to market i also think that because of the economic challenges we were just talking about that these level two driver assistance systems that technology path will diverge from the technology path that we need to be on to actually deliver truly self driving vehicles ones where you can get in it and drive it can get in it and sleep and have the equivalent or better safety than a human driver behind the wheel because again the economics are very different in those two worlds and so that leads to divergent technology so you just dont see the economics of gradually increasing from level two and doing so quickly enough to where it doesnt cause safety critical safety concerns you believe that it needs to diverge at this point into basically different routes and really that comes back to what are those l2 and l1 systems doing and they are driver assistance functions where the people that are marketing that responsibly are being very clear and putting human factors in place such that the driver is actually responsible for the vehicle and that the technology is there to support the driver and the safety cases that are built around those are dependent on that driver attention and attentiveness and at that point you can kind of give up to some degree for economic reasons you can give up on say false negatives and the way to think about this is for a four collision mitigation braking system if it half the times the driver missed a vehicle in front of it it hit the brakes and brought the vehicle to a stop that would be an incredible incredible advance in safety on our roads right that would be equivalent to seat belts but it would mean that if that vehicle wasnt being monitored it would hit one out of two cars and so economically thats a perfectly good solution for a driver assistance system what you should do at that point if you can get it to work 50 of the time is drive the cost out of that so you can get it on as many vehicles as possible but driving the cost out of it doesnt drive up performance on the false negative case and so youll continue to not have a technology that could really be available for a self driven vehicle so clearly the communication and this probably applies to all four vehicles as well the marketing and communication of what the technology is actually capable of how hard it is how easy it is all that kind of stuff is highly problematic so say everybody in the world was perfectly communicated and were made to be completely aware of every single technology out there what its able to do whats your intuition and now were maybe getting into philosophical ground is it possible to have a level two vehicle where we dont over trust it i dont think so if people truly understood the risks and internalized it then sure you could do that safely but thats a world that doesnt exist the people are going to if the facts are put in front of them theyre gonna then combine that with their experience and lets say theyre using an l2 system and they go up and down the 101 every day and they do that for a month and it just worked every day for a month like thats pretty compelling at that point just even if you know the statistics youre like well i dont know maybe theres something funny about those maybe theyre driving in difficult places like ive seen it with my own eyes it works and the problem is that that sample size that they have so its 30 miles up and down so 60 miles times 30 days so 60 180 1800 miles like thats a drop in the bucket compared to the what 85 million miles between fatalities and so they dont really have a true estimate based on their personal experience of the real risks but theyre gonna trust it anyway because its hard not to it worked for a month whats gonna change so even if you start a perfect understanding of the system your own experience will make it drift i mean thats a big concern over a year over two years even it doesnt have to be months and i think that as this technology moves from what i would say is kind of the more technology savvy ownership group to the mass market you may be able to have some of those folks who are really familiar with technology they may be able to internalize it better and your kind of immunization against this kind of false risk assessment might last longer but as folks who arent as savvy about that read the material and they compare that to their personal experience i think there its going to move more quickly so your work the program that youve created at google and now at aurora is focused more on the second path of creating full autonomy so its such a fascinating i think its one of the most interesting ai problems of the century right its i just talked to a lot of people just regular people i dont know my mom about autonomous vehicles and you begin to grapple with ideas of giving your life control over to a machine its philosophically interesting its practically interesting so lets talk about safety how do you think we demonstrate youve spoken about metrics in the past how do you think we demonstrate to the world that an autonomous vehicle an aurora system is safe this is one where its difficult because there isnt a soundbite answer that we have to show a combination of work that was done diligently and thoughtfully and this is where something like a functional safety process is part of that its like heres the way we did the work that means that we were very thorough so if you believe that what we said about this is the way we did it then you can have some confidence that we were thorough in the engineering work we put into the system and then on top of that to kind of demonstrate that we werent just thorough we were actually good at what we did therell be a kind of a collection of evidence in terms of demonstrating that the capabilities worked the way we thought they did statistically and to whatever degree we can demonstrate that both in some combination of simulations some combination of unit testing and decomposition testing and then some part of it will be on road data and i think the way well ultimately convey this to the public is therell be clearly some conversation with the public about it but well kind of invoke the kind of the trusted nodes and that well spend more time being able to go into more depth with folks like nhtsa and other federal and state regulatory bodies and kind of given that they are operating in the public interest and theyre trusted that if we can show enough work to them that theyre convinced then i think were in a pretty good place that means you work with people that are essentially experts at safety to try to discuss and show do you think the answers probably no but just in case do you think there exists a metric so currently people have been using number of disengagements and it quickly turns into a marketing scheme to sort of you alter the experiments you run to adjust i think youve spoken that you dont like dont love it no in fact i was on the record telling dmv that i thought this was not a great metric do you think its possible to create a metric a number that could demonstrate safety outside of fatalities so i do and i think that it wont be just one number so as we are internally grappling with this and at some point well be able to talk more publicly about it is how do we think about human performance in different tasks say detecting traffic lights or safely making a left turn across traffic and what do we think the failure rates are for those different capabilities for people and then demonstrating to ourselves and then ultimately folks in the regulatory role and then ultimately the public that we have confidence that our system will work better than that and so these individual metrics will kind of tell a compelling story ultimately i do think at the end of the day what we care about in terms of safety is life saved and injuries reduced and then ultimately kind of casualty dollars that people arent having to pay to get their car fixed and i do think that in aviation they look at a kind of an event pyramid where a crash is at the top of that and thats the worst event obviously and then theres injuries and near miss events and whatnot and violation of operating procedures and you kind of build a statistical model of the relevance of the low severity things or the high severity things and i think thats something where well be able to look at as well because an event per 85 million miles is statistically a difficult thing even at the scale of the us to kind of compare directly and that event fatality thats connected to an autonomous vehicle is significantly at least currently magnified in the amount of attention it gets so that speaks to public perception i think the most popular topic about autonomous vehicles in the public is the trolley problem formulation right which has lets not get into that too much but is misguided in many ways but it speaks to the fact that people are grappling with this idea of giving control over to a machine so how do you win the hearts and minds of the people that autonomy is something that could be a part of their lives i think you let them experience it right i think its right i think people should be skeptical i think people should ask questions i think they should doubt because this is something new and different they havent touched it yet and i think thats perfectly reasonable and but at the same time its clear theres an opportunity to make the road safer its clear that we can improve access to mobility its clear that we can reduce the cost of mobility and that once people try that and understand that its safe and are able to use in their daily lives i think its one of these things that will just be obvious and ive seen this practically in demonstrations that ive given where ive had people come in and theyre very skeptical again in a vehicle my favorite one is taking somebody out on the freeway and were on the 101 driving at 65 miles an hour and after 10 minutes they kind of turn and ask is that all it does and youre like its a self driving car im not sure exactly what you thought it would do right but it becomes mundane which is exactly what you want a technology like this to be right we dont really when i turn the light switch on in here i dont think about the complexity of those electrons being pushed down a wire from wherever it was and being generated its like i just get annoyed if it doesnt work right and what i value is the fact that i can do other things in this space i can see my colleagues i can read stuff on a paper i can not be afraid of the dark and i think thats what we want this technology to be like is its in the background and people get to have those life experiences and do so safely so putting this technology in the hands of people speaks to scale of deployment right so what do you think the dreaded question about the future because nobody can predict the future but just maybe speak poetically about when do you think well see a large scale deployment of autonomous vehicles 10000 those kinds of numbers well see that within 10 years im pretty confident whats an impressive scale what moment so youve done the darpa challenge where theres one vehicle at which moment does it become wow this is serious scale so i think the moment it gets serious is when we really do have a driverless vehicle operating on public roads and that we can do that kind of continuously without a safety driver without a safety driver in the vehicle i think at that moment weve kind of crossed the zero to one threshold and then it is about how do we continue to scale that how do we build the right business models how do we build the right customer experience around it so that it is actually a useful product out in the world and i think that is really at that point it moves from what is this kind of mixed science engineering project into engineering and commercialization and really starting to deliver on the value that we all see here and actually making that real in the world what do you think that deployment looks like where do we first see the inkling of no safety driver one or two cars here and there is it on the highway is it in specific routes in the urban environment i think its gonna be urban suburban type environments yeah with aurora when we thought about how to tackle this it was kind of in vogue to think about trucking as opposed to urban driving and again the human intuition around this is that freeways are easier to drive on because everybodys kind of going in the same direction and lanes are a little wider et cetera and i think that that intuition is pretty good except we dont really care about most of the time we care about all of the time and when youre driving on a freeway with a truck say 70 miles an hour and youve got 70000 pound load with you thats just an incredible amount of kinetic energy and so when that goes wrong it goes really wrong and those challenges that you see occur more rarely so you dont get to learn as quickly and theyre incrementally more difficult than urban driving but theyre not easier than urban driving and so i think this happens in moderate speed urban environments because if two vehicles crash at 25 miles per hour its not good but probably everybody walks away and those events where theres the possibility for that occurring happen frequently so we get to learn more rapidly we get to do that with lower risk for everyone and then we can deliver value to people that need to get from one place to another and once weve got that solved then the freeway driving part of this just falls out but were able to learn more safely more quickly in the urban environment so 10 years and then scale 20 30 year who knows if a sufficiently compelling experience is created it could be faster and slower do you think there could be breakthroughs and what kind of breakthroughs might there be that completely change that timeline again not only am i asking you to predict the future im asking you to predict breakthroughs that havent happened yet so whats the i think another way to ask that would be if i could wave a magic wand what part of the system would i make work today to accelerate it as quickly as possible dont say infrastructure please dont say infrastructure no its definitely not infrastructure its really that perception forecasting capability so if tomorrow you could give me a perfect model of whats happened what is happening and what will happen for the next five seconds around a vehicle on the roadway that would accelerate things pretty dramatically are you in terms of staying up at night are you mostly bothered by cars pedestrians or cyclists so i worry most about the vulnerable road users about the combination of cyclists and cars right or cyclists and pedestrians because theyre not in armor the cars theyre bigger theyve got protection for the people and so the ultimate risk is lower there whereas a pedestrian or a cyclist theyre out on the road and they dont have any protection and so we need to pay extra attention to that do you think about a very difficult technical challenge of the fact that pedestrians if you try to protect pedestrians by being careful and slow theyll take advantage of that so the game theoretic dance does that worry you of how from a technical perspective how we solve that because as humans the way we solve that is kind of nudge our way through the pedestrians which doesnt feel from a technical perspective as a appropriate algorithm but do you think about how we solve that problem yeah i think theres two different concepts there so one is am i worried that because these vehicles are self driving people will kind of step in the road and take advantage of them and ive heard this and i dont really believe it because if im driving down the road and somebody steps in front of me im going to stop even if im annoyed im not gonna just drive through a person stood in the road and so i think today people can take advantage of this and you do see some people do it i guess theres an incremental risk because maybe they have lower confidence that im gonna see them than they might have for an automated vehicle and so maybe that shifts it a little bit but i think people dont wanna get hit by cars and so i think that im not that worried about people walking out of the 101 and creating chaos more than they would today regarding kind of the nudging through a big stream of pedestrians leaving a concert or something i think that is further down the technology pipeline i think that youre right thats tricky i dont think its necessarily i think the algorithm people use for this is pretty simple its kind of just move forward slowly and if somebodys really close then stop and i think that that probably can be replicated pretty easily and particularly given that you dont do this at 30 miles an hour you do it at one that even in those situations the risk is relatively minimal but its not something were thinking about in any serious way and probably thats less an algorithm problem and more creating a human experience so the hci people that create a visual display that youre pleasantly as a pedestrian nudged out of the way thats an experience problem not an algorithm problem whos the main competitor to aurora today and how do you outcompete them in the long run so we really focus a lot on what were doing here i think that ive said this a few times that this is a huge difficult problem and its great that a bunch of companies are tackling it because i think its so important for society that somebody gets there so we dont spend a whole lot of time thinking tactically about whos out there and how do we beat that person individually what are we trying to do to go faster ultimately well part of it is the leadership team we have has got pretty tremendous experience and so we kind of understand the landscape and understand where the cul de sacs are to some degree and we try and avoid those i think theres a part of it just this great team weve built people this is a technology and a company that people believe in the mission of and so it allows us to attract just awesome people to go work weve got a culture i think that people appreciate that allows them to focus allows them to really spend time solving problems and i think that keeps them energized and then weve invested hard invested heavily in the infrastructure and architectures that we think will ultimately accelerate us so because of the folks were able to bring in early on because of the great investors we have we dont spend all of our time doing demos and kind of leaping from one demo to the next weve been given the freedom to invest in infrastructure to do machine learning infrastructure to pull data from our on road testing infrastructure to use that to accelerate engineering and i think that early investment and continuing investment in those kind of tools will ultimately allow us to accelerate and do something pretty incredible chris beautifully put its a good place to end thank you so much for talking today thank you very much really enjoyed it', 'the following is a conversation with gustav sorenstrom hes the chief research and development officer at spotify leading their product design data technology and engineering teams as ive said before in my research and in life in general i love music listening to it and creating it and using technology especially personalization through machine learning to enrich the music discovery and listening experience that is what spotify has been doing for years continually innovating defining how we experience music as a society in the digital age thats what gustav and i talk about among many other topics including our shared appreciation of the movie true romance in my view one of the great movies of all time this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with gustav sorenstrom spotify has over 50 million songs in its catalog so let me ask the all important question i feel like youre the right person to ask what is the definitive greatest song of all time it varies for me personally so you cant speak definitively for everyone i wouldnt believe very much in machine learning if i did right because everyone had the same taste so for you what is you have to pick what is the song all right so its pretty easy for me theres this song called youre so cool hans zimmer a soundtrack to true romance it was a movie that made a big impression on me and its kind of been following me through my life i actually had it play at my wedding i sat with the organist and helped him play it on an organ which was a pretty interesting experience that is probably my i would say top three movie of all time yeah this is an incredible movie yeah and it came out during my formative years and as ive discovered in music you shape your music taste during those years so it definitely affected me quite a bit did it affect you in any other kind of way well the movie itself affected me back then it was a big part of culture i didnt really adopt any characters from the movie but it was a great story of love fantastic actors and really i didnt even know who hans zimmer was at the time but fantastic music and so that song has followed me and the movie actually has followed me throughout my life that was quentin tarantino actually i think director or producer so its not stairway to heaven or bohemian rhapsody those are great theyre not my personal favorites but ive realized that people have different tastes and thats a big part of what we do well for me i would have to stick with stairway to heaven so 35000 years ago i looked this up on wikipedia flute like instruments started being used in caves as part of hunting rituals and primitive cultural gatherings things like that this is the birth of music since then we had a few folks beethoven elvis beatles justin bieber of course drake so in your view lets start like high level philosophical what is the purpose of music on this planet of ours i think music has many different purposes i think theres certainly a big purpose which is the same as much of entertainment which is escapism and to be able to live in some sort of other mental state for a while but i also think you have the opposite of escaping which is to help you focus on something you are actually doing because i think people use music as a tool to tune the brain to the activities that they are actually doing and its kind of like in one sense maybe its the rawest signal if you think about the brain as neural networks its maybe the most efficient hack we can do to actually actively tune it into some state that you want to be you can do it in other ways you can tell stories to put people in a certain mood but music is probably very effective to get you to a certain mood very fast i think you know theres a social component historically to music where people listen to music together i was just thinking about this that to me and you mentioned machine learning but to me personally music is a really private thing im speaking for myself i listen to music like almost nobody knows the kind of things i have in my library except people who are really close to me and they really only know a certain percentage theres like some weird stuff that im almost probably embarrassed by right its called the guilty pleasures right everyone has the guilty pleasures yeah hopefully theyre not too bad but for me its personal do you think of music as something thats social or as something thats personal or does it vary so i think its the same answer that you use it for both weve thought a lot about this during these 10 years at spotify obviously in one sense as you said music is incredibly social you go to concerts and so forth on the other hand it is your escape and everyone has these things that are very personal to them so what weve found is that when it comes to most people claim that they have a friend or two that they are heavily inspired by and that they listen to so i actually think music is very social but in a smaller group setting its an intimate form of its an intimate relationship its not something that you necessarily share broadly now at concerts you can argue you do but then youve gathered a lot of people that you have something in common with i think this broadcast sharing of music is something we tried on social networks and so forth but it turns out that people arent super interested in sharing their music they arent super interested in what their friends listen to theyre interested in understanding if they have something in common perhaps with a friend but not just as information right thats really interesting i was just thinking of it this morning listening to spotify i really have a pretty intimate relationship with spotify with my playlists right ive had them for many years now and theyve grown with me together theres an intimate relationship you have with a library of music that youve developed and well talk about different ways we can play with that can you do the impossible task and try to give a history of music listening from your perspective from before the internet and after the internet and just kind of everything leading up to streaming with spotify and so on ill try it could be a 100 year podcast ill try to do a brief version there are some things that i think are very interesting during the history of music which is that before recorded music to be able to enjoy music you actually had to be where the music was produced because you couldnt record it and time shift it right creation and consumption had to happen at the same time basically concerts and so you either had to get to the nearest village to listen to music and while that was cumbersome and it severely limited the distribution of music it also had some different qualities which was that the creator could always interact with the audience it was always live and also there was no time cap on the music so i think its not a coincidence that these early classical works theyre much longer than the three minutes the three minutes came in as a restriction of the first wax disc that could only contain a three minute song on one side right so actually the recorded music severely limited or put constraints i wont say limit i mean constraints are often good but it put very hard constraints on the music format so you kind of said instead of doing this opus on many tens of minutes or something now you get three and a half minutes because then youre out of wax on this disc but in return you get an amazing distribution your reach will widen right just on that point real quick without the mass scale distribution theres a scarcity component where you kind of look forward to it we had that its like the netflix versus hbo game of thrones you like wait for the event because you cant really listen to it so you like look forward to it and then its like you derive perhaps more pleasure because its more rare for you to listen to a particular piece you think theres value to that scarcity yeah i think that that is definitely a thing and theres always this component of if you have something in infinite amounts will you value it as much probably not humanity is always seeking some its relative so youre always seeking something you didnt have and when you have it you dont appreciate it as much so i think thats probably true but i think that thats probably true but i think thats why concerts exist so you can actually have both but i think net if you couldnt listen to music in your car driving thatd be worse that cost will be bigger than the benefit of the anticipation i think that you would have so yeah it started with live concerts then its being able to you know the phonograph invented right that you start to be able to record music exactly so then you got this massive distribution that made it possible to create two things i think first of all cultural phenomenons they probably need distribution to be able to happen but it also opened access to you know for a new kind of artist so you started to have these phenomenons like beatles and elvis and so forth that would really a function of distribution i think obviously of talent and innovation but there was also technical component and of course the next big innovation to come along was radio broadcast radio and i think radio is interesting because it started not as a music medium it started as an information medium for news and then radio needed to find something to fill the time with so that they could honestly play more ads and make more money and music was free so then you had this massive distribution where you could program to people i think those things that ecosystem is what created the ability for hits but it was also a very broadcast medium so you would tend to get these massive massive hits but maybe not such a long tail in terms of choice of everybody listens to the same stuff yeah and as you said i think there are some social benefits to that i think for example theres a high statistical chance that if i talk about the latest episode of game of thrones we have something to talk about just statistically in the age of individual choice maybe some of that goes away so i do see the value of shared cultural components but i also obviously love personalization and so lets catch this up to the internet so maybe napster well first of all theres mp3s tapes cds there was a digitalization of music with a cd really it was physical distribution but the music became digital and so they were files but basically boxed software to use a software analogy and then you could start downloading these files and i think there are two interesting things that happened back to music used to be longer before it was constrained by the distribution medium i dont think that was a coincidence and then really the only music genre to have developed mostly after music was a file again on the internet is edm and edm is often much longer than the traditional music i think its interesting to think about the fact that music is no longer constrained in minutes per song or something its a legacy of an old distribution technology and you see some of this new music that breaks the format not so much as i would have expected actually by now but it still happens so first of all i dont really know what edm is electronic dance music yeah you could say avicii avicii was one of the biggest in this genre so the main constraint is of time something like a three four five minute song so you could have songs that were eight minutes 10 minutes and so forth because it started as a digital product that you downloaded so you didnt have this constraint anymore so i think its something really interesting that i dont think has fully happened yet were kind of jumping ahead a little bit to where we are but i think theres tons of format innovation in music that should happen now that couldnt happen when you needed to really adhere to the distribution constraints if you didnt adhere to that you would get no distribution so björk for example the icelandic artist she made a full ipad app as an album that was very expensive even though the app store has great distribution she gets nowhere near the distribution versus staying within the three minute format so i think now that music is fully digital inside these streaming services there is the opportunity to change the format again and allow creators to be much more creative without limiting their distribution ability thats interesting that youre right its surprising that we dont see that taken advantage more often its almost like the constraints of the distribution from the 50s and 60s have molded the culture to where we want the five three to five minute song than anything else not just so we want the song as consumers and as artists because i write a lot of music and i never even thought about writing something longer than 10 minutes its really interesting that those constraints because all your training data has been three and a half minute songs right its right okay so yes digitization of data led to then mp3s yeah so i think you had this file then that was distributed physically but then you had the components of digital distribution and then the internet happened and there was this vacuum where you had a format that could be digitally shipped but there was no business model and then all these pirate networks happened napster and in pirate island napster and in sweden pirate bay which was one of the biggest and i think from a consumer point of view which kind of leads up to the inception of spotify from a consumer point of view consumers for the first time had this access model to music where they could without kind of any marginal cost they could try different tracks you could use music in new ways there was no marginal cost and that was a fantastic consumer experience to have access to all the music ever made i think was fantastic but it was also horrible for artists because there was no business model around it so they didnt make any money so the user need almost drove the user interface before there was a business model and then there were these download stores that allowed you to download files which was a solution but it didnt solve the access problem there was still a marginal cost of 99 cents to try one more track and i think that that heavily limits how you listen to music the example i always give is you know in spotify a huge amount of people listen to music while they sleep while they go to sleep and while they sleep if that costed you 99 cents per three minutes you probably wouldnt do that and you would be much less adventurous if there was a real dollar cost to exploring music so the access model is interesting in that it changes your music behavior you can be you can take much more risk because theres no marginal cost to it maybe let me linger on piracy for a second because i find especially coming from russia piracy is something thats very interesting to me not me of course ever but i have friends who have partook in piracy of music software tv shows sporting events and usually to me what that shows is not that theyre they can actually pay the money and theyre not trying to save money theyre choosing the best experience so what to me piracy shows is a business opportunity in all these domains and thats where i think youre right spotify stepped in is basically piracy was an experience you can explore with fine music you like and actually the interface of piracy is horrible because its i mean its bad metadata long download times all kinds of stuff and what spotify does is basically first rewards artists and second makes the experience of exploring music much better i mean the same is true i think for movies and so on that piracy reveals in the software space for example im a huge user and fan of adobe products and there was much more incentive to pirate adobe products before they went to a monthly subscription plan and now all of the said friends that used to pirate adobe products that i know now actually pay gladly for the monthly subscription yeah i think youre right i think its a sign of an opportunity for product development and that sometimes theres a product market fit before theres a business model fit in product development i think thats a sign of it in sweden i think it was a bit of both there was a culture where we even had a political party called the pirate party and this was during the time when people said that information should be free it was somehow wrong to charge for ones and zeros so i think people felt that artists should probably make some money somehow else and concerts or something so at least in sweden it was part really social acceptance even at the political level but that also forced spotify to compete with free which i dont think would actually could have happened anywhere else in the world the music industry needed to be doing bad enough to take that risk and sweden was like the perfect testing ground it had government funded high bandwidth low latency broadband which meant that the product would work and it was also there was no music revenue anyway so they were kind of like i dont think this is going to work but why not so this product is one that i dont think could have happened in america the worlds largest music market for example so how do you compete with free because thats an interesting world of the internet where most people dont like to pay for things so spotify steps in and tries to yes compete with free how do you do it so i think two things one is people are starting to pay for things on the internet i think one way to think about it was that advertising was the first business model because no one would put a credit card on the internet transactional with amazon was the second and maybe subscription is the third and if you look offline subscription is the biggest of those so that may still happen i think people are starting to pay for things but definitely back then we needed to compete with free today try to you know make sure that their business model works that they understand i think its back to doing something to improving their products like feedback loops and distribution so jumping back into terms of this fascinating world of a recommender system and listening to music and using machine learning to analyze things do you think its better to what currently correct me if im wrong but currently spotify lets people pick what they listen to the most part theres a discovery process but you kind of organize playlists is it better to let people pick what they listen to or recommend what they should listen to something like stations by spotify that i saw that youre playing around with maybe you can tell me whats the status of that this is a pandora style app that just kind of as opposed to you select the music you listen to it kind of feeds you the music you listen to whats the status of stations by spotify whats its future the story of spotify as we have grown has been that we made it more accessible to different audiences and stations is another one of those where the question is some people want to be very specific they actually want to hear starway to heaven right now that needs to be very easy to do and some people or even the same person at some point might say i want to feel upbeat or i want to feel happy or i want songs to sing in the car so they put in the information at a very different level and then we need to translate that into what that means musically so stations is a test to create like a consumption input vector that is much simpler where you can just tune it a little bit and see if that increases the overall reach but were trying to kind of serve the entire gamut of super advanced so called music aficionados all the way to people who they love listening to music but its not their number one priority in life theyre not going to sit and follow every new release from every new artist they need to be able to influence music at a different level so you can think of it as different products and i think one of the interesting things to answer your question on if its better to let the user choose or to play i think the answer is the challenge when machine learning kind of came along there was a lot of thinking about what does product development mean in a machine learning context people like andrew ng for example when he went to baidu he started doing a lot of practical machine learning went from academia and he thought a lot about this and he had this notion that a product manager designer and engineer they used to work around this wireframe to kind of describe what the product should look like it was something to talk about when youre doing a chatbot or a playlist what are you going to say it should be good thats not a good product description so how do you do that and he came up with this notion that the test set is the new wireframe the job of the product manager is to source a good test set that is representative of what like if you say i want to play this that is songs to sing in the car the job of the product manager is to go and source a good test set of what that means so then you can work with engineering to have algorithms to try to produce that so we try to think a lot about how to structure product development for a machine learning age and what we discovered was that a lot of it is actually in the expectation and you can go two ways so lets say that if you set the expectation with the user that this is a discovery product like discover weekly youre actually setting the expectation that most of what we show you will not be relevant when youre in the discovery process youre going to accept that actually if you find one gem every monday that you totally love youre probably going to be happy even though the statistical meaning one out of 10 is terrible or one out of 20 is terrible from a user point of view because the setting was discovery is fine sorry to interrupt real quick i just actually learned about discover weekly which is a spotify i dont know its a feature of spotify that shows you cool songs to listen to maybe i can do issue tracking i couldnt find it on my spotify app its in your library its in the library its in the list of library because i was like whoa this is cool i didnt know this existed and i tried to find it but okay i will show it to you and feedback to our product team there you go but yeah so yeah sorry just to mention the expectation there is basically that youre going to discover new songs yeah so then you can be quite adventurous in the recommendations you do but we have another product called daily mix which kind of implies that these are only going to be your favorites so if you have one out of 10 that is good and nine out of 10 that doesnt work for you youre going to think its a horrible product so actually a lot of the product development we learned over the years is about setting the right expectations so for daily mix you know algorithmically we would pick among things that feel very safe in your taste space whereas discover weekly we go kind of wild because the expectation is most of this is not going to so a lot of that a lot of to answer your question there a lot of should you let the user pick or not it depends we have some products where the whole point is that the user can click play put the phone in the pocket and it should be really good music for like an hour we have other products where you probably need to say like no no save no no and its very interactive i see that makes sense and then the radio product the stations product is one of these like click play put in your pocket for hours thats really interesting so youre thinking of different test sets for different users and trying to create products that sort of optimize for those test sets that represent a specific set of users yes i think one thing that i think is interesting is we invested quite heavily in editorial in people creating playlists using statistical data and that was successful for us and then we also invested in machine learning and for the longest time within spotify and within the rest of the industry there was always this narrative of humans versus the machine algo versus editorial and editors would say like well if i had that data if i could see your playlisting history and i made a choice for you i would have made a better choice and they would have because theyre much smarter than these algorithms the human is incredibly smart compared to our algorithms they can take culture into account and so forth the problem is that they cant make 200 million decisions per hour for every user that logs in so the algo may be not as sophisticated but much more efficient so there was this contradiction but then a few years ago we started focusing on this kind of human in the loop thinking around machine learning and we actually coined an internal term for it called algotorial a combination of algorithms and editors where if we take a concrete example you think of the editor this paid expert that we have thats really good at something like soul hip hop edm something right theyre a true expert no one in the industry so they have all the cultural knowledge you think of them as the product manager and you say that lets say that you want to create a you think that theres a product need in the world for something like songs to sing in the car or songs to sing in the shower im taking that example because it exists people love to scream songs in the car when they drive right so you want to create that product and you have this product manager whos a musical expert they create they come up with a concept like i think this is a missing thing in humanity like a playlist called songs to sing in the car they create the framing the image the title and they create a test set of they create a group of songs like a few thousand songs out of the catalog that they manually curate that are known songs that are great to sing in the car and they can take like true romance into account they understand things that our algorithms do not at all so they have this huge set of tracks then when we deliver that to you we look at your taste vectors and you get the 20 tracks that are songs to sing in the car in your taste so you have personalization and editorial input in the same process if that makes sense yeah it makes total sense and i have several questions around that this is like fascinating okay so first it is a little bit surprising to me that the world expert humans are outperforming machines at specifying songs to sing in the car so maybe you could talk to that a little bit i dont know if you can put it into words but what is it how difficult is this problem do you really i guess what im trying to ask is there how difficult is it to encode the cultural references the context of the song the artists all those things together can machine learning really not do that i mean i think machine learning is great at replicating patterns if you have the patterns but if you try to write with me a spec of what songs greatest song to sing in the car definition is is it loud does it have many choruses should it have been in movies it quickly gets incredibly complicated right yeah and a lot of it may not be in the structure of the song or the title it could be cultural references because you know it was a history so the definition problems quickly get and i think that was the insight of andrew ng when he said the job of the product manager is to understand these things that algorithms dont and then define what that looks like and then you have something to train towards right then you have kind of the test set and then so today the editors create this pool of tracks and then we personalize you could easily imagine that once you have this set you could have some automatic exploration on the rest of the catalog because then you understand what it is and then the other side of it when machine learning does help is this taste vector how hard is it to construct a vector that represents the things an individual human likes this human preference so you can you know music isnt like its not like amazon like things you usually buy music seems more amorphous like its this thing thats hard to specify like what is you know if you look at my playlist what is the music that i love its harder it seems to be much more difficult to specify concretely so how hard is it to build a taste vector it is very hard in the sense that you need a lot of data and i think what we found was that so its not a stationary problem it changes over time and so weve gone through the journey of if youve done a lot of computer vision obviously ive done a bunch of computer vision in my past and we started kind of with the handcrafted heuristics for you know this is kind of indie music this is this and if you consume this youd probably like this so we have we started there and we have some of that still then what was interesting about the playlist data was that you could find these latent things that wouldnt necessarily even make sense to you that could even capture maybe cultural references because they cooccurred things that wouldnt have appeared kind of mechanistically either in the content or so forth so i think that i think the core assumption is that there are patterns in almost everything and if there are patterns these embedding techniques are getting better and better now now as everyone else were also using kind of deep embeddings where you can encode binary values and so forth and what i think is interesting is this process to try to find things that do not necessarily you wouldnt actually have guessed so it is very hard in an engineering sense to find the right dimensions its an incredible scalability problem to do for hundreds of millions of users and to update it every day but in theory in theory embeddings isnt that complicated the fact that you try to find some principal components or something like that dimensionality reduction and so forth so the theory i guess is easy the practice is very very hard and its a huge engineering challenge but fortunately we have some amazing both research and engineering teams in this space yeah i guess the question is all i mean its similar i deal with it with autonomous vehicle spaces the question is how hard is driving and here is basically the question is of edge cases so embedding probably works not probably but i would imagine works well in a lot of cases so theres a bunch of questions that arise then so do song preferences does your taste vector depend on context like mood right so theres different moods and so how does that take in it is it possible to take that as a consideration or do you just leave that as a interface problem that allows the user to just control it so when im looking for workout music i kind of specify it by choosing certain playlists doing certain search yeah so thats a great point back to the product development you could try to spend a few years trying to predict which mood youre in automatically when you open spotify or you create a tab which is happy and sad right and youre going to be right 100 of the time with one click now its probably much better to let the user tell you if theyre happy or sad or if they want to work out on the other hand if your user interface becomes 2000 tabs youre introducing so much friction so no one will use the product so then you have to get better so its this thing where you have to be able to get better so then you have to get better so its this thing where i think maybe it was i dont remember who coined it but its called fault tolerant uis right you build a ui that is tolerant of being wrong and then you can be much less right in your algorithms so weve had to learn a lot of that building the right ui that fits where the machine learning is and a great discovery there which was by the teams during one of our hack days was this thing of taking discovery packaging it into a playlist and saying that these are new tracks that we think you might like based on this and setting the right expectation made it a great product so i think we have this benefit that for example tesla doesnt have that we can change the expectation we can build a fault tolerant setting its very hard to be fault tolerant when youre driving at 100 miles per hour or something and we have the luxury of being able to say that of being wrong if we have the right ui which gives us different abilities to take more risk so i actually think the self driving problem is much harder oh yeah for sure its much less fun because people die exactly and in spotify its such a more fun problem because failure is beautiful in a way it leads to exploration so its a really fun reinforcement learning problem the worst case scenario is you get these wtf tweets like how did i get this this song yeah which is a lot better than the self driving exactly so whats the feedback that a user whats the signal that a user provides into the system so you mentioned skipping what is like the strongest signal you didnt mention clicking like so we have a few signals that are important obviously playing playing through so one of the benefits of music actually even compared to podcasts or movies is the object itself is really only about three minutes so you get a lot of chances to recommend and the feedback loop is every three minutes instead of every two hours or something so you actually get kind of noisy but quite fast feedback and so you can see if people play through which is the inverse of skip really thats an important signal on the other hand much of the consumption happens when your phone is in your pocket maybe youre running or driving or youre playing on a speaker and so you not skipping doesnt mean that you love that song it may be that it wasnt bad enough that you would walk up and skip so its a noisy signal then we have the equivalent of the like which is you saved it to your library thats a pretty strong signal of affection and then we have the more explicit signal of playlisting like you took the time to create a playlist you put it in there theres a very little small chance that if you took all that trouble this is not a really important track to you and then we understand also what are the tracks it relates to so we have the playlisting we have the like and then we have the listening or skip and you have to have very different approaches to all of them because of different levels of noise one is very voluminous but noisy and the other is rare but you can probably trust it yeah its interesting because i think between those signals captures all the information youd want to capture i mean theres a feeling a shallow feeling for me that theres sometimes that ill hear a song thats like yes this is you know this was the right song for the moment but theres really no way to express that fact except by listening through it all the way and maybe playing it again at that time or something but theres no need for a button that says this was the best song i could have heard at this moment well were playing around with that with kind of the thumbs up concept saying like i really like this just kind of talking to the algorithm its unclear if thats the best way for humans to interact maybe it is maybe they should think of spotify as a person an agent sitting there trying to serve you and you can say like bad spotify good spotify right now the analogy weve had is more you shouldnt think of us we should be invisible and the feedback is if you save it its kind of you work for yourself you do a playlist because you think its great and we can learn from that its kind of back to tesla how they kind of have this shadow mode they sit in what you drive we kind of took the same analogy we sit in what you playlist and then maybe we can offer you an autopilot where you can take over for a while or something like that and then back off if you say like thats not good enough but i think its interesting to figure out what your mental model is if spotify is an ai that you talk to which i think might be a bit too abstract for many consumers or if you still think of it as its my music app but its just more helpful and it depends on the device its running on which brings us to smart speakers so i have a lot of the spotify listening i do is on devices i can talk to whether its from amazon google or apple whats the role of spotify on those devices how do you think of it differently than on the phone or on the desktop there are a few things to say about the first of all its incredibly exciting theyre growing like crazy especially here in the us and its solving a consumer need that i think is you can think of it as just remote interactivity you can control this thing from across the room and it may feel like a small thing but it turns out that friction matters to consumers being able to say play pause and so forth from across the room is very powerful so basically you made the living room interactive now and what we see in our data is that the number one use case for these speakers is music music and podcast so fortunately for us its been important to these companies to have those use case covered so they want to spotify on this we have very good relationships with them and were seeing tremendous success with them what i think is interesting about them is its already working we kind of had this epiphany many years ago back when we started using sonos if you went through all the trouble of setting up your sonos system you had this magical experience where you had all the music ever made in your living room and we made this assumption that the home everyone used to have a cd player at home but they never managed to get their files working in the home having this network attached storage was too cumbersome for most consumers so we made the assumption that the home would skip from the cd all the way to streaming books where you would buy the steering and would have all the music built in that took longer than we thought but with the voice speakers that was the unlocking that made kind of the connected speaker happen in the home so it really exploded and we saw this engagement that we predicted would happen what i think is interesting though is where its going from now right now you think of them as voice speakers but i think if you look at google io for example they just added a camera to it where when the alarm goes off instead of saying hey google stop you can just wave your hand so i think theyre going to think more of it as an agent or as an assistant truly an assistant and an assistant that can see you is going to be much more effective than a blind assistant so i think these things will morph and we wont necessarily think of them as quote unquote voice speakers anymore just as interactive access to the internet in the home but i still think that the biggest use case for those will be audio so for that reason were investing heavily in it and we built our own nlu stack to be able to the challenge here is how do you innovate in that world it lowers friction for consumers but its also much more constrained you have no pixels to play with in an audio only world its really the vocabulary that is the interface so we started investing and playing around quite a lot with that trying to understand what the future will be of you speaking and gesturing and waving at your music and actually youre actually nudging closer to the autonomous vehicle space because from everything ive seen the level of frustration people experience upon failure of natural language understanding is much higher than failure in other contexts people get frustrated really fast so if you screw that experience up even just a little bit they give up really quickly yeah and i think you see that in the data while its tremendously successful the most common interactions are play pause and next the things where if you compare it to taking up your phone unlocking it bringing up the app and skipping clicking skip it was much lower friction but then for longer more complicated things like can you find me that song about the people still bring up the phone and search and then play it on their speaker so we tried again to build a fault tolerant ui where for the more complicated things you can still pick up your phone have powerful full keyboard search and then try to optimize for where there is actually lower friction and try to its kind of like the test autopilot thing you have to be at the level where youre helpful if youre too smart and just in the way people are going to get frustrated and first of all im not obsessed with stairway to heaven its just a good song but let me mention that as a use case because its an interesting one ive literally told one of i dont want to say the name of the speaker because when people are listening to it itll make their speaker go off but i talked to the speaker and i say play stairway to heaven and every time it like not every time but a large percentage of the time plays the wrong stairway to heaven it plays like some cover of the and that part of the experience i actually wonder from a business perspective does spotify control that entire experience or no it seems like the nlu the natural language stuff is controlled by the speaker and then spotify stays at a layer below that its a good and complicated question some of which is dependent on the on the partners so its hard to comment on the on the specifics but the question is the right one the challenge is if you cant use any of the personalization i mean we know which stairway to heaven and the truth is maybe for for one person it is exactly the cover that they want and they would be very frustrated if a place i think we i think we default to the right version but but you actually want to be able to do the cover for the person that just played the cover 50 times or spotify is just going to seem stupid so you want to be able to leverage the personalization but you have this stack where you have the the asr and this thing called the end best list of the best guesses here and then the position comes in at the end you actually want the person to be here when youre guessing about what they actually meant so were working with these partners and its a complicated its a complicated thing where you want to you want to be able so first of all you want to be very careful with your users data you dont want to share your users data without the permission but you want to share some data so that their experience gets better so that these partners can understand enough but not too much and so forth so its really the trick is that its like a business driven relationship where youre doing product development across companies together which is which is really complicated but this is exactly why we built our own nlu so that we actually can make personalized guesses because this is the biggest frustration from a user point of view they dont understand about asr and best list and and business deals theyre like how hard can it be i was told this thing 50 times this version and still the place the wrong thing it cant it cant be hard so we try to take the user approach if the user the user is not going to understand the complications of business we have to solve it so lets talk about sort of a complicated subject that i myself im quite torn about the idea sort of of paying artists right i saw as of august 31st 2018 over 11 billion dollars were paid to rights holders so and further distributed to artists from spotify so a lot of money is being paid to artists first of all the whole time as a consumer for me when i look at spotify im not sure im remembering correctly but i think you said exactly how i feel which is this is too good to be true like when i start using spotify i assume you guys will go bankrupt in like a month its like this is too good a lot of people did i was like this is amazing so one question i have is sort of the bigger question how do you make money in this complicated world how do you deal with the relationship with record labels who are complicated these big youre essentially have the task of herding cats but like rich and powerful powerful cats and also have the task of paying artists enough and paying those labels enough and still making money in the internet space where people are not willing to pay hundreds of dollars a month so how do you navigate the space how do you navigate thats a beautiful description herding rich cats that before it is very complicated and i think certainly actually betting against spotify has been statistically a very smart thing to do just looking at the at the line of roadkill in music streaming services its its kind of i think if i understood the complexity when i joined spotify unfortunately fortunately i didnt know enough about the music industry to understand the complexities because then i would have made a more rational guess that it wouldnt work so you know ignorance is bliss but i think there have been a few distinct challenges i think as i said one of the things that made it work at all was that sweden and the nordics was a lost market so there was no risk for labels to try this i dont think it would have worked if if the market was healthy so that was the initial condition then we had this tremendous challenge with the model itself so now most people were pirating but for the people who bought a download or a cd the artists would get all the revenue for all the future plays then right so you got it all up front whereas the streaming model was like almost nothing day one almost nothing day two and then at some point this curve of incremental revenue would intersect with your day one payment and that took a long time to play out before before the music labels they understood that but on the artist side it took a lot of time to understand that actually if i have a big hit that is going to be played for many years this is a much better model because i get paid based on how much people use the product not how much they thought they would use it day one or so forth so it was a complicated model to get across but time helped with that and now the revenues to the music industry actually are bigger again than its gone through this incredible dip and now theyre back up and so were very proud of having been a part of that so there have been distinct problems i think when it comes to the labels we have taken the painful approach some of our competition at the time they kind of looked at other companies and said if we just ignore the rights we get really big really fast were going to be too big for the labels to kind of too big to fail theyre not going to kill us we didnt take that approach we went legal from day one and we negotiated and negotiated and negotiated it was very slow it was very frustrating we were angry at seeing other companies taking shortcuts and seeming to get away with it it was this game theory thing where over many rounds of playing the game this would be the right strategy and even though clearly theres a lot of frustrations at times during renegotiations there is this there is this weird trust where we have been honest and fair weve never screwed them theyve never screwed us its 10 years but theres this trust and like they know that if music doesnt get really big if lots of people do not want to listen to music and want to pay for it spotify has no business model so we actually are incredibly aligned other companies not to be tense but other companies have other business models where even if they made no money from music theyd still be profitable companies but spotify wont so i think the industry sees that we are actually aligned business wise so there is this trust that allows us to do product development even if its scary taking risks the free model itself was an incredible risk for the music industry to take that they should get credit for now some of it was that they had nothing to lose in the game some of it was that they had nothing to lose in sweden but frankly a lot of the labels also took risk and so i think we built up that trust with i think herding of cats sounds a bit whats the word it sounds like dismissive of the cats dismissive no every cat matters theyre all beautiful and very important exactly theyve taken a lot of risks and certainly its been frustrating so its really like playing its game theory if you play the game many times then you can have the statistical outcome that you bet on and it feels very painful when youre in the middle of that thing i mean theres risk theres trust theres relationships from just having read the biography of steve jobs similar kind of relationships were discussed in itunes the idea of selling a song for a dollar was very uncomfortable for labels exactly and there was no it was the same kind of thing it was trust it was game theory as a lot of relationships that had to be built and its really a terrifyingly difficult process that apple could go through a little bit because they could afford for that process to fail for spotify it seems terrifying because you cant initially i think a lot of it comes down to honestly daniel and his tenacity in negotiating which seems like an impossible task because he was completely unknown and so forth but maybe that was also the reason that it worked but i think game theory is probably the best way to think about it you could go straight for this nash equilibrium that someone is going to defect or you play it many times you try to actually go for the top left the corporations sell is there any magical reason why spotify seems to have won this so a lot of people have tried to do what spotify tried to do and spotify has come out well so the answer is that theres no magical reason because i dont believe in magic but i think there are there are reasons and i think some of them are that people have misunderstood a lot of what we actually do the actual spotify model is very complicated theyve looked at the premium model and said it seems like you can charge 999 for music and people are going to pay but thats not what happened actually when we launched the original mobile product everyone said they would never pay what happened was they started on the free product and then their engagement grew so much that eventually they said maybe it is worth 999 right its your propensity to pay gross with your engagement so we have this super complicated business model we operate two different business models advertising and premium at the same time and i think that is hard to replicate i struggle to think of other companies that run large scale advertising and subscription products at the same time so i think the business model is actually much more complicated than people think it is and so some people went after just the premium part without the free part and ran into a wall where no one wanted to pay some people went after just music should be free just ads which doesnt give you enough revenue and doesnt work for the music industry so i think that combination is kind of opaque from the outside so maybe i shouldnt say it here and reveal the secret but that turns out to be hard to replicate than you would think so theres a lot of brilliant business strategies out there brilliant business strategy here brilliance or luck probably more luck but it doesnt really matter it looks brilliant in retrospect lets call it brilliant yeah when the books are written theyll be brilliant youve mentioned that your philosophy is to embrace change so how will the music streaming and music listening world change over the next 10 years 20 years you look out into the far future what do you think i think that music and for that matter audio podcasts audiobooks i think its one of the few core human needs i think it there is no good reason to me why it shouldnt be at the scale of something like messaging or social networking i dont think its a niche thing to listen to music or news or something so i think scale is obviously one of the things that i really hope for i think i hope that its going to be billions of users i hope eventually everyone in the world gets access to all the worlds music ever made so obviously i think its going to be a much bigger business otherwise we wouldnt be betting this big now if you look more at how it is consumed what im hoping is back to this analogy of the software tool chain where i think i sometimes internally i make this analogy to text messaging text messaging was also based on standards in the area of mobile carriers you had the sms the 140 character 120 character sms and it was great because everyone agreed on the standards so as a consumer you got a lot of distributions and interoperability but it was a very constrained format and when the industry wanted to add pictures to that format to do the mms i looked it up and i think it took from the late 80s to early 2000s this is like a 15 20 year product cycle to bring pictures into that now once that entire value chain of creation and consumption got wrapped in one software stack within something like snapchat or whatsapp the first week they added disappearing messages then two weeks later they added stories the pace of innovation when youre on one software stack and you can affect both creation and consumption i think its going to be rapid so with these streaming services we now for the first time in history have enough i hope people on one of these services actually whether its spotify or amazon or apple or youtube and hopefully enough creators that you can actually start working with the format again and that excites me i think being able to change these constraints from 100 years that could really do something interesting i really hope its not just going to be the iteration on the same thing for the next 10 to 20 years as well yeah changing the creation of music the creation of audio the creation of podcasts is a really fascinating possibility i myself dont understand what it is about podcasts thats so intimate it just is i listen to a lot of podcasts i think it touches on a deep human need for connection that people do feel like theyre connected to when they listen i dont understand what the psychology of that is but in this world thats becoming more and more disconnected it feels like this is fulfilling a certain kind of need and empowering the creator as opposed to just the listener is really interesting im really excited that youre working on this yeah i think one of the things that is inspiring for our teams to work on podcasts is exactly that whether you think like i probably do that its something biological about perceiving to be in the middle of the conversation that makes you listen in a different way it doesnt really matter people seem to perceive it differently and there was this narrative for a long time that if you look at video everything kind of in the foreground it got shorter and shorter and shorter because of financial pressures and monetization and so forth and eventually at the end theres almost like 20 seconds clip people just screaming something and i feel really good about the fact that you could have interpreted that as people have no attention span anymore they dont want to listen to things theyre not interested in deeper stories people are getting dumber but then podcasts came along and its almost like no no the need still existed but maybe it was the fact that youre not prepared to look at your phone like this for two hours but if you can drive at the same time it seems like people really want to dig deeper and they want to hear like the more complicated version so to me that is very inspiring that that podcast is actually long form it gives me a lot of hope for humanity that people seem really interested in hearing deeper more complicated conversations this is i dont understand it its fascinating so the majority for this podcast listen to the whole thing this whole conversation weve been talking for an hour and 45 minutes and somebody will i mean most people will be listening to these words im speaking right now its crazy you wouldnt have thought that 10 years ago with where the world seemed to go thats very positive i think thats really exciting and empowering the creator there is really exciting last question you also have a passion for just mobile in general how do you see the smartphone world the digital space of smartphones and just everything thats on the move whether its internet of things and so on changing over the next 10 years and so on i think that one way to think about it is that computing might be moving out of these multipurpose devices the computer we had and the phone into specific purpose devices and it will be ambient that at least in my home you just shout something at someone and theres always one of these speakers close enough and so you start behaving differently its as if you have the internet ambient ambiently around you and you can ask it things so i think computing will kind of get more integrated and we wont necessarily think of it as connected to a device in the same way that we do today i dont know the path to that maybe we used to have these desktop computers and then we partially replaced that with the laptops and left the desktop at home when i work and then we got these phones and we started leaving the mobile phones we had the desktop at home when i work and then we got these phones and we started leaving the laptop at home for a while and maybe for stretches of time youre going to start using the watch and you can leave your phone at home for a run or something and were on this progressive path where i think what is happening with voice is that you have an interaction paradigm that doesnt require as large physical devices so i definitely think theres a future where you can have your airpods and your watch and you can do a lot of computing and i dont think its going to be this binary thing i think its going to be like many of us still have a laptop we just use it less and so you shift your consumption over and i dont know about ar glasses and so forth im excited about it i spent a lot of time in that area but i still think its quite far away ar vr all of that yeah vr is happening and working i think the recent oculus quest is quite impressive i think ar is further away at least that type of ar but i do think your phone or watch or glasses understanding where you are and maybe what youre looking at and being able to give you audio cues about that or you can say like what is this and it tells you what it is that i think might happen you use your watch or your glasses as a mouse pointer on reality i think it might be a while before i might be wrong i hope im wrong i think it might be a while before we walk around with these big lab glasses that project things i agree with you its actually really difficult when you have to understand the physical world enough to project onto it i lied about the last question go ahead because i just thought of audio and my favorite topic which is the movie her do you think whether its part of spotify or not well have i dont know if youve seen the movie her absolutely and there audio is the primary form of interaction and the connection with another entity that you can actually have a relationship with that you fall in love with based on voice alone audio alone do you think thats possible first of all based on audio alone to fall in love with somebody somebody or well yeah lets go with somebody just have a relationship based on audio alone and second question to that can we create an artificial intelligence system that allows one to fall in love with it and her him with you so this is my personal answer speaking for me as a person the answer is quite unequivocally yes on both i think what we just said about podcasts and the feeling of being in the middle of a conversation if you could have an assistant where and we just said that feels like a very personal setting so if you walk around with these headphones and this thing youre speaking with this thing all of the time that feels like its in your brain i think its going to be much easier to fall in love with than something that would be on your screen i think thats entirely possible and then from the you can probably answer this better than me but from the concept of if its going to be possible to build a machine that can achieve that i think whether you think of it as if you can fake it the philosophical zombie that assimilates it enough or it somehow actually is i think theres its only a question its only a question if you ask me about time id have a different answer but if you say ive given some half infinite time absolutely i think its just atoms and arrangement of information well i personally think that love is a lot simpler than people think so we started with true romance and ended in love i dont see a better place to end beautiful gustav thanks so much for talking today thank you so much it was a lot of fun it was fun and the first thing you need to do is obviously to lower the price to free and then you need to be better somehow and the way that spotify was better was on the user experience on the actual performance the latency of you know even if you had high bandwidth broadband it would still take you 30 seconds to a minute to download one of these tracks so the spotify experience of starting within the perceptual limit of immediacy about 250 milliseconds meant that the whole trick was it felt as if you had downloaded all of pirate bay it was on your hard drive it was that fast even though it wasnt and it was still free but somehow you were actually still being a legal citizen and that was the trick that spotify managed to pull off so ive actually heard you say this or write this and i was surprised that i wasnt aware of it because i just took it for granted you know whenever an awesome thing comes along youre just like of course it has to be this way thats exactly right that it felt like the entire worlds libraries at my fingertips because of that latency being reduced what was the technical challenge in reducing the latency so there was a group of really really talented engineers one of them called ludwig strigius he wrote the actually from gothenburg he wrote the initial the utorrent client which is kind of an interesting backstory to spotify that we have one of the top developers from utorrent clients as well so he wrote utorrent the worlds smallest utorrent client and then he was acquired very early by daniel and martin who founded spotify and they actually sold the utorrent client to bittorrent but kept ludwig so spotify had a lot of experience within peer to peer networking so the original innovation was a distribution innovation where spotify built an end to end media distribution system up until only a few years ago we actually hosted all the music ourselves so we had both the service side and the client and that meant that we could do things such as having a peer to peer solution to use local caching on the client side because back then the world was mostly desktop but we could also do things like hack the tcp protocols things like nagels algorithm for kind of exponential back off or ramp up and just go full throttle and optimize for latency at the cost of bandwidth and all of this end to end control meant that we could do an experience that felt like a step change these days we actually are on gcp we dont host our own stuff and everyone is really fast these days so that was the initial competitive advantage but then obviously you have to move on over time and that was over 10 years ago right that was in 2008 the product was launched in sweden it was in a beta i think 2007 and it was on the desktop right it was desktop only theres no phone there was no phone the iphone came out in 2008 but the app store came out one year later i think so the writing was on the wall but there was no phone yet youve mentioned that people would use spotify to discover the songs they like and then they would torrent those songs to so they can copy it to their phone just hilarious exactly not torrent pirate seriously piracy does seem to be like a good guide for business models video content as far as i know spotify doesnt have video content well we do have music videos and we do have videos on the service but the way we think about ourselves is that were an audio service and we think that if you look at the amount of time that people spend on audio its actually very similar to the amount of time that people spend on music its very similar to the amount of time that people spend on video so the opportunity should be equally big but today its not at all valued videos value much higher so we think its basically completely undervalued so we think of ourselves as an audio service but within that audio service i think video can make a lot of sense i think when youre discovering an artist you probably do want to see them and understand who they are to understand their identity you wont see that video every time 90 of the time the phone is going to be in your pocket for podcasters you use video i think that can make a ton of sense so we do have video but were an audio service where think of it as we call it internally backgroundable video video that is helpful but isnt the driver of the narrative i think also if we look at youtube theres quite a few folks who listen to music on youtube so in some sense youtube is a bit of a competitor to spotify which is very strange to me that people use youtube to listen to music they play essentially the music videos right but dont watch the videos and put it in their pocket well i think its similar to what strangely maybe its similar to what we were for the piracy networks where youtube for historical reasons have a lot of music videos so people use youtube for a lot of the discovery part of the process i think but then its not a really good sort of quote unquote mp3 player because it doesnt even background then you have to keep the app in the foreground so its not a good consumption tool but its a decently good discovery i mean i think youtube is a fantastic product and i use it for all kinds of purposes thats true if i were to admit something i do use youtube a little bit to assist in the discovery process of songs and then if i like it ill add it to spotify but thats ok thats ok with us ok so sorry were jumping around a little bit so its kind of incredible you look at napster you look at the early days of spotify one fascinating point is how do you grow a user base so youre there in sweden you have an idea i saw the initial sketches that look terrible how do you grow a user base from a few folks to millions i think there are a bunch of tactical answers so first of all i think you need a great product i dont think you take a bad product and market it to be successful so you need a great product but sorry to interrupt but its a totally new way to listen to music too so its not just did people realize immediately that spotify is a great product no i think they did so back to the point of piracy it was a totally new way to listen to music legally but people had been used to the access model in sweden and the rest of the world for a long time through piracy so one way to think about spotify it was just legal and fast piracy and so people have been using it for a long time so they werent alien to it they didnt really understand how it could be illegal because it seemed too fast and too good to be true which i think is a great product proposition if you can be too good to be true but what i saw again and again was people showing each other clicking the song showing how fast it started and say can you believe this so i really think it was about speed then we also had an invite program that was really meant for scaling because we hosted our own service we needed to control scaling but that built a lot of expectation and i dont want to say hype because hype implies that it wasnt true excitement around the product and weve replicated that when we launched in the us we also built up an invite only program first there are lots of tactics but i think you need a great product to solve some problem and basically the key innovation there was technology but on a meta level the innovation was really the access model versus the ownership model and that was tricky a lot of people said that they wanted to be able to do it i mean they wanted to own their music they would never kind of rent it or borrow it but i think the fact that we had a free tier which meant that you get to keep this music for life as well helped quite a lot so this is an interesting psychological point that maybe you can speak to it was a big shift for me its almost like i had to go to therapy for this i think i would describe my early listening experience and i think a lot of my friends do as basically hoarding music as youre like slowly one song by one song or maybe albums gathering a collection of music that you love and you own it its like often especially with cds or tape you like physically had it and what spotify what i had to come to grips with it was kind of liberating actually is to throw away all the music ive had this therapy session with lots of people and i think the mental trick is so actually weve seen the user data when spotify started a lot of people did the exact same thing they started hoarding as if the music would disappear almost the equivalent of downloading and so we had these playlists that had limits of like a few hundred thousand tracks we figured no one will ever well they do nuts and hundreds and hundreds of thousands of tracks and to this day some people want to actually save quote unquote and then play the entire catalog but i think the therapy session goes something like instead of throwing away your music if you took your files and you stored them in the locker at google itd be a streaming service its just that in that locker you have all the worlds music now for free so instead of giving away your music you got all the music its yours you could think of it as having a copy of the worlds catalog there forever so you actually got more music instead of less its just that you just took that hard disk and you sent it to someone who stored it for you and once you go through that mental journey im like its still my files theyre just over there and i just have 40 million or 50 million or something now then people are like ok thats good the problem is i think because you paid us a subscription if we hadnt had the free tier where you would feel like even if i dont want to pay anymore i still get to keep them you keep your playlist forever they dont disappear even though you stop paying i think that was really important if we would have started as you know you can put in all this time but if you stop paying you lose all your work i think that would have been a big challenge and was the big challenge for a lot of our competitors thats another reason why i think the free tier is really important that people need to feel the security that the work they put in it will never disappear even if they decide not to pay i like how you put the work you put in i actually stopped even thinking of it that way i just actually spotify taught me to just enjoy music as opposed to as opposed to what i was doing before which is like in an unhealthy way hoarding music which i found that because i was doing that i was listening to a small selection of songs way too much to where i was getting sick of them whereas spotify the more liberating kind of approach is i was just enjoying of course i listened to stairway to heaven over and over but because of the extra variety i dont get as sick of them theres an interesting statistic i saw so spotify has maybe you can correct me but over 50 million songs tracks and over 3 billion playlists so 50 million songs and 3 billion playlists 60 times more playlist songs what do you make of that yeah so the way i think about it is that from a statistician or machine learning point of view you have all these if you want to think about reinforcement learning you have this state space of all the tracks you can take different journeys through this world i think of these as people helping themselves and each other creating interesting vectors through this space of tracks and then its not so surprising that across many tens of millions of atomic units there will be billions of paths that make sense and were probably pretty quite far away from having found all of them so kind of our job now is users when spotify started it was really a search box that was for the time pretty powerful and then id like to refer to it as this programming language called playlisting where if you as you probably were pretty good at music you knew your new releases you knew your back catalog you knew your star with the heaven you could create a soundtrack for yourself using this playlisting tool this like meta programming language for music to soundtrack your life and people who were good at music its back to how do you scale the product for people who are good at music that wasnt actually enough if you had the catalog and a good search tool and you can create your own sessions you could create really good a soundtrack for your entire life probably perfectly personalized because you did it yourself but the problem was most people many people arent that good at music they just cant spend the time even if youre very good at music its going to be hard to keep up so what we did to try to scale this was to essentially try to build you can think of them as agents that this friend that some people had that helped them navigate this music catalog thats what were trying to do for you but also there is something like 200 million active users 1 million active users on spotify so there its okay so from the machine learning perspective you have these 200 million people plus theyre creating its really interesting to think of a playlist as i mean i dont know if you meant it that way but its almost like a programming language its or at least a trace of exploration of those individual agents the listeners and you have all this new tracks coming in so its a fascinating space that is ripe for machine learning so is there is it possible how can playlists be used as data in terms of machine learning and to help spotify organize the music so we found in our data not surprising that people who play listed lots they retain much better they had a great experience and so our first attempt was to playlist for users and so we acquired this company called tunigo of editors and professional playlisters and kind of leveraged the maximum of human intelligence to help build kind of these vectors through the track space for people and that broadened the product but then the obvious next and we use statistical means where they could see when they created a playlist how did that playlist perform they could see skips of the songs they could see how the songs perform and they manually iterated the playlist to maximize performance for a large group of people but there were never enough editors to playlists for you personally so the promise of machine learning was to go from kind of group personalization using editors and tools and statistics to individualization and then whats so interesting about the 3 billion playlists we have is we ended the truth is we lucked out this was not a priority strategy as is often the case it looks really smart in hindsight but it was dumb luck we looked at these playlists and we had some people in the company a person named eric beranodson he was really good at machine learning already back then in like 2007 2008 back then it was mostly collaborative filtering and so forth but we realized that what this is is people are grouping tracks for themselves that have some semantic meaning to them and then they actually label it with a playlist name as well so in a sense people were grouping tracks along semantic dimensions and labeling them and so could you use that information to find that latent embedding and so we started playing around with collaborative filtering and we saw tremendous success with it basically trying to extract some of these dimensions and if you think about it its not surprising at all itd be quite surprising if playlists were actually random if they had no semantic meaning for most people they group these tracks for some reason so we just happened across this incredible data set where people are taking these tens of millions of tracks and group them along different semantic vectors and the semantics being outside the individual users so its some kind of universal theres a universal embedding that holds across people on this earth yes i do think that the embeddings you find are going to be reflective of the people who play listed so if you have a lot of indie lovers who play list your embedding is going to perform better there but what we found was that yes there were these latent similarities they were very powerful and it was interesting because i think that the people who play listed the most initially were the so called music aficionados who were really into music and they often had a certain their taste was often geared towards a certain type of music and so what surprised us if you look at the problem from the outside you might expect that the algorithms would start performing best with mainstreamers first because it somehow feels like an easier problem to solve mainstream taste than really particular taste it was the complete opposite for us the recommendations performed fantastically for people who saw themselves as having very unique taste thats probably because all of them play listed and they didnt perform so well for mainstreamers they actually thought they were a bit too particular and unorthodox so we had the complete opposite of what we expected success within the hardest problem first and then had to try to scale to more mainstream recommendations so youve also acquired echo nest that analyzes song data so in your view maybe you can talk about so what kind of data is there from a machine learning perspective from a machine learning perspective theres a huge amount were talking about playlisting and just user data of what people are listening to the playlist theyre constructing and so on and then theres the actual data within a song what makes a song i dont know the actual waveforms how do you mix the two how much value is there in each to me it seems like user data is a romantic notion that the song itself would contain useful information but if i were to guess user data would be much more powerful like playlists would be much more powerful yeah so we use both our biggest success initially was with playlist data without understanding anything about the structure of the song but when we acquired echo nest they had the inverse problem they actually didnt have any play data they were just they were a provider of recommendations but they didnt actually have any play data so they looked at the structure of songs sonically and they looked at wikipedia for cultural references and so forth right and did a lot of nlu and so forth so we got that skill into the company and combined kind of our user data with their kind of content based so you can think of it as we were user based and they were content based in their recommendations and we combined those two and for some cases where you have a new song that has no play data obviously you have to try to go by either who the artist is or the sonic information in the song or what its similar to so theres definitely a value in both and we do a lot in both but i would say yes the user data captures things that have to do with culture in the greater society that you would never see in the content itself but that said we have seen we have a research lab in paris when we can talk more about that on machine learning on the creator side what it can do for creators not just for the consumers but where we looked at how does the structure of a song actually affect the listening behavior and it turns out that there is a lot of we can predict things like skips based on the song itself we could say that maybe you should move that chorus a bit because your skip is going to go up here there is a lot of latent structure in the music which is not surprising because it is some sort of mind hack so there should be structure thats probably what we respond to you just blew my mind actually from the creator perspective so thats a really interesting topic that probably most creators arent taking advantage of right so ive recently got to interact with a few folks youtubers who are like obsessed with this idea of what do i do to make sure people keep watching the video and they like look at the analytics of which point do people turn it off and so on first of all i dont think thats healthy but its because you can do it a little too much but it is a really powerful tool for helping the creative process you just made me realize you could do the same thing for creation of music and so is that something youve looked into and can you speak to how much opportunity there is for that kind of thing yeah so i listened to the podcast with ziraj and i thought it was fantastic and i reacted to the same thing where he said he posted something in the morning immediately watched the feedback where the drop off was and then responded to that in the afternoon which is quite different from how people make podcasts for example yes exactly i mean the feedback loop is almost non existent so if we back out one level i think actually both for music and podcasts which we also do at spotify i think theres a tremendous opportunity just for the creation workflow and i think its really interesting speaking to you who because youre a musician a developer and a podcaster if you think about those three different roles if you make the leap as a musician if you think about it as a software tool chain really your daw with the stems thats the ide right thats where you work in source code format with what youre creating then you sit around and you play with that and when youre happy you compile that thing into some sort of aac or mp3 or something you do that because you get distribution there are so many runtimes for that mp3 across the world in car stairs and stuff so if you kind of compile this execution you ship it out in kind of an old fashioned boxed software analogy and then you hope for the best right but as a software developer you would never do that first you go on github and you collaborate with other creators and then you think itd be crazy to just ship one version of your software without doing an a b test without any feedback loop issue tracking exactly and then you would look at the feedback loop and say try to optimize that thing right so i think if you think of it as a very specific software tool chain it looks quite arcane the tools that a music creator has versus what a software developer has so thats kind of how we think about it why wouldnt a music creator have something like github where you could collaborate much more easily so we bought this company called soundtrap which has a kind of google docs for music approach where you can collaborate with other people on the kind of source code format with stems and i think introducing things like ai tools there to help you as youre creating music both in helping you put accompaniment to your music like drums or something help you master and mix automatically help you understand how this track will perform exactly what you would expect as a software developer i think it makes a lot of sense and i think the same goes for a podcaster i think podcasters will expect to have the same kind of feedback loop that siraj has like why wouldnt you maybe its not healthy but sorry i wanted to criticize the fact because you can overdo it because a lot of the and were in a new era of that so you can become addicted to it and therefore what people say you become a slave to the youtube algorithm or sort of its always a danger of a new technology as opposed to say if youre creating a song becoming too obsessed about the intro riff to the song that keeps people listening versus actually the entirety of the creation process its a balance but the fact that theres zero i mean youre blowing my mind right now because youre completely right that there is no signal whatsoever theres no feedback whatsoever on the creation process and music or podcasting almost at all and are you saying that spotify is hoping to help create tools to not tools but no tools actually actually tools tools for creators absolutely so weve made some acquisitions the last few years around music creation this company called soundtrap which is a digital audio workstation but that is browser based and their focus was really the google docs approach we can collaborate with people much more easily than you could in previous tools so we have some of these tools that were working with that we want to make accessible and then we can connect it with our consumption data we can create this feedback loop where we could help you understand we could help you create and help you understand how you will perform we also acquired this other company within podcasting called anchor which is one of the biggest podcasting tools mobile focused so really focused on simple creation or easy access to creation but that also gives us this feedback loop and even before that we invested in something called spotify for artists and spotify for podcasters which is an app that you can download you can verify that you are that creator and then you get things that software developers have had for years you can see where if you look at your podcast for example on spotify or a song that you released you can see how its performing which cities its performing in whos listening to it whats the demographic breakup so similar in the sense that you can understand how youre actually doing on the platform so we definitely want to build tools i think you also interviewed the head of research for adobe and i think thats an back to photoshop that you like i think thats an interesting analogy as well photoshop i think has been very innovative in helping photographers and artists and i think there should be the same kind of tools for music creators where you could get ai assistance for example as youre creating music as you can do with adobe where you can i want a sky over here and you can get help creating that sky the really fascinating thing is what adobe doesnt have is a distribution for the content you create so you dont have the data of if i create if i you know whatever creation i make in photoshop or premiere i cant get like immediate feedback like i can on youtube for example about the way people are responding and if spotify is creating those tools thats a really exciting actually world but lets talk a little about podcasts so i have trouble talking to one person so its a bit terrifying and kind of hard to fathom but on average 60 to 100000 people will listen to this episode okay so its intimidating yeah its intimidating so i hosted on blueberry i dont know if im pronouncing that correctly actually it looks like most people listen to it on apple podcasts cast box and pocket casts and only about a thousand listen on spotify its just my podcast right so where do you see a time when spotify will dominate this so spotify is relatively new into this podcasting site yeah in podcasting whats the deal with podcasting and spotify how serious is spotify about podcasting do you see a time where everybody would listen to you know probably a huge amount of people majority perhaps listen to music on spotify do you see a time when the same is true for podcasting well i certainly hope so that is our mission our mission as a company is actually to enable a million creators to live off of their art and a billion people be inspired by it and what i think is interesting about that mission is it actually puts the creators first even though it started as a consumer focused company and its just to be able to live off of their art not just make some money off of their art as well so its quite an ambitious project so we think about creators of all kinds and we kind of expanded our mission from being music to being audio a while back and thats not so much because we think we made that decision we think that decision was made for us we think the world made that decision whether we like it or not when you put in your headphones youre going to make a choice between music and a new episode of your podcast or something else were in that world whether we like it or not and thats how radio works so we decided that we think its about audio you can see the rise of audiobooks and so forth we think audio is a great opportunity so we decided to enter it and obviously apple and apple podcasts is absolutely dominating in podcasting and we didnt have a single podcast only like two years ago what we did though was we looked at this and said can we bring something to this we want to do this but back to the original spotify we have to do something that consumers actually value to be able to do this and the reason weve gone from not existing at all to being quite a wide margin the second largest podcast consumption still wide gap to itunes but were growing quite fast i think its because when we looked at the consumer problem people said surprisingly that they wanted their podcasts and music in the same application so what we did was we took a little bit of a different approach where we said instead of building a separate podcast app we thought is there a consumer problem to solve here because the others are very successful already and we thought there was in making a more seamless experience where you can have your podcast and your music in the same application because we think its audio to you and that has been successful and that meant that we actually had 200 million people to offer this to instead of starting from zero so i think we have a good chance because were taking a different approach than the competition and back to the other thing i mentioned about creators because were looking at the end to end flow i think theres a tremendous amount of innovation to do around podcast as a format when we have creation tools and consumption i think we could start improving what podcasting is i mean podcast is this opaque big like one two hour file that youre streaming which it really doesnt make that much sense in 2019 that its not interactive theres no feedback loops nothing like that so i think if were going to win its going to have to be because we build a better product for creators and for consumers so well see but its certainly our goal we have a long way to go well the creators part is really exciting you already you got me hooked there cause the only stats i have blueberry just recently added the stats of whether its listened to the end or not and thats like a huge improvement but thats still nowhere to where you could possibly go in terms of statistics you just download the spotify podcasters up and verify and then then youll know where people dropped out in this episode oh wow okay the moment i started talking okay i might be depressed by this but okay so one um one other question is the original spotify for music and i have a question about podcasting in this line is the idea of podcasting about podcasting in this line is the idea of albums i have uh what did you uh music aficionados uh friends who are really uh big fans of music often uh really enjoy albums listening to entire albums of of an artist correct me if im wrong but i feel like spotify has helped replace the idea of an album with playlists so you create your own albums its its kind of the way at least ive experienced music and ive really enjoyed it that way one of the things that was missing in podcasting for me i dont know if its missing i dont know its an open question for me but the way i listened to podcasts is the way i would listen to albums so i take a joe rogan experience and thats an album and i listened you know i like i i put that on and i listened one episode after the next then theres a sequence and so on is there a room for doing what you did for music or doing what spotify did for music but uh creating playlists sort of uh this kind of playlisting idea of breaking apart from podcasting uh from individual podcasts and creating kind of uh this interplay or or have you thought about that space uh its a great question so i think in um in music youre right basically you bought an album so it was like you bought a small catalog of like 10 tracks right it was it was again it was actually a lot of a lot of consumption you think its about what you like but its based on the business model so you paid for this 10 track service and then you listened to that for a while and then when when everything was flat priced you tended to listen differently now so so i think the i think the album is still tremendously important thats why we have it and you can save albums and so forth and you have a huge amount of people who really listen according to albums and i like that because it is a creator format you can tell a longer story over several tracks and so some people listen to just one track some people actually want to hear that whole story now in podcast i think i think its different you can argue that podcasts might be more like shows on netflix have like a full season of narcos and youre probably not going to do like one episode of narcos and then one of house of cards like like you know theres a narrative there and you you you love the cast and you love these characters so i think people will people love shows and i think they will they will listen to those shows i do think you follow a bunch of shows at the same time so theres certainly an opportunity to bring you the latest episode of you know whatever the five six 10 things that that youre into but but i think i think people are going to listen to specific hosts and love those hosts for a long time because i think theres something different with podcasts where um this format of the the the the the the experience of the of the audience is actually sitting here right between us whereas if you look at something on tv the audio actually would come from you would sit over there and the audio would come to you from both of us as if you were watching not as you were part of the conversation so my experience is having listened to podcasts like yours and joe rogan is i feel like i know all of these people they they have a lot of experience i know all of these people they have no idea who i am but i feel like ive listened to so many hours of that its very different from me watching a watching like a tv show or an interview so i think you you kind of um fall in love with people and um experience in a in a different way so i think i think shows and hosts are going to be very uh very important i dont think thats going to go away into some sort of thing where where you dont even know who youre listening to i dont think thats going to happen what i do think is i think theres a tremendous discovery opportunity in podcast because the catalog is growing quite quickly and i think podcast is only a few like five 600000 shows right now if you look back to youtube as another analogy of creators no one really knows if you would lift the lid on youtube but its probably billions of episodes and so i think the podcast catalog would probably grow tremendously because the creation tools are getting easier and then youre going to have this discovery opportunity that i think is really big so so a lot of people tell me that they love their shows but discovering podcasts kind of suck its really hard to get into new show theyre usually quite long its a big time investment so i think theres plenty of opportunity in the discovery part yeah for sure a hundred percent in in even the dumbest theres so many low hanging fruit too uh for example just knowing what episode to listen to first to try out a podcast exactly uh because most podcasts dont have an order to them uh they they can be listened to out of order and sorry to say some are better than others episodes so some episodes of joe rogan are better than others and its nice to know uh which you should listen to to try it out and theres uh as far as i know almost no information uh in terms of like uh upvotes on how good an episode is exactly so i think part of the problem is uh you its kind of like music there isnt one answer people use music for different things and theres actually many different types of music theres workout music and theres classical piano music and focus music and and and uh so forth i think the same with podcasts some podcasts are sequential theyre supposed to be listened to in in order its actually its actually telling a narrative some podcasts are one topic uh kind of like yours but different guests so you could jump in anywhere some podcasts actually have completely different topics and for those podcasts it might be that i want you know we should recommend one episode because its about ai from someone but then they talk about something that youre not interested in the rest of the episodes so i think our what were spending a lot of time on now is just first understanding the domain and creating kind of the knowledge graph of how do these objects relate and how do people consume and i think well find that its going to be its going to be different im excited because youre the uh spotify is the first people im aware of that are trying to do this for podcasting podcasting has been like a wild west up until now its been a very we want to be very careful though because its been a very good wild west i think its this fragile ecosystem and i we want to make sure that you dont barge in and say like oh were going to internetize this thing and you have to think about the creators you have to understand how they get distribution today who listens to how they make money', 'the following is a conversation with kevin scott the cto of microsoft before that he was the senior vice president of engineering and operations at linkedin and before that he oversaw mobile ads engineering at google he also has a podcast called behind the tech with kevin scott which im a fan of this was a fun and wide ranging conversation that covered many aspects of computing it happened over a month ago before the announcement of microsofts investment in openai that a few people have asked me about im sure therell be one or two people in the future thatll talk with me about the impact of that investment this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and id like to give a special thank you to tom and nelante bighousen for their support of the podcast on patreon thanks tom and nelante hope i didnt mess up your last name too bad your support means a lot and inspires me to keep this series going and now heres my conversation with kevin scott youve described yourself as a kid in a candy store at microsoft because of all the interesting projects that are going on can you try to do the impossible task and give a brief whirlwind view of all the spaces that microsoft is working in both research and product if you include research it becomes even more difficult i think broadly speaking microsofts product portfolio includes everything from big cloud business like a big set of saas services we have sort of the original or like some of what are among the original productivity software products that everybody uses we have an operating system business we have a hardware business where we make everything from computer mice and headphones to high end personal computers and laptops we have a fairly broad ranging research group where we have people doing everything from economics research so theres this really really smart young economist glenn weil who my group works with a lot whos doing this research on these things called radical markets hes written an entire technical book about this whole notion of radical markets so like the research group sort of spans from that to human computer interaction to artificial intelligence and we have github we have linkedin we have a search advertising and news business and like probably a bunch of stuff that im embarrassingly not recounting in this list gaming to xbox and so on right yeah gaming for sure like i was having a super fun conversation this morning with phil spencer so when i was in college there was this game that lucasarts made called day of the tentacle that my friends and i played forever and like were doing some interesting collaboration now with the folks who made day of the tentacle and i was like completely nerding out with tim schafer like the guy who wrote a day of the tentacle this morning just a complete fan boy which sort of it like happens a lot like microsoft has been doing so much stuff at such breadth for such a long period of time that like being cto like most of the time my job is very very serious and sometimes like i get caught up in like how amazing it is to be able to have the conversations that i have with the people i get to have them with yeah to reach back into the sentimental and whats the radical markets and the economics so the idea with radical markets is like can you come up with new market based mechanisms to you know i think we have this were having this debate right now like does capitalism work like free markets work can the incentive structures that are built into these systems produce outcomes that are creating sort of equitably distributed benefits for every member of society you know and i think its a reasonable reasonable set of questions to be asking and so what glenn and so like you know one mode of thought there like if you have doubts that the markets are actually working you can sort of like tip towards like okay lets become more socialist and you know like have central planning and you know governments or some other central organization is like making a bunch of decisions about how you know sort of work gets done and you know like where the you know where the investments and where the outputs of those investments get distributed glenns notion is like lean more into like the market based mechanism so like for instance you know this is one of the more radical ideas like suppose that you had a radical pricing mechanism for assets like real estate where you were you could be bid out of your position in your home you know for instance so like if somebody came along and said you know like i can find higher economic utility for this piece of real estate that youre running your business in like then like you either have to you know sort of bid to sort of stay or like the thing thats got the higher economic utility you know sort of takes over the asset which would make it very difficult to have the same sort of rent seeking behaviors that youve got right now because like if you did speculative bidding like you would very quickly like lose a whole lot of money and so like the prices of the assets would be sort of like very closely indexed to like the value that they could produce and like because like youd have this sort of real time mechanism that would force you to sort of mark the value of the asset to the market then it could be taxed appropriately like you couldnt sort of sit on this thing and say oh like this house is only worth 10000 bucks when like everything around it is worth 10 million thats really so its an incentive structure that where the prices match the value much better yeah and glenn does a much better job than i do at selling and i probably picked the worlds worst example you know and its intentionally provocative so like this whole notion like im not sure whether i like this notion that like we can have a set of market mechanisms where i could get bid out of my property you know but you know like if youre thinking about something like elizabeth warrens wealth tax for instance like you would have i mean itd be really interesting in like how you would actually set the price on the assets and like you might have to have a mechanism like that if you put a tax like that in place its really interesting that that kind of research at least tangentially is touching microsoft research that youre really thinking broadly maybe you can speak to this connects to ai so we have a candidate andrew yang who kind of talks about artificial intelligence and the concern that people have about you know automations impact on society and arguably microsoft is at the cutting edge of innovation in all these kinds of ways and so its pushing ai forward how do you think about combining all our conversations together here with radical markets and socialism and innovation in ai that microsoft is doing and then andrew yangs worry that that will result in job loss for the lower and so on how do you think about that i think its sort of one of the most important questions in technology like maybe even in society right now about how is ai going to develop over the course of the next several decades and whats it going to be used for and what benefits will it produce and what negative impacts will it produce and who gets to steer this whole thing ill say at the highest level one of the real joys of getting to do what i do at microsoft is microsoft has this heritage as a platform company and so bill has this thing that he said a bunch of years ago where the measure of a successful platform is that it produces far more economic value for the people who build on top of the platform than is created for the platform owner or builder and i think we have to think about ai that way as a platform yeah it has to be a platform that other people can use to build businesses to fulfill their creative objectives to be entrepreneurs to solve problems that they have in their work and in their lives it cant be a thing where there are a handful of companies sitting in a very small handful of cities geographically who are making all the decisions about what goes into the ai and then on top of all this infrastructure then build all of the commercially valuable uses for it so i think thats bad from a sort of economics and sort of equitable distribution of value perspective sort of back to this whole notion of did the markets work but i think its also bad from an innovation perspective because i have infinite amounts of faith in human beings that if you give folks powerful tools they will go do interesting things and its more than just a few tens of thousands of people with the interesting tools it should be millions of people with the tools so its sort of like you think about the steam engine in the late 18th century like it was maybe the first large scale substitute for human labor that weve built like a machine and in the beginning when these things are getting deployed the folks who got most of the value from the steam engines were the folks who had capital so they could afford to build them and like they built factories around them and businesses and the experts who knew how to build and maintain them but access to that technology democratized over time like now like an engine its not like a differentiated thing like there isnt one engine company that builds all the engines and all of the things that use engines are made by this company and like they get all the economics from all of that like fully demarcated like theyre probably were sitting here in this room and like even though theyre probably things like the mems gyroscope that are in both of our phones like theres like little engines sort of everywhere theyre just a component in how we build the modern world like ai needs to get there yeah so thats a really powerful way to think if we think of ai as a platform versus a tool that microsoft owns as a platform that enables creation on top of it thats the way to democratize it thats really interesting actually and microsoft throughout its history has been positioned well to do that and the tie back to this radical markets thing like so my team has been working with glenn on this and jaren lanier actually so jaren is the sort of father of virtual reality like hes one of the most interesting human beings on the planet like a sweet sweet guy and so jaren and glenn and folks in my team have been working on this notion of data as labor or like they call it data dignity as well and so the idea is that if you again going back to this sort of industrial analogy if you think about data as the raw material that is consumed by the machine of ai in order to do useful things then like were not doing a really great job right now in having transparent marketplaces for valuing those data contributions so and we all make them explicitly like you go to linkedin you sort of set up your profile on linkedin like thats an explicit contribution like you know exactly the information that youre putting into the system and like you put it there because you have some nominal notion of what value youre going to get in return but its like only nominal like you dont know exactly what value youre getting in return like service is free like its low amount of perceived debt and then youve got all this indirect contribution that youre making just by virtue of interacting with all of the technology thats in your daily life and so like what glenn and jaren and this data dignity team are trying to do is like can we figure out a set of mechanisms that let us value those data contributions so that you could create an economy and like a set of controls and incentives that would allow people to like maybe even in the limit like earn part of their living through the data that theyre creating and like you can sort of see it in explicit ways there are these companies like scale ai and like there are a whole bunch of them in china right now that are basically data labeling companies so like youre doing supervised machine learning you need lots and lots of label training data and like those people who work for those companies are getting compensated for their data contributions into the system and so thats easier to put a number on their contribution because theyre explicitly labeling data correct but youre saying that were all contributing data in different kinds of ways and its fascinating to start to explicitly try to put a number on it do you think thats possible i dont know its hard it really is because we dont have as much transparency as i think we need in like how the data is getting used and its super complicated like we i think as technologists sort of appreciate like some of the subtlety there its like the data gets created and then it gets its not valuable like the data exhaust that you give off or the explicit data that i am putting into the system isnt super valuable atomically like its only valuable when you sort of aggregate it together into sort of large numbers this is true even for these like folks who are getting compensated for like labeling things like for supervised machine learning now like you need lots of labels to train a model that performs well and so i think thats one of the challenges its like how do you sort of figure out like because this data is getting combined in so many ways like through these combinations like how the value is flowing yeah thats fascinating yeah and its fascinating that youre thinking about this and i wasnt even going into this conversation expecting the breadth of research really that microsoft broadly is thinking about youre thinking about at microsoft so if we go back to 89 when microsoft released office or 1990 when they released windows 30 in your view i know you werent there through its history but how has the company changed in the 30 years since as you look at it now the good thing is its started off as a platform company like its still a platform company like the parts of the business that are thriving and most successful are those that are building platforms like the mission of the company now is the missions changed its like changed in a very interesting way so back in 89 90 like they were still on the original mission which was like put a pc on every desk and in every home and it was basically about democratizing access to this new personal computing technology which when bill started the company integrated circuit microprocessors were a brand new thing and people were building homebrew computers from kits like the way people build ham radios right now i think this is the interesting thing for folks who build platforms in general bill saw the opportunity there and what personal computers could do and it was like it was sort of a reach like you just sort of imagine like where things were when they started the company versus where things are now like in success when youve democratized a platform it just sort of vanishes into the platform you dont pay attention to it anymore like operating systems arent a thing anymore like theyre super important like completely critical and like when you see one fail like you just sort of understand but like its not a thing where youre not like waiting for the next operating system thing in the same way that you were in 1995 right like in 1995 like we had rolling stones on the stage with the windows 95 rollout like it was like the biggest thing in the world everybody lined up for it the way that people used to line up for iphone but like you know eventually and like this isnt necessarily a bad thing like it just sort of you know the success is that its sort of it becomes ubiquitous its like everywhere like human beings when their technology becomes ubiquitous they just sort of start taking it for granted so the mission now that satya rearticulated five plus years ago now when he took over as ceo of the company our mission is to empower every individual and every organization in the world to be more successful and so you know again like thats a platform mission and like the way that we do it now is is different its like we have a hyperscale cloud that people are building their applications on top of like we have a bunch of ai infrastructure that people are building their ai applications on top of we have you know we have a productivity suite of software like microsoft dynamics which you know some people might not think is the sexiest thing in the world but its like helping people figure out how to automate all of their business processes and workflows and to help those businesses using it to grow and be more so its a much broader vision in a way now than it was back then like it was sort of very particular thing and like now like we live in this world where technology is so powerful and its like such a basic fact of life that it both exists and is going to get better and better over time or at least more and more powerful over time so like you know what you have to do as a platform player is just much bigger right theres so many directions in which you can transform you didnt mention mixed reality too you know thats probably early days or it depends how you think of it but if we think on a scale of centuries its the early days of mixed reality oh for sure and so with hololens microsoft is doing some really interesting work there do you touch that part of the effort whats the thinking do you think of mixed reality as a platform too oh sure when we look at what the platforms of the future could be its like fairly obvious that like ai is one like you dont have to i mean like thats you know you sort of say it to like someone and you know like they get it but like we also think of the like mixed reality and quantum as like these two interesting you know potentially quantum computing yeah okay so lets get crazy then so youre talking about some futuristic things here well the mixed reality microsoft is really its not even futuristic its here it is its incredible stuff and look and its having an impact right now like one of the more interesting things thats happened with mixed reality over the past couple of years that i didnt clearly see is that its become the computing device for folks who for doing their work who havent used any computing device at all to do their work before so technicians and service folks and people who are doing like machine maintenance on factory floors so like they you know because theyre mobile and like theyre out in the world and theyre working with their hands and you know sort of servicing these like very complicated things theyre they dont use their mobile phone and like they dont carry a laptop with them and you know theyre not tethered to a desk and so mixed reality like where its getting traction right now where hololens is selling a lot of units is for these sorts of applications for these workers and its become like i mean like the people love it theyre like oh my god like this is like for them like the same sort of productivity boosts that you know like an office worker had when they got their first personal computer yeah but you did mention its certainly obvious ai as a platform but can we dig into it a little bit how does ai begin to infuse some of the products in microsoft so currently providing training of for example neural networks in the cloud or providing pre trained models or just even providing computing resources and whatever different inference that you wanna do using neural networks how do you think of ai infusing as a platform that microsoft can provide yeah i mean i think its super interesting its like everywhere and like we run these review meetings now where its me and satya and like members of satyas leadership team and like a cross functional group of folks across the entire company who are working on like either ai infrastructure or like have some substantial part of their product work using ai in some significant way now the important thing to understand is like when you think about like how the ai is gonna manifest in like an experience for something thats gonna make it better like i think you dont want the ainess to be the first order thing its like whatever the product is and like the thing that is trying to help you do like the ai just sort of makes it better and this is a gross exaggeration but like people get super excited about like where the ai is showing up in products and im like do you get that excited about like where youre using a hash table like in your code like its just another its just a tool its a very interesting programming tool but its sort of like its an engineering tool and so like it shows up everywhere so like weve got dozens and dozens of features now in office that are powered by like fairly sophisticated machine learning our search engine wouldnt work at all if you took the machine learning out of it the like increasingly things like content moderation on our xbox and xcloud platform when you mean moderation you mean like the recommender is like showing what you wanna look at next no no no its like anti bullying stuff so the usual social network stuff that you have to deal with yeah correct but its like really its targeted its targeted towards a gaming audience so its like a very particular type of thing where the line between playful banter and like legitimate bullying is like a subtle one and like you have to like its sort of tough like i have id love to if we could dig into it because youre also you led the engineering efforts of linkedin and if we look at linkedin as a social network and if we look at the xbox gaming as the social components the very different kinds of i imagine communication going on on the two platforms right and the line in terms of bullying and so on is different on the platforms so how do you i mean its such a fascinating philosophical discussion of where that line is i dont think anyone knows the right answer twitter folks are under fire now jack at twitter for trying to find that line nobody knows what that line is but how do you try to find the line for trying to prevent abusive behavior and at the same time let people be playful and joke around and that kind of thing i think in a certain way like if you have what i would call vertical social networks it gets to be a little bit easier so like if you have a clear notion of like what your social network should be used for or like what you are designing a community around then you dont have as many dimensions to your sort of content safety problem as you do in a general purpose platform i mean so like on linkedin like the whole social network is about connecting people with opportunity whether its helping them find a job or to sort of find mentors or to sort of help them like find their next sales lead or to just sort of allow them to broadcast their sort of professional identity to their network of peers and collaborators and sort of professional community like that is i mean like in some ways like thats very very broad but in other ways its sort of its narrow and so like you can build ais like machine learning systems that are capable with those boundaries of making better automated decisions about like what is sort of inappropriate and offensive comment or dangerous comment or illegal content when you have some constraints you know same thing with like the gaming social network so for instance like its about playing games not having fun and like the thing that you dont want to have happen on the platform is why bullying is such an important thing like bullying is not fun so you want to do everything in your power to encourage that not to happen and yeah but i think its sort of a tough problem in general and its one where i think you know eventually were going to have to have some sort of clarification from our policymakers about what it is that we should be doing like where the lines are because its tough like you dont like in democracy right like you dont want you want some sort of democratic involvement like people should have a say in like where the lines are drawn like you dont want a bunch of people making like unilateral decisions and like we are in a state right now for some of these platforms where you actually do have to make unilateral decisions where the policymaking isnt going to happen fast enough in order to like prevent very bad things from happening but like we need the policymaking side of that to catch up i think as quickly as possible because you want that whole process to be a democratic thing not a you know not some sort of weird thing where youve got a non representative group of people making decisions that have you know like national and global impact and its fascinating because the digital space is different than the physical space in which nations and governments were established and so what policy looks like globally what bullying looks like globally whats healthy communication looks like globally is an open question and were all figuring it out together which is fascinating yeah i mean with you know sort of fake news for instance and deep fakes and fake news generated by humans yeah so we can talk about deep fakes like i think that is another like you know sort of very interesting level of complexity but like if you think about just the written word right like we have you know we invented papyrus what 3000 years ago where we you know you could sort of put word on paper and then 500 years ago like we get the printing press like where the word gets a little bit more ubiquitous and then like you really really didnt get ubiquitous printed word until the end of the 19th century when the offset press was invented and then you know just sort of explodes and like you know the cross product of that and the industrial revolutions need for educated citizens resulted in like this rapid expansion of literacy and the rapid expansion of the word but like we had 3000 years up to that point to figure out like how to you know like whats journalism whats editorial integrity like whats you know whats scientific peer review and so like you built all of this mechanism to like try to filter through all of the noise that the technology made possible to like you know sort of getting to something that society could cope with and like if you think about just the piece the pc didnt exist 50 years ago and so in like this span of you know like half a century like weve gone from no digital you know no ubiquitous digital technology to like having a device that sits in your pocket where you can sort of say whatever is on your mind to like what did mary have in her mary meeker just released her new like slide deck last week you know weve got 50 penetration of the internet to the global population like there are like three and a half billion people who are connected now so its like its crazy crazy like inconceivable like how fast all of this happened so you know its not surprising that we havent figured out what to do yet but like we gotta really like lean into this set of problems because like we basically have three millennia worth of work to do about how to deal with all of this and like probably what you know amounts to the next decade worth of time so since were on the topic of tough you know tough challenging problems lets look at more on the tooling side in ai that microsoft is looking at is face recognition software so theres a lot of powerful positive use cases for face recognition but theres some negative ones and were seeing those in different governments in the world so how do you how does microsoft think about the use of face recognition software as a platform in governments and companies how do we strike an ethical balance here yeah i think weve articulated a clear point of view so brad smith wrote a blog post last fall i believe that sort of like outlined like very specifically what you know what our point of view is there and you know i think we believe that there are certain uses to which face recognition should not be put and we believe again that theres a need for regulation there like the government should like really come in and say that you know this is where the lines are and like we very much wanted to like figuring out where the lines are should be a democratic process but in the short term like weve drawn some lines where you know we push back against uses of face recognition technology you know like the city of san francisco for instance i think has completely outlawed any government agency from using face recognition tech and like that may prove to be a little bit overly broad but for like certain law enforcement things like you really i would personally rather be overly sort of cautious in terms of restricting use of it until like we have you know sort of defined a reasonable you know democratically determined regulatory framework for like where we could and should use it and you know the other thing there is like weve got a bunch of research that were doing and a bunch of progress that weve made on bias there and like there are all sorts of like weird biases that these models can have like all the way from like the most noteworthy one where you know you may have underrepresented minorities who are like underrepresented in the training data and then you start learning like strange things but like there are even you know other weird things like weve i think weve seen in the public research like models can learn strange things like all doctors are men for instance just yeah i mean and so like it really is a thing where its very important for everybody who is working on these things before they push publish they launch the experiment they you know push the code to you know online or they even publish the paper that they are at least starting to think about what some of the potential negative consequences are some of this stuff i mean this is where you know like the deep fake stuff i find very worrisome just because there are going to be some very good beneficial uses of like gan generated imagery and funny enough like one of the places where its actually useful is were using the technology right now to generate synthetic visual data for training some of the face recognition models to get rid of the bias so like thats one like super good use of the tech but like you know its getting good enough now where you know its going to sort of challenge a normal human beings ability to like now youre just sort of say like its very expensive for someone to fabricate a photorealistic fake video and like gans are going to make it fantastically cheap to fabricate a photorealistic fake video and so like what you assume you can sort of trust is true versus like be skeptical about is about to change and like were not ready for it i dont think the nature of truth right thats its also exciting because i think both you and i probably would agree that the way to solve to take on that challenge is with technology right theres probably going to be ideas of ways to verify which kind of video is legitimate which kind is not so to me thats an exciting possibility most likely for just the comedic genius that the internet usually creates with these kinds of videos and hopefully will not result in any serious harm yeah and it could be you know like i think we will have technology to that may be able to detect whether or not somethings fake or real although the fakes are pretty convincing even like when you subject them to machine scrutiny but you know we also have these increasingly interesting social networks you know that are under fire right now for some of the bad things that they do like one of the things you could choose to do with a social network is like you could you could use crypto and the networks to like have content signed where you could have a like full chain of custody that accompanied every piece of content so like when youre viewing something and like you want to ask yourself like how much can i trust this like you can click something and like have a verified chain of custody that shows like oh this is coming from this source and its like signed by like someone whose identity i trust yeah i think having that you know having that chain of custody like being able to like say oh heres this video like it may or may not have been produced using some of this deepfake technology but if youve got a verified chain of custody where you can sort of trace it all the way back to an identity and you can decide whether or not like i trust this identity like oh no this is really from the white house or like this is really from the you know the office of this particular presidential candidate or its really from you know jeff wiener ceo of linkedin or satya nadella ceo of microsoft like that might be like one way that you can solve some of the problems so like thats not the super high tech like weve had all of this technology forever and but i think youre right like it has to be some sort of technological thing because the underlying tech that is used to create this is not going to do anything but get better over time and the genie is sort of out of the bottle theres no stuffing it back in and theres a social component which i think is really healthy for a democracy where people will be skeptical about the thing they watch in general so you know which is good skepticism in general is good for content so deepfakes in that sense are creating a global skepticism about can they trust what they read it encourages further research i come from the soviet union where basically nobody trusted the media because you knew it was propaganda and that kind of skepticism encouraged further research about ideas as opposed to just trusting any one source well look i think its one of the reasons why the scientific method and our apparatus of modern science is so good like because you dont have to trust anything like the whole notion of modern science beyond the fact that this is a hypothesis and this is an experiment to test the hypothesis and this is a peer review process for scrutinizing published results but stuffs also supposed to be reproducible so you know its been vetted by this process but you also are expected to publish enough detail where if you are sufficiently skeptical of the thing you can go try to reproduce it yourself and like i dont know what it is like i think a lot of engineers are like this where like you know sort of this like your brain is sort of wired for skepticism like you dont just first order trust everything that you see and encounter and like youre sort of curious to understand you know the next thing but like i think its an entirely healthy thing and like we need a little bit more of that right now so im not a large business owner so im just a huge fan of many of microsoft products i mean i still actually in terms of i generate a lot of graphics and images and i still use powerpoint to do that it beats illustrator for me even professional sort of its fascinating so i wonder what is the future of lets say windows and office look like is do you see it i mean i remember looking forward to xp was it exciting when xp was released just like you said i dont remember when 95 was released but xp for me was a big celebration and when 10 came out i was like oh okay well its nice its a nice improvement so what do you see the future of these products i think theres a bunch of excite i mean on the office front theres gonna be this like increasing productivity wins that are coming out of some of these ai powered features that are coming like the products will sort of get smarter and smarter in like a very subtle way like theres not gonna be this big bang moment where like clippy is gonna reemerge and its gonna be wait a minute okay well have to wait wait wait is clippy coming back but quite seriously so injection of ai theres not much or at least im not familiar sort of assistive type of stuff going on inside the office products like a clippy style assistant personal assistant do you think that theres a possibility of that in the future so i think there are a bunch of like very small ways in which like machine learning powered assistive things are in the product right now so there are a bunch of interesting things like the auto response stuffs getting better and better and its like getting to the point where it can auto respond with like okay this persons clearly trying to schedule a meeting so it looks at your calendar and it automatically like tries to find like a time and a space thats mutually interesting like we have this notion of microsoft search at a microsoft search where its like not just web search but its like search across like all of your information thats sitting inside of like your office 365 tenant and like potentially in other products and like we have this thing called the microsoft graph that is basically an api federator that sort of like gets you hooked up across the entire breadth of like all of the like what were information silos before they got woven together with the graph like that is like getting increasing with increasing effectiveness sort of plumbed into some of these auto response things where youre gonna be able to see the system like automatically retrieve information for you like if you know like i frequently send out you know emails to folks where like i cant find a paper or a document or whatnot theres no reason why the system wont be able to do that for you and like i think the its building towards like having things that look more like like a fully integrated you know assistant but like youll have a bunch of steps that you will see before you like it will not be this like big bang thing where like clippy comes back and youve got this like you know manifestation of you know like a fully fully powered assistant so i think thats thats definitely coming in like all of the you know collaboration coauthoring stuffs getting better you know its like really interesting like if you look at how we use the office product portfolio at microsoft like more and more of it is happening inside of like teams as a canvas and like its this thing where you know youve got collaboration is like at the center of the product and like we built some like really cool stuff thats some of which is about to be open source that are sort of framework level things for doing for doing coauthoring thats awesome so in is there a cloud component to that so on the web or is it and forgive me if i dont already know this but with office 365 we still the collaboration we do if were doing word we still send the file around no no so this is were already a little bit better than that a little bit better than that and like you know so like the fact that youre unaware of it means weve got a better job to do like helping you discover discover this stuff but yeah i mean its already like got a huge huge cloud component and like part of you know part of this framework stuff i think were calling it like i like weve been working on it for a couple of years so like i know the internal code name for it but i think when we launched it to build its called the fluid framework and but like what fluid lets you do is like you can go into a conversation that youre having in teams and like reference like part of a spreadsheet that youre working on where somebodys like sitting in the excel canvas like working on the spreadsheet with a you know chart or whatnot and like you can sort of embed like part of the spreadsheet in the teams conversation where like you can dynamically update it and like all of the changes that youre making to the to this object are like you know coordinate and everything is sort of updating in real time so like you can be in whatever canvas is most convenient for you to get your work done so i out of my own sort of curiosity as an engineer i know what its like to sort of lead a team of 10 15 engineers microsoft has i dont know what the numbers are maybe 50 maybe 60000 engineers maybe 40 i dont know exactly what the number is its a lot its tens of thousands right so its more than 10 or 15 what i mean youve led different sizes mostly large size of engineers what does it take to lead such a large group into a continue innovation continue being highly productive and yet develop all kinds of new ideas and yet maintain like what does it take to lead such a large group of brilliant people i think the thing that you learn as you manage larger and larger scale is that there are three things that are like very very important for big engineering teams like one is like having some sort of forethought about what it is that youre gonna be building over large periods of time like not exactly like you dont need to know that like you know im putting all my chips on this one product and like this is gonna be the thing but like its useful to know like what sort of capabilities you think youre going to need to have to build the products of the future and then like invest in that infrastructure like whether and like im not just talking about storage systems or cloud apis its also like what does your development process look like what tools do you want like what culture do you want to build around like how youre you know sort of collaborating together to like make complicated technical things and so like having an opinion and investing in that is like it just gets more and more important and like the sooner you can get a concrete set of opinions like the better youre going to be like you can wing it for a while at small scales like you know when you start a company like you dont have to be like super specific about it but like the biggest miseries that ive ever seen as an engineering leader are in places where you didnt have a clear enough opinion about those things soon enough and then you just sort of go create a bunch of technical debt and like culture debt that is excruciatingly painful to clean up so like thats one bundle of things like the other you know another bundle of things is like its just really really important to like have a clear mission thats not just some cute crap you say because like you think you should have a mission but like something that clarifies for people like where it is that youre headed together like i know its like probably like a little bit too popular right now but yuval hararis book sapiens one of the central ideas in his book is that like storytelling is like the quintessential thing for coordinating the activities of large groups of people like once you get past dunbars number and like ive really really seen that just managing engineering teams like you can just brute force things when youre less than 120 150 folks where you can sort of know and trust and understand what the dynamics are between all the people but like past that like things just sort of start to catastrophically fail if you dont have some sort of set of shared goals that youre marching towards and so like even though it sounds touchy feely and you know like a bunch of technical people will sort of balk at the idea that like you need to like have a clear like the missions like very very very important youre always right right stories thats how our society thats the fabric that connects us all of us is these powerful stories and that works for companies too right it works for everything like i mean even down to like you know you sort of really think about it like our currency for instance is a story our constitution is a story our laws are stories i mean like we believe very very very strongly in them and thank god we do but like they are theyre just abstract things like theyre just words like if we dont believe in them theyre nothing and in some sense those stories are platforms and the kinds some of which microsoft is creating right they have platforms on which we define the future so last question what do you lets get philosophical maybe bigger than even microsoft what do you think the next 20 30 plus years looks like for computing for technology for devices do you have crazy ideas about the future of the world yeah look i think we you know were entering this time where weve got we have technology that is progressing at the fastest rate that it ever has and youve got youve got some really big social problems like society scale problems that we have to tackle and so you know i think were going to rise to the challenge and like figure out how to intersect like all of the power of this technology with all of the big challenges that are facing us whether its you know global warming whether its like the biggest remainder of the population boom is in africa for the next 50 years or so and like global warming is going to make it increasingly difficult to feed the global population in particular like in this place where youre going to have like the biggest population boom i think we you know like ai is going to like if we push it in the right direction like it can do like incredible things to empower all of us to achieve our full potential and to you know like live better lives but like that also means focus on like some super important things like how can you apply it to healthcare to make sure that you know like our quality and cost of and sort of ubiquity of health coverage is better and better over time like thats more and more important every day is like in the united states and like the rest of the industrialized world so western europe china japan korea like youve got this population bubble of like aging working you know working age folks who are you know at some point over the next 20 30 years theyre going to be largely retired and like youre going to have more retired people than working age people and then like youve got you know sort of natural questions about whos going to take care of all the old folks and whos going to do all the work and the answers to like all of these sorts of questions like where youre sort of running into you know like constraints of the you know the world and of society has always been like what tech is going to like help us get around this like when i was a kid in the 70s and 80s like we talked all the time about like population boom population boom like were going to like were not going to be able to like feed the planet and like we were like right in the middle of the green revolution where like this massive technology driven increase in crop productivity like worldwide and like some of that was like taking some of the things that we knew in the west and like getting them distributed to the you know to the developing world and like part of it were things like you know just smarter biology like helping us increase and like we dont talk about like overpopulation anymore because like we can more or less we sort of figured out how to feed the world like thats a technology story and so like im super super hopeful about the future and in the ways where we will be able to apply technology to solve some of these super challenging problems like ive like one of the things that im trying to spend my time doing right now is trying to get everybody else to be hopeful as well because you know back to harare like we are the stories that we tell like if we you know if we get overly pessimistic right now about like the potential future of technology like we you know like we may fail to get all of the things in place that we need to like have our best possible future and that kind of hopeful optimism im glad that you have it because youre leading large groups of engineers that are actually defining that are writing that story that are helping build that future which is super exciting and i agree with everything you said except i do hope clippy comes back we miss him i speak for the people so galen thank you so much for talking to me thank you so much for having me it was a pleasure', 'the following is a conversation with george hotz hes the founder of kama ai a machine learning based vehicle automation company he is most certainly an outspoken personality in the field of ai and technology in general he first gained recognition for being the first person to carry or unlock an iphone and since then hes done quite a few interesting things at the intersection of hardware and software this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and id like to give a special thank you to jennifer from canada for her support of the podcast on patreon merci beaucoup jennifer shes been a friend and an engineering colleague for many years since i was in grad school your support means a lot and inspires me to keep this series going and now heres my conversation with george hotz do you think were living in a simulation yes but it may be unfalsifiable what do you mean by unfalsifiable so if the simulation is designed in such a way that they did like a formal proof to show that no information can get in and out and if their hardware is designed for the anything in the simulation to always keep the hardware in spec it may be impossible to prove whether were in a simulation or not so theyve designed it such that its a closed system you cant get outside the system well maybe its one of three worlds were either in a simulation which can be exploited were in a simulation which not only cant be exploited but like the same things true about vms a really well designed vm you cant even detect if youre in a vm or not thats brilliant so the simulation is running on a virtual machine but now in reality all vms have ways to detect thats the point i mean youve done quite a bit of hacking yourself so you should know that really any complicated system will have ways in and out so this isnt necessarily true going forward i spent my time away from comma i learned coq its a dependently typed its a language for writing math proofs in and if you write code that compiles in a language like that it is correct by definition the types check its correctness so its possible that the simulation is written in a language like this in which case yeah yeah but that cant be sufficiently expressive a language like that oh it can it can be oh yeah okay well so all right so the simulation doesnt have to be turing complete if it has a scheduled end date looks like it does actually with entropy i mean i dont think that a simulation that results in something as complicated as the universe would have a form of proof of correctness right its possible of course we have no idea how good their tooling is and we have no idea how complicated the universe computer really is it may be quite simple its just very large right its very its definitely very large but the fundamental rules might be super simple yeah conways getting a life kind of stuff right so if you could hack so imagine a simulation that is hackable if you could hack it what would you change about the like how would you approach hacking a simulation the reason i gave that talk by the way im not familiar with the talk you gave i just read that you talked about escaping the simulation or something like that so maybe you can tell me a little bit about the theme and the message there too it wasnt a very practical talk about how to actually escape a simulation it was more about a way of restructuring an us versus them narrative if we continue on the path were going with technology i think were in big trouble like as a species and not just as a species but even as me as an individual member of the species so if we could change rhetoric to be more like to think upwards like to think about that were in a simulation and how we could get out already wed be on the right path what you actually do once you do that well i assume i would have acquired way more intelligence in the process of doing that so ill just ask that so the thinking upwards what kind of ideas what kind of breakthrough ideas do you think thinking in that way could inspire and why did you say upwards upwards into space are you thinking sort of exploration in all forms the space narrative that held for the modernist generation doesnt hold as well for the postmodern generation whats the space narrative are we talking about the same space the three dimensional space no no no space like going on space like building like elon musk like were going to build rockets were going to go to mars were going to colonize the universe and the narrative youre referring i was born in the soviet union youre referring to the race to space the race to space yeah explore okay that was a great modernist narrative yeah it doesnt seem to hold the same weight in todays culture im hoping for good postmodern narratives that replace it so lets think so you work a lot with ai so ai is one formulation of that narrative there could be also i dont know how much you do in vr and ar yeah thats another i know less about it but every time i play with it in our research its fascinating that virtual world are you interested in the virtual world i would like to move to virtual reality in terms of your work no i would like to physically move there the apartment i can rent in the cloud is way better than the apartment i can rent in the real world well its all relative isnt it because others will have very nice apartments too so youll be inferior in the virtual world as well no but thats not how i view the world right i dont view the world i mean its a very almost zero sum ish way to view the world say like my great apartment isnt great because my neighbor has one too no my great apartment is great because look at this dishwasher man you just touch the dish and its washed right and that is great in and of itself if i have the only apartment or if everybody had the apartment i dont care so you have fundamental gratitude the world first learned of george hots in august 2007 maybe before then but certainly in august 2007 when you were the first person to unlock carry unlock an iphone how did you get into hacking what was the first system you discovered vulnerabilities for and broke into so that was really kind of the first thing i had a book in 2006 called grey hat hacking and i guess i realized that if you acquired these sort of powers you could control the world but i didnt really know that much about computers back then i started with electronics the first iphone hack was physical cardware you had to open it up and pull an address line high and it was because i didnt really know about software exploitation i learned that all in the next few years and i got very good at it but back then i knew about like how memory chips are connected to processors and stuff you knew about software and programming you just didnt know oh really so your view of the world and computers was physical was hardware actually if you read the code that i released with that in august 2007 its atrocious what language was it c c nice and in a broken sort of state machine ask c i didnt know how to program yeah so how did you learn to program what was your journey cause i mean well talk about it youve live streamed some of your programming this chaotic beautiful mess how did you arrive at that years and years of practice i interned at google after the summer after the iphone unlock and i did a contract for them where i built hardware for street view and i wrote a software library to interact with it and it was terrible code and for the first time i got feedback from people who i respected saying no like dont write code like this now of course just getting that feedback is not enough the way that i really got good was i wanted to write this thing like that could emulate and then visualize like arm binaries cause i wanted to hack the iphone better and i didnt like that i couldnt like see what the i couldnt single step through the processor because i had no debugger on there especially for the low level things like the boot rum and the bootloader so i tried to build this tool to do it and i built the tool once and it was terrible i built the tool a second time it was terrible i built the tool a third time this was by the time i was at facebook it was kind of okay and then i built the tool a fourth time when i was a google intern again in 2014 and that was the first time i was like this is finally usable how do you pronounce this kira kira yeah so its essentially the most efficient way to visualize the change of state of the computer as the program is running thats what you mean by debugger yeah its a timeless debugger so you can rewind just as easily as going forward think about if youre using gdb you have to put a watch on a variable if you wanna see if that variable changes in kira you can just click on that variable and then it shows every single time when that variable was changed or accessed think about it like git for your computers the run log so theres like a deep log of the state of the computer as the program runs and you can rewind why isnt that maybe it is maybe you can educate me why isnt that kind of debugging used more often cause the toolings bad well two things one if youre trying to debug chrome chrome is a 200 megabyte binary that runs slowly on desktops so thats gonna be really hard to use for that but its really good to use for like ctfs and for boot roms and for small parts of code so its hard if youre trying to debug like massive systems whats a ctf and whats a boot rom a boot rom is the first code that executes the minute you give power to your iphone okay and ctf where these competitions that i played capture the flag capture the flag i was gonna ask you about that what are those look at i watched a couple of videos on youtube those look fascinating what have you learned about maybe at the high level of vulnerability of systems from these competitions i feel like in the heyday of ctfs you had all of the best security people in the world challenging each other and coming up with new toy exploitable things over here and then everybody okay who can break it and when you break it you get like theres like a file on the server called flag and then theres a program running listening on a socket thats vulnerable so you write an exploit you get a shell and then you cat flag and then you type the flag into like a web based scoreboard and you get points so the goal is essentially to find an exploit in the system that allows you to run shell to run arbitrary code on that system thats one of the categories thats like the pwnable category pwnable yeah pwnable its like you know you pwn the program its a program thats yeah yeah you know first of all i apologize im gonna say its because im russian but maybe you can help educate me some video game like misspelled own way back in the day yeah and its just i wonder if theres a definition ill have to go to urban dictionary for it itll be interesting to see what it says okay so what was the heyday of ctf by the way but was it what decade are we talking about i think like i mean maybe unbiased because its the era that i played but like 2011 to 2015 because the modern ctf scene is similar to the modern competitive programming scene you have people who like do drills you have people who practice and then once youve done that youve turned it less into a game of generic computer skill and more into a game of okay you drill on these five categories and then before that it wasnt it didnt have like as much attention as it had i dont know they were like i won 30000 once in korea for one of these competitions holy crap yeah they were they were that was so that means i mean money is money but that means there was probably good people there exactly yeah are the challenges human constructed or are they grounded in some real flaws and real systems usually theyre human constructed but theyre usually inspired by real flaws what kind of systems are imagined is really focused on mobile like what has vulnerabilities these days is it primarily mobile systems like android oh everything does still yeah of course the price has kind of gone up because less and less people can find them and whats happened in security is now if you want to like jailbreak an iphone you dont need one exploit anymore you need nine nine chained together what would it mean yeah wow okay so its really whats the benefit speaking higher level philosophically about hacking i mean it sounds from everything ive seen about you you just love the challenge and you dont want to do anything you dont want to bring that exploit out into the world and do any actual let it run wild you just want to solve it and then you go on to the next thing oh yeah i mean doing criminal stuffs not really worth it and ill actually use the same argument for why i dont do defense for why i dont do crime if you want to defend a system say the system has 10 holes right if you find nine of those holes as a defender you still lose because the attacker gets in through the last one if youre an attacker you only have to find one out of the 10 but if youre a criminal if you log on with a vpn nine out of the 10 times but one time you forget youre done because youre caught okay because you only have to mess up once to be caught as a criminal thats why im not a criminal but okay let me because i was having a discussion with somebody just at a high level about nuclear weapons actually why were having blown ourselves up yet and my feeling is all the smart people in the world if you look at the distribution of smart people smart people are generally good and then this other person i was talking to sean carroll the physicist and he was saying no good and bad people are evenly distributed amongst everybody my sense was good hackers are in general good people and they dont want to mess with the world whats your sense im not even sure about that like i have a nice life crime wouldnt get me anything but if youre good and you have these skills you probably have a nice life too right right you can use it for other things but is there an ethical is there a little voice in your head that says well yeah if you could hack something to where you could hurt people and you could earn a lot of money doing it though not hurt physically perhaps but disrupt their life in some kind of way isnt there a little voice that says well two things one i dont really care about money so like the money wouldnt be an incentive the thrill might be an incentive but when i was 19 i read crime and punishment and that was another great one that talked me out of ever really doing crime cause its like thats gonna be me id get away with it but it would just run through my head even if i got away with it you know and then you do crime for long enough youll never get away with it thats right in the end thats a good reason to be good i wouldnt say im good i would just say im not bad youre a talented programmer and a hacker in a good positive sense of the word youve played around found vulnerabilities in various systems what have you learned broadly about the design of systems and so on from that whole process you learn to not take things for what people say they are but you look at things for what they actually are yeah i understand thats what you tell me it is but what does it do right and you have nice visualization tools to really know what its really doing oh i wish im a better programmer now than i was in 2014 i said kira that was the first tool that i wrote that was usable i wouldnt say the code was great i still wouldnt say my code is great so how was your evolution as a programmer except practice so you started with c at which point did you pick up python because youre pretty big in python now now yeah in college i went to carnegie mellon when i was 22 i went back im like all right im gonna take all your hardest cs courses well see how i do right like did i miss anything by not having a real undergraduate education took operating systems compilers ai and theyre like a freshman wheat or math course and operating systems some of those classes you mentioned are pretty tough actually theyre great at least the 2012 circa 2012 operating systems and compilers were two of the they were the best classes ive ever taken in my life because you write an operating system and you write a compiler i wrote my operating system in c and i wrote my compiler in haskell but somehow i picked up python that semester as well i started using it for the ctfs actually thats when i really started to get into ctfs and ctfs youre all its a race against the clock so i cant write things in c oh theres a clock component so you really want to use the programming languages so you can be fastest 48 hours pwn as many of these challenges as you can pwn yeah you got like a hundred points of challenge whatever team gets the most you were both at facebook and google for a brief stint yeah with project zero actually at google for five months where you developed kira what was project zero about in general what im just curious about the security efforts in these companies well project zero started the same time i went there what years are there 2015 2015 so that was right at the beginning of project zero its small its googles offensive security team ill try to give the best public facing explanation that i can so the idea is basically these vulnerabilities exist in the world nation states have them some high powered bad actors have them sometime people will find these vulnerabilities and submit them in bug bounties to the companies but a lot of the companies dont really care they dont even fix the bug it doesnt hurt for there to be a vulnerability so project zero is like were going to do it different were going to announce a vulnerability and were going to give them 90 days to fix it and then whether they fix it or not to what youre describing which is really turning into not some kind of modular thing but really do formulate it as a learning problem and solve the learning problem with scale so how many years put one is how many years would it take to solve this problem or just how hard is this freaking problem well the cool thing is i think theres a lot of value that we can deliver along the way i think that you can build lane keeping assist actually plus adaptive cruise control plus okay looking at ways extends to like all of driving yeah most of driving right oh your adaptive cruise control treats red lights like cars okay so lets jump around you mentioned that you didnt like navigate an autopilot what advice how would you make it better do you think as a feature that if its done really well its a good feature i think that its too reliant on like hand coded hacks for like how does navigate an autopilot do a lane change it actually does the same lane change every time and it feels mechanical humans do different lane changes humans sometime will do a slow one sometimes do a fast one navigate an autopilot at least every time i use it it is the identical lane change how do you learn i mean this is a fundamental thing actually is the braking and then accelerating something thats still tesla probably does it better than most cars but it still doesnt do a great job of creating a comfortable natural experience and navigate an autopilot is just lane changes and extension of that so how do you learn to do a natural lane change so we have it and i can talk about how it works so i feel that we have the solution for lateral we dont yet have the solution for longitudinal theres a few reasons longitudinal is harder than lateral the lane change component the way that we train on it very simply is like our model has an input for whether its doing a lane change or not and then when we train the end to end model we hand label all the lane changes cause you have to ive struggled a long time about not wanting to do that but i think you have to or the training data for the training data right oh we actually we have an automatic ground truther which automatically labels all the lane changes was that possible to automatically label the lane changes yeah yeah detect the lane i see when it crosses it right and i dont have to get that high percent accuracy but its like 95 good enough now i set the bit when its doing the lane change in the end to end learning and then i set it to zero when its not doing a lane change so now if i wanted to do a lane change at test time i just put the bit to a one and itll do a lane change yeah but so if you look at the space of lane change you know some percentage not a hundred percent that we make as humans is not a pleasant experience cause we messed some part of it up its nerve wracking to change the look you have to see it has to accelerate how do we label the ones that are natural and feel good you know thats the cause thats your ultimate criticism the current navigate and autopilot just doesnt feel good well the current navigate and autopilot is a hand coded policy written by an engineer in a room who probably went out and tested it a few times on the 280 probably a more a better version of that but yes thats how we would have written it at comma ai yeah yeah yeah maybe tesla did tesla they tested it in the end that mightve been two engineers two engineers yeah no but so if you learn the lane change if you learn how to do a lane change from data just like you have a label that says lane change and then you put it in when you want it to do the lane change itll automatically do the lane change thats appropriate for the situation now to get at the problem of some humans do bad lane changes we havent worked too much on this problem yet its not that much of a problem in practice my theory is that all good drivers are good in the same way and all bad drivers are bad in different ways and weve seen some data to back this up well beautifully put so you just basically if thats true hypothesis then your task is to discover the good drivers the good drivers stand out because theyre in one cluster and the bad drivers are scattered all over the place and your net learns the cluster yeah thats so you just learn from the good drivers and theyre easy to cluster in fact we learned from all of them and the net automatically learns the policy thats like the majority but well eventually probably have to filter them out if that theory is true i hope its true because the counter theory is there is many clusters maybe arbitrarily many clusters of good drivers because if theres one cluster of good drivers you can at least discover a set of policies you can learn a set of policies which would be good universally yeah that would be a nice that would be nice if its true and youre saying that there is some evidence that lets say lane changes can be clustered into four clusters right right theres this finite level of i would argue that all four of those are good clusters all the things that are random are noise and probably bad and which one of the four you pick or maybe its 10 or maybe its 20 you can learn that its context dependent it depends on the scene and the hope is its not too dependent on the driver yeah the hope is that it all washes out the hope is that theres that the distributions not bimodal the hope is that its a nice gaussian so what advice would you give to tesla how to fix how to improve navigating autopilot thats the lessons that youve learned from comm ai the only real advice i would give to tesla is please put driver monitoring in your cars with respect to improving it you cant do that anymore i decided to interrupt but you know theres a practical nature of many of hundreds of thousands of cars being produced that dont have a good driver facing camera the model 3 has a selfie cam is it not good enough did they not put ir leds for night thats a good question but i do know that its fisheye and its relatively low resolution so its really not designed it wasnt it wasnt designed for driver monitoring you can hope that you can kind of scrape up and have something from it yeah but why didnt they put it in today put it in today put it in today every time ive heard karpathy talk about the problem and talking about like software 20 and how the machine learning is gobbling up everything i think this is absolutely the right strategy i think that he didnt write navigate on autopilot i think somebody else did and kind of hacked it on top of that stuff i think when karpathy says wait a second why did we hand code this lane change policy with all these magic numbers were gonna learn it from data theyll fix it they already know what to do there well thats andreis job is to turn everything into a learning problem and collect a huge amount of data the reality is though not every problem can be turned into a learning problem in the short term in the end everything will be a learning problem the reality is like if you wanna build l5 vehicles today it will likely involve no learning and thats the reality is so at which point does learning start its the crutch statement that lidar is a crutch at which point will learning get up to part of human performance its over human performance on imagenet classification on driving its a question still it is a question ill say this im here to play for 10 years im not here to try to im here to play for 10 years and make money along the way im not here to try to promise people that im gonna have my l5 taxi network up and working in two years do you think that was a mistake yes what do you think was the motivation behind saying that other companies are also promising l5 vehicles with very different approaches in 2020 2021 2022 if anybody would like to bet me that those things do not pan out i will bet you even money even money ill bet you as much as you want yeah so are you worried about whats going to happen cause youre not in full agreement on that whats going to happen when 2022 21 come around and nobody has fleets of autonomous vehicles well you can look at the history if you go back five years ago they were all promised by 2018 and 2017 but they werent that strong of promises i mean ford really declared pretty i think not many have declared as like definitively as they have now these dates well okay so lets separate l4 and l5 do i think that its possible for waymo to continue to kind of like hack on their system until it gets to level four in chandler arizona yes when theres no safety driver chandler arizona yeah by sorry which year are we talking about oh i even think thats possible by like 2020 2021 but level four chandler arizona not level five new york city level four meaning some very defined streets it works out really well very defined streets and then practically these streets are pretty empty if most of the streets are covered in waymos waymo can kind of change the definition of what driving is right if your self driving network is the majority of cars in an area they only need to be safe with respect to each other and all the humans will need to learn to adapt to them now go drive in downtown new york well yeah thats i mean already you can talk about autonomy and like on farms it already works great because you can really just follow the gps line so what does success look like for common ai what are the milestones like where you can sit back with some champagne and say we did it boys and girls well its never over yeah but you must drink champagne and celebrate so what is a good what are some wins a big milestone that were hoping for by mid next year is profitability of the company and were gonna have to revisit the idea of selling a consumer product but its not gonna be like the comma one when we do it its gonna be perfect open pilot has gotten so much better in the last two years were gonna have a few features were gonna have a hundred percent driver monitoring were gonna disable no safety features in the car actually i think itd be really cool what were doing right now our project this week is were analyzing the data set and looking for all the aeb triggers from the manufacturer systems we have better data set on that than the manufacturers how much just how many does toyota have 10 million miles of real world driving to know how many times their aeb triggered so let me give you cause you asked right financial advice yeah cause i work with a lot of automakers and one possible source of money for you which ill be excited to see you take on is basically selling the data so which is something that most people and not selling in a way where here here at automaker but creating weve done this actually at mit not for money purposes but you could do it for significant money purposes and make the world a better place by creating a consortia where automakers would pay in and then they get to have free access to the data and i think a lot of people are really hungry for that and would pay significant amount of money for it heres the problem with that i like this idea all in theory itd be very easy for me to give them access to my servers and we already have all open source tools to access this data its in a great format we have a great pipeline but theyre gonna put me in the room with some business development guy and im gonna have to talk to this guy and hes not gonna know most of the words im saying im not willing to tolerate that okay mick jagger no no no no no i think i agree with you im the same way but you just tell them the terms and theres no discussion needed if i could just tell them the terms yeah and like all right who wants access to my data i will sell it to you for lets say you want a subscription ill sell to you for 100k a month anyone 100k a month 100k a month ill give you access to this data subscription yeah yeah i think thats kind of fair came up with that number off the top of my head if somebody sends me like a three line email where its like we would like to pay 100k a month to get access to your data we would agree to like reasonable privacy terms of the people who are in the data set i would be happy to do it but thats not going to be the email the email is going to be hey do you have some time in the next month where we can sit down and we can i dont have time for that were moving too fast yeah you could politely respond to that email but not saying i dont have any time for your bullshit you say oh well unfortunately these are the terms and so this is we try to we brought the cost down for you in order to minimize the friction and communication absolutely heres the whatever it is one two million dollars a year and you have access and its not like i get that email from like but okay am i going to reach out am i going to hire a business development person whos going to reach out to the automakers no way yeah okay i got you if they reached into me im not going to ignore the email ill come back with something like yeah if youre willing to pay 100k a month for access to the data im happy to set that up thats worth my engineering time thats actually quite insightful of you youre right probably because many of the automakers are quite a bit old school there will be a need to reach out and they want it but therell need to be some communication youre right mobileye circa 2015 had the lowest rd spend of any chip maker like per per and you look at all the people who work for them and its all business development people because the car companies are impossible to work with yeah so youre you have no patience for that and youre youre legit android huh i have something to do right like like its not like its not like i dont like i dont mean to like be a dick and say like i dont have patience for that but its like that stuff doesnt help us with our goal of winning self driving cars if i want money in the short term if i showed off like the actual like the learning tech that we have its its somewhat sad like its years and years ahead of everybody elses not to maybe not teslas i think tesla has some more stuff to us actually yeah i think tesla has similar stuff but when you compare it to like what the toyota research institute has youre not even close to what we have no comments but i also cant i have to take your comments i intuitively believe you but i have to take it with a grain of salt because i mean you are an inspiration because you basically dont care about a lot of things that other companies care about you dont try to bullshit in a sense like make up stuff so to drive up valuation youre really very real and youre trying to solve the problem and admire that a lot what i dont necessarily fully cant trust you on with all due respect is how good it is right i can only but i also know how bad others are and so ill say two things about trust but verify right ill say two things about that one is try get in a 2020 corolla and try open pilot 06 when it comes out next month i think already youll look at this and youll be like this is already really good and then i could be doing that all with hand labelers and all with like the same approach that mobileye uses when we release a model that no longer has the lanes in it that only outputs a path then think about how we did that machine learning and then right away when you see and thats gonna be an open pilot thats gonna be an open pilot before 10 when you see that model youll know that everything im saying is true because how else did i get that model good you know what im saying is true about the simulator yeah yeah this is super exciting thats super exciting but like you know i listened to your talk with kyle and kyle was originally building the aftermarket system and he gave up on it because of technical challenges because of the fact that hes gonna have to support 20 to 50 cars we support 45 because what is he gonna do when the manufacturer abs system triggers we have alerts and warnings to deal with all of that and all the cars and how is he going to formally verify it well i got 10 million miles of data its probably better its probably better verified than the spec yeah im glad youre here talking to me this is ill remember this day because its interesting if you look at kyles from cruise im sure they have a large number of business development folks and you work with hes working with gm you could work with argo ai working with ford its interesting because chances that you fail business wise like bankrupt are pretty high yeah and yet its the android model is youre actually taking on the problem so thats really inspiring i mean well i have a long term way for comma to make money too and one of the nice things when you really take on the problem which is my hope for autopilot for example is things you dont expect ways to make money or create value that you dont expect will pop up oh ive known how to do it since kind of 2017 is the first time i said it which part to know how to do which part our long term plan is to be a car insurance company insurance yeah i love it yep yep i make driving twice as safe not only that i have the best data such to know who statistically is the safest drivers and oh oh we see you we see you driving unsafely were not gonna insure you and that causes a bifurcation in the market because the only people who cant get comma insurance are the bad drivers geico can insure them their premiums are crazy high our premiums are crazy low well win car insurance take over that whole market okay so if we win if we win but thats what im saying how do you turn comma into a 10 billion company its that thats right so you elon musk who else who else is thinking like this and working like this in your view who are the competitors are there people seriously i dont think anyone that im aware of is seriously taking on lane keeping like where its a huge business that turns eventually into full autonomy that then creates yeah like that creates other businesses on top of it and so on thinks insurance thinks all kinds of ideas like that do you know anyone else thinking like this not really thats interesting i mean my sense is everybody turns to that in like four or five years like ford once the autonomy doesnt fall through yeah but at this time elons the ios by the way he paved the way for all of us its the ios true i would not be doing comma ai today if it was not for those conversations with elon and if it were not for him saying like i think he said like well obviously were not gonna use lidar we use cameras humans use cameras so what do you think about that how important is lidar everybody else on l5 is using lidar what are your thoughts on his provocative statement that lidar is a crutch see sometimes hell say dumb things like the driver monitoring thing but sometimes hell say absolutely completely 100 obviously true things of course lidar is a crutch its not even a good crutch youre not even using it oh theyre using it for localization yeah which isnt good in the first place if you have to localize your car to centimeters in order to drive like thats not driving currently not doing much machine learning i thought for lidar data meaning like to help you in the task of general task of perception the main goal of those lidars on those cars i think is actually localization more than perception or at least thats what they use them for yeah thats true if you want to localize to centimeters you cant use gps the fanciest gps in the world cant do it especially if youre under tree cover and stuff with lidar you can do this pretty easily so you really theyre not taking on i mean in some research theyre using it for perception but and theyre certainly not which is sad theyre not fusing it well with vision they do use it for perception im not saying they dont use it for perception but the thing that they have vision based and radar based perception systems as well you could remove the lidar and keep around a lot of the dynamic object perception you want to get centimeter accurate localization good luck doing that with anything else so what should cruz waymo do like what would be your advice to them now i mean waymo is actually theyre i mean theyre doing theyre serious waymo out of the ball of them are quite so serious about the long game if l5 is a lot requires 50 years i think waymo will be the only one left standing at the end with the given the financial backing that they have buku google bucks ill say nice things about both waymo and cruz lets do it nice is good waymo is by far the furthest along with technology waymo has a three to five year lead on all the competitors if that if the waymo looking stack works maybe three year lead if the waymo looking stack works they have a three year lead now i argue that waymo has spent too much money to recapitalize to gain back their losses in those three years also self driving cars have no network effect like that uber has a network effect you have a market you have drivers and you have riders self driving cars you have capital and you have riders theres no network effect if i want to blanket a new city in self driving cars i buy the off the shelf chinese knockoff self driving cars and i buy enough of them in the city i cant do that with drivers and thats why uber has a first mover advantage that no self driving car company will can you disentangle that a little bit uber youre not talking about uber the autonomous vehicle uber youre talking about the uber car the yeah im uber i open for business in austin texas lets say i need to attract both sides of the market i need to both get drivers on my platform and riders on my platform and i need to keep them both sufficiently happy right riders arent gonna use it if it takes more than five minutes for an uber to show up drivers arent gonna use it if they have to sit around all day and theres no riders so you have to carefully balance a market and whenever you have to carefully balance a market theres a great first mover advantage because theres a switching cost for everybody right the drivers and the riders would have to switch at the same time lets even say that you know lets say a luber shows up and luber somehow you know agrees to do things at a bigger you know were just gonna weve done it more efficiently right luber is only takes 5 of a cut instead of the 10 that uber takes no one is gonna switch because the switching cost is higher than that 5 so you actually can in markets like that you have a first mover advantage yeah autonomous vehicles of the level five variety have no first mover advantage if the technology becomes commoditized say i wanna go to a new city look at the scooters its gonna look a lot more like scooters every person with a checkbook can blanket a city in scooters and thats why you have 10 different scooter companies which ones gonna win its a race to the bottom its a terrible market to be in because theres no market for scooters and the scooters dont get a say in whether they wanna be bought and deployed to a city or not right so the yeah were gonna entice the scooters with subsidies and deals and so whenever you have to invest that capital it doesnt it doesnt come back yeah that cant be your main criticism of the waymo approach oh im saying even if it does technically work even if it does technically work thats a problem yeah i dont know if i were to say i would say youre already there i havent even thought about that but i would say the bigger challenge is the technical approach the so waymos cruises and not just the technical approach but of creating value i still dont understand how you beat uber the human driven cars in terms of financially it doesnt make sense to me that people wanna get in an autonomous vehicle i dont understand how you make money in the longterm yes like real longterm but it just feels like theres too much capital investment needed oh and theyre gonna be worse than ubers because theyre gonna stop for every little thing everywhere ill say a nice thing about cruise that was my nice thing about waymo theyre three years ahead wait what was the nice oh because theyre three theyre three years technically ahead of everybody their tech stack is great my nice thing about cruise is gm buying them was a great move for gm for 1 billion gm bought an insurance policy against waymo they put cruise is three years behind waymo that means google will get a monopoly on the technology for at most three years and if technology works so you might not even be right about the three years it might be less might be less cruise actually might not be that far behind i dont know how much waymo has waffled around or how much of it actually is just that long tail yeah okay if thats the best you could say in terms of nice things thats more of a nice thing for gm that thats the smart insurance policy its a smart insurance policy i mean i think thats how i cant see cruise working out any other for cruise to leapfrog waymo would really surprise me yeah so lets talk about the underlying assumption of everything is were not gonna leapfrog tesla tesla would have to seriously mess up for us because youre okay so the way you leapfrog right is you come up with an idea or you take a direction perhaps secretly that the other people arent taking and so the cruise waymo even aurora i dont know aurora zooks is the same stack as well theyre all the same code base even and theyre all the same darpa urban challenge code base so the question is do you think theres a room for brilliance and innovation that will change everything like say okay so ill give you examples it could be if revolution and mapping for example that allow you to map things do hd maps of the whole world all weather conditions somehow really well or revolution and simulation to where the all the way you said before becomes incorrect that kind of thing any room for breakthrough innovation what i said before about oh they actually get the whole thing well ill say this about we divide driving into three problems and i actually havent solved the third yet but i havent had you how to do it so theres the static the static driving problem is assuming you are the only car on the road right and this problem can be solved 100 with mapping and localization this is why farms work the way they do if all you have to deal with is the static problem and you can statically schedule your machines right its the same as like statically scheduling processes you can statically schedule your tractors to never hit each other on their paths right cause they know the speed they go at so thats the static driving problem maps only helps you with the static driving problem yeah the question about static driving youve just made it sound like its really easy static driving is really easy how easy how well cause the whole drifting out of lane when tesla drifts out of lane its failing on the fundamental static driving problem tesla is drifting out of lane the static driving problem is not easy for the world the static driving problem is easy for one route one route and one weather condition with one state of lane markings and like no deterioration no cracks in the road no im assuming you have a perfect localizer so thats solved for the weather condition and the lane marking condition but thats the problem is how do you have a perfect localizer perfect localizers are not that hard to build okay come on now with lidar with lidar yeah oh with lidar okay with lidar yeah but you use lidar right like use lidar build a perfect localizer building a perfect localizer without lidar its gonna be hard you can get 10 centimeters without lidar you can get one centimeter with lidar im not even concerned about the one or 10 centimeters im concerned if every once in a while youre just way off yeah so this is why you have to carefully make sure youre always tracking your position you wanna use lidar camera fusion but you can get the reliability of that system up to 100000 miles and then you write some fallback condition where its not that bad if youre way off right i think that you can get it to the point its like asld that youre never in a case where youre way off and you dont know it yeah okay so this is brilliant so thats the static static we can especially with lidar and good hg maps you can solve that problem easy no i just disagree with your word easy the static problems so easy its very typical for you to say something is easy i got it no its not as challenging as the other ones okay well okay maybe its obvious how to solve it the third ones the hardest and a lot of people dont even think about the third one and even see it as different from the second one so the second one is dynamic the second one is like say theres an obvious example is like a car stopped at a red light right you cant have that car in your map because you dont know whether that car is gonna be there or not so you have to detect that car in real time and then you have to do the appropriate action right also that car is not a fixed object that car may move and you have to predict what that car will do right so this is the dynamic problem yeah so you have to deal with this this involves again like youre gonna need models of other peoples behavior are you including in that i dont wanna step on the third one oh but are you including in that your influence on people ah thats the third one okay thats the third one we call it the counterfactual yeah brilliant and that i just talked to judea pearl whos obsessed with counterfactuals and the counterfactual oh yeah yeah i read his books so the static and the dynamic yeah our approach right now for lateral will scale completely to the static and dynamic the counterfactual the only way i have to do it yet the thing that i wanna do once we have all of these cars is i wanna do reinforcement learning on the world im always gonna turn the exploiter up to max im not gonna have them explore but the only real way to get at the counterfactual is to do reinforcement learning because the other agents are humans so thats fascinating that you break it down like that i agree completely ive spent my life thinking about this problem its beautiful and part of it because youre slightly insane its good because not my life just the last four years no no you have some nonzero percent of your brain has a madman in it which is good thats a really good feature but theres a safety component to it that i think sort of with counterfactuals and so on that would just freak people out how do you even start to think about just in general i mean youve had some friction with nhtsa and so on i am frankly exhausted by safety engineers the prioritization on safety over innovation to a degree where it kills in my view kills safety in the long term so the counterfactual thing they just actually exploring this world of how do you interact with dynamic objects and so on how do you think about safety you can do reinforcement learning without ever exploring and i said that so you can think about your in reinforcement learning its usually called a temperature parameter and your temperature parameter is how often you deviate from the argmax i could always set that to zero and still learn and i feel that youd always want that set to zero on your actual system gotcha but the problem is you first dont know very much and so youre going to make mistakes so the learning the exploration happens through mistakes yeah but okay so the consequences of a mistake open pilot and autopilot are making mistakes left and right we have 700 daily active users a thousand weekly active users open pilot makes tens of thousands of mistakes a week these mistakes have zero consequences these mistakes are oh i wanted to take this exit and it went straight so im just going to carefully touch the wheel the humans catch them the humans catch them and the human disengagement is labeling that reinforcement learning in a completely consequence free way so driver monitoring is the way you ensure they keep yes they keep paying attention how is your messaging say i gave you a billion dollars you would be scaling it now oh i couldnt scale it with any amount of money id raise money if i could if i had a way to scale it yeah youre now not focused on scale i dont know how to do oh like i guess i could sell it to more people but i want to make the system better better better and i dont know how to i mean but whats the messaging here i got a chance to talk to elon and he basically said that the human factor doesnt matter you know the human doesnt matter because the system will perform therell be sort of a sorry to use the term but like a singular like a point where it gets just much better and so the human it wont really matter but it seems like that human catching the system when it gets into trouble is like the thing which will make something like reinforcement learning work so how do you think messaging for tesla for you should change for the industry in general should change i think our messaging is pretty clear at least like our messaging wasnt that clear in the beginning and i do kind of fault myself for that we are proud right now to be a level two system we are proud to be level two if we talk about level four its not with the current hardware its not gonna be just a magical ota upgrade its gonna be new hardware its gonna be very carefully thought out right now we are proud to be level two and we have a rigorous safety model i mean not like okay rigorous who knows what that means but we at least have a safety model and we make it explicit as in safetymd in openpilot and it says seriously though safetymd this is brilliant this is so android well this is the safety model and i like to have conversations like sometimes people will come to you and theyre like your systems not safe okay have you read my safety docs would you like to have an intelligent conversation about this and the answer is always no they just like scream about it runs python okay what so youre saying that because pythons not real time python not being real time never causes disengagements disengagements are caused by the model is qm but safetymd says the following first and foremost the driver must be paying attention at all times i still consider the software to be alpha software until we can actually enforce that statement but i feel its very well communicated to our users two more things one is the user must be able to easily take control of the vehicle at all times so if you step on the gas or brake with openpilot it gives full manual control back to the user or press the cancel button step two the car will never react so quickly we define so quickly to be about one second that you cant react in time and we do this by enforcing torque limits braking limits and acceleration limits so we have like our torque limits way lower than teslas this is another potential if i could tweak autopilot i would lower their torque limit and i would add driver monitoring because autopilot can jerk the wheel hard openpilot cant we limit and all this code is open source readable and i believe now its all misra c compliant whats that mean misra is like the automotive coding standard at first ive come to respect ive been reading like the standards lately and ive come to respect them theyre actually written by very smart people yeah theyre brilliant people actually they have a lot of experience theyre sometimes a little too cautious but in this case it pays off misra is written by like computer scientists and you can tell by the language they use you can tell by the language they use they talk about like whether certain conditions in misra are decidable or undecidable and you mean like the halting problem and yes all right youve earned my respect i will read carefully what you have to say and we wanna make our code compliant with that all right so youre proud level two beautiful so you were the founder and i think ceo of kama ai then you were the head of research what the heck are you now whats your connection to kama ai im the president but im one of those like unelected presidents of like a small dictatorship country not one of those like elected presidents oh so youre like putin when he was like the yeah i got you so theres a whats the governance structure whats the future of kama ai i mean yeah its a business do you want are you just focused on getting things right now making some small amount of money in the meantime and then when it works it works and you scale our burn rate is about 200k a month and our revenue is about 100k a month so we need to forex our revenue but we havent like tried very hard at that yet and the revenue is basically selling stuff online yeah we sell stuff shopkamaai is there other well okay so youll have to figure out the revenue thats our only see but to me thats like respectable revenues we make it by selling products to consumers who are honest and transparent about what they are most actually level four companies right cause you could easily start blowing up like smoke like overselling the hype and feeding into getting some fundraisers oh youre the guy youre a genius because you hacked the iphone oh i hate that i hate that yeah well i can trade my social capital for more money i did it once i almost regret it doing it the first time well on a small tangent whats your you seem to not like fame and yet youre also drawn to fame where are you on that currently have you had some introspection some soul searching yeah i actually ive come to a pretty stable position on that like after the first time i realized that i dont want attention from the masses i want attention from people who i respect who do you respect i can give a list of people so are these like elon musk type characters yeah well actually you know what ill make it more broad than that i wont make it about a person i respect skill i respect people who have skills right and i would like to like be im not gonna say famous but be like known among more people who have like real skills who in cars do you think have skill not do you respect oh kyle vogt has skill a lot of people at waymo have skill and i respect them i respect them as engineers like i can think i mean i think about all the times in my life where ive been like dead set on approaches and they turn out to be wrong so i mean this might i might be wrong i accept that i accept that theres a decent chance that im wrong and actually i mean having talked to chris hermsons sterling anderson those guys i mean i deeply respect chris i just admire the guy hes legit when you drive a car through the desert when everybody thinks its impossible thats legit and then i also really respect the people who are like writing the infrastructure of the world like the linus torvalds and the chris lattiners they were doing the real work i know theyre doing the real work this having talked to chris like chris lattiners you realize especially when theyre humble its like you realize oh you guys were just using your oh yeah all the hard work that you did yeah thats incredible what do you think mr anthony lewandowski what do you hes another mad genius sharp guy oh yeah what do you think he might long term become a competitor oh to comma well so i think that he has the other right approach i think that right now theres two right approaches one is what were doing and one is what hes doing can you describe i think its called pronto ai he started a new thing do you know what the approach is i actually dont know embark is also doing the same sort of thing the idea is almost that you want to so if youre i cant partner with honda and toyota honda and toyota are like 400000 person companies its not even a company at that point i dont think of it like i dont personify it i think of it like an object but a trucker drives for a fleet maybe that has like some truckers are independent some truckers drive for fleets with a hundred trucks there are tons of independent trucking companies out there start a trucking company and drive your costs down or figure out how to drive down the cost of trucking another company that i really respect is nato actually i respect their business model nato sells a driver monitoring camera and they sell it to fleet owners if i owned a fleet of cars and i could pay 40 bucks a month to monitor my employees this is gonna it like reduces accidents 18 its so like that in the space that is like the business model that i like most respect cause theyre creating value today yeah which is a thats a huge one how do we create value today with some of this and the lane keeping thing is huge and it sounds like youre creeping in or full steam ahead on the driver monitoring too which i think actually where the short term value if you can get it right i still im not a huge fan of the statement that everything has to have driver monitoring i agree with that completely but that statement usually misses the point that to get the experience of it right is not trivial oh no not at all in fact like so right now we have i think the timeout depends on speed of the car but we want to depend on like the scene state if youre on like an empty highway its very different if you dont pay attention than if like youre like coming up to a traffic light and longterm it should probably learn from the driver because thats to do i watched a lot of video weve built a smartphone detector just to analyze how people are using smartphones and people are using it very differently its a texting styles theres we havent watched nearly enough of the videos we havent i got millions of miles of people driving cars in this moment i spent a large fraction of my time just watching videos because its never fails to learn like it never ive never failed from a video watching session to learn something i didnt know before in fact i usually like when i eat lunch ill sit especially when the weather is good and just watch pedestrians with an eye to understand like from a computer vision eye just to see can this model can you predict what are the decisions made and theres so many things that we dont understand this is what i mean about the state vector yeah its im trying to always think like cause im understanding in my human brain how do we convert that into how hard is the learning problem here i guess is the fundamental question so something thats from a hacking perspective this is always comes up especially with folks well first the most popular question is the trolley problem right so thats not a sort of a serious problem there are some ethical questions i think that arise maybe you wanna do you think theres any ethical serious ethical questions we have a solution to the trolley problem at commai well so there is actually an alert in our code ethical dilemma detected its not triggered yet we dont know how yet to detect the ethical dilemmas but were a level two system so were going to disengage and leave that decision to the human youre such a troll no but the trolley problem deserves to be trolled yeah thats a beautiful answer actually i know i gave it to someone who was like sometimes people will ask like you asked about the trolley problem like you can have a kind of discussion about it like you get someone whos like really like earnest about it because its the kind of thing where if you ask a bunch of people in an office whether we should use a sql stack or a no sql stack if theyre not that technical they have no opinion but if you ask them what color they want to paint the office everyone has an opinion on that and thats why the trolley problem is i mean thats a beautiful answer yeah were able to detect the problem and were able to pass it on to the human wow ive never heard anyone say it this is your nice escape route okay but proud level two im proud level two i love it so the other thing that people have some concern about with ai in general is hacking so how hard is it do you think to hack an autonomous vehicle either through physical access or through the more sort of popular now these adversarial examples on the sensors okay the adversarial examples one you want to see some adversarial examples that affect humans right oh well there used to be a stop sign here but i put a black bag over the stop sign and then people ran it adversarial right like theres tons of human adversarial examples too the question in general about like security if you saw something just came out today and like there are always such hypey headlines about like how navigate on autopilot was fooled by a gps spoof to take an exit right at least thats all they could do was take an exit if your car is relying on gps in order to have a safe driving policy youre doing something wrong if youre relying and this is why v2v is such a terrible idea v2v now relies on both parties getting communication right this is not even so i think of safety security is like a special case of safety right safety is like we put a little you know piece of caution tape around the hole so that people wont walk into it by accident security is like put a 10 foot fence around the hole so you actually physically cannot climb into it with barbed wire on the top and stuff right so like if youre designing systems that are like unreliable theyre definitely not secure your car should always do something safe using its local sensors and then the local sensor should be hardwired and then could somebody hack into your can bus and turn your steering wheel on your brakes yes but they could do it before common ai too so lets think out of the box on some things so do you think teleoperation has a role in any of this so remotely stepping in and controlling the cars no i think that if the safety operation by design requires a constant link to the cars i think it doesnt work so thats the same argument youre using for v2i v2v well theres a lot of non safety critical stuff you can do with v2i i like v2i i like v2i way more than v2v because v2i is already like i already have internet in the car right theres a lot of great stuff you can do with v2i like for example you can well i already have v2i waze is v2i right waze can route me around traffic jams thats a great example of v2i and then okay the car automatically talks to that same service like it works so its improving the experience but its not a fundamental fallback for safety no if any of your things that require wireless communication are more than qm like have an asl rating it shouldnt be you previously said that life is work and that you dont do anything to relax so how do you think about hard work what do you think it takes to accomplish great things and theres a lot of people saying that there needs to be some balance you need to in order to accomplish great things you need to take some time off you need to reflect and so on now and then some people are just insanely working burning the candle on both ends how do you think about that i think i was trolling in the siraj interview when i said that off camera right before i smoked a little bit of weed like you know come on this is a joke right like i do nothing to relax look where i am im at a party right yeah yeah yeah thats true so no no of course i dont when i say that life is work though i mean that like i think that what gives my life meaning is work i dont mean that every minute of the day you should be working i actually think this is not the best way to maximize results i think that if youre working 12 hours a day you should be working smarter and not harder well so work gives you meaning for some people other sorts of meaning is personal relationships like family and so on youve also in that interview with siraj or the trolling mentioned that one of the things you look forward to in the future is ai girlfriends so thats a topic that im very much fascinated by not necessarily girlfriends but just forming a deep connection with ai what kind of system do you imagine when you say ai girlfriend whether you were trolling or not no that one im very serious about and im serious about that on both a shallow level and a deep level i think that vr brothels are coming soon and are going to be really cool its not cheating if its a robot i see the slogan already but theres i dont know if youve watched or just watched the black mirror episode i watched the latest one yeah yeah yeah oh the ashley 2 one no where theres two friends who are having sex with each other in oh in the vr game in the vr game its just two guys but one of them was a female yeah which is another mind blowing concept that in vr you dont have to be the form you can be two animals having sex its weird i mean ill see how nice that the software maps the nerve endings right yeah its huge i mean yeah they sweep a lot of the fascinating really difficult technical challenges under the rug like assuming its possible to do the mapping of the nerve endings then i wish yeah i saw that the way they did it with the little like stim unit on the head thatd be amazing so well no no on a shallow level like you could set up like almost a brothel with like real dolls and oculus quests write some good software i think itd be a cool novelty experience but no on a deeper like emotional level i mean yeah i would really like to fall in love with a machine do you see yourself having a long term relationship of the kind monogamous relationship that we have now with a robot with a ai system even not even just a robot so i think about maybe my ideal future when i was 15 i read eliezer yudkowskys early writings on the singularity and like that ai is going to surpass human intelligence massively he made some moores law based predictions that i mostly agree with and then i really struggled for the next couple of years of my life like why should i even bother to learn anything its all gonna be meaningless when the machines show up right maybe when i was that young i was still a little bit more pure and really like clung to that and then im like well the machines aint here yet you know and i seem to be pretty good at this stuff lets try my best you know like whats the worst that happens but the best possible future i see is me sort of merging with the machine and the way that i personify this is in a long term monogamous relationship with a machine oh you dont think theres a room for another human in your life if you really truly merge with another machine i mean i see merging i see like the best interface to my brain is like the same relationship interface to merge with an ai right what does that merging feel like ive seen couples whove been together for a long time and like i almost think of them as one person like couples who spend all their time together and thats fascinating youre actually putting what does that merging actually looks like its not just a nice channel like a lot of people imagine its just an efficient link search link to wikipedia or something i dont believe in that but its more youre saying that theres the same kind of relationship you have with another human thats a deep relationship thats what merging looks like thats pretty i dont believe that link is possible i think that that link so youre like oh im gonna download wikipedia right to my brain my reading speed is not limited by my eyes my reading speed is limited by my inner processing loop and to like bootstrap that sounds kind of unclear how to do it and horrifying but if i am with somebody and ill use a somebody who is making a super sophisticated model of me and then running simulations on that model im not gonna get into the question whether the simulations are conscious or not i dont really wanna know what its doing but using those simulations to play out hypothetical futures for me deciding what things to say to me to guide me along a path and thats how i envision it so on that path to ai of superhuman level intelligence youve mentioned that you believe in the singularity that singularity is coming again could be trolling could be not could be part all trolling has truth in it i dont know what that means anymore what is the singularity yeah so thats really the question how many years do you think before the singularity what form do you think it will take does that mean fundamental shifts in capabilities of ai or does it mean some other kind of ideas maybe thats just my roots but so i can buy a human beings worth of compute for like a million bucks today its about one tpu pod v3 i want like i think they claim a hundred pay to flops thats being generous i think humans are actually more like 20 so thats like five humans thats pretty good google needs to sell their tpus but i could buy i could buy i could buy gpus i could buy a stack of like id buy 1080 tis build data center full of them and for a million bucks i can get a human worth of compute but when you look at the total number of flops in the world when you look at human flops which goes up very very slowly with the population and machine flops which goes up exponentially but its still nowhere near i think thats the key thing to talk about when the singularity happened when most flops in the world are silicon and not biological thats kind of the crossing point like theyre now the dominant species on the planet and just looking at how technology is progressing when do you think that could possibly happen you think it would happen in your lifetime oh yeah definitely in my lifetime ive done the math i like 2038 because its the unix timestamp rollover yeah beautifully put so youve said that the meaning of life is to win if you look five years into the future what does winning look like so theres a lot of i can go into like technical depth to what i mean by that to win it may not mean i was criticized for that in the comments like doesnt this guy wanna like save the penguins in antarctica or like oh man listen to what im saying im not talking about like i have a yacht or something but i am an agent i am put into this world and i dont really know what my purpose is but if youre an intelligent agent and youre put into a world what is the ideal thing to do well the ideal thing mathematically you can go back to like schmidt hoover theories about this is to build a compressive model of the world to build a maximally compressive to explore the world such that your exploration function maximizes the derivative of compression of the past schmidt hoover has a paper about this and like i took that kind of as like a personal goal function so what i mean to win i mean like maybe this is religious but like i think that in the future i might be given a real purpose or i may decide this purpose myself and then at that point now i know what the game is and i know how to win i think right now im still just trying to figure out what the game is but once i know so you have imperfect information you have a lot of uncertainty about the reward function and youre discovering it exactly but the purpose is thats a better way to put it the purpose is to maximize it while you have a lot of uncertainty around it and youre both reducing the uncertainty and maximizing at the same time yeah and so thats at the technical level what is the if you believe in the universal prior what is the universal reward function thats the better way to put it so that win is interesting i think i speak for everyone in saying that i wonder what that reward function is for you and i look forward to seeing that in five years in 10 years i think a lot of people including myself are cheering you on man so im happy you exist and i wish you the best of luck thanks for talking to me man thank you have a good one were going to drop the zero day oh wow were going to drop the weapon thats so cool that is so cool i love the deadlines oh thats so cool give them real deadlines yeah and i think its done a lot for moving the industry forward i watched your coding sessions on the streamed online you code things up the basic projects usually from scratch i would say sort of as a programmer myself just watching you that you type really fast and your brain works in both brilliant and chaotic ways i dont know if thats always true but certainly for the live streams so its interesting to me because im more im much slower and systematic and careful and you just move i mean probably in order of magnitude faster so im curious is there a method to your madness is it just who you are theres pros and cons theres pros and cons to my programming style and im aware of them like if you ask me to like get something up and working quickly with like an api thats kind of undocumented i will do this super fast because i will throw things at it until it works if you ask me to take a vector and rotate it 90 degrees and then flip it over the xy plane ill spam program for two hours and wont get it oh because its something that you could do with a sheet of paper think through design and then just do you really just throw stuff at the wall and you get so good at it that it usually works i should become better at the other kind as well sometimes ill do things methodically its nowhere near as entertaining on the twitch streams i do exaggerate it a bit on the twitch streams as well the twitch streams i mean what do you want to see a game or you want to see actions per minute right ill show you apm for programming too yeah i recommend people go to it i think i watched i watched probably several hours of you like ive actually left you programming in the background while i was programming because you made me it was like watching a really good gamer its like energizes you because youre like moving so fast its so its awesome its inspiring and it made me jealous that like because my own programming is inadequate in terms of speed oh i was like so im twice as frantic on the live streams as i am when i code without them its super entertaining so i wasnt even paying attention to what you were coding which is great its just watching you switch windows and vim i guess is the most yeah theres vim on screen ive developed the workload at facebook and stuck with it how do you learn new programming tools ideas techniques these days whats your like a methodology for learning new things so i wrote for comma the distributed file systems out in the world are extremely complex like if you want to install something like like like ceph ceph is i think the like open infrastructure distributed file system or theres like newer ones like seaweed fs but these are all like 10000 plus line projects i think some of them are even a hundred thousand line and just configuring them as a nightmare so i wrote i wrote one its 200 lines and its it uses like nginx and volume servers and has this little master server that i wrote in go and the way i go this if i would say that im proud per line of any code i wrote maybe theres some exploits that i think are beautiful and then this this is 200 lines and just the way that i thought about it i think was very good and the reason its very good is because that was the fourth version of it that i wrote and i had three versions that i threw away you mentioned did you say go i wrote in go yeah in go is that a functional language i forget what go is go is googles language right its not functional its some its like in a way its c but easier its its strongly typed it has a nice ecosystem around it when i first looked at it i was like this is like python but it takes twice as long to do anything yeah now that ive openpilot is migrating to c but it still has large python components i now understand why python doesnt work for large code bases and why you want something like go interesting so why why doesnt python work for so even most speaking for myself at least like we do a lot of stuff basically demo level work with autonomous vehicles and most of the work is python yeah why doesnt python work for large code bases because well lack of type checking is a big part so errors creep in yeah and like you dont know the compiler can tell you like nothing right so everything is either you know like like syntax errors fine but if you misspell a variable in python the compiler wont catch that theres like linters that can catch it some of the time theres no types this is really the biggest downside and then well pythons slow but thats not related to it well maybe its kind of related to it so its lack of so whats whats in your toolbox these days is it python what else i need to move to something else my adventure into dependently typed languages i love these languages they just have like syntax from the 80s what do you think about javascript es6 like the modern or typescript javascript is the whole ecosystem is unbelievably confusing right npm updates a package from 022 to 025 and that breaks your babel linter which translates your es5 into es6 which doesnt run on so why do i have to compile my javascript again huh it may be the future though you think about i mean ive embraced javascript recently just because just like ive continually embraced php it seems that these worst possible languages live on for the longest like cockroaches never die yeah well its in the browser and its fast its fast yeah its in the browser and compute might stay become you know the browser its unclear what the role of the browser is in terms of distributed computation in the future so javascript is definitely here to stay yeah its interesting if autonomous vehicles will run on javascript one day i mean you have to consider these possibilities well all our debug tools are javascript we actually just open sourced them we have a tool explorer which you can annotate your disengagements and we have a tool cabana which lets you analyze the can traffic from the car so basically anytime youre visualizing something about the log youre using javascript well the web is the best ui toolkit by far so and then you know what youre coding in javascript we have a react guy hes good react nice lets get into it so lets talk autonomous vehicles yeah you founded comma ai lets at a high level how did you get into the world of vehicle automation can you also just for people who dont know tell the story of comma ai sure so i was working at this ai startup and a friend approached me and hes like dude i dont know where this is going but the coolest applied ai problem today is self driving cars im like well absolutely you want to meet with elon musk and hes looking for somebody to build a vision system for autopilot this is when they were still on ap1 they were still using mobileye elon back then was looking for a replacement and he brought me in and we talked about a contract where i would deliver something that meets mobileye level performance i would get paid 12 million if i could deliver it tomorrow and i would lose 1 million for every month i didnt deliver yeah so i was like okay this is a great deal this is a super exciting challenge you know what even if it takes me 10 months i get 2 million its good maybe i can finish up in five maybe i dont finish it at all and i get paid nothing and i can still work for 12 months for free so maybe just take a pause on that im also curious about this because ive been working in robotics for a long time and im curious to see a person like you just step in and sort of somewhat naive but brilliant right so thats the best place to be because you basically full steam take on a problem how confident how from that time because you know a lot more now at that time how hard do you think it is to solve all of autonomous driving i remember i suggested to elon in the meeting putting a gpu behind each camera to keep the compute local this is an incredibly stupid idea i leave the meeting 10 minutes later and im like i could have spent a little bit of time thinking about this problem before i went in why is it a stupid idea oh just send all your cameras to one big gpu youre much better off doing that oh sorry you said behind every camera have a gpu every camera have a small gpu i was like oh ill put the first few layers of my comms there ugh whyd i say that thats possible its possible but its a bad idea its not obviously a bad idea pretty obviously bad but whether its actually a bad idea or not i left that meeting with elon beating myself up im like whyd i say something stupid yeah you havent at least thought through every aspect of it yeah hes very sharp too usually in life i get away with saying stupid things and then kind of course oh right away he called me out about it and usually in life i get away with saying stupid things and then a lot of times people dont even notice and ill correct it and bring the conversation back but with elon it was like nope okay well thats not at all why the contract fell through i was much more prepared the second time i met him yeah but in general how hard did you think it is like 12 months is a tough timeline oh i just thought id clone mobileye iq3 i didnt think id solve level five self driving or anything so the goal there was to do lane keeping good lane keeping i saw my friend showed me the outputs from a mobileye and the outputs from a mobileye was just basically two lanes at a position of a lead car im like i can gather a data set and train this net in weeks and i did well first time i tried the implementation of mobileye in a tesla i was really surprised how good it is its going incredibly good cause i thought its just cause ive done a lot of computer vision i thought itd be a lot harder to create a system that thats stable so i was personally surprised you know have to admit it cause i was kind of skeptical before trying it cause i thought it would go in and out a lot more it would get disengaged a lot more and its pretty robust so what how hard is the problem when you tackled it so i think ap1 was great like elon talked about disengagements on the 405 down in la with like the lane marks are kind of faded and the mobileye system would drop out like i had something up and working that i would say was like the same quality in three months same quality but how do you know you say stuff like that confidently but you cant and i love it but the question is you cant youre kind of going by feel cause you test it out absolutely absolutely like i would take i borrowed my friends tesla i would take ap1 out for a drive and then i would take my system out for a drive and it seems reasonably like the same so the 405 how hard is it to create something that could actually be a product thats deployed i mean ive read an article where elon this respondent said something about you saying that to build autopilot is more complicated than a single george hodge level job how hard is that job to create something that would work across globally why dont think globally is the challenge but elon followed that up by saying its gonna take two years in a company of 10 people and here i am four years later with a company of 12 people and i think we still have another two to go two years so yeah so what do you think about how tesla is progressing with autopilot of v2 v3 i think weve kept pace with them pretty well i think navigate and autopilot is terrible we had some demo features internally of the same stuff and we would test it and im like im not shipping this even as like open source software to people why do you think its terrible consumer reports does a great job of describing it like when it makes a lane change it does it worse than a human you shouldnt ship things like autopilot open pilot they lane keep better than a human if you turn it on for a stretch of a highway like an hour long its never gonna touch a lane line human will touch probably a lane line twice you just inspired me i dont know if youre grounded in data on that i read your paper okay but thats interesting i wonder actually how often we touch lane lines in general like a little bit because it is i could answer that question pretty easily with the common data set yeah im curious ive never answered it i dont know i just two is like my personal it feels right thats interesting because every time you touch a lane thats a source of a little bit of stress and kind of lane keeping is removing that stress thats ultimately the biggest value add honestly is just removing the stress of having to stay in lane and i think honestly i dont think people fully realize first of all that thats a big value add but also that thats all it is and that not only i find it a huge value add i drove down when we moved to san diego i drove down in a enterprise rental car and i missed it so i missed having the system so much its so much more tiring to drive without it it is that lane centering thats the key feature yeah and in a way its the only feature that actually adds value to peoples lives in autonomous vehicles today waymo does not add value to peoples lives its a more expensive slower uber maybe someday itll be this big cliff where it adds value but i dont usually believe it it is fascinating i havent talked to this is good cause i havent i have intuitively but i think were making it explicit now i actually believe that really good lane keeping is a reason to buy a car will be a reason to buy a car and its a huge value add ive never until we just started talking about it i havent really quite realized it that ive felt with elons chase of level four is not the correct chase it was on cause you should just say tesla has the best as if from a tesla perspective say tesla has the best lane keeping comma ai should say comma ai is the best lane keeping and that is it yeah yeah so do you think you have to do the longitudinal as well you cant just lane keep you have to do acc but acc is much more forgiving than lane keep especially on the highway by the way are you comma ais camera only correct no we use the radar from the car youre able to get the okay hmm we can do a camera only now its gotten to the point but we leave the radar there as like a its fusion now okay so lets maybe talk through some of the system specs on the hardware whats the hardware side of what youre providing whats the capabilities on the software side with openpilot and so on so openpilot as the box that we sell that it runs on its a phone in a plastic case its nothing special we sell it without the software so you buy the phone its just easy itll be easy set up but its sold with no software openpilot right now is about to be 06 when it gets to 10 i think well be ready for a consumer product were not gonna add any new features were just gonna make the lane keeping really really good okay i got it so what do we have right now its a snapdragon 820 its a sony imx 298 forward facing camera driver monitoring camera its just a selfie camera on the phone and a can transceiver maybe theres a little thing called pandas and they talk over usb to the phone and then they have three can buses that they talk to the car one of those can buses is the radar can bus one of them is the main car can bus and the other one is the proxy camera can bus we leave the existing camera in place so we dont turn aeb off right now we still turn aeb off if youre using our longitudinal but were gonna fix that before 10 got it wow thats cool and its can both ways so how are you able to control vehicles so we proxy the vehicles that we work with already have a lane keeping assist system so lane keeping assist can mean a huge variety of things it can mean it will apply a small torque to the wheel after youve already crossed a lane line by a foot which is the system in the older toyotas versus like i think tesla still calls it lane keeping assist where itll keep you perfectly in the center of the lane on the highway you can control like with the joystick the car so these cars already have the capability of drive by wire so is it trivial to convert a car that it operates with openpilot is able to control the steering oh a new car or a car that we so we have support now for 45 different makes of cars what are the cars in general mostly hondas and toyotas we support almost every honda and toyota made this year and then a bunch of gms a bunch of subarus a bunch of chevys it doesnt have to be like a prius it could be a corolla as well oh the 2020 corolla is the best car with openpilot it just came out the actuator has less lag than the older corolla i think i started watching a video with your i mean the way you make videos is awesome youre just literally at the dealership streaming yeah i had my friend on the phone im like bro you wanna stream for an hour yeah and basically like if stuff goes a little wrong youre just like you just go with it yeah i love it well its real yeah its real thats so beautiful and its so in contrast to the way other companies would put together a video like that kind of why i like to do it like that good i mean if you become super rich one day and successful i hope you keep it that way because i think thats actually what people love that kind of genuine oh its all that has value to me money has no if i sell out to like make money i sold out it doesnt matter what do i get yacht i dont want a yacht and i think teslas actually has a small inkling of that as well with autonomy day they did reveal more than i mean of course theres marketing communications you could tell but its more than most companies would reveal which is i hope they go towards that direction more other companies gm ford oh teslas gonna win level five they really are so lets talk about it you think youre focused on level two currently currently were gonna be one to two years behind tesla getting to level five okay were android right were android youre android im just saying once tesla gets it were one to two years behind im not making any timeline on when teslas gonna get it thats right you did that was brilliant im sorry tesla investors if you think youre gonna have an autonomous robo taxi fleet by the end of the year yeah so thats ill bet against that so what do you think about this the most level four companies are kind of just doing their usual safety driver doing full autonomy kind of testing and then tesla does basically trying to go from lane keeping to full autonomy what do you think about that approach how successful would it be its a ton better approach because tesla is gathering data on a scale that none of them are theyre putting real users behind the wheel of the cars its i think the only strategy that works the incremental well so theres a few components to tesla approach thats more than just the incrementalists what you spoke with is the ones the software so over the air software updates necessity i mean waymo crews have those too those arent but those differentiate from the automakers right no lane keeping systems have no cars with lane keeping system have that except tesla yeah and the other one is the data the other direction which is the ability to query the data i dont think theyre actually collecting as much data as people think but the ability to turn on collection and turn it off so im both in the robotics world and the psychology human factors world many people believe that level two autonomy is problematic because of the human factor like the more the task is automated the more theres a vigilance decrement you start to fall asleep you start to become complacent start texting more and so on do you worry about that cause if were talking about transition from lane keeping to full autonomy if youre spending 80 of the time not supervising the machine do you worry about what that means to the safety of the drivers one we dont consider open pilot to be 10 until we have 100 driver monitoring you can cheat right now our driver monitoring system theres a few ways to cheat it theyre pretty obvious were working on making that better before we ship a consumer product that can drive cars i want to make sure that i have driver monitoring that you cant cheat whats like a successful driver monitoring system look like is it all about just keeping your eyes on the road well a few things so thats what we went with at first for driver monitoring im checking im actually looking at where your head is looking the cameras not that high resolution eyes are a little bit hard to get well head is this big i mean thats head is good and actually a lot of it just psychology wise to have that monitor constantly there it reminds you that you have to be paying attention but we want to go further we just hired someone full time to come on to do the driver monitoring i want to detect phone in frame and i want to make sure youre not sleeping how much does the camera see of the body this one not enough not enough the next one everything well its interesting fisheye because were doing just data collection not real time but fisheye is a beautiful being able to capture the body and the smartphone is really like the biggest problem ill show you i can show you one of the pictures from our new system awesome so youre basically saying the driver monitoring will be the answer to that i think the other point that you raised in your paper is good as well youre not asking a human to supervise a machine without giving them the they can take over at any time right our safety model you can take over we disengage on both the gas or the brake we dont disengage on steering i dont feel you have to but we disengage on gas or brake so its very easy for you to take over and its very easy for you to reengage that switching should be super cheap the cars that require even autopilot requires a double press thats almost i see i dont like that and then the cancel to cancel in autopilot you either have to press cancel which no one knows what that is so they press the brake but a lot of times you dont actually want to press the brake you want to press the gas so you should cancel on gas or wiggle the steering wheel which is bad as well wow thats brilliant i havent heard anyone articulate that point oh this is all i think about its the because i think i think actually tesla has done a better job than most automakers at making that frictionless but you just described that it could be even better i love super cruise as an experience once its engaged i dont know if youve used it but getting the thing to try to engage yeah ive used the ive driven super cruise a lot so whats your thoughts on the super cruise system you disengage super cruise and it falls back to acc so my cars like still accelerating it feels weird otherwise when you actually have super cruise engaged on the highway it is phenomenal we bought that cadillac we just sold it but we bought it just to like experience this and i wanted everyone in the office to be like this is what were striving to build gm pioneering with the driver monitoring you like their driver monitoring system it has some bugs if theres a sun shining back here itll be blind to you right but overall mostly yeah thats so cool that you know all this stuff i dont often talk to people that because its such a rare car unfortunately currently we bought one explicitly for this we lost like 25k in the deprecation but i feel its worth it i was very pleasantly surprised that gm system was so innovative and really wasnt advertised much wasnt talked about much yeah and i was nervous that it would die that it would disappear well they put it on the wrong car they should have put it on the bolt and not some weird cadillac that nobody bought i think thats gonna be into theyre saying at least its gonna be into their entire fleet so what do you think about as long as were on the driver monitoring what do you think about elon musks claim that driver monitoring is not needed normally i love his claims that one is stupid that one is stupid and you know hes not gonna have his level five fleet by the end of the year hopefully hes like okay i was wrong im gonna add driver monitoring because when these systems get to the point that theyre only messing up once every thousand miles you absolutely need driver monitoring so let me play cause i agree with you but let me play devils advocate one possibility is that without driver monitoring people are able to monitor self regulate monitor themselves you know that so your idea is youve seen all the people sleeping in teslas yeah well im a little skeptical of all the people sleeping in teslas because ive stopped paying attention to that kind of stuff because i want to see real data its too much glorified it doesnt feel scientific to me so i want to know how many people are really sleeping in teslas versus sleeping i was driving here sleep deprived in a car with no automation i was falling asleep i agree that its hypey its just like you know what if you want to put driver monitoring i rented a my last autopilot experience was i rented a model three in march and drove it around the wheel thing is annoying and the reason the wheel thing is annoying we use the wheel thing as well but we dont disengage on wheel for tesla you have to touch the wheel just enough to trigger the torque sensor to tell it that youre there but not enough as to disengage it which dont use it for two things dont disengage on wheel you dont have to that whole experience wow beautifully put all of those elements even if you dont have driver monitoring that whole experience needs to be better driver monitoring i think would make i mean i think super cruise is a better experience once its engaged over autopilot i think super cruise is a transition to engagement and disengagement are significantly worse yeah well theres a tricky thing because if i were to criticize super cruise is its a little too crude and i think like six seconds or something if you look off road itll start warning you its some ridiculously long period of time and just the way i think its basically its a binary it should be adaptive yeah it needs to learn more about you it needs to communicate what it sees about you more tesla shows what it sees about the external world it would be nice if super cruise would tell us what it sees about the internal world its even worse than that you press the button to engage and it just says super cruise unavailable yeah why why yeah that transparency is good weve renamed the driver monitoring packet to driver state driver state we have car state packet which has the state of the car and you have driver state packet which has the state of the driver so what is the estimate their bac whats bac blood alcohol content you think thats possible with computer vision absolutely to me its an open question i havent looked into it too much actually i quite seriously looked at the literature its not obvious to me that from the eyes and so on you can tell you might need stuff from the car as well yeah you might need how theyre controlling the car right and thats fundamentally at the end of the day what you care about but i think especially when people are really drunk theyre not controlling the car nearly as smoothly as they would look at them walking right the car is like an extension of the body so i think you could totally detect and if you could fix people who are drunk distracted asleep if you fix those three yeah thats huge so what are the current limitations of open pilot what are the main problems that still need to be solved were hopefully fixing a few of them in 06 were not as good as autopilot at stop cars so if youre coming up to a red light at 55 so its the radar stopped car problem which is responsible for two autopilot accidents its hard to differentiate a stopped car from a signpost yeah a static object so you have to fuse you have to do this visually theres no way from the radar data to tell the difference maybe you can make a map but i dont really believe in mapping at all anymore wait wait wait what you dont believe in mapping no so you basically the open pilot solution is saying react to the environment as you see it just like human beings do and then eventually when you want to do navigate on open pilot ill train the net to look at ways ill run ways in the background ill train a confident way are you using gps at all we use it to ground truth we use it to very carefully ground truth the paths we have a stack which can recover relative to 10 centimeters over one minute and then we use that to ground truth exactly where the car went in that local part of the environment but its all local how are you testing in general just for yourself like experiments and stuff where are you located san diego san diego yeah ok so you basically drive around there collect some data and watch the performance we have a simulator now and we have our simulator is really cool our simulator is not its not like a unity based simulator our simulator lets us load in real state what do you mean we can load in a drive and simulate what the system would have done on the historical data ooh nice interesting so what yeah right now were only using it for testing but as soon as we start using it for training thats it thats all that matters whats your feeling about the real world versus simulation do you like simulation for training if this moves to training so we have to distinguish two types of simulators right theres a simulator that is completely fake i could get my car to drive around in gta i feel that this kind of simulator is useless youre never theres so many my analogy here is like ok fine youre not solving the computer vision problem but youre solving the computer graphics problem right and you dont think you can get very far by creating ultra realistic graphics no because you can create ultra realistic graphics of the road now create ultra realistic behavioral models of the other cars oh well ill just use myself driving no you wont you need actual human behavior because thats what youre trying to learn driving does not have a spec the definition of driving is what humans do when they drive whatever waymo does i dont think its driving right well i think actually waymo and others if theres any use for reinforcement learning ive seen it used quite well i study pedestrians a lot too is try to train models from real data of how pedestrians move and try to use reinforcement learning models to make pedestrians move in human like ways by that point youve already gone so many layers you detected a pedestrian did you hand code the feature vector of their state did you guys learn anything from computer vision before deep learning well ok i feel like this is so perception to you is the sticking point i mean whats the hardest part of the stack here there is no human understandable feature vector separating perception and planning thats the best way i can put that there is no so its all together and its a joint problem so you can take localization localization and planning there is a human understandable feature vector between these two things i mean ok so i have like three degrees position three degrees orientation and those derivatives maybe those second derivatives thats human understandable thats physical between perception and planning so like waymo has a perception stack and then a planner and one of the things waymo does right is they have a simulator that can separate those two they can like replay their perception data and test their system which is what im talking about about like the two different kinds of simulators theres the kind that can work on real data and theres the kind that cant work on real data now the problem is that i dont think you can hand code a feature vector right like you have some list of like oh heres my list of cars in the scenes heres my list of pedestrians in the scene this isnt what humans are doing what are humans doing global and youre saying thats too difficult to hand engineer im saying that there is no state vector given a perfect i could give you the best team of engineers in the world to build a perception system and the best team to build a planner all you have to do is define the state vector that separates those two im missing the state vector that separates those two what do you mean so what is the output of your perception system output of the perception system its ok well theres several ways to do it one is the slam components localization the other is drivable area drivable space drivable space yeah and then theres the different objects in the scene and different objects in the scene over time maybe to give you input to then try to start modeling the trajectories of those objects sure thats it i can give you a concrete example of something you missed whats that so say theres a bush in the scene humans understand that when they see this bush that there may or may not be a car behind that bush drivable area and a list of objects does not include that humans are doing this constantly at the simplest intersections so now you have to talk about occluded area but even that what do you mean by occluded ok so i cant see it well if its the other side of a house i dont care whats the likelihood that theres a car in that occluded area and if you say ok well add that i can come up with 10 more examples that you cant add certainly occluded area would be something that simulator would have because its simulating the entire occlusion is part of it occlusion is part of a vision stack but what im saying is if you have a hand engineered if your perception system output can be written in a spec document it is incomplete yeah i mean certainly its hard to argue with that because in the end thats going to be true yeah and ill tell you what the output of our perception system is whats that its a 1024 dimensional vector trained by neural net oh you know that no its 1024 dimensions of who knows what because its operating on real data yeah and thats the perception thats the perception state think about an autoencoder for faces if you have an autoencoder for faces and you say it has 256 dimensions in the middle and im taking a face over here and projecting it to a face over here can you hand label all 256 of those dimensions well no but those have to generate automatically but even if you tried to do it by hand could you come up with a spec between your encoder and your decoder no because it wasnt designed but there no no no but if you could design it if you could design a face reconstructor system could you come up with a spec no but i think were missing here a little bit i think youre just being very poetic about expressing a fundamental problem of simulators that theyre going to be missing so much that the feature vector will just look fundamentally different in the simulated world than the real world im not making a claim about simulators im making a claim about the spec division between perception and planning even in your system just in general just in general if youre trying to build a car that drives if youre trying to hand code the output of your perception system like saying heres a list of all the cars in the scene heres a list of all the people heres a list of the occluded areas heres a vector of drivable areas its insufficient and if you start to believe that you realize that what waymo and cruz are doing is impossible currently what were doing is the perception problem is converting the scene into a chessboard and then you reason some basic reasoning around that chessboard and youre saying that really theres a lot missing there first of all why are we talking about this because isnt this a full autonomy is this something you think about oh i want to win self driving cars so your definition of win includes level four or five level five i dont think level four is a real thing i want to build the alphago of driving so alphago is really end to end yeah is yeah its end to end and do you think this whole problem is that also kind of what youre getting at with the perception and the planning is that this whole problem the right way to do it is really to learn the entire thing ill argue that not only is it the right way its the only way thats going to exceed human performance well its certainly true for go everyone who tried to hand code go things built human inferior things and then someone came along and wrote some 10000 line thing that doesnt know anything about go that beat everybody its 10000 lines true in that sense the open question then that maybe i can ask you is driving is much harder than go the open question is how much harder so how because i think the elon musk approach here with planning and perception is similar', 'the following is a conversation with paola arlotta shes a professor of stem cell and regenerative biology at harvard university and is interested in understanding the molecular laws that govern the birth differentiation and assembly of the human brains cerebral cortex she explores the complexity of the brain by studying and engineering elements of how the brain develops this was a fascinating conversation to me its part of the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and id like to give a special thank you to amy jeffress for her support of the podcast on patreon shes an artist and you should definitely check out her instagram at lovetruthgood three beautiful words your support means a lot and inspires me to keep the series going and now heres my conversation with paola arlotta you studied the development of the human brain for many years so let me ask you an out of the box question first how likely is it that theres intelligent life out there in the universe outside of earth with something like the human brain so i can put it another way how unlikely is the human brain how difficult is it to build a thing through the evolutionary process well it has happened here right on this planet once yes once so that simply tells you that it could of course happen again other places its only a matter of probability what the probability that you would get a brain like the ones that we have like the human brain so how difficult is it to make the human brain its pretty difficult but most importantly i guess we know very little about how this process really happens and there is a reason for that actually multiple reasons for that most of what we know about how the mammalian brain so the brain of mammals develop comes from studying in labs other brains not our own brain the brain of mice for example but if i showed you a picture of a mouse brain and then you put it next to a picture of a human brain they dont look at all like each other so theyre very different and therefore there is a limit to what you can learn about how the human brain is made by studying the mouse brain there is a huge value in studying the mouse brain there are many things that we have learned but its not the same thing so in having studied the human brain or through the mouse and through other methodologies that well talk about do you have a sense i mean youre one of the experts in the world how much do you feel you know about the brain and how often do you find yourself in awe of this mysterious thing yeah you pretty much find yourself in awe all the time its an amazing process its a process by which by means that we dont fully understand at the very beginning of embryogenesis the structure called the neural tube literally self assembles and it happens in an embryo and it can happen also from stem cells in a dish okay and then from there these stem cells that are present within the neural tube give rise to all of the thousands and thousands of different cell types that are present in the brain through time right with the interesting very intriguing interesting observation is that the time that it takes for the human brain to be made its human time meaning that for me and you it took almost nine months of gestation to build the brain and then another 20 years of learning postnatally to get the brain that we have today that allows us to this conversation a mouse takes 20 days or so for an embryo to be born and so the brain is built in a much shorter period of time and the beauty of it is that if you take mouse stem cells and you put them in a culture dish the brain organoid that you get from a mouse is formed faster than if you took human stem cells and put them in the dish and let them make a human brain organoid so the very developmental process is controlled by the speed of the species which means its on purpose its not accidental or there is something in that temporal its very exactly that is very important for us to get the brain we have and we can speculate for why that is you know it takes us a long time as human beings after were born to learn all the things that we have to learn to have the adult brain its actually 20 years think about it from when a baby is born to when a teenager goes through puberty to adults its a long time do you think you can maybe talk through the first few months and then on to the first 20 years and then for the rest of their lives what is the development of the human brain look like what are the different stages yeah at the beginning you have to build a brain right and the brain is made of cells whats the very beginning which beginning are we talking about in the embryo as the embryo is developing in the womb in addition to making all of the other tissues of the embryo the muscle the heart the blood the embryo is also building the brain and it builds from a very simple structure called the neural tube which is basically nothing but a tube of cells that spans sort of the length of the embryo from the head all the way to the tail lets say of the embryo and then over in human beings over many months of gestation from that neural tube which contains stem cell like cells of the brain you will make many many other building blocks of the brain so all of the other cell types because there are many many different types of cells in the brain that will form specific structures of the brain so you can think about embryonic development of the brain as just the time in which you are making the building blocks the cells are the stem cells relatively homogeneous like uniform or are they all different types its a very good question its exactly how it works you start with a more homogeneous perhaps more multipotent type of stem cell with multipotent with multipotent it means that it has the potential to make many many different types of other cells and then with time these progenitors become more heterogeneous which means more diverse there are gonna be many different types of the stem cells and also they will give rise to progeny to other cells that are not stem cells that are specific cells of the brain that are very different from the mother stem cell and now you think about this process of making cells from the stem cells over many many months of development for humans and what youre doing youre building the cells that physically make the brain and then you arrange them in specific structures that are present in the final brain so you can think about the embryonic development of the brain as the time where youre building the bricks youre putting the bricks together to form buildings structures regions of the brain and where you make the connections between these many different type of cells especially nerve cells neurons right that transmit action potentials and electricity ive heard you also say somewhere i think correct me if im wrong that the order of the way this builds matters oh yes if you are an engineer and you think about development you can think of it as well i could also take all the cells and bring them all together into a brain in the end but development is much more than that so the cells are made in a very specific order that subserve the final product that you need to get and so for example all of the nerve cells the neurons are made first and all of the supportive cells of the neurons like the glia is made later and there is a reason for that because they have to assemble together in specific ways but you also may say well why dont we just put them all together in the end its because as they develop next to each other they influence their own development so its a different thing for a glia to be made alone in a dish than a glia cell be made in a developing embryo with all these other cells around it that produce all these other signals first of all thats mind blowing this development process from my perspective in artificial intelligence you often think of how incredible the final product is the final product the brain but youre making me realize that the final product is just the beautiful thing is the actual development process do we know the code that drives that development yeah do we have any sense first of all thank you for saying that its really the formation of the brain its really its development it is this incredibly choreographed dance that happens the same way every time each one of us builds the brain right and that builds an organ that allows us to do what were doing today right that is mind blowing and this is why developmental neurobiologists never get tired of studying that now youre asking about the code what drives this how is this done well its millions of years of evolution of really fine tuning gene expression programs that allow certain cells to be made at a certain time and to become a certain cell type but also mechanical forces of pressure bending this embryo is not just it will not stay a tube this brain for very long at some point this tube in the front of the embryo will expand to make the primordium of the brain right now the forces that control that the cells feel and this is another beautiful thing the very force that they feel which is different from a week before a week ago will tell the cell oh youre being squished in a certain way begin to produce these new genes because now you are at the corner or you are in a stretch of cells or whatever it is and that so that mechanical physical force shapes the fate of the cell as well so its not only chemical its also mechanical so from my perspective biology is this incredibly complex mess gooey mess so youre saying mechanical forces how different is like a computer or any kind of mechanical machine that we humans build and the biological systems have you been because youve worked a lot with biological systems are they as much of a mess as it seems from a perspective of an engineer a mechanical engineer yeah they are much more prone to taking alternative routes right so if you we go back to printing a brain versus developing a brain of course if you print a brain given that you start with the same building blocks the same cells you could potentially print it the same way every time but that final brain may not work the same way as a brain built during development does because the very same building blocks that youre using developed in a completely different environment right it was not the environment of the brain therefore theyre gonna be different just by definition so if you instead use development to build lets say a brain organoid which maybe we will be talking about in a few minutes those things are fascinating yes so if you use processes of development then when you watch it you can see that sometimes things can go wrong in some organoids and by wrong i mean different one organoid from the next while if you think about that embryo it always goes right so this development its for as complex as it is every time a baby is born has with very few exceptions so the brain is like the next baby but its not the same if you develop it in a dish and first of all we dont even develop a brain you develop something much simpler in the dish but there are more options for building things differently which really tells you that evolution has played a really tight game here for how in the end the brain is built in vivo so just a quick maybe dumb question but it seems like this is not the building process is not a dictatorship it seems like theres not a centralized like high level mechanism that says okay this cell built itself the wrong way im gonna kill it it seems like theres a really strong distributed mechanism is that in your sense for what you mean there are a lot of possibilities right and if you think about for example different species building their brain each brain is a little bit different so the brain of a lizard is very different from that of a chicken from that of one of us and so on and so forth and still is a brain but it was built differently starting from stem cells that pretty much had the same potential but in the end evolution builds different brains in different species because that serves in a way the purpose of that species and the wellbeing of that organism and so there are many possibilities but then there is a way and you were talking about a code nobody knows what the entire code of development is of course we dont we know bits and pieces of very specific aspects of development of the brain what genes are involved to make a certain cell types how those two cells interact to make the next level structure that we might know but the entirety of it how its so well controlled its really mind blowing so in the first two months in the embryo or whatever the first few weeks months so yeah the building blocks are constructed the actual the different regions of the brain i guess in the nervous system well this continues way longer than just the first few months so over the very first few months you build a lot of the cells but then there is continuous building of new cell types all the way through birth and then even postnatally i dont know if youve ever heard of myelin myelin is this sort of insulation that is built around the cables of the neurons so that the electricity can go really fast from the axons i guess theyre called the axons theyre called axons exactly and so as human beings we myelinate our cells postnatally a kid a six year old kid has barely started the process of making the mature oligodendrocytes which are the cells that then eventually will wrap the axons into myelin and this will continue believe it or not until we are about 25 30 years old so there is a continuous process of maturation and tweaking and additions and also in response to what we do i remember taking ap biology in high school and in the textbook it said that im going by memory here that scientists disagree on the purpose of myelin in the brain is that totally wrong so like i guess it speeds up the okay i might be wrong here but i guess it speeds up the electricity traveling down the axon or something yeah so thats the most sort of canonical and definitely thats the case so you have to imagine an axon and you can think about it as a cable of some type with electricity going through and what myelin does by insulating the outside i should say there are tracts of myelin and pieces of axons that are naked without myelin and so by having the insulation the electricity instead of going straight through the cable it will jump over a piece of myelin right to the next naked little piece and jump again and therefore thats the idea that you go faster and it was always thought that in order to build a big brain a big nervous system in order to have a nervous system that can do very complex type of things then you need a lot of myelin because you wanna go fast with this information from point a to point b well a few years ago maybe five years ago or so we discovered that some of the most evolved which means the newest type of neurons that we have as nonhuman primates as human beings in the top of our cerebral cortex which should be the neurons that do some of the most complex things that we do well those have axons that have very little myelin wow and they have very interesting ways in which they put this myelin on their axons you know a little piece here then a long track with no myelin another chunk there and some dont have myelin at all so now you have to explain where were going with evolution and if you think about it perhaps as an electrical engineer when i looked at it i initially thought and im a developmental neurobiologist i thought maybe this is what we see now but if we give evolution another few million years well see a lot of myelin on these neurons too but i actually think now that thats instead the future of the brain less myelin less myelin might allow for more flexibility on what you do with your axons and therefore more complicated and unpredictable type of functions which is also a bit mind blowing so it seems like its controlling the timing of the signal so theyre in the timing you can encode a lot of information yeah and so the brain the timing the chemistry of that little piece of axon perhaps its a dynamic process where the myelin can move now you see how many layers of variability you can add and thats actually really good if youre trying to come up with a new function or a new capability or something unpredictable in a way so were gonna jump around a little bit but the old question of how much is nature and how much is nurture in terms of this incredible thing after the development is over we seem to be kind of somewhat smart intelligent cognition consciousness all of these things are just incredible ability to reason and so on emerge in your sense how much is in the hardware in the nature and how much is in the nurture is learned through with our parents through interacting with the environment and so on its really both right if you think about it so we are born with a brain as babies that has most of its cells and most of its structures and that will take a few years to grow to add more to be better but really then we have this 20 years of interacting with the environment around us and so what that brain that was so perfectly built or imperfectly built due to our genetic cues will then be used to incorporate the environment in its further maturation and development and so your experiences do shape your brain i mean we know that like if you and i may have had a different childhood or a different we have been going to different schools we have been learning different things and our brain is a little bit different because of that we behave differently because of that and so especially postnatally experience is extremely important we are born with a plastic brain what that means is a brain that is able to change in response to stimuli that can be sensory so perhaps some of the most illuminating studies that were done were studies in which the sensory organs were not working right like if you are born with eyes that dont work then your very brain that piece of the brain that normally would process vision the visual cortex develops postnatally differently and it might be used to do something different right so thats the most extreme the plasticity of the brain i guess is the magic hardware that it and then its flexibility in all forms is what enables the learning postnatally can you talk about organoids what are they and how can you use them to help us understand the brain and the development of the brain this is very very important so the first thing id like to say please skip this in the video the first thing id like to say is that an organoid a brain organoid is not the same as a brain okay its a fundamental distinction its a system a cellular system that one can develop in the culture dish starting from stem cells that will mimic some aspects of the development of the brain but not all of it they are very small maximum they become about four to five millimeters in diameters they are much simpler than our brain of course but yet they are the only system where we can literally watch a process of human brain development unfold and by watch i mean study it remember when i told you that we cant understand everything about development in our own brain by studying a mouse well we cant study the actual process of development of the human brain because it all happens in utero so we will never have access to that process ever and therefore this is our next best thing like a bunch of stem cells that can be coaxed into starting a process of neural tube formation remember that tube that is made by the embryo early on and from there a lot of the cell types that are present within the brain and you can simply watch it and study but you can also think about diseases where development of the brain does not proceed normally right properly think about neurodevelopmental diseases there are many many different types think about autism spectrum disorders there are also many different types of autism so there you could take a stem cell which really means either a sample of blood or a sample of skin from the patient make a stem cell and then with that stem cell watch a process of formation of a brain organ or a brain organoid of that person with that genetics with that genetic code in it and you can ask what is this genetic code doing to some aspects of development of the brain and for the first time you may come to solutions like what cells are involved in autism right so many questions around this so if you take this human stem cell for that particular person with that genetic code how and you try to build an organoid how often will it look similar whats the yeah so the reproducibility yes or how much variability is the flip side of that yeah so there is much more variability in building organoids than there is in building brain its really true that the majority of us when we are born as babies our brains look a lot like each other this is the magic that the embryo does where it builds a brain in the context of a body and there is very little variability there there is disease of course but in general a little variability when you build an organoid we dont have the full code for how this is done and so in part the organoid somewhat builds itself because there are some structures of the brain that the cells know how to make and another part comes from the investigator the scientist adding to the media factors that we know in the mouse for example would foster a certain step of development but its very limited and so as a result the kind of product you get in the end is much more reductionist is much more simple than what you get in vivo it mimics early events of development as of today and it doesnt build very complex type of anatomy and structure does not as of today which happens instead in vivo and also the variability that you see one organ to the next tends to be higher than when you compare an embryo to the next so okay then the next question is how hard and maybe another flip side of that expensive is it to go from one stem cell to an organoid how many can you build in like because it sounds very complicated its work definitely and its money definitely but you can really grow a very high number of these organoids can go perhaps i told you the maximum they become about five millimeters in diameter so this is about the size of a tiny tiny raisin or perhaps the seed of an apple and so you can grow 50 to 100 of those inside one big bioreactors which are these flasks where the media provides nutrients for the organoids so the problem is not to grow more or less of them its really to figure out how to grow them in a way that they are more and more reproducible for example organoid to organoid so they can be used to study a biological process because if you have too much variability then you never know if what you see is just an exception or really the rule so what does an organoid look like are there different neurons already emerging is there well first can you tell me what kind of neurons are there yes are they sort of all the same are they not all the same how much do we understand and how much of that variance if any can exist in organoids yes so you could grow i told you that the brain has different parts so the cerebral cortex is on the top part of the brain but there is another region called the striatum that is below the cortex and so on and so forth all of these regions have different types of cells in the actual brain okay and so scientists have been able to grow organoids that may mimic some aspects of development of these different regions of the brain and so we are very interested in the cerebral cortex thats the coolest part right very cool i agree with you we wouldnt be here talking if we didnt have a cerebral cortex its also i like to think the part of the brain that really truly makes us human the most evolved in recent evolution and so in the attempt to make the cerebral cortex and by figuring out a way to have these organoids continue to grow and develop for extended periods of times much like it happens in the real embryo months and months in culture then you can see that many different types of neurons of the cortex appear and at some point also the astrocytes so the glia cells of the cerebral cortex also appear what are these astrocytes the astrocytes are not neurons so theyre not nerve cells but they play very important roles one important role is to support the neuron but of course they have much more active type of roles theyre very important for example to make the synapses which are the point of contact and communication between two neurons so all that chemistry fun happens in the synapses happens because of these cells are they the medium in which it happens because of the interactions happens because you are making the cells and they have certain properties including the ability to make neurotransmitters which are the chemicals that are secreted to the synapses including the ability of making these axons grow with their growth cones and so on and so forth and then you have other cells around it that release chemicals or touch the neurons or interact with them in different ways to really foster this perfect process in this case of synaptogenesis and this does happen within organoids so the mechanical and the chemical stuff happens the connectivity between neurons this in a way is not surprising because scientists have been culturing neurons forever and when you take a neuron even a very young one and you culture it eventually finds another cell or another neuron to talk to it will form a synapse are we talking about mice neurons are we talking about human neurons it doesnt matter both so you can culture a neuron like a single neuron and give it a little friend and it starts interacting yes so neurons are able to it sounds its more simple than what it may sound to you neurons have molecular properties and structural properties that allow them to really communicate with other cells and so if you put not one neuron but if you put several neurons together chances are that they will form synapses with each other okay great so an organoid is not a brain no but theres some its able to especially what youre talking about mimics some properties of the cerebral cortex for example so what can you understand about the brain by studying an organoid of a cerebral cortex i can literally study all this incredible diversity of cell type all these many many different classes of cells how are they made how do they look like what do they need to be made properly and what goes wrong if now the genetics of that stem cell that i used to make the organoid came from a patient with a neurodevelopmental disease can i actually watch for the very first time what may have gone wrong years before in this kid when its own brain was being made think about that loop in a way its a little tiny rudimentary window into the past into the time when that brain in a kid that had this neurodevelopmental disease was being made and i think thats unbelievably powerful because today we have no idea of what cell types we barely know what brain regions are affected in these diseases now we have an experimental system that we can study in the lab and we can ask what are the cells affected when during development things went wrong what are the molecules among the many many different molecules that control brain development which ones are the ones that really messed up here and we want perhaps to fix and what is really the final product is it a less strong kind of circuit and brain is it a brain that lacks a cell type what is it because then we can think about treatment and care for these patients that is informed rather than just based on current diagnostics so how hard is it to detect through the developmental process its a super exciting tool to see how different conditions develop how hard is it to detect that wait a minute this is abnormal development yeah how much signal is there how much of it is it a mess because things can go wrong at multiple levels right you could have a cell that is born and built but then doesnt work properly or a cell that is not even born or a cell that doesnt interact with other cells differently and so on and so forth so today we have technology that we did not have even five years ago that allows us to look for example at the molecular picture of a cell of a single cell in a sea of cells with high precision and so that molecular information where you compare many many single cells for the genes that they produce between a control individual and an individual with a neurodevelopmental disease that may tell you what is different molecularly or you could see that some cells are not even made for example or that the process of maturation of the cells may be wrong there are many different levels here and we can study the cells at the molecular level but also we can use the organoids to ask questions about the properties of the neurons the functional properties how they communicate with each other how they respond to a stimulus and so on and so forth and we may get an abnormalities there right detect those so how early is this work in the maybe in the history of science so i mean like so if you were to if you and i time travel a thousand years into the future organoids seem to be maybe im romanticizing the notion but youre building not a brain but something that has properties of a brain so it feels like you might be getting close to in the building process to build this to understand so how far are we in this understanding process of development a thousand years from now its a long time from now so if this planet is still gonna be here a thousand years from now so i mean if you know like they write a book obviously therell be a chapter about you thats right that science fiction book today yeah today about i mean i guess where we really understood very little about the brain a century ago i was a big fan in high school of reading freud and so on still am of psychiatry i would say we still understand very little about the functional aspect of just but how in the history of understanding the biology of the brain the development how far are we along its a very good question and so this is just of course my opinion i think that we did not have technology even 10 years ago or certainly not 20 years ago to even think about experimentally investigating the development of the human brain so weve done a lot of work in science to study the brain or many other organisms now we have some technologies which ill spell out that allow us to actually look at the real thing and look at the brain at the human brain so what are these technologies there has been huge progress in stem cell biology the moment someone figured out how to turn a skin cell into an embryonic stem cell basically and that how that embryonic stem cell could begin a process of development again to for example make a brain there was a huge advance and in fact there was a nobel prize for that that started the field really of using stem cells to build organs now we can build on all the knowledge of development that we build over the many many many years to say how do we make the stem cells now make more and more complex aspects of development of the human brain so this field is young the field of brain organoids but its moving faster and its moving fast in a very serious way that is rooted in labs with the right ethical framework and really building on solid science for what reality is and what is not but it will go faster and it will be more and more powerful we also have technology that allows us to basically study the properties of single cells across many many millions of single cells which we didnt have perhaps five years ago so now with that even an organoid that has millions of cells can be profiled in a way looked at with very very high resolution the single cell level to really understand what is going on and you could do it in multiple stages of development and you can build your hypothesis and so on and so forth so its not gonna be a thousand years its gonna be a shorter amount of time and i see this as sort of an exponential growth of this field enabled by these technologies that we didnt have before and so were gonna see something transformative that we didnt see at all in the prior thousand years so i apologize for the crazy sci fi questions but the developmental process is fascinating to watch and study but how far are we away from and maybe how difficult is it to build not just an organoid but a human brain from a stem cell yeah first of all thats not the goal for the majority of the serious scientists that work on this because you dont have to build the whole human brain to make this model useful for understanding how the brain develops or understanding disease you dont have to build the whole thing so let me just comment on this fascinating it shows to me the difference between you and i as youre actually trying to understand the beauty of the human brain and to use it to really help thousands or millions of people with disease and so on right from an artificial intelligence perspective were trying to build systems that we can put in robots and try to create systems that have echoes of the intelligence about reasoning about the world navigating the world its different objectives i think yeah thats very much science fiction science fiction but we operate in science fiction a little bit so on that point of building a brain even though that is not the focus or interest perhaps of the community how difficult is it is it truly science fiction at this point i think the field will progress like i said and that the system will be more and more complex in a way right but there are properties that emerge from the human brain that have to do with the mind that may have to do with consciousness that may have to do with intelligence or whatever that we really dont understand even how they can emerge from an actual real brain and therefore we can now measure or study in an organoid so i think that this field many many years from now may lead to the building of better neural circuits that really are built out of understanding of how this process really works and its hard to predict how complex this really will be i really dont think were so far from it makes me laugh really its really that far from building the human brain but youre gonna be building something that is always a bad version of it but that may have really powerful properties and might be able to respond to stimuli or be used in certain context and this is why i really think that there is no other way to do this science but within the right ethical framework because where youre going with this is also we can talk about science fiction and write that book and we could today but this work happens in a specific ethical framework that we dont decide just as scientists but also as a society so the ethical framework here is a fascinating one is a complicated one yes do you have a sense a grasp of how we think about ethically of building organoids from human stem cells to understand the brain it seems like a tool for helping potentially millions of people cure diseases or at least start the cure by understanding it but is there more is there gray areas that we have to think about ethically absolutely we must think about that every discussion about the ethics of this needs to be based on actual data from the models that we have today and from the ones that we will have tomorrow so its a continuous conversation its not something that you decide now today there is no issue really very simple models that clearly can help you in many ways without much think about but tomorrow we need to have another conversation and so on and so forth and so the way we do this is to actually really bring together constantly a group of people that are not only scientists but also bioethicists the lawyers philosophers psychiatrists and so on psychologists and so on and so forth to decide as a society really what we should and what we should not do so thats the way to think about the ethics now i also think though that as a scientist i have a moral responsibility so if you think about how transformative it could be for understanding and curing a neuropsychiatric disease to be able to actually watch and study and treat with drugs the very brain of the patient that you are trying to study how transformative at this moment in time this could be we couldnt do it five years ago we could do it now right if we didnt do it taking a stem cell of a particular patient patient and make an organoid for a simple and different from the human brain it still is his process of brain development with his or her genetics and we could understand perhaps what is going wrong perhaps we could use as a platform as a cellular platform to screen for drugs to fix a process and so on and so forth right so we could do it now we couldnt do it five years ago should we not do it what is the downside of doing it i dont see a downside at this very moment if we invited a lot of people im sure there would be somebody who would argue against it what would be the devils advocate argument yeah yeah so its exactly perhaps what you alluded at with your question that you are enabling some process of formation of the brain that could be misused at some point or that could be showing properties that ethically we dont wanna see in a tissue so today i repeat today this is not an issue and so you just gain dramatically from the science without because the system is so simple and so different in a way from the actual brain but because it is the brain we have an obligation to really consider all of this right and again its a balanced conversation where we should put disease and betterment of humanity also on that plate what do you think at least historically there was some politicization politicization of embryonic stem cells a stem cell research do you still see that out there is that still a force that we have to think about especially in this larger discourse that were having about the role of science in at least american society yeah this is a very good question its very very important i see a very central role for scientists to inform decisions about what we should or should not do in society and this is because the scientists have the firsthand look and understanding of really the work that they are doing and again this varies depending on what were talking about here so now were talking about brain organoids i think that the scientists need to be part of that conversation about what is will be allowed in the future or not allowed in the future to do with the system and i think that is very very important because they bring the reality of data to the conversation and so they should have a voice so data should have a voice data needs to have a voice because in not only data we should also be good at communicating with non scientists the data so there has been often time there is a lot of discussion and you know excitement and fights about certain topics just because of the way they are described ill give you an example if i called the same cellular system we just talked about a brain organoid or if i called it a human mini brain your reaction is gonna be very different to this and so the way the systems are described i mean we and journalists alike need to be a bit careful that this debate is a real debate and informed by real data thats all im asking and yeah the language matters here so i work on autonomous vehicles and there the use of language could drastically change the interpretation and the way people feel about what is the right way to proceed forward you are as ive seen from a presentation youre a parent i saw you show a couple of pictures of your son is it just the one two two son and a daughter son and a daughter so what have you learned from the human brain by raising two of them more than i could ever learn in the lab what have i learned ive learned that children really have these amazing plastic minds right that we have a responsibility to you know foster their growth in good healthy ways that keep them curious that keeps them adventurous that doesnt raise them in fear of things but also respecting who they are which is in part you know coming from the genetics we talked about my children are very different from each other despite the fact that theyre the product of the same two parents i also learned that what you do for them comes back to you like you know if youre a good parent youre gonna most of the time have you know perhaps a decent kids at the end so what do you think just a quick comment what do you think is the source of that difference thats often the surprising thing for parents is that they cant believe that our kids oh theyre so different yet they came from the same parents well they are genetically different even they came from the same two parents because the mixing of gametes you know we know this genetics creates every time a genetically different individual which will have a specific mix of genes that is a different mix every time from the two parents and so theyre not twins they are genetically different even just that little bit of variation because you said really from a biological perspective the brains look pretty similar well so let me clarify that so the genetics you have the genes that you have that play that beautiful orchestrated symphony of development different genes will play it slightly differently its like playing the same piece of music but with a different orchestra and a different director the music will not come out it will be still a piece by the same author but it will come out differently if its played by the high school orchestra instead of the scala in milan and so you are born superficially with the same brain it has the same cell types similar patterns of connectivity but the properties of the cells and how the cells will then react to the environment as you experience your world will be also shaped by who genetically you are speaking just as a parent this is not something that comes from my work i think you can tell at birth that these kids are different that they have a different personality in a way right so both is needed the genetics as well as the nurturing afterwards so you are one human with a brain sort of living through the whole mess of it the human condition full of love maybe fear ultimately mortal how has studying the brain changed the way you see yourself when you look in the mirror when you think about your life the fears the love when you see your own life your own mortality yeah thats a very good question its almost impossible to dissociate some time for me some of the things we do or some of the things that other people do from oh thats because that part of the brain is working in a certain way or thinking about a teenager going through teenage years and being at time funny in the way they think and impossible for me not to think its because theyre going through this period of time called critical periods of plasticity where their synapses are being eliminated here and there and theyre just confused and so from that comes perhaps a different take on that behavior or maybe i can justify it scientifically in some sort of way i also look at humanity in general and i am amazed by what we can do and the kind of ideas that we can come up with and i cannot stop thinking about how the brain is continuing to evolve i dont know if you do this but i think about the next brain sometimes where are we going with this like what are the features of this brain that evolution is really playing with to get us in the future the new brain its not over right its a work in progress so let me just a quick comment on that do you think theres a lot of fascination and hope for artificial intelligence of creating artificial brains you said the next brain when you imagine over a period of a thousand years the evolution of the human brain do you sometimes envisioning that future see an artificial one artificial intelligence as it is hoped by many not hoped thought by many people would be actually the next evolutionary step in the development of humans yeah i think in a way that will happen right its almost like a part of the way we evolve we evolve in the world that we created that we interact with that shape us as we grow up and so on and so forth sometime i think about something that may sound silly but think about the use of cell phones part of me thinks that somehow in their brain there will be a region of the cortex that is attuned to that tool and this comes from a lot of studies in modern organisms where really the cortex especially adapts to the kind of things you have to do so if we need to move our fingers in a very specific way we have a part of our cortex that allows us to do this kind of very precise movement an owl that has to see very very far away with big eyes the visual cortex very big the brain attunes to your environment so the brain will attune to the technologies that we will have and will be shaped by it so the cortex very well may be will be shaped by it in artificial intelligence it may merge with it it may get envelop it and adjust even if its not a merge of the kind of oh lets have a synthetic element together with a biological one the very space around us the fact for example think about we put on some goggles of virtual reality and we physically are surfing the ocean right like ive done it and you have all these emotions that come to you your brain placed you in that reality and it was able to do it like that just by putting the goggles on it didnt take thousands of years of adapting to this the brain is plastic so adapts to new technology so you could do it from the outside by simply hijacking some sensory capacities that we have so clearly over recent evolution the cerebral cortex has been a part of the brain that has known the most evolution so we have put a lot of chips on evolving this specific part of the brain and the evolution of cortex is plasticity its this ability to change in response to things so yes they will integrate that we want it or not well theres no better way to end it paola thank you so much for talking today youre very welcome this is very exciting', 'the following is a conversation with keoki jackson hes the cto of lockheed martin a company that through its long history has created some of the most incredible engineering marvels human beings have ever built including planes that fly fast and undetected defense systems that intersect nuclear threats that can take the lives of millions and systems that venture out into space the moon mars and beyond and these days more and more artificial intelligence has an assistive role to play in these systems ive read several books in preparation for this conversation it is a difficult one because in part lockheed martin builds military systems that operate in a complicated world that often does not have easy solutions in the gray area between good and evil i hope one day this world will rid itself of war in all its forms but the path to achieving that in a world that does have evil is not obvious what is obvious is good engineering and artificial intelligence research has a role to play on the side of good lockheed martin and the rest of our community are hard at work at exactly this task we talk about these and other important topics in this conversation also most certainly both keoki and i have a passion for space us humans venturing out toward the stars we talk about this exciting future as well this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with keoki jackson i read several books on lockheed martin recently my favorite in particular is by ben rich carlos concords personal memoir it gets a little edgy at times but from that i was reminded that the engineers at lockheed martin have created some of the most incredible engineering marvels human beings have ever built throughout the 20th century and the 21st do you remember a particular project or system at lockheed or before that at the space shuttle columbia that you were just in awe at the fact that us humans could create something like this you know thats a great question theres a lot of things that i could draw on there when you look at the skunk works and ben richs book in particular of course it starts off with basically the start of the jet age and the p 80 and i had the opportunity to sit next to one of the apollo astronauts charlie duke recently at dinner and i said hey whats your favorite aircraft and he said well it was by far the f 104 starfighter which was another aircraft that came out of lockheed there it was the first mach 2 jet fighter aircraft they called it the missile with a man in it and so those are the kinds of things i grew up hearing stories about you know of course the sr 71 is incomparable as kind of the epitome of speed altitude and just the coolest looking aircraft ever so theres a reconnaissance thats a plane thats a yeah intelligence surveillance and reconnaissance aircraft that was designed to be able to outrun basically go faster than any air defense system but you know ill tell you im a space junkie thats why i came to mit thats really what took me ultimately to lockheed martin and i grew up and so lockheed martin for example has been essentially at the heart of every planetary mission like all the mars missions weve had a part in and weve talked a lot about the 50th anniversary of apollo here in the last couple of weeks right but remember 1976 july 20th again national space days the landing of the viking lander on the surface of mars just a huge accomplishment and when i was a young engineer at lockheed martin i got to meet engineers who had designed you know various pieces of that mission as well so thats what i grew up on is these planetary missions the start of the space shuttle era and ultimately had the opportunity to see lockheed martins part lockheed martins part and we can maybe talk about some of these here but lockheed martins part in all of these space journeys over the years do you dream and i apologize for getting philosophical at times or sentimental i do romanticize the notion of space exploration so do you dream of the day when us humans colonize another planet like mars or a man a woman a human being steps on mars absolutely and thats a personal dream of mine i havent given up yet on my own opportunity to fly into space but as you know from the lockheed martin perspective this is something that were working towards every day and of course you know were building the orion spacecraft which is the most sophisticated human rated spacecraft ever built and its really designed for these deep space journeys you know starting with the moon but ultimately going to mars and being the platform you know from a design perspective we call the mars base camp to be able to take humans to the surface and then after a mission of a couple of weeks bring them back up safely and so that is something i want to see happen during my time at lockheed martin so im pretty excited about that and i think you know once we prove thats possible you know colonization might be a little bit further out but its something that id hope to see so maybe you can give a little bit of an overview of so lockheed martin has partnered with a few years ago with boeing to work with the dod and nasa to build launch systems and rockets with the ula whats beyond that whats lockheeds mission timeline long term dream in terms of space you mentioned the moon ive heard you talk about asteroids as mars whats the timeline whats the engineering challenges and whats the dream long term yeah i think the dream long term is to have a permanent presence in space beyond low earth orbit ultimately with a long term presence on the moon and then to the planets to mars and sorry to interrupt on that so long term presence means sustained and sustainable presence in an economy a space economy that really goes alongside that with human beings and being able to launch perhaps from those so like hop you know theres a lot of energy that goes in those hops right so i think the first step is being able to get there and to be able to establish sustained bases right and build from there and a lot of that means getting as you know things like the cost of launch down and you mentioned united launch alliance and so i dont wanna speak for ula but obviously theyre working really hard to on their next generation of launch vehicles to maintain that incredible mission success record that ula has but ultimately continue to drive down the cost and make the flexibility the speed and the access ever greater so whats the missions that are in the horizon that you could talk to is there a hope to get to the moon absolutely absolutely i mean i think you know this or you may know this theres a lot of ways to accomplish some of these goals and so thats a lot of whats in discussion today but ultimately the goal is to be able to establish a base essentially in cislunar space that would allow for ready transfer from orbit to the lunar surface and back again and so thats sort of that near term i say near term in the next decade or so vision starting off with a stated objective by this administration to get back to the moon in the 2024 2025 timeframe which is right around the corner here how big of an engineering challenge is that i think the big challenge is not so much to go but to stay right and so we demonstrated in the 60s that you could send somebody up do a couple of days of mission and bring them home again successfully now were talking about doing that id say more to i dont wanna say an industrial scale but a sustained scale right so permanent habitation regular reuse of vehicles the infrastructure to get things like fuel air consumables replacement parts all the things that you need to sustain that kind of infrastructure so those are certainly engineering challenges there are budgetary challenges and those are all things that were gonna have to work through the other thing and i shouldnt i dont wanna minimize this i mean im excited about human exploration but the reality is our technology and where weve come over the last 40 years essentially has changed what we can do with robotic exploration as well and to me its incredibly thrilling and this seems like old news now but the fact that we have rovers driving around the surface of mars and sending back data is just incredible the fact that we have satellites in orbit around mars that are collecting weather theyre looking at the terrain theyre mapping all of these kinds of things on a continuous basis thats incredible and the fact that you got the time lag of course going to the planets but you can effectively have virtual human presence there in a way that we have never been able to do before and now with the advent of even greater processing power better ai systems better cognitive systems and decision systems you put that together with the human piece and weve really opened up the solar system in a whole different way and ill give you an example weve got osiris rex which is a mission to the asteroid bennu so the spacecraft is out there right now on basically a year mapping activity to map the entire surface of that asteroid in great detail you know all autonomously piloted right but the idea then that and this is not too far away its gonna go in its got a sort of fancy vacuum cleaner with a bucket its gonna collect the sample off the asteroid and then send it back here to earth and so you know we have gone from sort of those tentative steps in the 70s you know early landings video of the solar system to now weve sent spacecraft to pluto we have gone to comets and brought and intercepted comets weve brought stardust you know material back so thats weve gone far and theres incredible opportunity to go even farther so it seems quite crazy that this is even possible that can you talk a little bit about what it means to orbit an asteroid and with a bucket to try to pick up some soil samples yeah so part of it is just kind of the you know these are the same kinds of techniques we use here on earth for high speed high accuracy imagery stitching these scenes together and creating essentially high accuracy world maps right and so thats what were doing obviously on a much smaller scale with an asteroid but the other thing thats really interesting you put together sort of that neat control and you know data and imagery problem but the stories around how we designed the collection i mean as essentially you know this is the sort of the human ingenuity element right that you know essentially had an engineer who had a one day hes like oh starts messing around with parts vacuum cleaner bucket you know maybe we could do something like this and that was what led to what we call the pogo stick collection right where basically a thing comes down its only there for seconds does that collection grabs the essentially blows the regolith material into the collection hopper and off it goes it doesnt really land almost its a very short landing wow thats incredible so what is in those we talked a little bit more about space whats the role of the human in all of this what are the challenges what are the opportunities for humans as they pilot these vehicles in space and for humans that may step foot on either the moon or mars yeah its a great question because you know i just have been extolling the virtues of robotic and you know rovers autonomous systems and those absolutely have a role i think the thing that we dont know how to replace today is the ability to adapt on the fly to new information and i believe that will come but were not there yet theres a ways to go and so you know you think back to apollo 13 and the ingenuity of the folks on the ground and on the spacecraft essentially cobbled together a way to get the carbon dioxide scrubbers to work those are the kinds of things that ultimately you know and id say not just from dealing with anomalies but you know dealing with new information you see something and rather than waiting 20 minutes or half an hour an hour to try to get information back and forth but be able to essentially revector on the fly collect you know different samples take a different approach choose different areas to explore those are the kinds of things that human presence enables that is still a ways ahead of us on the ai side yeah theres some interesting stuff well talk about on the teaming side here on earth thats pretty cool to explore and in space lets not leave the space piece out so what does teaming what does ai and humans working together in space look like yeah one of the things were working on is a system called maya which is you think of it so its an ai assistant in space in space exactly and you think of it as the alexa in space right but this goes hand in hand with a lot of other developments and so todays world everything is essentially model based model based systems engineering to the actual digital tapestry that goes through the design the build the manufacture the testing and ultimately the sustainment of these system and so our vision is really that you know when our astronauts are there around mars youre gonna have that entire digital library of the spacecraft of its operations all the test data all the test data and flight data from previous missions to be able to look and see if there are anomalous conditions and tell the humans and potentially deal with that before it becomes a bad situation and help the astronauts work through those kinds of things and its not just you know dealing with problems as they come up but also offering up opportunities for additional exploration capability for example so thats the vision is that you know these are gonna take the best of the human to respond to changing circumstances and rely on the best of ai capabilities to monitor these you know this almost infinite number of data points and correlations of data points that humans frankly arent that good at so how do you develop systems in space like this whether its alexa in space or in general any kind of control systems any kind of intelligent systems when you cant really test stuff too much out in space its very expensive to test stuff so how do you develop such systems yeah thats the beauty of this digital twin if you will and of course with lockheed martin weve over the past you know five plus decades been refining our knowledge of the space environment of how materials behave dynamics the controls the radiation environments all of these kinds of things so were able to create very sophisticated models theyre not perfect but theyre very good and so you can actually do a lot i spent part of my career you know simulating communication spacecraft you know missile warning spacecraft gps spacecraft in all kinds of scenarios and all kinds of environments so this is really just taking that to the next level the interesting thing is that now youre bringing into that loop a system depending on how its developed that may be non deterministic it may be learning as it goes and in fact we anticipate that it will be learning as it goes and so that brings a whole new level of interest i guess into how do you do verification and validation of these non deterministic learning systems in scenarios that may go out of the bounds or the envelope that you have initially designed them to so had this system and its intelligence has the same complexity some of the same complexity human does and learns over time its unpredictable in certain kinds of ways in the so you still you also have to model that when youre thinking about it so in your thoughts its possible to model the majority of situations the important aspects of situations here on earth and in space enough to test stuff yeah this is really an active area of research and were actually funding university research in a variety of places including mit this is in the realm of trust and verification and validation of id say autonomous systems in general and then as a subset of that autonomous systems that incorporate artificial intelligence capabilities and this is not an easy problem were working with startup companies weve got internal rd but our conviction is that autonomy and more and more ai enabled autonomy is gonna be in everything that lockheed martin develops and fields and its gonna be retrofitting it autonomy and ai are gonna be retrofit into existing systems theyre gonna be part of the design for all of our future systems and so maybe i should take a step back and say the way we define autonomy so we talk about autonomy essentially a system the kinds of incredibly destructive world wars that we saw in the first half of the 20th century now things have gotten more complicated since that time and since the cold war it is more of a multipolar great powers world today just to give you an example back then there were in the cold war timeframe just a handful of nations that had ballistic missile capability by last count and this is a few years old theres over 70 nations today that have that similar kinds of numbers in terms of space based capabilities so the world has gotten more complex and more challenging and the threats i think have proliferated in ways that we didnt expect the nation today is in the middle of a recapitalization of our strategic deterrent i look at that as one of the most important things that our nation can do what is involved in deterrence is it being ready to attack or is it the defensive systems that catch attacks a little bit of both and so its a complicated game theoretical kind of program but ultimately we are trying to prevent the use of any of these weapons and the theory behind prevention is that even if an adversary uses a weapon against you you have the capability to essentially strike back and do harm to them thats unacceptable and so that will deter them from making use of these weapons systems the deterrence calculus has changed of course with more nations now having these kinds of weapons but i think from my perspective its very important to maintain a strategic deterrent you have to have systems that you know will work when theyre required to work now you know that they have to be adaptable to a variety of different scenarios in todays world and so thats what this recapitalization of systems that were built over previous decades making sure that they are appropriate not just for today but for the decades to come so the other thing id really like to note is strategic deterrence has a very different character today we used to think of weapons of mass destruction in terms of nuclear chemical biological and today we have a cyber threat weve seen examples of the use of cyber weaponry and if you think about the possibilities of using cyber capabilities or an adversary attacking the us to take out things like critical infrastructure electrical grids water systems those are scenarios that are strategic in nature to the survival of a nation as well so that is the kind of world that we live in today and part of my hope on this is one that we can also develop technical or technological systems perhaps enabled by ai and autonomy that will allow us to contain and to fight back against these kinds of new threats that were not conceived when we first developed our strategic deterrence yeah i know that lockheed is involved in cyber so i saw that you mentioned that its an incredibly nuclear almost seems easier than cyber because theres so many attack theres so many ways that cyber can evolve in such an uncertain future but talking about engineering with a mission i mean in this case that youre engineering systems that basically save the world well like i said were privileged to work on some very challenging problems for very critical customers here in the us and with our allies abroad as well lockheed builds both military and nonmilitary systems and perhaps the future of lockheed may be more in nonmilitary applications if you talk about space and beyond i say that as a preface to a difficult question so president eisenhower in 1961 in his farewell address talked about the military industrial complex and that it shouldnt grow beyond what is needed so what are your thoughts on those words on the military industrial complex on the concern of growth of their developments beyond what may be needed that where it may be needed is a critical phrase of course and i think it is worth pointing out as you noted that lockheed martin we are in a number of commercial businesses from energy to space to commercial aircraft and so i wouldnt neglect the importance of those parts of our business as well i think the world is dynamic and there was a time and it doesnt seem that long ago to me it was while i was a graduate student here at mit and we were talking about the peace dividend at the end of the cold war if you look at expenditure on military systems as a fraction of gdp were far below peak levels of the past and to me at least it looks like a time where youre seeing global threats changing in a way that would warrant relevant investments in defensive capabilities the other thing id note for military and defensive systems its not quite a free market right we dont sell to people on the street and that warrants a very close partnership between id say the customers and the people that design build and maintain these systems because of the very unique nature the very difficult requirements the very great importance on safety and on operating the way theyre intended every time and so that does create and frankly its one of lockheed martins great strengths is that we have this expertise built up over many years in partnership with our customers to be able to design and build these systems that meet these very unique mission needs yeah because building those systems is very costly theres very little room for mistake i mean its yeah just ben richs book and so on just tells the story its nerve wracking just reading it if youre an engineer it reads like a thriller okay let me lets go back to space for a second i guess im always happy to go back to space so a few quick maybe out there maybe fun questions maybe a little provocative what are your thoughts on the efforts of the new folks spacex and elon musk what are your thoughts about what elon is doing do you see him as competition do you enjoy competition what are your thoughts yeah first of all certainly elon id say spacex and some of his other ventures are definitely a competitive force in the space industry and do we like competition yeah we do and we think were very strong competitors i think its you know competition is what the us is founded on in a lot of ways and always coming up with a better way and i think its really important to continue to have fresh eyes coming in new innovation i do think its important to have level playing fields and so you wanna make sure that youre not giving different requirements to different players but you know i tell people you know i spent a lot of time at places like mit im gonna be at the mit beaverwork summer institute over the weekend here and i tell people this is the most exciting time to be in the space business in my entire life and it is this explosion of new capabilities that have been driven by things like the you know the massive increase in computing power things like the massive increase in comms capabilities advanced and additive manufacturing are really bringing down the barriers to entry in this field and its driving just incredible innovation and its happening at startups but its also happening at lockheed martin you may not realize this but lockheed martin working with stanford actually built the first cubesat that was launched here out of the us that was called quakesat and we did that with stellar solutions this was right around just after 2000 i guess and so weve been in that you know from the very beginning and you know i talked about some of these like you know maya and orion but you know were in the middle of what we call smartsats and software defined satellites that can essentially restructure and remap their purpose their mission on orbit to give you almost you know unlimited flexibility for these satellites over their lifetimes so those are just a couple of examples but yeah this is a great time to be in space absolutely so wright brothers flew for the first time 116 years ago so now we have supersonic stealth planes and all the technology weve talked about what innovations obviously you cant predict the future but do you see lockheed in the next 100 years if you take that same leap how will the world of technology and engineering change i know its an impossible question but nobody could have predicted that we could even fly 120 years ago so what do you think is the edge of possibility that were going to be exploring in the next 100 years i dont know that there is an edge i you know weve been around for almost that entire time right the lockheed brothers and glen l martin starting their companies in the basement of a church and an old service station were very different companies today than we were back then right and thats because weve continuously reinvented ourselves over all of those decades i think its fair to say i know this for sure the world of the future its gonna move faster its gonna be more connected its gonna be more autonomous and its gonna be more complex than it is today and so this is the world you know as a cto at lockheed martin that i think about what are the technologies that we have to invest in whether its things like ai and autonomy you know you can think about quantum computing which is an area that weve invested in to try to stay ahead of these technological changes and frankly some of the threats that are out there i believe that were gonna be out there in the solar system that were gonna be defending and defending well against probably you know military threats that nobody has even thought about today we are going to be were gonna use these capabilities to have far greater knowledge of our own planet the depths of the oceans you know all the way to the upper reaches of the atmosphere and everything out to the sun and to the edge of the solar system so thats what i look forward to and im excited i mean just looking ahead in the next decade or so to the steps that i see ahead of us in that time i dont think theres a better place to end keoki thank you so much lex its been a real pleasure and sorry it took so long to get up here but im glad we were able to make it happen that composes selects and then executes decisions with varying levels of human intervention and so you could think of no autonomy so this is essentially the human doing the task you can think of effectively partial autonomy where the human is in the loop so making decisions in every case about what the autonomous system can do either in the cockpit or remotely or remotely exactly but still in that control loop and then theres what youd call supervisory autonomy so the autonomous system is doing most of the work the human can intervene to stop it or to change the direction and then ultimately full autonomy where the human is off the loop altogether and for different types of missions wanna have different levels of autonomy so now take that spectrum and this conviction that autonomy and more and more ai are in everything that we develop the kinds of things that lockheed martin does a lot of times are safety of life critical kinds of missions you think about aircraft for example and so we require and our customers require an extremely high level of confidence one that were gonna protect life two that these systems will behave in ways that their operators can understand and so this gets into that whole field again being able to verify and validate that the systems have been and that they will operate the way theyre designed and the way theyre expected and furthermore that they will do that in ways that can be explained and understood and that is an extremely difficult challenge yeah so heres a difficult question i dont mean to bring this up but i think its a good case study that people are familiar with the boeing 737 max commercial airplane has had two recent crashes where their flight control software system failed and its software so i dont mean to speak about boeing but broadly speaking we have this in the autonomous vehicle space too semi autonomous we have millions of lines of code software making decisions there is a little bit of a clash of cultures because software engineers dont have the same culture of safety often that people who build systems like at lockheed martin do where it has to be exceptionally safe you have to test this on so how do we get this right when software is making so many decisions yeah and theres a lot of things that have to happen and by and large i think it starts with the culture which is not necessarily something that a is taught in school or b is something that would come depending on what kind of software youre developing it may not be relevant right if youre targeting ads or something like that so and by and large id say not just lockheed martin but certainly the aerospace industry as a whole has developed a culture that does focus on safety safety of life operational safety mission success but as you note these systems have gotten incredibly complex and so theyre to the point where its almost impossible you know state spaces become so huge that its impossible to or very difficult to do a systematic verification across the entire set of potential ways that an aircraft could be flown all the conditions that could happen all the potential failure scenarios now maybe thats soluble one day maybe when we have our quantum computers at our fingertips well be able to actually simulate across an entire you know almost infinite state space but today you know theres a lot of work to really try to bound the system to make sure that it behaves in predictable ways and then have this culture of continuous inquiry and skepticism and questioning to say did we really consider the right realm of possibilities have we done the right range of testing do we really understand you know in this case you know human and machine interactions the human decision process alongside the machine processes and so thats that culture we call it the culture of mission success at lockheed martin that really needs to be established and its not something you know its something that people learn by living in it and its something that has to be promulgated you know and its done you know from the highest levels at a company of lockheed martin like lockheed martin yeah and the same is being faced at certain autonomous vehicle companies where that culture is not there because it started mostly by software engineers so thats what theyre struggling with is there lessons that you think we should learn as an industry and a society from the boeing 737 max crashes these crashes obviously are tremendous tragedies theyre tragedies for all of the people the crew the families the passengers the people on the ground involved and you know its also a huge business and economic setback as well i mean you know weve seen that its impacting essentially the trade balance of the us so these are important questions and these are the kinds that you know weve seen similar kinds of questioning at times you know you go back to the challenger accident and it is i think always important to remind ourselves that humans are fallible that the systems we create as perfect as we strive to make them we can always make them better and so another element of that culture of mission success is really that commitment to continuous improvement if theres something that goes wrong a real commitment to root cause and true root cause understanding to taking the corrective actions and to making the future systems better and certainly we strive for you know no accidents and if you look at the record of the commercial airline industry as a whole and the commercial aircraft industry as a whole you know theres a very nice decaying exponential to years now where we have no commercial aircraft accidents at all right fatal accidents at all so that didnt happen by accident it was through the regulatory agencies faa the airframe manufacturers really working on a system to identify root causes and drive them out so maybe we can take a step back and many people are familiar but lockheed martin broadly what kind of categories of systems are you involved in building you know lockheed martin we think of ourselves as a company that solves hard mission problems and the output of that might be an airplane or a spacecraft or a helicopter or a radar or something like that but ultimately were driven by these you know what is our customer what is that mission that they need to achieve and so thats what drove the sr71 right how do you get pictures of a place where youve got sophisticated air defense systems that are capable of handling any aircraft that was out there at the time right so that you know thats what yielded an sr71 lets build a nice flying camera exactly and make sure it gets out and it gets back right and that led ultimately to really the start of the space program in the us as well so now take a step back to lockheed martin of today and we are you know on the order of 105 years old now between lockheed and martin the two big heritage companies of course were made up of a whole bunch of other companies that came in as well general dynamics you know kind of go down the list today you can think of us in this space of solving mission problems so obviously on the aircraft side tactical aircraft building the most advanced fighter aircraft that the world has ever seen were up to now several hundred of those delivered building almost a hundred a year and of course working on the things that come after that on the space side we are engaged in pretty much every venue of space utilization and exploration you can imagine so i mentioned things like navigation and timing gps communication satellites missile warning satellites weve built commercial surveillance satellites weve built commercial communication satellites we do civil space so everything from human exploration to the robotic exploration of the outer planets and keep going on the space front but a couple of other areas that id like to put out were heavily engaged in building critical defensive systems and so a couple that ill mention the aegis combat system this is basically the integrated air and missile defense system for the us and allied fleets and so protects carrier strike groups for example from incoming ballistic missile threats aircraft threats cruise missile threats and kind of go down the list so the carriers the fleet itself is the thing that is being protected the carriers arent serving as a protection for something else well thats a little bit of a different application weve actually built the version called aegis ashore which is now deployed in a couple of places around the world so that same technology i mean basically can be used to protect either an ocean going fleet or a land based activity another one the thaad program so thaad this is the theater high altitude area defense this is to protect relatively broad areas against sophisticated ballistic missile threats and so now its deployed with a lot of us capabilities and now we have international customers that are looking to buy that capability as well and so these are systems that defend not just defend militaries and military capabilities but defend population areas we saw maybe the first public use of these back in the first gulf war with the patriot systems and these are the kinds of things that lockheed martin delivers and theres a lot of stuff that goes into it a lot of stuff that goes with it so think about the radar systems and the sensing systems that cue these the command and control systems that decide how you pair a weapon against an incoming threat and then all the human and machine interfaces to make sure that they can be operated successfully in very strenuous environments yeah theres some incredible engineering that at every front like you said so maybe if we just take a look at lockheed history broadly maybe even looking at skunk works what are the biggest most impressive milestones of innovation so if you look at stealth i would have called you crazy if you said thats possible at the time and supersonic and hypersonic so traveling at first of all traveling at the speed of sound is pretty damn fast and supersonic and hypersonic three four five times the speed of sound that seems i would also call you crazy if you say you can do that so can you tell me how its possible to do these kinds of things and is there other milestones and innovation thats going on that you can talk about yeah well let me start on the skunk works saga and you kind of alluded to it in the beginning skunk works is as much an idea as a place and so its driven really by kelly johnsons 14 principles and im not gonna list all 14 of them off but the idea and this im sure will resonate with any engineer whos worked on a highly motivated small team before the idea that if you can essentially have a small team of very capable people who wanna work on really hard problems you can do almost anything especially if you kind of shield them from bureaucratic influences if you create very tight relationships with your customers so that you have that team and shared vision with the customer those are the kinds of things that enable the skunk works to do these incredible things and we listed off a number that you brought up stealth and i wish i could have seen ben rich with a ball bearing rolling it across the desk to a general officer and saying would you like to have an aircraft that has the radar cross section of this ball bearing probably one of the least expensive and most effective marketing campaigns in the history of the industry so just for people that are not familiar the way you detect aircraft im sure theres a lot of ways but radar for the longest time theres a big blob that appears in the radar how do you make a plane disappear so it looks as big as a ball bearing whats involved in technology wise there whats the broadly sort of the stuff you can speak about ill stick to whats in ben richs book but obviously the geometry of how radar gets reflected and the kinds of materials that either reflect or absorb are kind of the couple of the critical elements there and its a cat and mouse game right i mean you know radars get better stealth capabilities get better and so its a really a game of continuous improvement and innovation there ill leave it at that yeah so the idea that something is essentially invisible is quite fascinating but the other one is flying fast so speed of sound is 750 60 miles an hour so supersonic is three you know mach three something like that yeah we talk about the supersonic obviously and we kind of talk about that as that realm from mach one up through about mach five and then hypersonic so you know high supersonic speeds would be past mach five and you got to remember lockheed martin and actually other companies have been involved in hypersonic development since the late 60s you know you think of everything from the x 15 to the space shuttle as examples of that i think the difference now is if you look around the world particularly the threat environment that were in today youre starting to see you know publicly folks like the russians and the chinese saying they have hypersonic weapons capability that could threaten us and allied capabilities and also basically you know the claims are these could get around defensive systems that are out there today and so theres a real sense of urgency you hear it from folks like the undersecretary of defense for research and engineering dr mike griffin and others in the department of defense that hypersonics is something thats really important to the nation in terms of both parity but also defensive capabilities and so thats something that you know were pleased its something that lockheed martins you know had a heritage in weve invested r and d dollars on our side for many years and we have a number of things going on with various us government customers in that field today that were very excited about so i would anticipate well be hearing more about that in the future from our customers and ive actually havent read much about this probably you cant talk about much of it at all but on the defensive side its a fascinating problem of perception of trying to detect things that are really hard to see can you comment on how hard that problem is and how hard is it to stay ahead even if we go back a few decades stay ahead of the competition well maybe id again you gotta think of these as ongoing capability development and so think back to the early days of missile defense so this would be in the 80s the sdi program and in that timeframe we proved and lockheed martin proved that you could hit a bullet with a bullet essentially and which is something that had never been done before to take out an incoming ballistic missile and so thats led to these incredible hit to kill kinds of capabilities pac 3 thats the patriot advanced capability model 3 that lockheed martin builds the thaad system that i talked about so now hypersonics theyre different from ballistic systems and so we gotta take the next step in defensive capability i can ill leave that there but i can only imagine now let me just comment sort of as an engineer its sad to know that so much that lockheed has done in the past is classified or today and its shrouded in secrecy it has to be by the nature of the application so like what i do so what we do here at mit we would like to inspire young engineers young scientists and yet in the lockheed case some of that engineer has to stay quiet how do you think about that how does that make you feel is there a future where more can be shown or is it just the nature of this world that it has to remain secret its a good question i think the public can see enough of and including students who may be in grade school high school college today to understand the kinds of really hard problems that we work on and i mean look at the f35 right and obviously a lot of the detailed performance levels are sensitive and controlled but we can talk about what an incredible aircraft this is supersonic super cruise kind of a fighter stealth capabilities its a flying information system in the sky with data fusion sensor fusion capabilities that have never been seen before so these are the kinds of things that i believe these are the kinds of things that got me excited when i was a student i think these still inspire students today and the other thing id say i mean people are inspired by space people are inspired by aircraft our employees are also inspired by that sense of mission and ill just give you an example i had the privilege to work and lead our gps programs for some time and that was a case where i actually worked on a program that touches billions of people every day and so when i said i worked on gps everybody knew what i was talking about even though they didnt maybe appreciate the technical challenges that went into that but ill tell you i got a briefing one time from a major in the air force and he said i go by callsign gimp gps is my passion i love gps and he was involved in the operational test of the system and he said i was out in iraq and i was on a helicopter blackhawk helicopter and i was bringing back a sergeant and a handful of troops from a deployed location and he said my job is gps so i asked that sergeant and hes beaten down and kind of half asleep and i said what do you think about gps and he brightened up his eyes lit up and he said well gps that brings me and my troops home every day i love gps and thats the kind of story where its like okay im really making a difference here in the kind of work so that mission piece is really important the last thing ill say is and this gets to some of these questions around advanced technologies its not theyre not just airplanes and spacecraft anymore for people who are excited about advanced software capabilities about ai about bringing machine learning these are the things that were doing to exponentially increase the mission capabilities that go on those platforms and those are the kinds of things that i think are more and more visible to the public yeah i think autonomy especially in flight is super exciting do you see a day here we go back into philosophy future when most fighter jets will be highly autonomous to a degree where a human doesnt need to be in the cockpit in almost all cases well i mean thats a world that to a certain extent were in today now these are remotely piloted aircraft to be sure but we have hundreds of thousands of flight hours a year now in remotely piloted aircraft and then if you take the f35 there are huge layers i guess in levels of autonomy built into that aircraft so that the pilot is essentially more of a mission manager rather than doing the data the second to second elements of flying the aircraft so in some ways its the easiest aircraft in the world to fly and kind of a funny story on that so i dont know if you know how aircraft carrier landings work but basically theres whats called a tail hook and it catches wires on the deck of the carrier and thats what brings the aircraft to a screeching halt right and theres typically three of these wires so if you miss the first the second one you catch the next one right and we got a little criticism i dont know how true this story is but we got a little criticism the f35 is so perfect it always gets the second wires were wearing out the wire because it always hits that one but thats the kind of autonomy that just makes these essentially up levels what the human is doing to more of that mission manager so much of that landing by the f35 is autonomous well its just the control systems are such that you really have dialed out the variability that comes with all the environmental conditions youre wearing it out so my point is to a certain extent that world is here today do i think that were gonna see a day anytime soon when there are no humans in the cockpit i dont believe that but i do think were gonna see much more human machine teaming and were gonna see that much more at the tactical edge and we did a demo and you asked about what the skunk works is doing these days and so this is something i can talk about but we did a demo with the air force research laboratory we called it have raider and so using an f16 as an autonomous wingman and we demonstrated all kinds of maneuvers and various mission scenarios with the autonomous f16 being that so called loyal or trusted wingman and so those are the kinds of things that weve shown what is possible now given that youve up leveled that pilot to be a mission manager now they can control multiple other aircraft think of them almost as extensions of your own aircraft flying alongside with you so thats another example of how this is really coming to fruition and then i mentioned the landings but think about just the implications for humans and flight safety and this goes a little bit back to the discussion we were having about how do you continuously improve the level of safety through automation while working through the complexities that automation introduces so one of the challenges that you have in high performance fighter aircraft is whats called g lock so this is g induced loss of consciousness so you pull nine gs youre wearing a pressure suit thats not enough to keep the blood going to your brain you black out and of course thats bad if you happen to be flying low near the deck and in an obstacle or terrain environment and so we developed a system in our aeronautics division called auto gcast so autonomous ground collision avoidance system and we built that into the f16 its actually saved seven aircraft eight pilots already in a relatively short time its been deployed it was so successful that the air force said hey we need to have this in the f35 right away so weve actually done testing of that now on the f35 and weve also integrated an autonomous air collision avoidance system so think the air to air problem so now its the integrated collision avoidance system but these are the kinds of capabilities i wouldnt call them ai i mean theyre very sophisticated models of the aircraft dynamics coupled with the terrain models to be able to predict when essentially the pilot is doing something that is gonna take the aircraft or the pilots not doing something in this case but it just gives you an example of how autonomy can be really a lifesaver in todays world its like a autonomous automated emergency braking in cars but is there any exploration of perception of for example detecting a g lock that the pilot is out so as opposed to perceiving the external environment to infer that the pilot is out but actually perceiving the pilot directly yeah this is one of those cases where youd like to not take action if you think the pilots there and its almost like systems that try to detect if a drivers falling asleep on the road right with limited success so i mean this is what i call the system of last resort right where if the aircraft has determined that its going into the terrain get it out of there and this is not something that were just doing in the aircraft world and i wanted to highlight we have a technology we call matrix but this is developed at sikorsky innovations the whole idea there is what we call optimal piloting so not optional piloting or unpiloted but optimal piloting so an faa certified system so you have a high degree of confidence its generally pretty deterministic so we know that itll do in different situations but effectively be able to fly a mission with two pilots one pilot no pilots and you can think of it almost as like a dial of the level of autonomy that you want but able so its running in the background at all times and able to pick up tasks whether its sort of autopilot kinds of tasks or more sophisticated path planning kinds of activities to be able to do things like for example land on an oil rig in the north sea in bad weather zero zero conditions and you can imagine of course theres a lot of military utility to capability like that you could have an aircraft that you want to send out for a crewed mission but then at night if you want to use it to deliver supplies in an unmanned mode that could be done as well and so theres clear advantages there but think about on the commercial side if youre an aircraft taken youre gonna fly out to this oil rig if you get out there and you cant land then you gotta bring all those people back reschedule another flight pay the overtime for the crew that you just brought back because they didnt get where they were going pay for the overtime for the folks that are out there in the oil rig this is real economic these are dollars and cents kinds of advantages were bringing in the commercial world as well so heres a difficult question from the ai space that i would love it if youre able to comment so a lot of this autonomy in ai youve mentioned just now has this empowering effect one is the last resort it keeps you safe the other is theres a with the teaming and in general assistive ai and i think theres always a race so the world is full of the world is complex its full of bad actors so theres often a race to make sure that we keep this country safe right but with ai there is a concern that its a slightly different race though theres a lot of people in the ai space that are concerned about the ai arms race that as opposed to the united states becoming having the best technology and therefore keeping us safe even we lose ability to keep control of it so this the ai arms race getting away from all of us humans so do you share this worry do you share this concern when were talking about military applications that too much control and decision making capabilities giving to software or ai well i dont see it happening today and in fact this is something from a policy perspective its obviously a very dynamic space but the department of defense has put quite a bit of thought into that and maybe before talking about the policy ill just talk about some of the why and you alluded to it being a sort of a complicated and a little bit scary world out there but theres some big things happening today you hear a lot of talk now about a return to great powers competition particularly around china and russia with the us but there are some other big players out there as well and what weve seen is the deployment of some very id say concerning new weapon systems particularly with russia and breaching some of the irbm intermediate range ballistic missile treaties thats been in the news a lot the building of islands artificial islands in the south china sea by the chinese and then arming those islands the annexation of crimea by russia the invasion of ukraine so theres some pretty scary things and then you add on top of that the north korean threat has certainly not gone away theres a lot going on in the middle east with iran in particular and we see this global terrorism threat has not abated so there are a lot of reasons to look for technology to assist with those problems whether its ai or other technologies like hypersonics which we discussed so now let me give just a couple of hypotheticals so people react sort of in the second timeframe right photon hitting your eye to movement is on the order of a few tenths of a second kinds of processing time roughly speaking computers are operating in the nanosecond timescale right so just to bring home what that means a nanosecond to a second is like a second to 32 years so seconds on the battlefield in that sense literally are lifetimes and so if you can bring an autonomous or ai enabled capability that will enable the human to shrink maybe youve heard the term the ooda loop so this whole idea that a typical battlefield decision is characterized by observe so information comes in orient how does that what does that mean in the context decide what do i do about it and then act take that action if you can use these capabilities to compress that ooda loop to stay inside what your adversary is doing thats an incredible powerful force on the battlefield thats a really nice way to put it that the role of ai and computing in general has a lot to benefit from just decreasing from 32 years to one second as opposed to on the scale of seconds and minutes and hours making decisions that humans are better at making and it actually goes the other way too so thats on the short timescale so humans kind of work in the one second two seconds to eight hours after eight hours you get tired you gotta go to the bathroom whatever the case might be so theres this whole range of other things think about surveillance and guarding facilities think about moving material logistics sustainment a lot of these what they call dull dirty and dangerous things that you need to have sustained activity but its sort of beyond the length of time that a human can practically do as well so theres this range of things that are critical in military and defense applications that ai and autonomy are particularly well suited to now the interesting question that you brought up is okay how do you make sure that stays within human control so that was the context for now the policy and so there is a dod directive called 300009 because thats the way we name stuff in this world but id say its well worth reading its only a couple of pages long but it makes some key points and its really around making sure that theres human agency and control over use of semi autonomous and autonomous weapons systems making sure that these systems are tested verified and evaluated in realistic real world type scenarios making sure that the people are actually trained on how to use them making sure that the systems have human machine interfaces that can show what state theyre in and what kinds of decisions theyre making making sure that youve established doctrine and tactics and techniques and procedures for the use of these kinds of systems and so and by the way i mean none of this is easy but im just trying to lay kind of the picture of how the us has said this is the way were gonna treat ai and autonomous systems that its not a free for all and like there are rules of war and rules of engagement with other kinds of systems think chemical weapons biological weapons we need to think about the same sorts of implications and this is something thats really important for lockheed martin i mean obviously we are a hundred percent complying with our customer and the policies and regulations but i mean ai is an incredible enabler say within the walls of lockheed martin in terms of improving production efficiency doing helping engineers doing generative design improving logistics driving down energy costs i mean there are so many applications but were also very interested in some of the elements of ethical application within lockheed martin so we need to make sure that things like privacy is taken care of that we do everything we can to drive out bias in ai enabled kinds of systems that we make sure that humans are involved in decisions that were not just delegating accountability to algorithms and so for us it all comes back i talked about culture before and it comes back to sort of the lockheed martin culture and our core values and so its pretty simple for us and do whats right respect others perform with excellence and now how do we tie that back to the ethical principles will govern how ai is used within lockheed martin and we actually have a world pretty so you might not know this but there are actually awards for ethics programs lockheed martins had a recognized ethics program for many years and this is one of the things that our ethics team is working with our engineering team on one of the miracles to me perhaps a layman again i was born in the soviet union so i have echoes at least in my family history of world war ii and the cold war do you have a sense of why human civilization has not destroyed itself through nuclear war so nuclear deterrence and thinking about the future does this technology have a role to play here and what is the long term future of nuclear deterrence look like yeah this is one of those hard hard questions and i should note that lockheed martin is both proud and privileged to play a part in multiple legs of our nuclear and strategic deterrent systems like the trident submarine launch ballistic missiles you talk about is there still a possibility that the human race could destroy itself id say that possibility is real but interestingly in some sense i think the strategic deterrence have prevented', 'the following is a conversation with pamela mccordick shes an author who has written on the history and the philosophical significance of artificial intelligence her books include machines who think in 1979 the fifth generation in 1983 with ed feigenbaum whos considered to be the father of expert systems the edge of chaos that features women and many more books i came across her work in an unusual way by stumbling in a quote from machines who think that is something like artificial intelligence began with the ancient wish to forge the gods that was a beautiful way to draw a connecting line between our societal relationship with ai from the grounded day to day science math and engineering to popular stories and science fiction and myths of automatons that go back for centuries through her literary work she has spent a lot of time with the seminal figures of artificial intelligence including the founding fathers of ai from the 1956 dartmouth summer workshop where the field was launched i reached out to pamela for a conversation in hopes of getting a sense of what those early days were like and how their dreams continue to reverberate through the work of our community today i often dont know where the conversation may take us but i jump in and see having no constraints rules or goals is a wonderful way to discover new ideas this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with pamela mccordick in 1979 your book machines who think was published in it you interview some of the early ai pioneers and explore the idea that ai was born not out of maybe math and computer science but out of myth and legend so tell me if you could the story of how you first arrived at the book the journey of beginning to write it i had been a novelist id published two novels and i was sitting under the portal at stanford one day the house we were renting for the summer and i thought i should write a novel about these weird people in ai i know and then i thought ah dont write a novel write a history simple just go around interview them splice it together voila instant book ha ha ha it was much harder than that but nobody else was doing it and so i thought well this is a great opportunity and there were people who john mccarthy for example thought it was a nutty idea the field had not evolved yet so on and he had some mathematical thing he thought i should write instead and i said no john i am not a woman in search of a project this is what i want to do i hope youll cooperate and he said oh mutter mutter well okay its your time what was the pitch for the i mean such a young field at that point how do you write a personal history of a field thats so young i said this is wonderful the founders of the field are alive and kicking and able to talk about what theyre doing did they sound or feel like founders at the time did they know that they have founded something oh yeah they knew what they were doing was very important very what i now see in retrospect is that they were at the height of their research careers and its humbling to me that they took time out from all the things that they had to do as a consequence of being there and to talk to this woman who said i think im going to write a book about you no it was amazing just amazing so who stands out to you maybe looking 63 years ago the dartmouth conference so marvin minsky was there mccarthy was there claude shannon alan newell herb simon some of the folks youve mentioned then theres other characters right one of your coauthors he wasnt at dartmouth he wasnt at dartmouth no he was i think an undergraduate then and of course joe traub all of these are players not at dartmouth but in that era right cmu and so on so who are the characters if you could paint a picture that stand out to you from memory those people youve interviewed and maybe not people that were just in the in the atmosphere in the atmosphere of course the four founding fathers were extraordinary guys they really were who are the founding fathers alan newell herbert simon marvin minsky john mccarthy they were the four who were not only at the dartmouth conference but newell and simon arrived there with a working program called the logic theorist everybody else had great ideas about how they might do it but but they werent going to do it yet and you mentioned joe traub my husband i was immersed in ai before i met joe because i had been ed feigenbaums assistant at stanford and before that i had worked on a book edited by feigenbaum and julian feldman called computers and thought it was the first textbook of readings of ai and they only did it because they were trying to teach ai to people at berkeley and there was nothing youd have to send them to this journal and that journal this was not the internet where you could go look at an article so i was fascinated from the get go by ai i was an english major what did i know and yet i was fascinated and thats why you saw that historical that literary background which i think is very much a part of the continuum of ai that ai grew out of that same impulse that traditional what was what drew you to ai how did you even think of it back then what was the possibilities the dreams what was interesting to you the idea of intelligence outside the human cranium this was a phenomenal idea and even when i finished machines who think i didnt know if they were going to succeed in fact the final chapter is very wishy washy frankly succeed the field did yeah so was there the idea that ai began with the wish to forge the gods so the spiritual component that we crave to create this other thing greater than ourselves for those guys i dont think so newell and simon were cognitive psychologists what they wanted was to simulate aspects of human intelligence and they found they could do it on the computer minsky just thought it was a really cool thing to do likewise mccarthy mccarthy had got the idea in 1949 when he was a caltech student and he listened to somebodys lecture its in my book i forget who it was and he thought oh that would be fun to do how do we do that and he took a very mathematical approach minsky was hybrid and newell and simon were very much cognitive psychology how can we simulate various things about human cognition what happened over the many years is of course our definition of intelligence expanded tremendously these days biologists are comfortable talking about the intelligence of the cell the intelligence of the brain not just human brain but the intelligence of any kind of brain cephalopods i mean an octopus is really intelligent by any amount we wouldnt have thought of that in the 60s even the 70s so all these things have worked in and i did hear one behavioral primatologist franz de waal say ai taught us the questions to ask yeah this is what happens right when you try to build it is when you start to actually ask questions it puts a mirror to ourselves yeah right so you were there in the middle of it it seems like not many people were asking the questions that you were or just trying to look at this field the way you were i was so low when i went to get funding for this because i needed somebody to transcribe the interviews and i needed travel expenses i went to everything you could think of the nsf the darpa there was an air force place that doled out money and each of them said well thats a very interesting idea but well think about it and the national science foundation actually said to me in plain english hey youre only a writer youre not a historian of science and i said yeah thats true but the historians of science will be crawling all over this field im writing for the general audience so i thought and they still wouldnt budge i finally got a private grant without knowing who it was from from ed fredkin at mit he was a wealthy man and he liked what he called crackpot ideas and he considered this a crackpot idea and he was willing to support it i am ever grateful let me say that some would say that a history of science approach to ai or even just a history or anything like the book that youve written hasnt been written since maybe im not familiar but its certainly not many if we think about bigger than just these couple of decades few decades what are the roots of ai oh they go back so far yes of course theres all the legendary stuff the golem and the early robots of the 20th century but they go back much further than that if you read homer homer has robots in the iliad and a classical scholar was pointing out to me just a few months ago well you said you just read the odyssey the odyssey is full of robots it is i said yeah how do you think odysseuss ship gets from one place to another he doesnt have the crew people to do that the crewmen yeah its magic its robots oh i thought how interesting so weve had this notion of ai for a long time and then toward the end of the 19th century the beginning of the 20th century there were scientists who actually tried to make this happen some way or another not successfully they didnt have the technology for it and of course babbage in the 1850s and 60s he saw that what he was building was capable of intelligent behavior and when he ran out of funding the british government finally said thats enough he and lady lovelace decided oh well why dont we play the ponies with this he had other ideas for raising money too but if we actually reach back once again i think people dont actually really know that robots do appear and ideas of robots you talk about the hellenic and the hebraic points of view oh yes can you tell me about each i defined it this way the hellenic point of view is robots are great they are party help they help this guy hephaestus this god hephaestus in his forge i presume he made them to help him and so on and so forth and they welcome the whole idea of robots the hebraic view has to do with i think its the second commandment thou shalt not make any graven image in other words you better not start imitating humans because thats just forbidden its the second commandment and a lot of the reaction to artificial intelligence has been a sense that this is somehow wicked this is somehow blasphemous we shouldnt be going there now you can say yeah but there are going to be some downsides and i say yes there are but blasphemy is not one of them you know there is a kind of fear that feels to be almost primal is there religious roots to that because so much of our society has religious roots and so there is a feeling of like you said blasphemy of creating the other of creating something you know it doesnt have to be artificial intelligence its creating life in general its the frankenstein idea theres the annotated frankenstein on my coffee table its a tremendous novel it really is just beautifully perceptive yes we do fear this and we have good reason to fear it but because it can get out of hand maybe you can speak to that fear the psychology if youve thought about it you know theres a practical set of fears concerns in the short term you can think if we actually think about artificial intelligence systems you can think about bias of discrimination in algorithms you can think about their social networks have algorithms that recommend the content you see thereby these algorithms control the behavior of the masses theres these concerns but to me it feels like the fear that people have is deeper than that so have you thought about the psychology of it i think in a superficial way i have there is this notion that if we produce a machine that can think it will outthink us and therefore replace us i guess thats a primal fear of almost kind of a kind of mortality so around the time you said you worked at stanford with ed feigenbaum so lets look at that one person throughout his history clearly a key person one of the many in the history of ai how has he changed in general around him how has stanford changed in the last how many years are we talking about here oh since 65 65 so maybe it doesnt have to be about him it could be bigger but because he was a key person in expert systems for example how is that how are these folks who youve interviewed in the 70s 79 changed through the decades in eds case i know him well we are dear friends we see each other every month or so he told me that when machines who think first came out he really thought all the front matter was kind of bologna and 10 years later he said no i see what youre getting at yes this is an impulse that has been a human impulse for thousands of years to create something outside the human cranium that has intelligence i think its very hard when youre down at the algorithmic level and youre just trying to make something work which is hard enough to step back and think of the big picture it reminds me of when i was in santa fe i knew a lot of archaeologists which was a hobby of mine and i would say yeah yeah well you can look at the shards and say oh this came from this tribe and this came from this trade route and so on but what about the big picture and a very distinguished archaeologist said to me they dont think that way no theyre trying to match the shard to where it came from where did the remainder of this corn come from was it grown here was it grown elsewhere and i think this is part of any scientific field youre so busy doing the hard work and it is hard work that you dont step back and say oh well now lets talk about the general meaning of all this yes so none of the even minsky and mccarthy they oh those guys did yeah the founding fathers did early on or later pretty early on but in a different way from how i looked at it the two cognitive psychologists newell and simon they wanted to imagine reforming cognitive psychology so that we would really really understand the brain minsky was more speculative and john mccarthy saw it as i think im doing him right by this he really saw it as a great boon for human beings to have this technology and that was reason enough to do it and he had wonderful wonderful fables about how if you do the mathematics you will see that these things are really good for human beings and if you had a technological objection he had an answer a technological answer but heres how we could get over that and then blah blah blah and one of his favorite things was what he called the literary problem which of course he presented to me several times that is everything in literature there are conventions in literature one of the conventions is that you have a villain and a hero and the hero in most literature is human and the villain in most literature is a machine and he said thats just not the way its going to be but thats the way were used to it so when we tell stories about ai its always with this paradigm i thought yeah hes right looking back the classics rur is certainly the machines trying to overthrow the humans frankenstein is different frankenstein is a creature he never has a name frankenstein of course is the guy who created him the human dr frankenstein this creature wants to be loved wants to be accepted and it is only when frankenstein turns his head in fact runs the other way and the creature is without love that he becomes the monster that he later becomes so whos the villain in frankenstein its unclear right oh it is unclear yeah its really the people who drive him by driving him away they bring out the worst thats right they give him no human solace and he is driven away youre right he becomes at one point the friend of a blind man and he serves this blind man and they become very friendly but when the sighted people of the blind mans family come in ah youve got a monster here so its very didactic in its way and what i didnt know is that mary shelley and percy shelley were great readers of the literature surrounding abolition in the united states the abolition of slavery and they picked that up wholesale you are making monsters of these people because you wont give them the respect and love that they deserve do you have if we get philosophical for a second do you worry that once we create machines that are a little bit more intelligent lets look at roomba the vacuums the cleaner that this darker part of human nature where we abuse the other the somebody whos different will come out i dont worry about it i could imagine it happening but i think that what ai has to offer the human race will be so attractive that people will be won over so you have looked deep into these people had deep conversations and its interesting to get a sense of stories of the way they were thinking and the way it was changed the way your own thinking about ai has changed so you mentioned mccarthy what about the years at cmu carnegie mellon with joe sure joe was not in ai he was in algorithmic complexity was there always a line between ai and computer science for example is ai its own place of outcasts was that the feeling there was a kind of outcast period for ai for instance in 1974 the new field was hardly 10 years old the new field of computer science was asked by the national science foundation i believe but it may have been the national academies i cant remember to tell your fellow scientists where computer science is and what it means and they wanted to leave out ai and they only agreed to put it in because don knuth said hey this is important you cant just leave that out really don dude don knuth yes i talked to him recently too out of all the people yes but you see an ai person couldnt have made that argument he wouldnt have been believed but knuth was believed yes so joe traub worked on the real stuff joe was working on algorithmic complexity but he would say in plain english again and again the smartest people i know are in ai really oh yes no question anyway joe loved these guys what happened was that i guess it was as i started to write machines who think herb simon and i became very close friends he would walk past our house on northumberland street every day after work and i would just be putting my cover on my typewriter and i would lean out the door and say herb would you like a sherry and herb almost always would like a sherry so hed stop in and wed talk for an hour two hours my journal says we talked this afternoon for three hours what was on his mind at the time in terms of on the ai side of things oh we didnt talk too much about ai we talked about other things just life we both love literature and herb had read proust in the original french twice all the way through i cant ive read it in english in translation so we talked about literature we talked about languages we talked about music because he loved music we talked about art because he was actually enough of a painter that he had to give it up because he was afraid it was interfering with his research and so on so no it was really just chat chat but it was very warm so one summer i said to herb my students have all the really interesting conversations i was teaching at the university of pittsburgh then in the english department they get to talk about the meaning of life and that kind of thing and what do i have i have university meetings where we talk about the photocopying budget and whether the course on romantic poetry should be one semester or two so herb laughed he said yes i know what you mean he said but you could do something about that dot that was his wife dot and i used to have a salon at the university of chicago every sunday night and we would have essentially an open house and people knew it wasnt for a small talk it was really for some topic of depth he said but my advice would be that you choose the topic ahead of time fine i said so we exchanged mail over the summer that was us post in those days because you didnt have personal email and i decided i would organize it and there would be eight of us alan noland his wife herb simon and his wife dorothea there was a novelist in town a man named mark harris he had just arrived and his wife josephine mark was most famous then for a novel called bang the drum slowly which was about baseball and joe and me so eight people and we met monthly and we just sank our teeth into really hard topics and it was great fun tk how have your own views around artificial intelligence changed through the process of writing machines who think and afterwards the ripple effects rl i was a little skeptical that this whole thing would work out it didnt matter to me it was so audacious ai generally and in some ways it hasnt worked out the way i expected so far that is to say theres this wonderful lot of apps thanks to deep learning and so on but those are algorithmic and in the part of symbolic processing theres very little yet and thats a field that lies waiting for industrious graduate students tk maybe you can tell me some figures that popped up in your life in the 80s with expert systems where there was the symbolic ai possibilities of what most people think of as ai if you dream of the possibilities of ai its really expert systems and those hit a few walls and there was challenges there and i think yes they will reemerge again with some new breakthroughs and so on but what did that feel like both the possibility and the winter that followed the slowdown in research bg ah you know this whole thing about ai winter is to me a crock tk snow winters bg because i look at the basic research that was being done in the 80s which is supposed to be my god it was really important it was laying down things that nobody had thought about before but it was basic research you couldnt monetize it hence the winter tk thats the winter bg you know research scientific research goes and fits and starts it isnt this nice smooth oh this follows this follows this no it just doesnt work that way tk the interesting thing the way winters happen its never the fault of the researchers its the some source of hype over promising well no let me take that back sometimes it is the fault of the researchers sometimes certain researchers might over promise the possibilities they themselves believe that were just a few years away sort of just recently talked to elon musk and he believes hell have an autonomous vehicle will have autonomous vehicles in a year and he believes it bg a year tk a year yeah with mass deployment of a time bg for the record this is 2019 right now so hes talking 2020 tk to do the impossible you really have to believe it and i think whats going to happen when you believe it because theres a lot of really brilliant people around him is some good stuff will come out of it some unexpected brilliant breakthroughs will come out of it when you really believe it when you work that hard bg i believe that and i believe autonomous vehicles will come i just dont believe itll be in a year i wish tk but nevertheless theres autonomous vehicles is a good example theres a feeling many companies have promised by 2021 by 2022 ford gm basically every single automotive company has promised theyll have autonomous vehicles so that kind of over promise is what leads to the winter because well come to those dates there wont be autonomous vehicles bg and therell be a feeling well wait a minute if we took your word at that time that means we just spent billions of dollars had made no money and theres a counter response to where everybody gives up on it sort of intellectually at every level the hope just dies and all thats left is a few basic researchers so youre uncomfortable with some aspects of this idea tk well its the difference between science and commerce bg so you think science goes on the way it does tk oh science can really be killed by not getting proper funding or timely funding i think great britain was a perfect example of that the lighthill report in i cant remember the year essentially said theres no use great britain putting any money into this its going nowhere and this was all about social factions in great britain edinburgh hated cambridge and cambridge hated manchester somebody else can write that story but it really did have a hard effect on research there now theyve come roaring back with deep mind but thats one guy and his visionaries around him bg but just to push on that its kind of interesting you have this dislike of the idea of an ai winter wheres that coming from where were you tk oh because i just dont think its true bg there was a particular period of time its a romantic notion certainly tk yeah well no i admire science perhaps more than i admire commerce commerce is fine hey you know we all gotta live but science has a much longer view than commerce and continues almost regardless it cant continue totally regardless but almost regardless of whats saleable and whats not whats monetizable and whats not bg so the winter is just something that happens on the commerce side and the science marches thats a beautifully optimistic and inspiring message i agree with you i think if we look at the key people that work in ai that work in key scientists in most disciplines they continue working out of the love for science you can always scrape up some funding to stay alive and they continue working diligently but there certainly is a huge amount of funding now and theres a concern on the ai side and deep learning theres a concern that we might with over promising hit another slowdown in funding which does affect the number of students you know that kind of thing rg yeah it does bg so the kind of ideas you had in machines who think did you continue that curiosity through the decades that followed rg yes i did bg and what was your view historical view of how ai community evolved the conversations about it the work has it persisted the same way from its birth rg no of course not its just as we were just talking the symbolic ai really kind of dried up and it all became algorithmic i remember a young ai student telling me what he was doing and i had been away from the field long enough id gotten involved with complexity at the santa fe institute i thought algorithms yeah theyre in the service of but theyre not the main event no they became the main event that surprised me and we all know the downside of this we all know that if youre using an algorithm to make decisions based on a gazillion human decisions baked into it are all the mistakes that humans make the bigotries the short sightedness and so on and so on bg so you mentioned santa fe institute so youve written the novel edge of chaos but its inspired by the ideas of complexity a lot of which have been extensively explored at the santa fe institute its another fascinating topic just sort of emergent complexity from chaos nobody knows how it happens really but it seems to where all the interesting stuff does happen so how did first not your novel but just complexity in general and the work at santa fe fit into the bigger puzzle of the history of ai or maybe even your personal journey through that rg one of the last projects i did concerning ai in particular was looking at the work of harold cohen the painter and harold was deeply involved with ai he was a painter first and what his project arin which was a lifelong project did was reflect his own cognitive processes okay harold and i even though i wrote a book about it we had a lot of friction between us and i went i thought this is it the book died it was published and fell into a ditch this is it im finished its time for me to do something different by chance this was a sabbatical year for my husband and we spent two months at the santa fe institute and two months at caltech and then the spring semester in munich germany okay those two months at the santa fe institute were so restorative for me and i began to the institute was very small then it was in some kind of office complex on old santa fe trail everybody kept their door open so you could crack your head on a problem and if you finally didnt get it you could walk in to see stuart kaufman or any number of people and say i dont get this can you explain and one of the people that i was talking to about complex adaptive systems was murray gelman and i told murray what harold cohen had done and i said you know this sounds to me like a complex adaptive system and he said yeah it is well what do you know harold aaron had all these kids and cousins all over the world in science and in economics and so on and so forth i was so relieved i thought okay your instincts are okay youre doing the right thing i didnt have the vocabulary and that was one of the things that the santa fe institute gave me if i could have rewritten that book no it had just come out i couldnt rewrite it i would have had a vocabulary to explain what aaron was doing okay so i got really interested in what was going on at the institute the people were again bright and funny and willing to explain anything to this amateur george cowan who was then the head of the institute said he thought it might be a nice idea if i wrote a book about the institute and i thought about it and i had my eye on some other project god knows what and i said im sorry george yeah id really love to do it but just not going to work for me at this moment he said oh too bad i think it would make an interesting book well he was right and i was wrong i wish id done it but thats interesting i hadnt thought about that that that was a road not taken that i wish id taken well you know what just on that point its quite brave for you as a writer as sort of coming from a world of literature and the literary thinking and historical thinking i mean just from that world and bravely talking to quite i assume large egos in ai or in complexity yeah in ai or in complexity and so on howd you do it i mean i suppose they could be intimidated of you as well because its two different worlds coming together i never picked up that anybody was intimidated by me but how were you brave enough where did you find the guts to sort of god just dumb luck i mean this is an interesting rock to turn over im going to write a book about it and you know people have enough patience with writers if they think theyre going to end up in a book that they let you flail around and so on well but they also look if the writer has if theres a sparkle in their eye if they get it yeah sure when were you at the santa fe institute the time im talking about is 1990 1991 1992 but we then because joe was an external faculty member were in santa fe every summer we bought a house there and i didnt have that much to do with the institute anymore i was writing my novels i was doing whatever i was doing but i loved the institute and i loved again the audacity of the ideas that really appeals to me i think that theres this feeling much like in great institutes of neuroscience for example that theyre in it for the long game of understanding something fundamental about reality and nature and thats really exciting so if we start now to look a little bit more recently how you know ai is really popular today how is this world you mentioned algorithmic but in general is the spirit of the people the kind of conversations you hear through the grapevine and so on is that different than the roots that you remember no the same kind of excitement the same kind of this is really going to make a difference in the world and it will it has you know a lot of folks especially young 20 years old or something they think weve just found something special here were going to change the world tomorrow on a time scale do you have a sense of what of the time scale at which breakthroughs of the time scale at which breakthroughs in ai happen i really dont because look at deep learning that was jeffrey hinton came up with the algorithm in 86 but it took all these years for the technology to be good enough to actually be applicable so no i cant predict that at all i cant i wouldnt even try well let me ask you to not to try to predict but to speak to the you know im sure in the 60s as it continues now theres people that think lets call it we can call it this fun word the singularity when theres a phase shift theres some profound feeling where were all really surprised by whats able to be achieved im sure those dreams are there i remember reading quotes in the 60s and those continued how have your own views maybe if you look back about the timeline of a singularity changed well im not a big fan of the singularity as ray kurzweil has presented it how would you define the ray kurzweil how do you think of singularity in those if i understand kurzweils view its sort of theres going to be this moment when machines are smarter than humans and you know game over however the game over is i mean do they put us on a reservation do they et cetera et cetera and first of all machines are smarter than humans in some ways all over the place and they have been since adding machines were invented so its not its not going to come like some great eatable crossroads you know where they meet each other and our offspring oedipus says youre dead its just not going to happen yeah so its already game over with calculators right theyre already out to do much better at basic arithmetic than us but you know theres a human like intelligence and its not the ones that destroy us but you know somebody that you can have as a as a friend you can have deep connections with that kind of passing the touring test and beyond those kinds of ideas have you dreamt of those oh yes yes yes those possibilities in a book i wrote with ed feigenbaum a book i wrote with ed feigenbaum theres a little story called the geriatric robot and how i came up with the geriatric robot is a story in itself but heres what the geriatric robot does it doesnt just clean you up and feed you and wheel you out into the sun its great advantages it listens it says tell me again about the great coup of 73 tell me again about how awful or how wonderful your grandchildren are and so on and so forth and it isnt hanging around to inherit your money it isnt hanging around because it cant get any other job this is his job and so on and so forth well i would love something like that yeah i mean for me that deeply excites me so i think theres a lot of us lex you gotta know it was a joke i dreamed it up because i needed to talk to college students and i needed to give them some idea of what ai might be and they were rolling in the aisles as i elaborated and elaborated and elaborated when it went into the book they took my hide off in the new york review of books this is just what we have thought about these people in ai theyre inhuman come on get over it dont you think thats a good thing for the world that ai could potentially do i do absolutely and furthermore im pushing 80 now by the time i need help like that i also want it to roll itself in a corner and shut the fuck up let me linger on that point do you really though yeah i do heres why dont you want it to push back a little bit a little but i have watched my friends go through the whole issue around having help in the house and some of them have been very lucky and had fabulous help and some of them have had people in the house who want to keep the television going on all day who want to talk on their phones all day no just roll yourself in the corner and shut the fuck up unfortunately us humans when were assistants were still even when were assisting others we care about ourselves more of course and so you create more frustration and a robot ai assistant can really optimize the experience for you i was just speaking to the point you actually bring up a very very good point but i was speaking to the fact that us humans are a little complicated that we dont necessarily want a perfect servant i dont maybe you disagree with that but theres a i think theres a push and pull with humans youre right a little tension a little mystery that of course thats really difficult for ai to get right but i do sense especially today with social media that people are getting more and more lonely even young folks and sometimes especially young folks that loneliness theres a longing for connection and ai can help alleviate some of that loneliness some just somebody who listens like in person so to speak so to speak yeah so to speak yeah that to me is really exciting that is really exciting but so if we look at that that level of intelligence which is exceptionally difficult to achieve actually as the singularity or whatever thats the human level bar that people have dreamt of that too turing dreamt of it he had a date timeline do you have how have your own timeline evolved on past i dont even think about it you dont even think no just this field has been so full of surprises for me youre just taking in and see the fun about the basic science yeah i just cant maybe thats because ive been around the field long enough to think you know dont go that way herb simon was terrible about making these predictions of when this and that would happen and he was a sensible guy his quotes are often used right as a legend yeah yeah do you have concerns about ai the existential threats that many people like elon musk and sam harris and others are thinking about yeah that takes up half a chapter in my book i call it the male gaze well you hear me out the male gaze is actually a term from film criticism and im blocking on the women who dreamed this up but she pointed out how most movies were made from the male point of view that women were objects not subjects they didnt have any agency and so on and so forth so when elon and his pals hawking and so on came ai is going to eat our lunch and our dinner and our midnight snack too i thought what and i said to ed feigenbaum oh this is the first guy first these guys have always been the smartest guy on the block and here comes something that might be smarter oh lets stamp it out before it takes over and ed laughed he said i didnt think about it that way but i did i did and it is the male gaze okay suppose these things do have agency well lets wait and see what happens can we imbue them with ethics can we imbue them with a sense of empathy or are they just going to be i dont know weve had centuries of guys like that thats interesting that the ego the male gaze is immediately threatened and so you cant think in a patient calm way of how the tech could evolve speaking of which your 96 book the future of women i think at the time and now certainly now i mean im sorry maybe at the time but im more cognizant of now is extremely relevant you and nancy ramsey talk about four possible futures of women in science and tech so if we look at the decades before and after the book was released can you tell a history sorry of women in science and tech and how it has evolved how have things changed where do we stand not enough they have not changed enough the way that women are ground down in computing is simply unbelievable but what are the four possible futures for women in tech from the book what youre really looking at are various aspects of the present so for each of those you could say oh yeah we do have backlash look at whats happening with abortion and so on and so forth we have one step forward one step back the golden age of equality was the hardest chapter to write and i used something from the santa fe institute which is the sandpile effect that you drop sand very slowly onto a pile and it grows and it grows and it grows until suddenly it just breaks apart and in a way me too has done that that was the last drop of sand that broke everything apart that was a perfect example of the sandpile effect and that made me feel good it didnt change all of society but it really woke a lot of people up but are you in general optimistic about maybe after me too i mean me too is about a very specific kind of thing boy solve that and you solve everything but are you in general optimistic about the future yes im a congenital optimistic i cant help it what about ai what are your thoughts about the future of ai of course i get asked what do you worry about and the one thing i worry about is the things we cant anticipate theres going to be something out of left field that we will just say we werent prepared for that i am generally optimistic when i first took up being interested in ai like most people in the field more intelligence was like more virtue you know what could be bad and in a way i still believe that but i realize that my notion of intelligence has broadened there are many kinds of intelligence and we need to imbue our machines with those many kinds so youve now just finished or in the process of finishing the book that youve been working on the memoir how have you changed i know its just writing but how have you changed the process if you look back what kind of stuff did it bring up to you that surprised you looking at the entirety of it all the biggest thing and it really wasnt a surprise is how lucky i was oh my to have access to the beginning of a scientific field that is going to change the world how did i luck out and yes of course my view of things has widened a lot if i can get back to one feminist part of our conversation without knowing it it really was subconscious i wanted ai to succeed because i was so tired of hearing that intelligence was inside the male cranium and i thought if there was something out there that wasnt a male thinking and doing well then that would put a lie to this whole notion of intelligence resides in the male cranium i did not know that until one night harold cohen and i were having a glass of wine maybe two and he said what drew you to ai and i said oh you know smartest people i knew great project blah blah blah and i said and i wanted something besides male smarts and it just bubbled up out of me like what its kind of brilliant actually so ai really humbles all of us and humbles the people that need to be humbled the most lets hope wow that is so beautiful pamela thank you so much for talking to me its really a huge honor its been a great pleasure thank you', 'the following is a conversation with jeremy howard hes the founder of fastai a research institute dedicated to making deep learning more accessible hes also a distinguished research scientist at the university of san francisco a former president of kaggle as well as a top ranking competitor there and in general hes a successful entrepreneur educator researcher and an inspiring personality in the ai community when someone asks me how do i get started with deep learning fastai is one of the top places that point them to its free its easy to get started its insightful and accessible and if i may say so it has very little bs that can sometimes dilute the value of educational content on popular topics like deep learning fastai has a focus on practical application of deep learning and hands on exploration of the cutting edge that is incredibly both accessible to beginners and useful to experts this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with jeremy howard whats the first program you ever written first program i wrote that i remember would be at high school i did an assignment where i decided to try to find out if there were some better musical scales than the normal 12 tone 12 interval scale so i wrote a program on my commodore 64 in basic that searched through other scale sizes to see if it could find one where there were more accurate harmonies like mid tone like you want an actual exactly three to two ratio or else with a 12 interval scale its not exactly three to two for example so thats well tempered as they say in there and basic on a commodore 64 where was the interest in music from or is it just technical i did music all my life so i played saxophone and clarinet and piano and guitar and drums and whatever how does that thread go through your life wheres music today its not where i wish it was for various reasons couldnt really keep it going particularly because i had a lot of problems with rsi with my fingers and so i had to kind of like cut back anything that used hands and fingers i hope one day ill be able to get back to it health wise so theres a love for music underlying it all yeah whats your favorite instrument saxophone sax or baritone saxophone well probably bass saxophone but theyre awkward well i always love it when music is coupled with programming theres something about a brain that utilizes those that emerges with creative ideas so youve used and studied quite a few programming languages can you give an overview of what youve used what are the pros and cons of each well my favorite programming environment well most certainly was microsoft access back in like the earliest days so that was visual basic for applications which is not a good programming language but the programming environment was fantastic its like the ability to create you know user interfaces and tie data and actions to them and create reports and all that as ive never seen anything as good theres things nowadays like airtable which are like small subsets of that which people love for good reason but unfortunately nobodys ever achieved anything like that what is that if you could pause on that for a second oh access is it a database it was a database program that microsoft produced part of office and they kind of withered you know but basically it lets you in a totally graphical way create tables and relationships and queries and tie them to forms and set up you know event handlers and calculations and it was a very complete powerful system designed for not massive scalable things but for like useful little applications that i loved so whats the connection between excel and access so very close so access kind of was the relational database equivalent if you like so people still do a lot of that stuff that should be in access in excel as they know it excels great as well so but its just not as rich a programming model as vba combined with a relational database and so ive always loved relational databases but today programming on top of relational database is just a lot more of a headache you know you generally either need to kind of you know you need something that connects that runs some kind of database server unless you use sqlite which has its own issues then you kind of often if you want to get a nice programming model youll need to like create an add an orm on top and then i dont know theres all these pieces to tie together and its just a lot more awkward than it should be there are people that are trying to make it easier so in particular i think of f sharp you know don syme who him and his team have done a great job of making something like a database appear in the type system so you actually get like tab completion for fields and tables and stuff like that anyway so that was kind of anyway so like that whole vba office thing i guess was a starting point which i still miss and i got into standard visual basic which thats interesting just to pause on that for a second its interesting that youre connecting programming languages to the ease of management of data yeah so in your use of programming languages you always had a love and a connection with data ive always been interested in doing useful things for myself and for others which generally means getting some data and doing something with it and putting it out there again so thats been my interest throughout so i also did a lot of stuff with applescript back in the early days so its kind of nice being able to get the computer and computers to talk to each other and to do things for you and then i think that one the programming language i most loved then would have been delphi which was object pascal created by anders heilsberg who previously did turbo pascal and then went on to createnet and then went on to create typescript delphi was amazing because it was like a compiled fast language that was as easy to use as visual basic delphi what is it similar to in more modern languages visual basic visual basic yeah but a compiled fast version so im not sure theres anything quite like it anymore if you took like c sharp or java and got rid of the virtual machine and replaced it with something you could compile a small type binary i feel like its where swift could get to with the new swift ui and the cross platform development going on like thats one of my dreams is that well hopefully get back to where delphi was there is actually a free pascal project nowadays called lazarus which is also attempting to kind of recreate delphi so theyre making good progress so okay delphi thats one of your favorite programming languages well its programming environments again id say pascals not a nice language if you wanted to know specifically about what languages i like i would definitely pick j as being an amazingly wonderful language whats j j are you aware of apl i am not except from doing a little research on the work youve done okay so not at all surprising youre not familiar with it because its not well known but its actually one of the main families of programming languages going back to the late 50s early 60s so there was a couple of major directions one was the kind of lambda calculus alonzo church direction which i guess kind of lisp and scheme and whatever which has a history going back to the early days of computing the second was the kind of imperative slash oo algo similar going on to c c and so forth there was a third which are called array oriented languages which started with a paper by a guy called ken iverson which was actually a math theory paper not a programming paper it was called notation as a tool for thought and it was the development of a new way a new type of math notation and the idea is that this math notation was much more flexible expressive and also well defined than traditional math notation which is none of those things math notation is awful and so he actually turned that into a programming language and cause this was the early 50s or the sorry late 50s all the names were available so he called his language a programming language or apl apl so apl is a implementation of notation as a tool for thought by which he means math notation and ken and his son went on to do many things but eventually they actually produced a new language that was built on top of all the learnings of apl and that was called j and j is the most expressive composable language of beautifully designed language ive ever seen does it have object oriented components does it have that kind of thing not really its an array oriented language its the third path are you saying array array oriented yeah what does it mean to be array oriented so array oriented means that you generally dont use any loops but the whole thing is done with kind of a extreme version of broadcasting if youre familiar with that numpy slash python concept so you do a lot with one line of code it looks a lot like math notation highly compact and the idea is that you can kind of because you can do so much with one line of code a single screen of code is very unlikely to you very rarely need more than that to express your program and so you can kind of keep it all in your head and you can kind of clearly communicate it its interesting that apl created two main branches k and j j is this kind of like open source niche community of crazy enthusiasts like me and then the other path k was fascinating its an astonishingly expensive programming language which many of the worlds most ludicrously rich hedge funds use so the entire k machine is so small it sits inside level three cache on your cpu and it easily wins every benchmark ive ever seen in terms of data processing speed but you dont come across it very much because its like 100000 per cpu to run it its like this path of programming languages is just so much i dont know so much more powerful in every way than the ones that almost anybody uses every day so its all about computation its really focused on computation its pretty heavily focused on computation i mean so much of programming is data processing by definition so theres a lot of things you can do with it but yeah theres not much work being done on making like user interface toolkits or whatever i mean theres some but theyre not great at the same time youve done a lot of stuff with perl and python so where does that fit into the picture of j and k and apl well its just much more pragmatic like in the end you kind of have to end up where the libraries are you know like cause to me my focus is on productivity i just want to get stuff done and solve problems so perl was great i created an email company called fastmail and perl was great cause back in the late nineties early two thousands it just had a lot of stuff it could do i still had to write my own monitoring system and my own web framework my own whatever cause like none of that stuff existed but it was a super flexible language to do that in and you used perl for fastmail you used it as a backend like so everything was written in perl yeah yeah everything everything was perl why do you think perl hasnt succeeded or hasnt dominated the market where python really takes over a lot of the tasks well i mean perl did dominate it was everything everywhere but then the guy that ran perl larry wohl kind of just didnt put the time in anymore and no project can be successful if there isnt you know particularly one that started with a strong leader that loses that strong leadership so then python has kind of replaced it you know python is a lot less elegant language in nearly every way but it has the data science libraries and a lot of them are pretty great so i kind of use it cause its the best we have but its definitely not good enough but what do you think the future of programming looks like what do you hope the future of programming looks like if we zoom in on the computational fields on data science on machine learning i hope swift is successful because the goal of swift the way chris latner describes it is to be infinitely hackable and thats what i want i want something where me and the people i do research with and my students can look at and change everything from top to bottom theres nothing mysterious and magical and inaccessible unfortunately with python its the opposite of that because python is so slow its extremely unhackable you get to a point where its like okay from here on down at c so your debugger doesnt work in the same way your profiler doesnt work in the same way your build system doesnt work in the same way its really not very hackable at all whats the part you like to be hackable is it for the objective of optimizing training of neural networks inference of neural networks is it performance of the system or is there some non performance related just its everything i mean in the end i want to be productive as a practitioner so that means that so like at the moment our understanding of deep learning is incredibly primitive theres very little we understand most things dont work very well even though it works better than anything else out there theres so many opportunities to make it better so you look at any domain area like i dont know speech recognition with deep learning or natural language processing classification with deep learning or whatever every time i look at an area with deep learning i always see like oh its terrible theres lots and lots of obviously stupid ways to do things that need to be fixed so then i want to be able to jump in there and quickly experiment and make them better you think the programming language has a role in that huge role yeah so currently python has a big gap in terms of our ability to innovate particularly around recurrent neural networks and natural language processing because its so slow the actual loop where we actually loop through words we have to do that whole thing in cuda c so we actually cant innovate with the kernel the heart of that most important algorithm and its just a huge problem and this happens all over the place so we hit research limitations another example convolutional neural networks which are actually the most popular architecture for lots of things maybe most things in deep learning we almost certainly should be using sparse convolutional neural networks but only like two people are because to do it you have to rewrite all of that cuda c level stuff and yeah just researchers and practitioners dont so theres just big gaps in what people actually research on what people actually implement because of the programming language problem so you think its just too difficult to write in cuda c that a higher level programming language like swift should enable the easier fooling around creative stuff with rnns or with sparse convolutional neural networks kind of whos at fault whos at charge of making it easy for a researcher to play around i mean no ones at fault just nobodys got around to it yet or its just its hard right and i mean part of the fault is that we ignored that whole apl kind of direction nearly everybody did for 60 years 50 years but recently people have been starting to reinvent pieces of that and kind of create some interesting new directions in the compiler technology so the place where thats particularly happening right now is something called mlir which is something that again chris latina the swift guy is leading and yeah because its actually not gonna be swift on its own that solves this problem because the problem is that currently writing a acceptably fast you know gpu program is too complicated regardless of what language you use right and thats just because if you have to deal with the fact that ive got you know 10000 threads and i have to synchronize between them all and i have to put my thing into grid blocks and think about warps and all this stuff its just so much boilerplate that to do that well you have to be a specialist at that and its gonna be a years work to you know optimize that algorithm in that way but with things like tensor comprehensions i just saw a subatomic particle do something which the theory doesnt explain you could publish that without an explanation and then in the next 60 years people can try to work out how to explain it we dont allow this in the deep learning world so its literally impossible for leslie to publish a paper that says ive just seen something amazing happen this thing trained 10 times faster than it should have i dont know why and so the reviewers were like well you cant publish that because you dont know why so anyway thats important to pause on because theres so many discoveries that would need to start like that every other scientific field i know of works that way i dont know why ours is uniquely disinterested in publishing unexplained experimental results but there it is so it wasnt published having said that i read a lot more unpublished papers than published papers because thats where you find the interesting insights so i absolutely read this paper and i was just like this is astonishingly mind blowing and weird and awesome and like why isnt everybody only talking about this because like if you can train these things 10 times faster they also generalize better because youre doing less epochs which means you look at the data less you get better accuracy so ive been kind of studying that ever since and eventually leslie kind of figured out a lot of how to get this done and we added minor tweaks and a big part of the trick is starting at a very low learning rate very gradually increasing it so as youre training your model you would take very small steps at the start and you gradually make them bigger and bigger until eventually youre taking much bigger steps than anybody thought was possible theres a few other little tricks to make it work but basically we can reliably get super convergence and so for the dawn bench thing we were using just much higher learning rates than people expected to work what do you think the future of i mean it makes so much sense for that to be a critical hyperparameter learning rate that you vary what do you think the future of learning rate magic looks like well theres been a lot of great work in the last 12 months in this area and people are increasingly realizing that optimize like we just have no idea really how optimizers work and the combination of weight decay which is how we regularize optimizers and the learning rate and then other things like the epsilon we use in the adam optimizer they all work together in weird ways and different parts of the model this is another thing weve done a lot of work on is research into how different parts of the model should be trained at different rates in different ways so we do something we call discriminative learning rates which is really important particularly for transfer learning so really i think in the last 12 months a lot of people have realized that all this stuff is important theres been a lot of great work coming out and were starting to see algorithms appear which have very very few dials if any that you have to touch so i think whats gonna happen is the idea of a learning rate well it almost already has disappeared in the latest research and instead its just like we know enough about how to interpret the gradients and the change of gradients we see to know how to set every parameter in an optimal way so you see the future of deep learning where really wheres the input of a human expert needed well hopefully the input of a human expert will be almost entirely unneeded from the deep learning point of view so again like googles approach to this is to try and use thousands of times more compute to run lots and lots of models at the same time and hope that one of them is good automl kind of thing yeah automl kind of stuff which i think is insane when you better understand the mechanics of how models learn you dont have to try a thousand different models to find which one happens to work the best you can just jump straight to the best one which means that its more accessible in terms of compute cheaper and also with less hyperparameters to set it means you dont need deep learning experts to train your deep learning model for you which means that domain experts can do more of the work which means that now you can focus the human time on the kind of interpretation the data gathering identifying model errors and stuff like that yeah the data side how often do you work with data these days in terms of the cleaning looking at it like darwin looked at different species while traveling about do you look at data have you in your roots in kaggle always yeah look at data yeah i mean its a key part of our course its like before we train a model in the course we see how to look at the data and then the first thing we do after we train our first model which we fine tune an imagenet model for five minutes and then the thing we immediately do after that is we learn how to analyze the results of the model by looking at examples of misclassified images and looking at a classification matrix and then doing research on google to learn about the kinds of things that its misclassifying so to me one of the really cool things about machine learning models in general is that when you interpret them they tell you about things like what are the most important features which groups are you misclassifying and they help you become a domain expert more quickly because you can focus your time on the bits that the model is telling you is important so it lets you deal with things like data leakage for example if it says oh the main feature im looking at is customer id and youre like oh customer id should be predictive and then you can talk to the people that manage customer ids and theyll tell you like oh yes as soon as a customers application is accepted we add a one on the end of their customer id or something so yeah looking at data particularly from the lens of which parts of the data the model says is important is super important yeah and using the model to almost debug the data to learn more about the data exactly what are the different cloud options for training your own networks last question related to dawnbench well its part of a lot of the work you do but from a perspective of performance i think youve written this in a blog post theres aws theres tpu from google whats your sense what the future holds what would you recommend now in terms of training so from a hardware point of view googles tpus and the best nvidia gpus are similar i mean maybe the tpus are like 30 faster but theyre also much harder to program there isnt a clear leader in terms of hardware right now although much more importantly the nvidia gpus are much more programmable theyve got much more written for all of them so like thats the clear leader for me and where i would spend my time as a researcher and practitioner but then in terms of the platform i mean were super lucky now with stuff like google gcp google cloud and aws that you can access a gpu pretty quickly and easily but i mean for aws its still too hard like you have to find an ami and get the instance running and then install the software you want and blah blah blah gcp is currently the best way to get started on a full server environment because they have a fantastic fast ai in pytorch ready to go instance which has all the courses preinstalled it has jupyter notebook pre running jupyter notebook is this wonderful interactive computing system which everybody basically should be using for any kind of data driven research but then even better than that there are platforms like salamander which we own and paperspace where literally you click a single button and it pops up a jupyter notebook straight away without any kind of installation or anything and all the course notebooks are all preinstalled so like for me this is one of the things we spent a lot of time kind of curating and working on because when we first started our courses the biggest problem was people dropped out of lesson one because they couldnt get an aws instance running so things are so much better now and like we actually have if you go to coursefastai the first thing it says is heres how to get started with your gpu and theres like you just click on the link and you click start and youre going youll go gcp i have to confess ive never used the google gcp yeah gcp gives you 300 of compute for free which is really nice but as i say salamander and paperspace are even easier still okay so from the perspective of deep learning frameworks you work with fastai if you go to this framework and pytorch and tensorflow what are the strengths of each platform in your perspective so in terms of what weve done our research on and taught in our course we started with theano and keras and then we switched to tensorflow and keras and then we switched to pytorch and then we switched to pytorch and fastai and that kind of reflects a growth and development of the ecosystem of deep learning libraries theano and tensorflow were great but were much harder to teach and to do research and development on because they define whats called a computational graph upfront a static graph where you basically have to say here are all the things that im gonna eventually do in my model and then later on you say okay do those things with this data and you cant like debug them you cant do them step by step you cant program them interactively in a jupyter notebook and so forth pytorch was not the first but pytorch was certainly the strongest entrant to come along and say lets not do it that way lets just use normal python and everything you know about in python is just gonna work and well figure out how to make that run on the gpu as and when necessary that turned out to be a huge leap in terms of what we could do with our research and what we could do with our teaching because it wasnt limiting yeah i mean it was critical for us for something like dawnbench to be able to rapidly try things its just so much harder to be a researcher and practitioner when you have to do everything upfront and you cant inspect it problem with pytorch is its not at all accessible to newcomers because you have to like write your own training loop and manage the gradients and all this stuff and its also like not great for researchers because youre spending your time dealing with all this boilerplate and overhead rather than thinking about your algorithm so we ended up writing this very multi layered api that at the top level you can train a state of the art neural network in three lines of code and which kind of talks to an api which talks to an api which talks to an api which like you can dive into at any level and get progressively closer to the machine kind of levels of control and this is the fast ai library thats been critical for us and for our students and for lots of people that have won deep learning competitions with it and written academic papers with it its made a big difference were still limited though by python and particularly this problem with things like recurrent neural nets say where you just cant change things unless you accept it going so slowly that its impractical so in the latest incarnation of the course and with some of the research were now starting to do were starting to do stuff some stuff in swift i think were three years away from that being super practical but im in no hurry im very happy to invest the time to get there but with that we actually already have a nascent version of the fast ai library for vision running on swift and tensorflow cause a python for tensorflow is not gonna cut it its just a disaster what they did was they tried to replicate the bits that people were saying they like about pytorch this kind of interactive computation but they didnt actually change their foundational runtime components so they kind of added this like syntax sugar they call tf eager tensorflow eager which makes it look a lot like pytorch but its 10 times slower than pytorch to actually do a step so because they didnt invest the time in like retooling the foundations cause their code base is so horribly complex yeah i think its probably very difficult to do that kind of retooling yeah well particularly the way tensorflow was written it was written by a lot of people very quickly in a very disorganized way so like when you actually look in the code as i do often im always just like oh god what were they thinking its just its pretty awful so im really extremely negative about the potential future for python for tensorflow but swift for tensorflow can be a different beast altogether it can be like it can basically be a layer on top of mlir that takes advantage of you know all the great compiler stuff that swift builds on with llvm and yeah i think it will be absolutely fantastic well youre inspiring me to try i havent truly felt the pain of tensorflow 20 python its fine by me but of yeah i mean it does the job if youre using like predefined things that somebody has already written but if you actually compare you know like ive had to do cause ive been having to do a lot of stuff with tensorflow recently you actually compare like okay i want to write something from scratch and youre like i just keep finding its like oh its running 10 times slower than pytorch so is the biggest cost lets throw running time out the window how long it takes you to program thats not too different now thanks to tensorflow eager thats not too different but because so many things take so long to run you wouldnt run it at 10 times slower like you just go like oh this is taking too long and also theres a lot of things which are just less programmable like tfdata which is the way data processing works in tensorflow is just this big mess its incredibly inefficient and they kind of had to write it that way because of the tpu problems i described earlier so i just you know i just feel like theyve got this huge technical debt which theyre not going to solve without starting from scratch so heres an interesting question then if theres a new student starting today what would you recommend they use well i mean we obviously recommend fastai and pytorch because we teach new students and thats what we teach with so we would very strongly recommend that because it will let you get on top of the concepts much more quickly so then youll become an actual and youll also learn the actual state of the art techniques you know so you actually get world class results honestly it doesnt much matter what library you learn because switching from the trainer to mxnet to tensorflow to pytorch is gonna be a couple of days work as long as you understand the foundation as well but you think will swift creep in there as a thing that people start using not for a few years particularly because like swift has no data science community libraries schooling and the swift community has a total lack of appreciation and understanding of numeric computing so like they keep on making stupid decisions you know for years theyve just done dumb things around performance and prioritization thats clearly changing now because the developer of swift chris latner is working at google on swift for tensorflow so like thats a priority itll be interesting to see what happens with apple because like apple hasnt shown any sign of caring about numeric programming in swift so i mean hopefully theyll get off their ass and start appreciating this because currently all of their low level libraries are not written in swift theyre not particularly swifty at all stuff like coreml theyre really pretty rubbish so yeah so theres a long way to go but at least one nice thing is that swift for tensorflow can actually directly use python code and python libraries in a literally the entire lesson one notebook of fast ai runs in swift right now in python mode so thats a nice intermediate thing how long does it take if you look at the two fast ai courses how long does it take to get from point zero to completing both courses it varies a lot somewhere between two months and two years generally so for two months how many hours a day on average so like somebody who is a very competent coder can do 70 hours per course and pick up 70 70 seven zero thats it okay but a lot of people i know take a year off to study fast ai full time and say at the end of the year they feel pretty competent because generally theres a lot of other things you do like generally theyll be entering kaggle competitions they might be reading ian goodfellows book they might theyll be doing a bunch of stuff and often particularly if they are a domain expert their coding skills might be a little on the pedestrian side so part of its just like doing a lot more writing what do you find is the bottleneck for people usually except getting started and setting stuff up i would say coding yeah i would say the best the people who are strong coders pick it up the best although another bottleneck is people who have a lot of experience of classic statistics can really struggle because the intuition is so the opposite of what theyre used to theyre very used to like trying to reduce the number of parameters in their model and looking at individual coefficients and stuff like that so i find people who have a lot of coding background and know nothing about statistics are generally gonna be the best off so you taught several courses on deep learning and as feynman says best way to understand something is to teach it what have you learned about deep learning from teaching it a lot thats a key reason for me to teach the courses i mean obviously its gonna be necessary to achieve our goal of getting domain experts to be familiar with deep learning but it was also necessary for me to achieve my goal of being really familiar with deep learning i mean to see so many domain experts from so many different backgrounds its definitely i wouldnt say taught me but convinced me something that i liked to believe was true which was anyone can do it so theres a lot of kind of snobbishness out there about only certain people can learn to code only certain people are gonna be smart enough like do ai thats definitely bullshit ive seen so many people from so many different backgrounds get state of the art results in their domain areas now its definitely taught me that the key differentiator between people that succeed and people that fail is tenacity that seems to be basically the only thing that matters a lot of people give up but of the ones who dont give up pretty much everybody succeeds even if at first im just kind of like thinking like wow they really arent quite getting it yet are they but eventually people get it and they succeed so i think thats been i think theyre both things i liked to believe was true but i dont feel like i really had strong evidence for them to be true but now i can say ive seen it again and again ive seen it again and again so what advice do you have for someone who wants to get started in deep learning train lots of models thats how you learn it so i think its not just me i think our course is very good but also lots of people independently have said its very good it recently won the cogx award for ai courses as being the best in the world so id say come to our course coursefastai and the thing i keep on hopping on in my lessons is train models print out the inputs to the models print out to the outputs to the models like study change the inputs a bit look at how the outputs vary just run lots of experiments to get an intuitive understanding of whats going on to get hooked do you think you mentioned training do you think just running the models inference like if we talk about getting started no youve got to fine tune the models so thats the critical thing because at that point you now have a model thats in your domain area so theres no point running somebody elses model because its not your model so it only takes five minutes to fine tune a model for the data you care about and in lesson two of the course we teach you how to create your own data set from scratch by scripting google image search so and we show you how to actually create a web application running online so i create one in the course that differentiates between a teddy bear a grizzly bear and a brown bear and it does it with basically 100 accuracy took me about four minutes to scrape the images from google search in the script theres a little graphical widgets we have in the notebook that help you clean up the data set theres other widgets that help you study the results to see where the errors are happening and so now weve got over a thousand replies in our share your work here thread of students saying heres the thing i built and so theres people who like and a lot of them are state of the art like somebody said oh i tried looking at devangari characters and i couldnt believe it the thing that came out was more accurate than the best academic paper after lesson one and then theres others which are just more kind of fun like somebody whos doing trinidad and tobago hummingbirds she said thats kind of their national bird and shes got something that can now classify trinidad and tobago hummingbirds so yeah train models fine tune models with your data set and then study their inputs and outputs how much is fastai courses free everything we do is free we have no revenue sources of any kind its just a service to the community youre a saint okay once a person understands the basics trains a bunch of models if we look at the scale of years what advice do you have for someone wanting to eventually become an expert train lots of models but specifically train lots of models in your domain area so an expert what right we dont need more expert like create slightly evolutionary research in areas that everybodys studying we need experts at using deep learning to diagnose malaria or we need experts at using deep learning to analyze language to study media bias so we need experts in analyzing fisheries to identify problem areas in the ocean thats what we need so become the expert in your passion area and this is a tool which you can use for just about anything and youll be able to do that thing better than other people particularly by combining it with your passion and domain expertise so thats really interesting even if you do wanna innovate on transfer learning or active learning your thought is i mean its one i certainly share is you also need to find a domain or data set that you actually really care for if youre not working on a real problem that you understand how do you know if youre doing it any good how do you know if your results are good how do you know if youre getting bad results why are you getting bad results is it a problem with the data like how do you know youre doing anything useful yeah to me the only really interesting research is not the only but the vast majority of interesting research is like try and solve an actual problem and solve it really well so both understanding sufficient tools on the deep learning side and becoming a domain expert in a particular domain are really things within reach for anybody yeah i mean to me i would compare it to like studying self driving cars having never looked at a car or been in a car or turned a car on which is like the way it is for a lot of people theyll study some academic data set where they literally have no idea about that by the way im not sure how familiar with autonomous vehicles but that is literally you describe a large percentage of robotics folks working in self driving cars is they actually havent considered driving they havent actually looked at what driving looks like they havent driven and its a problem because you know when youve actually driven you know like these are the things that happened to me when i was driving theres nothing that beats the real world examples of just experiencing them youve created many successful startups what does it take to create a successful startup same thing as becoming a successful deep learning practitioner which is not giving up so you can run out of money or run out of time or run out of something you know but if you keep costs super low and try and save up some money beforehand so you can afford to have some time then just sticking with it is one important thing doing something you understand and care about is important by something i dont mean the biggest problem i see with deep learning people is they do a phd in deep learning and then they try and commercialize their phd it is a waste of time because that doesnt solve an actual problem you picked your phd topic because it was an interesting kind of engineering or math or research exercise but yeah if youve actually spent time as a recruiter and you know that most of your time was spent sifting through resumes and you know that most of the time youre just looking for certain kinds of things and you can try doing that with a model for a few minutes and see whether thats something which a model seems to be able to do as well as you could then youre on the right track to creating a startup and then i think just yeah being just be pragmatic and try and stay away from venture capital money as long as possible preferably forever so yeah on that point do you venture capital so did you were you able to successfully run startups with self funded for quite a while yeah so my first two were self funded and that was the right way to do it is that scary no vc startups are much more scary because you have these people on your back who do this all the time and who have done it for years telling you grow grow grow grow and they dont care if you fail they only care if you dont grow fast enough so thats scary whereas doing the ones myself well with partners who were friends was nice because like we just went along at a pace that made sense and we were able to build it to something which was big enough that we never had to work again but was not big enough that any vc would think it was impressive and that was enough for us to be excited you know so i thought thats a much better way to do things than most people in generally speaking not for yourself but how do you make money during that process do you cut into savings so yeah so for so i started fast mail and optimal decisions at the same time in 1999 with two different friends and for fast mail i guess i spent 70 a month on the server and when the server ran out of space i put a payments button on the front page and said if you want more than 10 mega space you have to pay 10 a year and so run low like keep your costs down yeah so i kept my costs down and once you know once i needed to spend more money i asked people to spend the money for me and that that was that basically from then on we were making money and i was profitable from then for optimal decisions it was a bit harder because we were trying to sell something that was more like a 1 million sale but what we did was we would sell scoping projects so kind of like prototypy projects but rather than doing it for free we would sell them 50 to 100000 so again we were covering our costs and also making the client feel like we were doing something valuable so in both cases we were profitable from six months in ah nevertheless its scary i mean yeah sure i mean its its scary before you jump in and i just i guess i was comparing it to the scarediness of vc i felt like with vc stuff it was more scary kind of much more in somebody elses hands will they fund you or not and what do they think of what youre doing i also found it very difficult with vcs back startups to actually do the thing which i thought was important for the company rather than doing the thing which i thought would make the vc happy and vcs always tell you not to do the thing that makes them happy but then if you dont do the thing that makes them happy they get sad so and do you think optimizing for the whatever they call it the exit is a good thing to optimize for i mean it can be but not at the vc level because the vc exit needs to be you know a thousand x so where else the lifestyle exit if you can sell something for 10 million then youve made it right so i dont it depends if you want to build something thats gonna youre kind of happy to do forever then fine if you want to build something you want to sell in three years time thats fine too i mean theyre both perfectly good outcomes so youre learning swift now in a way i mean youve already im trying to and i read that you use at least in some cases space repetition as a mechanism for learning new things i use anki quite a lot myself me too i actually never talk to anybody about it dont know how many people do it but it works incredibly well for me can you talk to your experience like how did you what do you first of all okay lets back it up what is space repetition so space repetition is an idea created by a psychologist named ebbinghaus i dont know must be a couple of hundred years ago or something 150 years ago he did something which sounds pretty damn tedious he wrote down random sequences of letters on cards and tested how well he would remember those random sequences a day later a week later whatever he discovered that there was this kind of a curve where his probability of remembering one of them would be dramatically smaller the next day and then a little bit smaller the next day and a little bit smaller the next day what he discovered is that if he revised those cards after a day the probabilities would decrease at a smaller rate and then if you revise them again a week later they would decrease at a smaller rate again and so he basically figured out a roughly optimal equation for when you should revise something you wanna remember so space repetition learning is using this simple algorithm just something like revise something after a day and then three days and then a week and then three weeks and so forth and so if you use a program like anki as you know it will just do that for you and it will say did you remember this and if you say no it will reschedule it back to appear again like 10 times faster than it otherwise would have its a kind of a way of being guaranteed to learn something because by definition if youre not learning it it will be rescheduled to be revised more quickly unfortunately though its also like it doesnt let you fool yourself if youre not learning something you know like your revisions will just get more and more so you have to find ways to learn things productively and effectively like treat your brain well so using like mnemonics and stories and context and stuff like that so yeah its a super great technique its like learning how to learn is something which everybody should learn before they actually learn anything but almost nobody does so what have you so it certainly works well for learning new languages for i mean for learning like small projects almost but do you you know i started using it for i forget who wrote a blog post about this inspired me it mightve been you im not sure i started when i read papers ill concepts and ideas ill put them was it michael nielsen it was michael nielsen so michael started doing this recently and has been writing about it so the kind of todays ebbinghaus is a guy called peter wozniak who developed a system called supermemo and hes been basically trying to become like the worlds greatest renaissance man over the last few decades hes basically lived his life with space repetition learning for everything i and sort of like michaels only very recently got into this but he started really getting excited about doing it for a lot of different things for me personally i actually dont use it for anything except chinese and the reason for that is that chinese is specifically a thing i made a conscious decision that i want to continue to remember even if i dont get much of a chance to exercise it cause like im not often in china so i dont or else something like programming languages or papers i have a very different approach which is i try not to learn anything from them but instead i try to identify the important concepts and like actually ingest them so like really understand that concept deeply and study it carefully i will decide if it really is important if it is like incorporated into our library you know incorporated into how i do things or decide its not worth it say so i find i find i then remember the things that i care about because im using it all the time so ive for the last 25 years ive committed to spending at least half of every day learning or practicing something new which is all my colleagues have always hated because it always looks like im not working on what im meant to be working on but it always means i do everything faster because ive been practicing a lot of stuff so i kind of give myself a lot of opportunity to practice new things and so i find now i dont yeah i dont often kind of find myself wishing i could remember something because if its something thats useful then ive been using it a lot its easy enough to look it up on google but speaking chinese you cant look it up on google do you have advice for people learning new things so if you what have you learned as a process as a i mean it all starts with just making the hours and the day available yeah you got to stick with it which is again the number one thing that 99 of people dont do so the people i started learning chinese with none of them were still doing it 12 months later im still doing it 10 years later i tried to stay in touch with them but they just no one did it for something like chinese like study how human learning works so every one of my chinese flashcards is associated with a story and that story is specifically designed to be memorable and we find things memorable which are like funny or disgusting or sexy or related to people that we know or care about so i try to make sure all of the stories that are in my head have those characteristics yeah so you have to you know you wont remember things well if they dont have some context and yeah you wont remember them well if you dont regularly practice them whether it be just part of your day to day life or the chinese and me flashcards i mean the other thing is ill let yourself fail sometimes so like ive had various medical problems over the last few years and basically my flashcards just stopped for about three years and thereve been other times ive stopped for a few months and its so hard because you get back to it and its like you have 18000 cards due its like and so you just have to go all right well i can either stop and give up everything or just decide to do this every day for the next two years until i get back to it the amazing thing has been that even after three years i you know the chinese were still in there like it was so much faster to relearn than it was to learn the first time yeah absolutely its in there i have the same with guitar with music and so on its sad because the work sometimes takes away and then you wont play for a year but really if you then just get back to it every day youre right there again what do you think is the next big breakthrough in artificial intelligence what are your hopes in deep learning or beyond that people should be working on or you hope therell be breakthroughs i dont think its possible to predict i think what we already have is an incredibly powerful platform to solve lots of societally important problems that are currently unsolved so i just hope that people will lots of people will learn this toolkit and try to use it i dont think we need a lot of new technological breakthroughs to do a lot of great work right now and when do you think were going to create a human level intelligence system do you think dont know how hard is it how far away are we dont know dont know i have no way to know i dont know why people make predictions about this because theres no data and nothing to go on and its just like theres so many societally important problems to solve right now i just dont find it a really interesting question to even answer so in terms of societally important problems whats the problem that is within reach well i mean for example there are problems that ai creates right so more specifically labor force displacement is going to be huge and people keep making this frivolous econometric argument of being like oh theres been other things that arent ai that have come along before and havent created massive labor force displacement therefore ai wont so thats a serious concern for you oh yeah andrew yang is running on it yeah its im desperately concerned and you see already that the changing workplace has led to a hollowing out of the middle class youre seeing that students coming out of school today have a less rosy financial future ahead of them than their parents did which has never happened in recent in the last few hundred years you know weve always had progress before and you see this turning into anxiety and despair and even violence so i very much worry about that youve written quite a bit about ethics too i do think that every data scientist working with deep learning needs to recognize they have an incredibly high leverage tool that theyre using that can influence society in lots of ways and if theyre doing research that that research is gonna be used by people doing this kind of work and they have a responsibility to consider the consequences and to think about things like how will humans be in the loop here how do we avoid runaway feedback loops how do we ensure an appeals process for humans that are impacted by my algorithm how do i ensure that the constraints of my algorithm are adequately explained to the people that end up using them theres all kinds of human issues which only data scientists are actually in the right place to educate people are about but data scientists tend to think of themselves as just engineers and that they dont need to be part of that process which is wrong well youre in the perfect position to educate them better to read literature to read history to learn from history well jeremy thank you so much for everything you do for inspiring huge amount of people getting them into deep learning and having the ripple effects the flap of a butterflys wings that will probably change the world so thank you very much thank you thank you thank you thank you and tile and mlir and tvm theres all these various projects which are all about saying lets let people create like domain specific languages for tensor computations these are the kinds of things we do generally on the gpu for deep learning and then have a compiler which can optimize that tensor computation a lot of this work is actually sitting on top of a project called halide which is a mind blowing project where they came up with such a domain specific language in fact two one domain specific language for expressing this is what my tensor computation is and another domain specific language for expressing this is the kind of the way i want you to structure the compilation of that and like do it block by block and do these bits in parallel and they were able to show how you can compress the amount of code by 10x compared to optimized gpu code and get the same performance so thats like so these other things are kind of sitting on top of that kind of research and mlir is pulling a lot of those best practices together and now were starting to see work done on making all of that directly accessible through swift so that i could use swift to kind of write those domain specific languages and hopefully well get then swift cuda kernels written in a very expressive and concise way that looks a bit like j and apl and then swift layers on top of that and then a swift ui on top of that and itll be so nice if we can get to that point now does it all eventually boil down to cuda and nvidia gpus unfortunately at the moment it does but one of the nice things about mlir if amd ever gets their act together which they probably wont is that they or others could write mlir backends for other gpus or rather tensor computation devices of which today there are increasing number like graph core or vertex ai or whatever so yeah being able to target lots of backends would be another benefit of this and the market really needs competition because at the moment nvidia is massively overcharging for their kind of enterprise class cards because there is no serious competition because nobody else is doing the software properly in the cloud there is some competition right but not really other than tpus perhaps but tpus are almost unprogrammable at the moment so tpus have the same problem that you cant its even worse so tpus google actually made an explicit decision to make them almost entirely unprogrammable because they felt that there was too much ip in there and if they gave people direct access to program them people would learn their secrets so you cant actually directly program the memory in a tpu you cant even directly create code that runs on and that you look at on the machine that has the tpu it all goes through a virtual machine so all you can really do is this kind of cookie cutter thing of like plug in high level stuff together which is just super tedious and annoying and totally unnecessary so what was the tell me if you could the origin story of fast ai what is the motivation its mission its dream so i guess the founding story is heavily tied to my previous startup which is a company called analytic which was the first company to focus on deep learning for medicine and i created that because i saw that was a huge opportunity to theres about a 10x shortage of the number of doctors in the world in the developing world that we need i expected it would take about 300 years to train enough doctors to meet that gap but i guess that maybe if we used deep learning for some of the analytics we could maybe make it so you dont need as highly trained doctors for diagnosis for diagnosis and treatment planning wheres the biggest benefit just before we get to fast ai wheres the biggest benefit of ai and medicine that you see today and maybe next time not much happening today in terms of like stuff thats actually out there its very early but in terms of the opportunity its to take markets like india and china and indonesia which have big populations africa small numbers of doctors and provide diagnostic particularly treatment planning and triage kind of on device so that if you do a test for malaria or tuberculosis or whatever you immediately get something that even a healthcare worker thats had a month of training can get a very high quality assessment of whether the patient might be at risk and tell okay well send them off to a hospital so for example in africa outside of south africa theres only five pediatric radiologists for the entire continent so most countries dont have any so if your kid is sick and they need something diagnosed through medical imaging the person even if youre able to get medical imaging done the person that looks at it will be a nurse at best but actually in india for example and china almost no x rays are read by anybody by any trained professional because they dont have enough so if instead we had a algorithm that could take the most likely high risk 5 and say triage basically say okay someone needs to look at this it would massively change the kind of way that whats possible with medicine in the developing world and remember they have increasingly they have money theyre the developing world theyre not the poor world theyre the developing world so they have the money so theyre building the hospitals theyre getting the diagnostic equipment but theres no way for a very long time will they be able to have the expertise shortage of expertise okay and thats where the deep learning systems can step in and magnify the expertise they do have exactly yeah so you do see just to linger a little bit longer the interaction do you still see the human experts still at the core of these systems yeah absolutely is there something in medicine that could be automated almost completely i dont see the point of even thinking about that because we have such a shortage of people why would we want to find a way not to use them we have people so the idea of like even from an economic point of view if you can make them 10x more productive getting rid of the person doesnt impact your unit economics at all and it totally ignores the fact that there are things people do better than machines so its just to me thats not a useful way of framing the problem i guess just to clarify i guess i meant there may be some problems where you can avoid even going to the expert ever sort of maybe preventative care or some basic stuff allowing food allowing the expert to focus on the things that are really that you know well thats what the triage would do right so the triage would say okay theres 99 sure theres nothing here so that can be done on device and they can just say okay go home so the experts are being used to look at the stuff which has some chance its worth looking at which most things its not its fine why do you think that is you know its fine why do you think we havent quite made progress on that yet in terms of the scale of how much ai is applied in the medical field oh theres a lot of reasons i mean one is its pretty new i only started in liddick in like 2014 and before that its hard to express to what degree the medical world was not aware of the opportunities here so i went to rsna which is the worlds largest radiology conference and i told everybody i could you know like im doing this thing with deep learning please come and check it out and no one had any idea what i was talking about and no one had any interest in it so like weve come from absolute zero which is hard and then the whole regulatory framework education system everything is just set up to think of doctoring in a very different way so today there is a small number of people who are deep learning practitioners and doctors at the same time and were starting to see the first ones come out of their phd programs so zach kahane over in boston cambridge has a number of students now who are data science experts deep learning experts and actual medical doctors quite a few doctors have completed our fast ai course now and are publishing papers and creating journal reading groups in the american council of radiology and like its just starting to happen but its gonna be a long time coming its gonna happen but its gonna be a long process the regulators have to learn how to regulate this they have to build guidelines and then the lawyers at hospitals have to develop a new way of understanding that sometimes it makes sense for data to be looked at in raw form in large quantities in order to create well changing results yeah so the regulation around data all that it sounds probably the hardest problem but sounds reminiscent of autonomous vehicles as well many of the same regulatory challenges many of the same data challenges yeah i mean funnily enough the problem is less the regulation and more the interpretation of that regulation by lawyers in hospitals so hipaa is actually was designed to pay and hipaa does not stand for privacy it stands for portability its actually meant to be a way that data can be used and it was created with lots of gray areas because the idea is that would be more practical and it would help people to use this legislation to actually share data in a more thoughtful way unfortunately its done the opposite because when a lawyer sees a gray area they say oh if we dont know we wont get sued then we cant do it so hipaa is not exactly the problem the problem is more that theres hospital lawyers are not incented to make bold decisions about data portability or even to embrace technology that saves lives they more want to not get in trouble for embracing that technology it also saves lives in a very abstract way which is like oh weve been able to release these 100000 anonymized records i cant point to the specific person whose life that saved i can say like oh we ended up with this paper which found this result which diagnosed a thousand more people than we would have otherwise but its like which ones were helped its very abstract and on the counter side of that you may be able to point to a life that was taken because of something that was yeah or a person whose privacy was violated its like oh this specific person was deidentified so identified just a fascinating topic were jumping around well get back to fast ai but on the question of privacy data is the fuel for so much innovation in deep learning whats your sense on privacy whether were talking about twitter facebook youtube just the technologies like in the medical field that rely on peoples data in order to create impact how do we get that right respecting peoples privacy and yet creating technology that is learning from data one of my areas of focus is on doing more with less data more with less data which so most vendors unfortunately are strongly incented to find ways to require more data and more computation so google and ibm being the most obvious ibm yeah so watson so google and ibm both strongly push the idea that you have to be that they have more data and more computation and more intelligent people than anybody else and so you have to trust them to do things because nobody else can do it and googles very upfront about this like jeff dean has gone out there and given talks and said our goal is to require a thousand times more computation but less people our goal is to use the people that you have better and the data you have better and the computation you have better so one of the things that weve discovered is or at least highlighted is that you very very very often dont need much data at all and so the data you already have in your organization will be enough to get state of the art results so like my starting point would be to kind of say around privacy is a lot of people are looking for ways to share data and aggregate data but i think often thats unnecessary they assume that they need more data than they do because theyre not familiar with the basics of transfer learning which is this critical technique for needing orders of magnitude less data is your sense one reason you might wanna collect data from everyone is like in the recommender system context where your individual jeremy howards individual data is the most useful for providing a product thats impactful for you so for giving you advertisements for recommending to you movies for doing medical diagnosis is your sense we can build with a small amount of data general models that will have a huge impact for most people that we dont need to have data from each individual on the whole id say yes i mean there are things like you know recommender systems have this cold start problem where you know jeremy is a new customer we havent seen him before so we cant recommend him things based on what else hes bought and liked with us and theres various workarounds to that like in a lot of music programs well start out by saying which of these artists do you like which of these albums do you like which of these songs do you like netflix used to do that nowadays they tend not to people kind of dont like that because they think oh we dont wanna bother the user so you could work around that by having some kind of data sharing where you get my marketing record from axiom or whatever and try to guess from that to me the benefit to me and to society of saving me five minutes on answering some questions versus the negative externalities of the privacy issue doesnt add up so i think like a lot of the time the places where people are invading our privacy in order to provide convenience is really about just trying to make them more money and they move these negative externalities to places that they dont have to pay for them so when you actually see regulations appear that actually cause the companies that create these negative externalities to have to pay for it themselves they say well we cant do it anymore so the cost is actually too high but for something like medicine yeah i mean the hospital has my medical imaging my pathology studies my medical records and also i own my medical data so you can so i help a startup called docai one of the things docai does is that it has an app you can connect to you know sutter health and labcorp and walgreens and download your medical data to your phone and then upload it again at your discretion to share it as you wish so with that kind of approach we can share our medical information with the people we want to yeah so control i mean really being able to control who you share it with and so on yeah so that has a beautiful interesting tangent to return back to the origin story of fastai right so before i started fastai i spent a year researching where are the biggest opportunities for deep learning because i knew from my time at kaggle in particular that deep learning had kind of hit this threshold point where it was rapidly becoming the state of the art approach in every area that looked at it and id been working with neural nets for over 20 years i knew that from a theoretical point of view once it hit that point it would do that in kind of just about every domain and so i kind of spent a year researching what are the domains thats gonna have the biggest low hanging fruit in the shortest time period i picked medicine but there were so many i could have picked and so there was a kind of level of frustration for me of like okay im really glad weve opened up the medical deep learning world and today its huge as you know but we cant do i cant do everything i dont even know like in medicine it took me a really long time to even get a sense of like what kind of problems do medical practitioners solve what kind of data do they have who has that data so i kind of felt like i need to approach this differently if i wanna maximize the positive impact of deep learning rather than me picking an area and trying to become good at it and building something i should let people who are already domain experts in those areas and who already have the data do it themselves so that was the reason for fastai is to basically try and figure out how to get deep learning into the hands of people who could benefit from it and help them to do so in as quick and easy and effective a way as possible got it so sort of empower the domain experts yeah and like partly its because like unlike most people in this field my background is very applied and industrial like my first job was at mckinsey  company i spent 10 years in management consulting i spend a lot of time with domain experts so i kind of respect them and appreciate them and i know thats where the value generation in society is and so i also know how most of them cant code and most of them dont have the time to invest three years in a graduate degree or whatever so i was like how do i upskill those domain experts i think that would be a super powerful thing the biggest societal impact i could have so yeah that was the thinking so much of fastai students and researchers and the things you teach are pragmatically minded practically minded figuring out ways how to solve real problems and fast so from your experience whats the difference between theory and practice of deep learning well most of the research in the deep learning world is a total waste of time right thats what i was getting at yeah its a problem in science in general scientists need to be published which means they need to work on things that their peers are extremely familiar with and can recognize in advance in that area so that means that they all need to work on the same thing and so it really and the thing they work on theres nothing to encourage them to work on things that are practically useful so you get just a whole lot of research which is minor advances and stuff thats been very highly studied and has no significant practical impact whereas the things that really make a difference like i mentioned transfer learning like if we can do better at transfer learning then its this like world changing thing where suddenly like lots more people can do world class work with less resources and less data but almost nobody works on that or another example active learning which is the study of like how do we get more out of the human beings in the loop thats my favorite topic yeah so active learning is great but its almost nobody working on it because its just not a trendy thing right now you know what somebody sorry to interrupt youre saying that nobody is publishing on active learning but theres people inside companies anybody who actually has to solve a problem theyre going to innovate on active learning yeah everybody kind of reinvents active learning when they actually have to work in practice because they start labeling things and they think gosh this is taking a long time and its very expensive and then they start thinking well why am i labeling everything im only the machines only making mistakes on those two classes theyre the hard ones maybe ill just start labeling those two classes and then you start thinking well why did i do that manually why cant i just get the system to tell me which things are going to be hardest its an obvious thing to do but yeah its just like transfer learning its understudied and the academic world just has no reason to care about practical results the funny thing is like ive only really ever written one paper i hate writing papers and i didnt even write it it was my colleague sebastian ruder who actually wrote it i just did the research for it but it was basically introducing transfer learning successful transfer learning to nlp for the first time the algorithm is called ulm fit and it actually i actually wrote it for the course for the fast ai course i wanted to teach people nlp and i thought i only want to teach people practical stuff and i think the only practical stuff is transfer learning and i couldnt find any examples of transfer learning in nlp so i just did it and i was shocked to find that as soon as i did it which you know the basic prototype took a couple of days smashed the state of the art on one of the most important data sets in a field that i knew nothing about and i just thought well this is ridiculous and so i spoke to sebastian about it and he kindly offered to write it up the results and so it ended up being published in acl which is the top computational linguistics conference so like people do actually care once you do it but i guess its difficult for maybe like junior researchers or like i dont care whether i get citations or papers or whatever theres nothing in my life that makes that important which is why ive never actually bothered to write a paper myself but for people who do i guess they have to pick the kind of safe option which is like yeah make a slight improvement on something that everybodys already working on yeah nobody does anything interesting or succeeds in life with the safe option although i mean the nice thing is nowadays everybody is now working on nlp transfer learning because since that time weve had gpt and gpt2 and bert and you know its like its so yeah once you show that somethings possible everybody jumps in i guess so i hope to be a part of and i hope to see more innovation and active learning in the same way i think transfer learning and active learning are fascinating public open work i actually helped start a startup called platform ai which is really all about active learning and yeah its been interesting trying to kind of see what research is out there and make the most of it and theres basically none so weve had to do all our own research once again and just as you described can you tell the story of the stanford competition dawn bench and fastais achievement on it sure so something which i really enjoy is that i basically teach two courses a year the practical deep learning for coders which is kind of the introductory course and then cutting edge deep learning for coders which is the kind of research level course and while i teach those courses i basically have a big office at the university of san francisco big enough for like 30 people and i invite anybody any student who wants to come and hang out with me while i build the course and so generally its full and so we have 20 or 30 people in a big office with nothing to do but study deep learning so it was during one of these times that somebody in the group said oh theres a thing called dawn bench that looks interesting and i was like what the hell is that and they set out some competition to see how quickly you can train a model seems kind of not exactly relevant to what were doing but it sounds like the kind of thing which you might be interested in and i checked it out and i was like oh crap theres only 10 days till its over its too late and were kind of busy trying to teach this course but were like oh it would make an interesting case study for the course its like its all the stuff were already doing why dont we just put together our current best practices and ideas so me and i guess about four students just decided to give it a go and we focused on this small one called cifar 10 which is little 32 by 32 pixel images can you say what dawn bench is yeah so its a competition to train a model as fast as possible it was run by stanford and its cheap as possible too thats also another one for as cheap as possible and there was a couple of categories imagenet and cifar 10 so imagenet is this big 13 million image thing that took a couple of days to train remember a friend of mine pete warden whos now at google i remember he told me how he trained imagenet a few years ago when he basically like had this little granny flat out the back that he turned into his imagenet training center and he figured you know after like a year of work he figured out how to train it in like 10 days or something its like that was a big job whereas cifar 10 at that time you could train in a few hours you know its much smaller and easier so we thought wed try cifar 10 and yeah ive really never done that before like id never really like things like using more than one gpu at a time was something i tried to avoid cause to me its like very against the whole idea of accessibility is should better do things with one gpu i mean have you asked in the past before after having accomplished something how do i do this faster much faster oh always but its always for me its always how do i make it much faster on a single gpu that a normal person could afford in their day to day life its not how could i do it faster by you know having a huge data center cause to me its all about like as many people should better use something as possible without fussing around with infrastructure so anyways in this case its like well we can use eight gpus just by renting a aws machine so we thought wed try that and yeah basically using the stuff we were already doing we were able to get you know the speed you know within a few days we had the speed down to i dont know a very small number of minutes i cant remember exactly how many minutes it was but it mightve been like 10 minutes or something and so yeah we found ourselves at the top of the leaderboard easily for both time and money which really shocked me cause the other people competing in this were like google and intel and stuff who i like know a lot more about this stuff than i think we do so then we were emboldened we thought lets try the imagenet one too i mean it seemed way out of our league but our goal was to get under 12 hours and we did which was really exciting but we didnt put anything up on the leaderboard but we were down to like 10 hours but then google put in like five hours or something and were just like oh were so screwed but we kind of thought well keep trying you know if google can do it in five i mean google did on five hours on something on like a tpu pod or something like a lot of hardware but we kind of like had a bunch of ideas to try like a really simple thing was why are we using these big images theyre like 224 or 256 by 256 pixels you know why dont we try smaller ones and just to elaborate theres a constraint on the accuracy that your trained model is supposed to achieve right yeah you gotta achieve 93 i think it was for imagenet exactly which is very tough so you have to yeah 93 like they picked a good threshold it was a little bit higher than what the most commonly used resnet 50 model could achieve at that time so yeah so its quite a difficult problem to solve but yeah we realized if we actually just use 64 by 64 images it trained a pretty good model and then we could take that same model and just give it a couple of epochs to learn 224 by 224 images and it was basically already trained it makes a lot of sense like if you teach somebody like heres what a dog looks like and you show them low res versions and then you say heres a really clear picture of a dog they already know what a dog looks like so that like just we jumped to the front and we ended up winning parts of that competition we actually ended up doing a distributed version over multiple machines a couple of months later and ended up at the top of the leaderboard we had 18 minutes imagenet yeah and it was and people have just kept on blasting through again and again since then so so whats your view on multi gpu or multiple machine training in general as a way to speed code up i think its largely a waste of time both of them i think its largely a waste of time both multi gpu on a single machine and yeah particularly multi machines cause its just clunky multi gpus is less clunky than it used to be but to me anything that slows down your iteration speed is a waste of time so you could maybe do your very last you know perfecting of the model on multi gpus if you need to but so for example i think doing stuff on imagenet is generally a waste of time why test things on 13 million images most of us dont use 13 million images and weve also done research that shows that doing things on a smaller subset of images gives you the same relative answers anyway so from a research point of view why waste that time so actually i released a couple of new data sets recently one is called imagenet the french imagenet which is a small subset of imagenet which is designed to be easy to classify whats how do you spell imagenet its got an extra t and e at the end cause its very french and then another one called imagewolf which is a subset of imagenet that only contains dog breeds and thats a hard one right thats a hard one and ive discovered that if you just look at these two subsets you can train things on a single gpu in 10 minutes and the results you get are directly transferable to imagenet nearly all the time and so now im starting to see some researchers start to use these much smaller data sets i so deeply love the way you think because i think you mightve written a blog post saying that sort of going these big data sets is encouraging people to not think creatively absolutely so youre too it sort of constrains you to train on large resources and because you have these resources you think more research will be better and then you start so like somehow you kill the creativity yeah and even worse than that lex i keep hearing from people who say i decided not to get into deep learning because i dont believe its accessible to people outside of google to do useful work so like i see a lot of people make an explicit decision to not learn this incredibly valuable tool because theyve drunk the google koolaid which is that only googles big enough and smart enough to do it and i just find that so disappointing and its so wrong and i think all of the major breakthroughs in ai in the next 20 years will be doable on a single gpu like i would say my sense is all the big sort of well lets put it this way none of the big breakthroughs of the last 20 years have required multiple gpus so like batch norm relu dropout to demonstrate that theres something to them every one of them none of them has required multiple gpus gans the original gans didnt require multiple gpus well and weve actually recently shown that you dont even need gans so weve developed gan level outcomes without needing gans and we can now do it with again by using transfer learning we can do it in a couple of hours on a single gpu youre just using a generator model without the adversarial part yeah so weve found loss functions that work super well without the adversarial part and then one of our students a guy called jason antich has created a system called dealtify which uses this technique to colorize old black and white movies you can do it on a single gpu colorize a whole movie in a couple of hours and one of the things that jason and i did together was we figured out how to add a little bit of gan at the very end which it turns out for colorization makes it just a bit brighter and nicer and then jason did masses of experiments to figure out exactly how much to do but its still all done on his home machine on a single gpu in his lounge room and if you think about colorizing hollywood movies that sounds like something a huge studio would have to do but he has the worlds best results on this theres this problem of microphones were just talking to microphones now its such a pain in the ass to have these microphones to get good quality audio and i tried to see if its possible to plop down a bunch of cheap sensors and reconstruct higher quality audio from multiple sources because right now i havent seen the work from okay we can say even expensive mics automatically combining audio from multiple sources to improve the combined audio people havent done that and that feels like a learning problem so hopefully somebody can well i mean its evidently doable and it should have been done by now i felt the same way about computational photography four years ago why are we investing in big lenses when three cheap lenses plus actually a little bit of intentional movement so like take a few frames gives you enough information to get excellent subpixel resolution which particularly with deep learning you would know exactly what you meant to be looking at we can totally do the same thing with audio i think its madness that it hasnt been done yet is there progress on the photography company yeah photography is basically standard now so the google pixel night light i dont know if youve ever tried it but its astonishing you take a picture in almost pitch black and you get back a very high quality image and its not because of the lens same stuff with like adding the bokeh to the background blurring its done computationally this is the pixel right here yeah basically everybody now is doing most of the fanciest stuff on their phones with computational photography and also increasingly people are putting more than one lens on the back of the camera so the same will happen for audio for sure and theres applications in the audio side if you look at an alexa type device most people ive seen especially i worked at google before when you look at noise background removal you dont think of multiple sources of audio you dont play with that as much as i would hope people would but i mean you can still do it even with one like again not much works been done in this area so were actually gonna be releasing an audio library soon which hopefully will encourage development of this because its so underused the basic approach we used for our super resolution and which jason uses for dealtify of generating high quality images the exact same approach would work for audio no ones done it yet but it would be a couple of months work okay also learning rate in terms of dawn bench theres some magic on learning rate that you played around with thats kind of interesting yeah so this is all work that came from a guy called leslie smith leslies a researcher who like us cares a lot about just the practicalities of training neural networks quickly and accurately which i think is what everybody should care about but almost nobody does and he discovered something very interesting which he calls super convergence which is there are certain networks that with certain settings of high parameters could suddenly be trained 10 times faster by using a 10 times higher learning rate now no one published that paper because its not an area of kind of active research in the academic world no academics recognize that this is important and also deep learning in academia is not considered a experimental science so unlike in physics where you could say like', 'the following is a conversation with yann lecun hes considered to be one of the fathers of deep learning which if youve been hiding under a rock is the recent revolution in ai that has captivated the world with the possibility of what machines can learn from data hes a professor at new york university a vice president and chief ai scientist at facebook and co recipient of the turing award for his work on deep learning hes probably best known as the founding father of convolutional neural networks in particular their application to optical character recognition and the famed mnist dataset he is also an outspoken personality unafraid to speak his mind in a distinctive french accent and explore provocative ideas both in the rigorous medium of academic research and the somewhat less rigorous medium of twitter and facebook this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with yann lecun you said that 2001 space odyssey is one of your favorite movies hal 9000 decides to get rid of the astronauts for people who havent seen the movie spoiler alert because he it she believes that the astronauts they will interfere with the mission do you see hal as flawed in some fundamental way or even evil or did he do the right thing neither theres no notion of evil in that context other than the fact that people die but it was an example of what people call value misalignment right you give an objective to a machine and the machine strives to achieve this objective and if you dont put any constraints on this objective like dont kill people and dont do things like this the machine given the power will do stupid things just to achieve this objective or damaging things to achieve this objective its a little bit like i mean were used to this in the context of human society we put in place laws to prevent people from doing bad things because spontaneously they would do those bad things right so we have to shape their cost function their objective function if you want through laws to kind of correct and education obviously to sort of correct for those so maybe just pushing a little further on that point how you know theres a mission theres this fuzziness around the ambiguity around what the actual mission is but you know do you think that there will be a time from a utilitarian perspective where an ai system where it is not misalignment where it is alignment for the greater good of society that an ai system will make decisions that are difficult well thats the trick i mean eventually well have to figure out how to do this and again were not starting from scratch because weve been doing this with humans for millennia so designing objective functions for people is something that we know how to do and we dont do it by you know programming things although the legal code is called code so that tells you something and its actually the design of an objective function thats really what legal code is right it tells you here is what you can do here is what you cant do if you do it you pay that much thats an objective function so there is this idea somehow that its a new thing for people to try to design objective functions that are aligned with the common good but no weve been writing laws for millennia and thats exactly what it is so thats where you know the science of lawmaking and computer science will come together will come together so theres nothing special about hal or ai systems its just the continuation of tools used to make some of these difficult ethical judgments that laws make yeah and we have systems like this already that make many decisions for ourselves in society that need to be designed in a way that they like rules about things that sometimes have bad side effects and we have to be flexible enough about those rules so that they can be broken when its obvious that they shouldnt be applied so you dont see this on the camera here but all the decoration in this room is all pictures from 2001 and space odyssey wow is that by accident or is there a lot no by accident its by design oh wow so if you were to build hal 10000 so an improvement of hal 9000 what would you improve well first of all i wouldnt ask it to hold secrets and tell lies because thats really what breaks it in the end thats the fact that its asking itself questions about the purpose of the mission and its you know pieces things together that its heard you know all the secrecy of the preparation of the mission and the fact that it was the discovery on the lunar surface that really was kept secret and one part of hals memory knows this and the other part does not know it and is supposed to not tell anyone and that creates internal conflict so you think theres never should be a set of things that an ai system should not be allowed like a set of facts that should not be shared with the human operators well i think no i think it should be a bit like in the design of autonomous ai systems there should be the equivalent of you know the oath that a hypocrite oath that doctors sign up to right so theres certain things certain rules that you have to abide by and we can sort of hardwire this into our machines to kind of make sure they dont go so im not you know an advocate of the three laws of robotics you know the asimov kind of thing because i dont think its practical but you know some level of limits but to be clear these are not questions that are kind of really worth asking today because we just dont have the technology to do this we dont have autonomous intelligent machines we have intelligent machines some are intelligent machines that are very specialized but they dont really sort of satisfy an objective theyre just you know kind of trained to do one thing so until we have some idea for design of a full fledged autonomous intelligent system asking the question of how we design this objective i think is a little too abstract its a little too abstract theres useful elements to it in that it helps us understand our own ethical codes humans so even just as a thought experiment if you imagine that an agi system is here today how would we program it is a kind of nice thought experiment of constructing how should we have a law have a system of laws for us humans its just a nice practical tool and i think theres echoes of that idea too in the ai systems we have today that dont have to be that intelligent yeah like autonomous vehicles these things start creeping in that are worth thinking about but certainly they shouldnt be framed as how yeah looking back what is the most im sorry if its a silly question but what is the most beautiful or surprising idea in deep learning or ai in general that youve ever come across sort of personally when you said back and just had this kind of oh thats pretty cool moment thats nice thats surprising i dont know if its an idea rather than a sort of empirical fact the fact that you can build gigantic neural nets train them on relatively small amounts of data relatively with stochastic gradient descent and that it actually works breaks everything you read in every textbook right every pre deep learning textbook that told you you need to have fewer parameters and you have data samples if you have a non convex objective function you have no guarantee of convergence all those things that you read in textbook and they tell you to stay away from this and theyre all wrong the huge number of parameters non convex and somehow which is very relative to the number of parameters data its able to learn anything right does that still surprise you today well it was kind of obvious to me before i knew anything that this is a good idea and then it became surprising that it worked because i started reading those textbooks okay okay so can you talk through the intuition of why it was obvious to you if you remember well okay so the intuition was its sort of like those people in the late 19th century who proved that heavier than air flight was impossible and of course you have birds right they do fly and so on the face of it its obviously wrong as an empirical question right and so we have the same kind of thing that we know that the brain works we dont know how but we know it works and we know its a large network of neurons and interaction and that learning takes place by changing the connection so kind of getting this level of inspiration without copying the details but sort of trying to derive basic principles and that kind of gives you a clue as to which direction to go theres also the idea somehow that ive been convinced of since i was an undergrad that even before that intelligence is inseparable from learning so the idea somehow that you can create an intelligent machine by basically programming for me it was a non starter from the start every intelligent entity that we know about arrives at this intelligence through learning so machine learning was a completely obvious path also because im lazy so you know kind of hes automate basically everything and learning is the automation of intelligence so do you think so what is learning then what falls under learning because do you think of reasoning as learning well reasoning is certainly a consequence of learning as well just like other functions of the brain the big question about reasoning is how do you make reasoning compatible with gradient based learning do you think neural networks can be made to reason yes there is no question about that again we have a good example right the question is how so the question is how much prior structure do you have to put in the neural net so that something like human reasoning will emerge from it you know from learning another question is all of our kind of model of what reasoning is that are based on logic are discrete and are therefore incompatible with gradient based learning and im a very strong believer in this idea of gradient based learning i dont believe that other types of learning that dont use kind of gradient information if you want so you dont like discrete mathematics you dont like anything discrete well thats its not that i dont like it its just that its incompatible with learning and im a big fan of learning right so in fact thats perhaps one reason why deep learning has been kind of looked at with suspicion by a lot of computer scientists because the math is very different the math that you use for deep learning you know it kind of has more to do with you know cybernetics the kind of math you do in electrical engineering than the kind of math you do in computer science and you know nothing in machine learning is exact right computer science is all about sort of you know obviously compulsive attention to details of like you know every index has to be right and you can prove that an algorithm is correct right machine learning is the science of sloppiness really thats beautiful so okay maybe lets feel around in the dark of what is a neural network that reasons or a system that works with continuous functions thats able to do build knowledge however we think about reasoning build on previous knowledge build on extra knowledge create new knowledge generalize outside of any training set to ever build what does that look like if yeah maybe give inklings of thoughts of what that might look like yeah i mean yes and no if i had precise ideas about this i think you know wed be building it right now and there are people working on this whose main research interest is actually exactly that right so what you need to have is a working memory so you need to have some device if you want some subsystem that can store a relatively large number of factual episodic information for you know a reasonable amount of time so you know in the brain for example there are kind of three main types of memory one is the sort of memory of the state of your cortex and that sort of disappears within 20 seconds you cant remember things for more than about 20 seconds or a minute if you dont have any other form of memory the second type of memory which is longer term is still short term is the hippocampus so you can you know you came into this building you remember where the exit is where the elevators are you have some map of that building thats stored in your hippocampus you might remember something about what i said you know a few minutes ago i forgot it all already of course its been erased but you know but that would be in your hippocampus and then the longer term memory is in the synapse the synapses right so what you need if you want a system thats capable of reasoning is that you want the hippocampus like thing right and thats what people have tried to do with memory networks and you know neural training machines and stuff like that right and now with transformers which have sort of a memory in there kind of self attention system you can think of it this way so thats one element you need another thing you need is some sort of network that can access this memory get an information back and then kind of crunch on it and then do this iteratively multiple times because a chain of reasoning is a process by which you update your knowledge about the state of the world about you know whats going to happen et cetera and that has to be this sort of recurrent operation basically and you think that kind of if we think about a transformer so that seems to be too small to contain the knowledge thats to represent the knowledge thats contained in wikipedia for example well a transformer doesnt have this idea of recurrence its got a fixed number of layers and thats the number of steps that you know limits basically its representation but recurrence would build on the knowledge somehow i mean it would evolve the knowledge and expand the amount of information perhaps or useful information within that knowledge but is this something that just can emerge with size because it seems like everything we have now is too small not just no its not clear i mean how you access and write into an associative memory in an efficient way i mean sort of the original memory network maybe had something like the right architecture but if you try to scale up a memory network so that the memory contains all the wikipedia it doesnt quite work right so theres a need for new ideas there okay but its not the only form of reasoning so theres another form of reasoning which is true which is very classical also in some types of ai and its based on lets call it energy minimization okay so you have some sort of objective some energy function that represents the quality or the negative quality okay energy goes up when things get bad and they get low when things get good so lets say you want to figure out what gestures do i need to do to grab an object or walk out the door if you have a good model of your own body a good model of the environment using this kind of energy minimization you can do planning and in optimal control its called model predictive control you have a model of whats gonna happen in the world as a consequence of your actions and that allows you to by energy minimization figure out the sequence of action that optimizes a particular objective function which measures minimizes the number of times youre gonna hit something and the energy youre gonna spend doing the gesture and et cetera so thats a form of reasoning planning is a form of reasoning and perhaps what led to the ability of humans to reason is the fact that or species that appear before us had to do some sort of planning to be able to hunt and survive and survive the winter in particular and so its the same capacity that you need to have so in your intuition is if we look at expert systems and encoding knowledge as logic systems as graphs in this kind of way is not a useful way to think about knowledge graphs are a little brittle or logic representation so basically variables that have values and then constraint between them that are represented by rules is a little too rigid and too brittle right so some of the early efforts in that respect were to put probabilities on them so a rule if you have this and that symptom you have this disease with that probability and you should prescribe that antibiotic with that probability right thats the mycin system from the 70s and thats what that branch of ai led to based on networks and graphical models and causal inference and variational method so there is certainly a lot of interesting work going on in this area the main issue with this is knowledge acquisition how do you reduce a bunch of data to a graph of this type yeah it relies on the expert on the human being to encode to add knowledge and thats essentially impractical yeah its not scalable thats a big question the second question is do you want to represent knowledge as symbols and do you want to manipulate them with logic and again thats incompatible with learning so one suggestion which jeff hinton has been advocating for many decades is replace symbols by vectors think of it as pattern of activities in a bunch of neurons or units or whatever you want to call them and replace logic by continuous functions okay and that becomes now compatible but most of those are incredibly boring what i like is select you know 10 of them that are kind of the most informative and with just that i would probably reach the same so its a weak form of active learning if you want yes but there might be a much stronger version yeah thats right thats what and thats an awful question if it exists the question is how much stronger can you get elon musk is confident talked to him recently hes confident that large scale data and deep learning can solve the autonomous driving problem what are your thoughts on the limits possibilities of deep learning in this space its obviously part of the solution i mean i dont think well ever have a set driving system or at least not in the foreseeable future that does not use deep learning let me put it this way now how much of it so in the history of sort of engineering particularly sort of ai like systems theres generally a first phase where everything is built by hand then there is a second phase and that was the case for autonomous driving 20 30 years ago theres a phase where theres a little bit of learning is used but theres a lot of engineering thats involved in kind of taking care of corner cases and putting limits et cetera because the learning system is not perfect and then as technology progresses we end up relying more and more on learning thats the history of character recognition its the history of science character recognition is the history of speech recognition now computer vision natural language processing and i think the same is going to happen with autonomous driving that currently the methods that are closest to providing some level of autonomy some decent level of autonomy where you dont expect a driver to kind of do anything is where you constrain the world so you only run within 100 square kilometers or square miles in phoenix where the weather is nice and the roads are wide which is what waymo is doing you completely overengineer the car with tons of lidars and sophisticated sensors that are too expensive for consumer cars but theyre fine if you just run a fleet and you engineer the hell out of everything else you map the entire world so you have complete 3d model of everything so the only thing that the perception system has to take care of is moving objects and construction and sort of things that werent in your map and you can engineer a good slam system and all that stuff so thats kind of the current approach thats closest to some level of autonomy but i think eventually the longterm solution is going to rely more and more on learning and possibly using a combination of self supervised learning and model based reinforcement or something like that but ultimately learning will be not just at the core but really the fundamental part of the system yeah it already is but it will become more and more what do you think it takes to build a system with human level intelligence you talked about the ai system in the movie her being way out of reach our current reach this might be outdated as well but its still way out of reach its still way out of reach what would it take to build her do you think so i can tell you the first two obstacles that we have to clear but i dont know how many obstacles there are after this so the image i usually use is that there is a bunch of mountains that we have to climb and we can see the first one but we dont know if there are 50 mountains behind it or not and this might be a good sort of metaphor for why ai researchers in the past have been overly optimistic about the result of ai you know for example noel and simon wrote the general problem solver and they called it the general problem solver general problem solver and of course the first thing you realize is that all the problems you want to solve are exponential and so you cant actually use it for anything useful but you know yeah so yeah all you see is the first peak so in general what are the first couple of peaks for her so the first peak which is precisely what im working on is self supervised learning how do we get machines to run models of the world by observation kind of like babies and like young animals so weve been working with you know cognitive scientists so this emmanuelle dupoux whos at fair in paris is a half time is also a researcher in a french university and he has this chart that shows that which how many months of life baby humans kind of learn different concepts and you can measure this in sort of various ways so things like distinguishing animate objects from inanimate objects you can tell the difference at age two three months whether an object is going to stay stable is going to fall you know about four months you can tell you know there are various things like this and then things like gravity the fact that objects are not supposed to float in the air but are supposed to fall you run this around the age of eight or nine months if you look at the data eight or nine months if you look at a lot of you know eight month old babies you give them a bunch of toys on their high chair first thing they do is they throw them on the ground and they look at them its because you know theyre learning about actively learning about gravity gravity yeah okay so theyre not trying to annoy you but they you know they need to do the experiment right yeah so you know how do we get machines to learn like babies mostly by observation with a little bit of interaction and learning those models of the world because i think thats really a crucial piece of an intelligent autonomous system so if you think about the architecture of an intelligent autonomous system it needs to have a predictive model of the world so something that says here is a world at time t here is a state of the world at time t plus one if i take this action and its not a single answer it can be a yeah it can be a distribution yeah yeah well but we dont know how to represent distributions in high dimensional t spaces so its gotta be something weaker than that okay but with some representation of uncertainty if you have that then you can do what optimal control theorists call model predictive control which means that you can run your model with a hypothesis for a sequence of action and then see the result now what you need the other thing you need is some sort of objective that you want to optimize am i reaching the goal of grabbing this object am i minimizing energy am i whatever right so there is some sort of objective that you have to minimize and so in your head if you have this model you can figure out the sequence of action that will optimize your objective that objective is something that ultimately is rooted in your basal ganglia at least in the human brain thats what its basal ganglia computes your level of contentment or miscontentment i dont know if thats a word unhappiness okay yeah yeah discontentment discontentment maybe and so your entire behavior is driven towards kind of minimizing that objective which is maximizing your contentment computed by your basal ganglia and what you have is an objective function which is basically a predictor of what your basal ganglia is going to tell you so youre not going to put your hand on fire because you know its going to burn and youre going to get hurt and youre predicting this because of your model of the world and your sort of predictor of this objective right so if you have those three components you have four components you have the hardwired objective hardwired contentment objective computer if you want calculator and then you have the three components one is the objective predictor which basically predicts your level of contentment one is the model of the world and theres a third module i didnt mention which is the module that will figure out the best course of action to optimize an objective given your model okay yeah and you can call this a policy network or something like that right now you need those three components to act autonomously intelligently and you can be stupid in three different ways you can be stupid because your model of the world is wrong you can be stupid because your objective is not aligned with what you actually want to achieve okay in humans that would be a psychopath and then the third way you can be stupid is that you have the right model you have the right objective but youre unable to figure out a course of action to optimize your objective given your model okay some people who are in charge of big countries actually have all three that are wrong all right which countries i dont know okay so if we think about this agent if we think about the movie her youve criticized the art project that is sophia the robot and what that project essentially does is uses our natural inclination to anthropomorphize things that look like human and give them more do you think that could be used by ai systems like in the movie her so do you think that body is needed to create a feeling of intelligence well if sophia was just an art piece i would have no problem with it but its presented as something else let me on that comment real quick if creators of sophia could change something about their marketing or behavior in general what would it be whats im just about everything i mean dont you think heres a tough question let me so i agree with you so sophia is not the general public feels that sophia can do way more than she actually can thats right and the people who created sophia are not honestly publicly communicating trying to teach the public right but heres a tough question dont you think the same thing is scientists in industry and research are taking advantage of the same misunderstanding in the public when they create ai companies or publish stuff some companies yes i mean there is no sense of theres no desire to delude theres no desire to kind of over claim when something is done right you publish a paper on ai that has this result on imagenet its pretty clear i mean its not even interesting anymore but i dont think there is that i mean the reviewers are generally not very forgiving of unsupported claims of this type and but there are certainly quite a few startups that have had a huge amount of hype around this that i find extremely damaging and ive been calling it out when ive seen it so yeah but to go back to your original question like the necessity of embodiment i think i dont think embodiment is necessary i think grounding is necessary so i dont think were gonna get machines that really understand language without some level of grounding in the real world and its not clear to me that language is a high enough bandwidth medium to communicate how the real world works so i think for this can you talk to what grounding means so grounding means that so there is this classic problem of common sense reasoning you know the winograd schema right and so i tell you the trophy doesnt fit in the suitcase because its too big or the trophy doesnt fit in the suitcase because its too small and the it in the first case refers to the trophy in the second case to the suitcase and the reason you can figure this out is because you know where the trophy and the suitcase are you know one is supposed to fit in the other one and you know the notion of size and a big object doesnt fit in a small object unless its a tardis you know things like that right so you have this knowledge of how the world works of geometry and things like that i dont believe you can learn everything about the world by just being told in language how the world works i think you need some low level perception of the world you know be it visual touch you know whatever but some higher bandwidth perception of the world by reading all the worlds text you still might not have enough information thats right theres a lot of things that just will never appear in text and that you cant really infer so i think common sense will emerge from you know certainly a lot of language interaction but also with watching videos or perhaps even interacting in virtual environments and possibly you know robot interacting in the real world but i dont actually believe necessarily that this last one is absolutely necessary but i think that theres a need for some grounding but the final product doesnt necessarily need to be embodied youre saying no it just needs to have an awareness a grounding to right but it needs to know how the world works to have you know to not be frustrating to talk to and you talked about emotions being important thats a whole nother topic well so you know i talked about this the basal ganglia as the thing that calculates your level of miscontentment and then there is this other module that sort of tries to do a prediction of whether youre going to be content or not thats the source of some emotion so fear for example is an anticipation of bad things that can happen to you right you have this inkling that there is some chance that something really bad is going to happen to you and that creates fear well you know for sure that something bad is going to happen to you you kind of give up right its not fear anymore its uncertainty that creates fear so the punchline is were not going to have autonomous intelligence without emotions whatever the heck emotions are so you mentioned very practical things of fear but theres a lot of other mess around it but there are kind of the results of you know drives yeah theres deeper biological stuff going on and ive talked to a few folks on this theres fascinating stuff that ultimately connects to our brain if we create an agi system sorry human level intelligence human level intelligence system and you get to ask her one question what would that question be you know i think the first one well create would probably not be that smart theyd be like a four year old okay so you would have to ask her a question to know shes not that smart yeah well whats a good question to ask you know to be impressed what is the cause of wind and if she answers oh its because the leaves of the tree are moving and that creates wind shes onto something and if she says thats a stupid question shes really onto something no and then you tell her actually you know here is the real thing she says oh yeah that makes sense so questions that reveal the ability to do common sense reasoning about the physical world yeah and youll sum it up with causal inference causal inference well it was a huge honor congratulations on your turing award thank you so much for talking today thank you thank you for having me theres a very good set of ideas by written in a paper about 10 years ago by leon boutout who is here at facebook the title of the paper is from machine learning to machine reasoning and his idea is that a learning system should be able to manipulate objects that are in a space and then put the result back in the same space so its this idea of working memory basically and its very enlightening and in a sense that might learn something like the simple expert systems i mean you can learn basic logic operations there yeah quite possibly theres a big debate on sort of how much prior structure you have to put in for this kind of stuff to emerge thats the debate i have with gary marcus and people like that yeah yeah so and the other person so i just talked to judea pearl from the you mentioned causal inference world so his worry is that the current neural networks are not able to learn what causes what causal inference between things so i think hes right and wrong about this if hes talking about the sort of classic type of neural nets people sort of didnt worry too much about this but theres a lot of people now working on causal inference and theres a paper that just came out last week by leon boutou among others david lopez baz and a bunch of other people exactly on that problem of how do you kind of get a neural net to sort of pay attention to real causal relationships which may also solve issues of bias in data and things like this so id like to read that paper because that ultimately the challenges also seems to fall back on the human expert to ultimately decide causality between things people are not very good at establishing causality first of all so first of all you talk to physicists and physicists actually dont believe in causality because look at all the basic laws of microphysics are time reversible so theres no causality the arrow of time is not real yeah its as soon as you start looking at macroscopic systems where there is unpredictable randomness where there is clearly an arrow of time but its a big mystery in physics actually how that emerges is it emergent or is it part of the fundamental fabric of reality or is it a bias of intelligent systems that because of the second law of thermodynamics we perceive a particular arrow of time but in fact its kind of arbitrary right so yeah physicists mathematicians they dont care about i mean the math doesnt care about the flow of time well certainly macrophysics doesnt people themselves are not very good at establishing causal relationships if you ask i think it was in one of seymour paperts book on children learning he studied with jean piaget hes the guy who coauthored the book perceptron with marvin minsky that kind of killed the first wave of neural nets but he was actually a learning person he in the sense of studying learning in humans and machines thats why he got interested in perceptron and he wrote that if you ask a little kid about what is the cause of the wind a lot of kids will say they will think for a while and theyll say oh its the branches in the trees they move and that creates wind right so they get the causal relationship backwards and its because their understanding of the world and intuitive physics is not that great right i mean these are like you know four or five year old kids you know it gets better and then you understand that this it can be right but there are many things which we can because of our common sense understanding of things what people call common sense and our understanding of physics we can theres a lot of stuff that we can figure out causality even with diseases we can figure out whats not causing what often theres a lot of mystery of course but the idea is that you should be able to encode that into systems because it seems unlikely theyd be able to figure that out themselves well whenever we can do intervention but you know all of humanity has been completely deluded for millennia probably since its existence about a very very wrong causal relationship where whatever you can explain you attribute it to you know some deity some divinity right and thats a cop out thats a way of saying like i dont know the cause so you know god did it right so you mentioned marvin minsky and the irony of you know maybe causing the first ai winter you were there in the 90s you were there in the 80s of course in the 90s why do you think people lost faith in deep learning in the 90s and found it again a decade later over a decade later yeah it wasnt called deep learning yet it was just called neural nets but yeah they lost interest i mean i think i would put that around 1995 at least the machine learning community there was always a neural net community but it became kind of disconnected from sort of mainstream machine learning if you want there were it was basically electrical engineering that kept at it and computer science gave up on neural nets i dont know you know i was too close to it to really sort of analyze it with sort of an unbiased eye if you want but i would make a few guesses so the first one is at the time neural nets were it was very hard to make them work in the sense that you would implement backprop in your favorite language and that favorite language was not python it was not matlab it was not any of those things because they didnt exist right you had to write it in fortran oc or something like this right so you would experiment with it you would probably make some very basic mistakes like you know badly initialize your weights make the network too small because you read in the textbook you know you dont want too many parameters right and of course you know and you would train on xor because you didnt have any other data set to trade on and of course you know it works half the time so you would say i give up also you would train it with batch gradient which you know isnt that sufficient so theres a lot of theres a bag of tricks that you had to know to make those things work or you had to reinvent and a lot of people just didnt and they just couldnt make it work so thats one thing the investment in software platform to be able to kind of you know display things figure out why things dont work kind of get a good intuition for how to get them to work have enough flexibility so you can create you know network architectures like convolutional nets and stuff like that it was hard i mean you had to write everything from scratch and again you didnt have any python or matlab or anything right i read that sorry to interrupt but i read that you wrote in lisp the first versions of lanet with convolutional networks which by the way one of my favorite languages thats how i knew you were legit turing award whatever you programmed in lisp thats its still my favorite language but its not that we programmed in lisp its that we had to write our lisp interpreter okay because its not like we used one that existed so we wrote a lisp interpreter that we hooked up to you know a backend library that we wrote also for sort of neural net computation and then after a few years around 1991 we invented this idea of basically having modules that know how to forward propagate and back propagate gradients and then interconnecting those modules in a graph number two had made proposals on this about this in the late eighties and we were able to implement this using our lisp system eventually we wanted to use that system to build production code for character recognition at bell labs so we actually wrote a compiler for that lisp interpreter so that patricia simard who is now at microsoft kind of did the bulk of it with leon and me and so we could write our system in lisp and then compile to c and then well have a self contained complete system that could kind of do the entire thing neither pytorch nor tensorflow can do this today yeah okay its coming yeah i mean theres something like that in pytorch called torchscript and so you know we had to write our lisp interpreter we had to write our lisp compiler we had to invest a huge amount of effort to do this and not everybody if you dont completely believe in the concept youre not going to invest the time to do this now at the time also you know or today this would turn into torch or pytorch or tensorflow or whatever wed put it in open source everybody would use it and you know realize its good back before 1995 working at att theres no way the lawyers would let you release anything in open source of this nature and so we could not distribute our code really and on that point and sorry to go on a million tangents but on that point i also read that there was some almost like a patent on convolutional neural networks at bell labs so that first of all i mean just theres two actually that ran out thankfully in 2007 in 2007 so im gonna what can we just talk about that for a second i know youre a facebook but youre also at nyu and what does it mean to patent ideas like these software ideas essentially or what are mathematical ideas or what are they okay so theyre not mathematical ideas they are you know algorithms and there was a period where the us patent office would allow the patent of software as long as it was embodied the europeans are very different they dont quite accept that they have a different concept but you know i dont i no longer i mean i never actually strongly believed in this but i dont believe in this kind of patent facebook basically doesnt believe in this kind of patent google fires patents because theyve been burned with apple and so now they do this for defensive purpose but usually they say were not gonna sue you if you infringe facebook has a similar policy they say you know we fire patents on certain things for defensive purpose were not gonna sue you if you infringe unless you sue us so the industry does not believe in patents they are there because of you know the legal landscape and various things but i dont really believe in patents for this kind of stuff so thats a great thing so i ill tell you a worse story actually so what happens was the first patent about convolutional net was about kind of the early version of convolutional net that didnt have separate pooling layers it had convolutional layers which tried more than one if you want right and then there was a second one on convolutional nets with separate pooling layers trained with backprop and there were files filed in 89 and 1990 or something like this at the time the life of a patent was 17 years so heres what happened over the next few years is that we started developing character recognition technology around convolutional nets and in 1994 a check reading system was deployed in atm machines in 1995 it was for large check reading machines in back offices et cetera and those systems were developed by an engineering group that we were collaborating with at att and they were commercialized by ncr which at the time was a subsidiary of att now att split up in 1996 early 1996 and the lawyers just looked at all the patents and they distributed the patents among the various companies they gave the convolutional net patent to ncr because they were actually selling products that used it but nobody at ncr had any idea what a convolutional net was yeah okay so between 1996 and 2007 so theres a whole period until 2002 where i didnt actually work on machine learning or convolutional net i resumed working on this around 2002 and between 2002 and 2007 i was working on them crossing my finger that nobody at ncr would notice nobody noticed yeah and i hope that this kind of somewhat as you said lawyers aside relative openness of the community now will continue it accelerates the entire progress of the industry and the problems that facebook and google and others are facing today is not whether facebook or google or microsoft or ibm or whoever is ahead of the other its that we dont have the technology to build the things we want to build we want to build intelligent virtual assistants that have common sense we dont have monopoly on good ideas for this we dont believe we do maybe others believe they do but we dont okay if a startup tells you they have the secret to human level intelligence and common sense dont believe them they dont and its gonna take the entire work of the world research community for a while to get to the point where you can go off and each of those companies kind of start to build things on this were not there yet its absolutely and this calls to the gap between the space of ideas and the rigorous testing of those ideas of practical application that you often speak to youve written advice saying dont get fooled by people who claim to have a solution to artificial general intelligence who claim to have an ai system that works just like the human brain or who claim to have figured out how the brain works ask them what the error rate they get on mnist or imagenet so this is a little dated by the way 2000 i mean five years whos counting okay but i think your opinion is still mnist and imagenet yes may be dated there may be new benchmarks right but i think that philosophy is one you still in somewhat hold that benchmarks and the practical testing the practical application is where you really get to test the ideas well it may not be completely practical like for example it could be a toy data set but it has to be some sort of task that the community as a whole has accepted as some sort of standard kind of benchmark if you want it doesnt need to be real so for example many years ago here at fair people jason west and antoine borne and a few others proposed the babi tasks which were kind of a toy problem to test the ability of machines to reason actually to access working memory and things like this and it was very useful even though it wasnt a real task mnist is kind of halfway real task so toy problems can be very useful its just that i was really struck by the fact that a lot of people particularly a lot of people with money to invest would be fooled by people telling them oh we have the algorithm of the cortex and you should give us 50 million yes absolutely so theres a lot of people who try to take advantage of the hype for business reasons and so on but let me sort of talk to this idea that sort of new ideas the ideas that push the field forward may not yet have a benchmark or it may be very difficult to establish a benchmark i agree thats part of the process establishing benchmarks is part of the process so what are your thoughts about so we have these benchmarks on around stuff we can do with images from classification to captioning to just every kind of information you can pull off from images and the surface level theres audio data sets theres some video what can we start natural language what kind of stuff what kind of benchmarks do you see that start creeping on to more something like intelligence like reasoning like maybe you dont like the term but agi echoes of that kind of formulation a lot of people are working on interactive environments in which you can train and test intelligence systems so there for example its the classical paradigm of supervised learning is that you have a data set you partition it into a training set validation set test set and theres a clear protocol right but what if that assumes that the samples are statistically independent you can exchange them the order in which you see them shouldnt matter things like that but what if the answer you give determines the next sample you see which is the case for example in robotics right you robot does something and then it gets exposed to a new room and depending on where it goes the room would be different so that creates the exploration problem the what if the samples so that creates also a dependency between samples right you if you move if you can only move in space the next sample youre gonna see is gonna be probably in the same building most likely right so all the assumptions about the validity of this training set test set hypothesis break whenever a machine can take an action that has an influence in the world and its what its gonna see so people are setting up artificial environments where that takes place right the robot runs around a 3d model of a house and can interact with objects and things like this so you do robotics based simulation you have those opening a gym type thing or mujoko kind of simulated robots and you have games things like that so thats where the field is going really this kind of environment now back to the question of agi i dont like the term agi because it implies that human intelligence is general and human intelligence is nothing like general its very very specialized we think its general wed like to think of ourselves as having general intelligence we dont were very specialized were only slightly more general than why does it feel general so you kind of the term general i think whats impressive about humans is ability to learn as we were talking about learning to learn in just so many different domains its perhaps not arbitrarily general but just you can learn in many domains and integrate that knowledge somehow okay the knowledge persists so let me take a very specific example yes its not an example its more like a quasi mathematical demonstration so you have about 1 million fibers coming out of one of your eyes okay 2 million total but lets talk about just one of them its 1 million nerve fibers your optical nerve lets imagine that they are binary so they can be active or inactive right so the input to your visual cortex is 1 million bits mm hmm now theyre connected to your brain in a particular way and your brain has connections that are kind of a little bit like a convolutional net theyre kind of local you know in space and things like this now imagine i play a trick on you its a pretty nasty trick i admit i cut your optical nerve and i put a device that makes a random perturbation of a permutation of all the nerve fibers so now what comes to your brain is a fixed but random permutation of all the pixels theres no way in hell that your visual cortex even if i do this to you in infancy will actually learn vision to the same level of quality that you can got it and youre saying theres no way youve learned that no because now two pixels that are nearby in the world will end up in very different places in your visual cortex and your neurons there have no connections with each other because theyre only connected locally so this whole our entire the hardware is built in many ways to support the locality of the real world yes thats specialization yeah but its still pretty damn impressive so its not perfect generalization its not even close no no its not that its not even close its not at all yeah its not its specialized yeah so how many boolean functions so lets imagine you want to train your visual system to recognize particular patterns of those one million bits okay so thats a boolean function right either the pattern is here or not here this is a two way classification with one million binary inputs how many such boolean functions are there okay you have two to the one million combinations of inputs for each of those you have an output bit and so you have two to the one million boolean functions of this type okay which is an unimaginably large number how many of those functions can actually be computed by your visual cortex and the answer is a tiny tiny tiny tiny tiny tiny sliver like an enormously tiny sliver yeah yeah so we are ridiculously specialized okay but okay thats an argument against the word general i think theres a i agree with your intuition but im not sure its it seems the brain is impressively capable of adjusting to things so its because we cant imagine tasks that are outside of our comprehension right so we think were general because were general of all the things that we can apprehend but there is a huge world out there of things that we have no idea we call that heat by the way heat heat so at least physicists call that heat or they call it entropy which is kind of you have a thing full of gas right closed system for gas right closed or not closed it has pressure it has temperature it has you know and you can write equations pv equal n on t you know things like that right when you reduce the volume the temperature goes up the pressure goes up you know things like that right for perfect gas at least those are the things you can know about that system and its a tiny tiny number of bits compared to the complete information of the state of the entire system because the state of the entire system will give you the position of momentum of every molecule of the gas and what you dont know about it is the entropy and you interpret it as heat the energy contained in that thing is what we call heat now its very possible that in fact there is some very strong structure in how those molecules are moving its just that they are in a way that we are just not wired to perceive yeah were ignorant to it and theres in your infinite amount of things were not wired to perceive and youre right thats a nice way to put it were general to all the things we can imagine which is a very tiny subset of all things that are possible so its like comograph complexity or the comograph chitin sum of complexity yeah you know every bit string or every integer is random except for all the ones that you can actually write down yeah yeah yeah yeah yeah yeah yeah okay so beautifully put but you know so we can just call it artificial intelligence we dont need to have a general or human level human level intelligence is good you know youll start anytime you touch human it gets interesting because you know its because we attach ourselves to human and its difficult to define what human intelligence is yeah nevertheless my definition is maybe dem impressive intelligence okay dem impressive demonstration of intelligence whatever and so on that topic most successes in deep learning have been in supervised learning what is your view on unsupervised learning is there a hope to reduce involvement of human input and still have successful systems that have practical use yeah i mean theres definitely a hope its more than a hope actually its mounting evidence for it and thats basically all i do like the only thing im interested in at the moment is i call it self supervised learning not unsupervised because unsupervised learning is a loaded term people who know something about machine learning you know tell you so youre doing clustering or pca which is not the case and the white public you know when you say unsupervised learning oh my god machines are gonna learn by themselves without supervision you know they see this as wheres the parents yeah so i call it self supervised learning because in fact the underlying algorithms that are used are the same algorithms as the supervised learning algorithms except that what we train them to do is not predict a particular set of variables like the category of an image and not to predict a set of variables that have been provided by human labelers but what youre trying the machine to do is basically reconstruct a piece of its input that is being maxed out essentially you can think of it this way right so show a piece of video to a machine and ask it to predict whats gonna happen next and of course after a while you can show what happens and the machine will kind of train itself to do better at that task you can do like all the latest most successful models in natural language processing use self supervised learning you know sort of bert style systems for example right you show it a window of a dozen words on a text corpus you take out 15 of the words and then you train the machine to predict the words that are missing that self supervised learning its not predicting the future its just predicting things in the middle but you could have it predict the future thats what language models do so you construct so in an unsupervised way you construct a model of language do you think or video or the physical world or whatever right how far do you think that can take us do you think bert understands anything to some level it has a shallow understanding of text but it needs to i mean to have kind of true human level intelligence i think you need to ground language in reality so some people are attempting to do this right having systems that kind of have some visual representation of what is being talked about which is one reason you need those interactive environments actually but this is like a huge technical problem that is not solved and that explains why self supervised learning works in the context of natural language but does not work in the context or at least not well in the context of image recognition and video although its making progress quickly and the reason that reason is the fact that its much easier to represent uncertainty in the prediction in a context of natural language than it is in the context of things like video and images so for example if i ask you to predict what words are missing 15 of the words that ive taken out the possibilities are small that means its small right there is 100000 words in the lexicon and what the machine spits out is a big probability vector right its a bunch of numbers between zero and one that sum to one and we know how to do this with computers so there representing uncertainty in the prediction is relatively easy and thats in my opinion why those techniques work for nlp for images if you ask if you block a piece of an image and you ask the system reconstruct that piece of the image there are many possible answers they are all perfectly legit right and how do you represent this set of possible answers you cant train a system to make one prediction you cant train a neural net to say here it is thats the image because theres a whole set of things that are compatible with it so how do you get the machine to represent not a single output but a whole set of outputs and similarly with video prediction theres a lot of things that can happen in the future of video youre looking at me right now im not moving my head very much but i might turn my head to the left or to the right if you dont have a system that can predict this and you train it with least square to minimize the error with the prediction and what im doing what you get is a blurry image of myself in all possible future positions that i might be in which is not a good prediction so there might be other ways to do the self supervision for visual scenes like what i mean if i knew i wouldnt tell you publish it first i dont know no there might be so i mean these are kind of there might be artificial ways of like self play in games the way you can simulate part of the environment oh that doesnt solve the problem its just a way of generating data but because you have more of a control like maybe you can control yeah its a way to generate data thats right and because you can do huge amounts of data generation that doesnt youre right well it creeps up on the problem from the side of data and you dont think thats the right way to creep up it doesnt solve this problem of handling uncertainty in the world right so if you have a machine learn a predictive model of the world in a game that is deterministic or quasi deterministic its easy right just give a few frames of the game to a convnet put a bunch of layers and then have the game generates the next few frames and if the game is deterministic it works fine and that includes feeding the system with the action that your little character is gonna take the problem comes from the fact that the real world and most games are not entirely predictable and so there you get those blurry predictions and you cant do planning with blurry predictions right so if you have a perfect model of the world you can in your head run this model with a hypothesis for a sequence of actions and youre going to predict the outcome of that sequence of actions but if your model is imperfect how can you plan yeah it quickly explodes what are your thoughts on the extension of this which topic im super excited about its connected to something you were talking about in terms of robotics is active learning so as opposed to sort of completely unsupervised or self supervised learning you ask the system for human help for selecting parts you want annotated next so if you think about a robot exploring a space or a baby exploring a space or a system exploring a data set every once in a while asking for human input do you see value in that kind of work i dont see transformative value its going to make things that we can already do more efficient or they will learn slightly more efficiently but its not going to make machines sort of significantly more intelligent i think and by the way there is no opposition theres no conflict between self supervised learning reinforcement learning and supervised learning or imitation learning or active learning i see self supervised learning as a preliminary to all of the above yes so the example i use very often is how is it that so if you use classical reinforcement learning deep reinforcement learning if you want the best methods today so called model free reinforcement learning to learn to play atari games take about 80 hours of training to reach the level that any human can reach in about 15 minutes they get better than humans but it takes them a long time alpha star okay the you know aureal vinyals and his teams the system to play starcraft plays you know a single map a single type of player a single player and can reach better than human level with about the equivalent of 200 years of training playing against itself its 200 years right its not something that no human can ever do i mean im not sure what lesson to take away from that okay now take those algorithms the best algorithms we have today to train a car to drive itself it would probably have to drive millions of hours it will have to kill thousands of pedestrians it will have to run into thousands of trees it will have to run off cliffs and it had to run off cliff multiple times before it figures out that its a bad idea first of all and second of all before it figures out how not to do it and so i mean this type of learning obviously does not reflect the kind of learning that animals and humans do there is something missing thats really really important there and my hypothesis which ive been advocating for like five years now is that we have predictive models of the world that include the ability to predict under uncertainty and what allows us to not run off a cliff when we learn to drive most of us can learn to drive in about 20 or 30 hours of training without ever crashing causing any accident and if we drive next to a cliff we know that if we turn the wheel to the right the car is gonna run off the cliff and nothing good is gonna come out of this because we have a pretty good model of intuitive physics that tells us the car is gonna fall we know about gravity babies learn this around the age of eight or nine months that objects dont float they fall and we have a pretty good idea of the effect of turning the wheel on the car and we know we need to stay on the road so theres a lot of things that we bring to the table which is basically our predictive model of the world and that model allows us to not do stupid things and to basically stay within the context of things we need to do we still face unpredictable situations and thats how we learn but that allows us to learn really really really quickly so thats called model based reinforcement learning theres some imitation and supervised learning because we have a driving instructor that tells us occasionally what to do but most of the learning is learning the model learning physics that weve done since we were babies thats where all almost all the learning and the physics is somewhat transferable from its transferable from scene to scene stupid things are the same everywhere yeah i mean if you have experience of the world you dont need to be from a particularly intelligent species to know that if you spill water from a container the rest is gonna get wet you might get wet so cats know this right yeah right so the main problem we need to solve is how do we learn models of the world thats what im interested in thats what self supervised learning is all about if you were to try to construct a benchmark for lets look at mnist i love that data set do you think its useful interesting slash possible to perform well on mnist with just one example of each digit and how would we solve that problem the answer is probably yes the question is what other type of learning are you allowed to do so if what youre allowed to do is train on some gigantic data set of labeled digit thats called transfer learning and we know that works okay we do this at facebook like in production right we train large convolutional nets to predict hashtags that people type on instagram and we train on billions of images literally billions and then we chop off the last layer and fine tune on whatever task we want that works really well you can beat the imagenet record with this we actually open sourced the whole thing like a few weeks ago yeah thats still pretty cool but yeah so what would be impressive whats useful and impressive what kind of transfer learning would be useful and impressive is it wikipedia that kind of thing no no so i dont think transfer learning is really where we should focus we should try to do you know have a kind of scenario for benchmark where you have unlabeled data and you can and its very large number of unlabeled data it could be video clips it could be where you do you know frame prediction it could be images where you could choose to you know mask a piece of it could be whatever but theyre unlabeled and youre not allowed to label them so you do some training on this and then you train on a particular supervised task imagenet or a nist and you measure how your test error decrease or validation error decreases as you increase the number of label training samples okay and what youd like to see is that you know your error decreases much faster than if you train from scratch from random weights so that to reach the same level of performance and a completely supervised purely supervised system would reach you would need way fewer samples so thats the crucial question because it will answer the question to like you know people interested in medical image analysis okay you know if i want to get to a particular level of error rate for this task i know i need a million samples can i do you know self supervised pre training to reduce this to about 100 or something and you think the answer there is self supervised pre training yeah some form some form of it telling you active learning but you disagree no its not useless its just not gonna lead to a quantum leap its just gonna make things that we already do so youre way smarter than me i just disagree with you but i dont have anything to back that its just intuition so i worked a lot of large scale data sets and theres something that might be magic in active learning but okay and at least i said it publicly at least im being an idiot publicly okay its not being an idiot its you know working with the data you have i mean i mean certainly people are doing things like okay i have 3000 hours of you know imitation learning for start driving car', 'the following is a conversation with vijay kumar hes one of the top roboticists in the world a professor at the university of pennsylvania a dean of pen engineering former director of grasp lab or the general robotics automation sensing and perception laboratory at penn that was established back in 1979 thats 40 years ago vijay is perhaps best known for his work in multi robot systems robot swarms and micro aerial vehicles robots that elegantly cooperate in flight under all the uncertainty and challenges that the real world conditions present this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with vijay kumar what is the first robot youve ever built or were a part of building way back when i was in graduate school i was part of a fairly big project that involved building a very large hexapod its weighed close to 7000 pounds and it was powered by hydraulic actuation or it was actuated by hydraulics with 18 motors hydraulic motors each controlled by an intel 8085 processor and an 8086 co processor and so imagine this huge monster that had 18 joints each controlled by an independent computer and there was a 19th computer that actually did the coordination between these 18 joints so i was part of this project and my thesis work was how do you coordinate the 18 legs and in particular the pressures in the hydraulic cylinders to get efficient locomotion it sounds like a giant mess so how difficult is it to make all the motors communicate presumably you have to send signals hundreds of times a second or at least so this was not my work but the folks who worked on this wrote what i believe to be the first multiprocessor operating system this was in the 80s and you had to make sure that obviously messages got across from one joint to another you have to remember the clock speeds on those computers were about half a megahertz right the 80s so not to romanticize the notion but how did it make you feel to see that robot move it was amazing in hindsight it looks like well we built this thing which really should have been much smaller and of course todays robots are much smaller you look at boston dynamics or ghost robotics a spinoff from penn but back then you were stuck with the substrate you had the compute you had so things were unnecessarily big but at the same time and this is just human psychology somehow bigger means grander people never had the same appreciation for nanotechnology or nanodevices as they do for the space shuttle or the boeing 747 yeah youve actually done quite a good job at illustrating that small is beautiful in terms of robotics so what is on that topic is the most beautiful or elegant robot in motion that youve ever seen not to pick favorites or whatever but something that just inspires you that you remember well i think the thing that im most proud of that my students have done is really think about small uavs that can maneuver in constrained spaces and in particular their ability to coordinate with each other and form three dimensional patterns so once you can do that you can essentially create 3d objects in the sky and you can deform these objects on the fly so in some sense your toolbox of what you can create has suddenly got enhanced and before that we did the two dimensional version of this so we had ground robots forming patterns and so on so that was not as impressive that was not as beautiful but if you do it in 3d suspended in midair and youve got to go back to 2011 when we did this now its actually pretty standard to do these things eight years later but back then it was a big accomplishment so the distributed cooperation is where beauty emerges in your eyes well i think beauty to an engineer is very different from beauty to someone whos looking at robots from the outside if you will but what i meant there so before we said that grand so before we said that grand is associated with size and another way of thinking about this is just the physical shape and the idea that you can get physical shapes in midair and have them deform thats beautiful but the individual components the agility is beautiful too right that is true too so then how quickly can you actually manipulate these three dimensional shapes and the individual components yes youre right but by the way you said uav unmanned aerial vehicle whats a good term for drones uavs quad copters is there a term thats being standardized i dont know if there is everybody wants to use the word drones and ive often said this drones to me is a pejorative word it signifies something thats dumb thats pre programmed that does one little thing and robots are anything but drones so i actually dont like that word but thats what everybody uses you could call it unpiloted unpiloted but even unpiloted could be radio controlled could be remotely controlled in many different ways and i think the right word is thinking about it as an aerial robot you also say agile autonomous aerial robot right yeah so agility is an attribute but they dont have to be so what biological system because youve also drawn a lot of inspiration with those ive seen bees and ants that youve talked about what living creatures have you found to be most inspiring as an engineer instructive in your work in robotics to me so ants are really quite incredible creatures right so you i mean the individuals arguably are very simple in how theyre built and yet theyre incredibly resilient as a population and as individuals theyre incredibly robust so if you take an ant its six legs you remove one leg it still works just fine and it moves along and i dont know that he even realizes its lost a leg so thats the robustness at the individual ant level but then you look about this instinct for self preservation of the colonies and they adapt in so many amazing ways you know transcending gaps by just chaining themselves together when you have a flood being able to recruit other teammates to carry big morsels of food and then going out in different directions looking for food and then being able to demonstrate consensus even though they dont communicate directly with each other the way we communicate with each other in some sense they also know how to do democracy probably better than what we do yeah somehow its even democracy is emergent it seems like all of the phenomena that we see is all emergent it seems like theres no centralized communicator there is so i think a lot is made about that word emergent and it means lots of things to different people but youre absolutely right i think as an engineer you think about what element elemental behaviors were primitives you could synthesize so that the whole looks incredibly powerful incredibly synergistic the whole definitely being greater than some of the parts and ants are living proof of that so when you see these beautiful swarms where theres biological systems of robots do you sometimes think of them as a single individual living intelligent organism so its the same as thinking of our human beings are human civilization as one organism or do you still as an engineer think about the individual components and all the engineering that went into the individual components well thats very interesting so again philosophically as engineers what we wanna do is to go beyond the individual components the individual units and think about it as a unit as a cohesive unit without worrying about the individual components if you start obsessing about the individual building blocks and what they do you inevitably will find it hard to scale up just mathematically just think about individual things you wanna model and if you want to have 10 of those then you essentially are taking cartesian products of 10 things and that makes it really complicated then to do any kind of synthesis or design in that high dimension space is really hard so the right way to do this is to think about the individuals in a clever way so that at the higher level when you look at lots and lots of them abstractly you can think of them in some low dimensional space so what does that involve for the individual do you have to try to make the way they see the world as local as possible and the other thing do you just have to make them robust to collisions like you said with the ants if something fails the whole swarm doesnt fail right i think as engineers we do this i mean you think about we build planes or we build iphones and we know that by taking individual components well engineered components with well specified interfaces that behave in a predictable way you can build complex systems so thats ingrained i would claim in most engineers thinking and its true for computer scientists as well i think whats different here is that you want the individuals to be robust in some sense as we do in these other settings but you also want some degree of resiliency for the population and so you really want them to be able to reestablish communication with their neighbors you want them to rethink their strategy for group behavior you want them to reorganize and thats where i think a lot of the challenges lie so just at a high level what does it take for a bunch of what should we call them flying robots to create a formation just for people who are not familiar with robotics in general how much information is needed how do you even make it happen without a centralized controller so i mean there are a couple of different ways of looking at this if you are a purist you think of it as a way of recreating what nature does so nature forms groups for several reasons but mostly its because of this instinct that organisms have of preserving their colonies their population which means what you need shelter you need food you need to procreate and thats basically it so the kinds of interactions you see are all organic theyre all local and the only information that they share and mostly its indirectly is to again preserve the herd or the flock or the swarm and either by looking for new sources of food or looking for new shelters right right as engineers when we build swarms we have a mission and when you think of a mission and it involves mobility most often its described in some kind of a global coordinate system as a human as an operator as a commander or as a collaborator i have my coordinate system and i want the robots to be consistent with that so i might think of it slightly differently i might want the robots to recognize that coordinate system which means not only do they have to think locally in terms of who their immediate neighbors are but they have to be cognizant of what the global environment is they have to be cognizant of what the global environment looks like so if i say surround this building and protect this from intruders well theyre immediately in a building centered coordinate system and i have to tell them where the building is and theyre globally collaborating on the map of that building theyre maintaining some kind of global not just in the frame of the building but theres information thats ultimately being built up explicitly as opposed to kind of implicitly like nature might correct correct so in some sense nature is very very sophisticated but the tasks that nature solves or needs to solve are very different from the kind of engineered tasks artificial tasks that we are forced to address and again theres nothing preventing us from solving these other problems but ultimately its about impact you want these swarms to do something useful and so youre kind of driven into this very unnatural if you will unnatural meaning not like how nature does setting and its probably a little bit more expensive to do it the way nature does because nature is less sensitive to the loss of the individual and cost wise in robotics i think youre more sensitive to losing individuals i think thats true although if you look at the price to performance ratio of robotic components its coming down dramatically right it continues to come down so i think were asymptotically approaching the point where we would get yeah the cost of individuals would really become insignificant so lets step back at a high level view the impossible question of what kind of as an overview what kind of autonomous flying vehicles are there in general i think the ones that receive a lot of notoriety are obviously the military vehicles military vehicles are controlled by a base station but have a lot of human supervision but they have limited autonomy which is the ability to go from point a to point b and even the more sophisticated now sophisticated vehicles can do autonomous takeoff and landing and those usually have wings and theyre heavy usually theyre wings but then theres nothing preventing us from doing this for helicopters as well there are many military organizations that have autonomous helicopters in the same vein and by the way you look at autopilots and airplanes and its actually very similar in fact one interesting question we can ask is if you look at all the air safety violations all the crashes that occurred would they have happened if the plane were truly autonomous and i think youll find that in many of the cases because of pilot error we made silly decisions and so in some sense even in air traffic commercial air traffic theres a lot of applications although we only see autonomy being enabled at very high altitudes when the plane is an autopilot the plane is an autopilot theres still a role for the human and that kind of autonomy is youre kind of implying i dont know what the right word is but its a little dumber than it could be right so in the lab of course we can afford to be a lot more aggressive and the question we try to ask is can we make robots that will be able to make decisions without any kind of external infrastructure so what does that mean so the most common piece of infrastructure that airplanes use today is gps gps is also the most brittle form of information if you have driven in a city try to use gps navigation in tall buildings you immediately lose gps and so thats not a very sophisticated way of building autonomy i think the second piece of infrastructure they rely on is communications again its very easy to jam communications in fact if you use wifi you know that wifi signals drop out cell signals drop out so to rely on something like that is not good the third form of infrastructure we use and i hate to call it infrastructure but it is that in the sense of robots is people so you could rely on somebody to pilot you and so the question you wanna ask is if there are no pilots theres no communications with any base station if theres no knowledge of position and if theres no a priori map a priori knowledge of what the environment looks like a priori model of what might happen in the future can robots navigate so that is true autonomy so thats true autonomy and were talking about you mentioned like military application of drones okay so what else is there you talk about agile autonomous flying robots aerial robots so thats a different kind of its not winged its not big at least its small so i use the word agility mostly or at least were motivated to do agile robots mostly because robots can operate and should be operating in constrained environments and if you want to operate the way a global hawk operates i mean the kinds of conditions in which you operate are very very restrictive if you wanna go inside a building for example for search and rescue or to locate an active shooter or you wanna navigate under the canopy in an orchard to look at health of plants or to look for to count fruits to measure the tree trunks these are things we do by the way theres some cool agriculture stuff youve shown in the past its really awesome so in those kinds of settings you do need that agility agility does not necessarily mean you break records for the 100 meters dash what it really means is you see the unexpected and youre able to maneuver in a safe way and in a way that gets you the most information about the thing youre trying to do by the way you may be the only person who in a ted talk has used a math equation which is amazing people should go see one of your ted talks actually its very interesting because the ted curator chris anderson told me you cant show math and i thought about it but thats who i am i mean thats our work and so i felt compelled to give the audience a taste for at least some math so on that point simply what does it take to make a thing with four motors fly a quadcopter one of these little flying robots how hard is it to make it fly how do you coordinate the four motors how do you convert those motors into actual movement so this is an interesting question weve been trying to do this since 2000 it is a commentary on the sensors that were available back then the computers that were available back then and a number of things happened between 2000 and 2007 one is the advances in computing which is so we all know about moores law but i think 2007 was a tipping point the year of the iphone the year of the cloud lots of things happened in 2007 but going back even further inertial measurement units as a sensor really matured again lots of reasons for that certainly theres a lot of federal funding particularly darpa in the us but they didnt anticipate this boom in imus but if you look subsequently what happened is that every car manufacturer had to put an airbag in which meant you had to have an accelerometer on board and so that drove down the price to performance ratio wow i should know this thats very interesting thats very interesting the connection there and thats why research is very its very hard to predict the outcomes and again the federal government spent a ton of money on things that they thought were useful for resonators but it ended up enabling these small uavs which is great because i could have never raised that much money and sold this project hey we want to build these small uavs can you actually fund the development of low cost imus so why do you need an imu on an imu so ill come back to that so in 2007 2008 we were able to build these and then the question youre asking was a good one how do you coordinate the motors to develop this but over the last 10 years everything is commoditized a high school kid today can pick up a raspberry pi kit and build this all the low levels functionality is all automated but basically at some level you have to drive the motors at the right rpms the right velocity in order to generate the right amount of thrust in order to position it and orient it in a way that you need to in order to fly the feedback that you get is from onboard sensors and the imu is an important part of it the imu tells you what the acceleration is as well as what the angular velocity is and those are important pieces of information in addition to that you need some kind of local position or velocity information for example when we walk we implicitly have this information because we kind of know what our stride length is we also are looking at images fly past our retina if you will and so we can estimate velocity we also have accelerometers in our head and were able to integrate all these pieces of information to determine where we are as we walk and so robots have to do something very similar you need an imu you need some kind of a camera or other sensor thats measuring velocity and then you need some kind of a global reference frame if you really want to think about doing something in a world coordinate system and so how do you estimate your position with respect to that global reference frame thats important as well so coordinating the rpms of the four motors is what allows you to first of all fly and hover and then you can change the orientation and the velocity and so on exactly exactly so its a bunch of degrees of freedom that youre complaining about theres six degrees of freedom but you only have four inputs the four motors and it turns out to be a remarkably versatile configuration you think at first well i only have four motors how do i go sideways but its not too hard to say well if i tilt myself i can go sideways and then you have four motors pointing up how do i rotate in place about a vertical axis well you rotate them at different speeds and that generates reaction moments and that allows you to turn so its actually a pretty its an optimal configuration from an engineer standpoint its very simple very cleverly done and very versatile so if you could step back to a time so ive always known flying robots as to me it was natural that a quadcopter should fly but when you first started working with it how surprised are you that you can make do so much with the four motors how surprising is it that you can make this thing fly first of all that you can make it hover that you can add control to it firstly this is not the four motor configuration is not ours you can it has at least a hundred year history and various people various people try to get quadrotors to fly without much success as i said weve been working on this since 2000 our first designs were well this is way too complicated why not we try to get an omnidirectional flying robot so our early designs we had eight rotors and so these eight rotors were arranged uniformly on a sphere if you will so you can imagine a symmetric configuration and so you should be able to fly anywhere but the real challenge we had is the strength to weight ratio is not enough and of course we didnt have the sensors and so on so everybody knew or at least the people who worked with rotorcrafts knew four rotors will get it done so that was not our idea but it took a while before we could actually do the onboard sensing and the computation that was needed for the kinds of agile maneuvering that we wanted to do in our little aerial robots and that only happened between 2007 and 2009 in our lab yeah and you have to send the signal maybe a hundred times a second so the compute there everything has to come down in price and what are the steps of getting from point a to point b so we just talked about like local control but if all the kind of cool dancing in the air that ive seen you show how do you make it happen how do you make a trajectory first of all okay figure out a trajectory so plan a trajectory and then how do you make that trajectory happen yeah i think planning is a very fundamental problem in robotics i think 10 years ago it was an esoteric thing but today with self driving cars everybody can understand this basic idea that a car sees a whole bunch of things and it has to keep a lane or maybe make a right turn or switch lanes it has to plan a trajectory it has to be safe it has to be efficient so everybodys familiar with that thats kind of the first step that you have to think about when you say autonomy and so for us its about finding smooth motions motions that are safe so we think about these two things one is optimality one is safety clearly you cannot compromise safety so youre looking for safe optimal motions the other thing you have to think about is can you actually compute a reasonable trajectory in a small amount of time cause you have a time budget so the optimal becomes suboptimal but in our lab we focus on synthesizing smooth trajectory that satisfy all the constraints in other words dont violate any safety constraints and is as efficient as possible and when i say efficient it could mean i want to get from point a to point b as quickly as possible or i want to get to it as gracefully as possible or i want to consume as little energy as possible but always staying within the safety constraints but yes always finding a safe trajectory so theres a lot of excitement and progress in the field of machine learning and reinforcement learning and the neural network variant of that with deep reinforcement learning do you see a role of machine learning in so a lot of the success of flying robots did not rely on machine learning except for maybe a little bit of the perception on the computer vision side on the control side and the planning do you see theres a role in the future for machine learning so let me disagree a little bit with you i think we never perhaps called out in my work called out learning but even this very simple idea of being able to fly through a constrained space the first time you try it youll invariably you might get it wrong if the task is challenging and the reason is to get it perfectly right you have to model everything in the environment and flying is notoriously hard to model there are aerodynamic effects that we constantly discover even just before i was talking to you i was talking to a student about how blades flap when they fly and that ends up changing how a rotorcraft is accelerated in the angular direction does he use like micro flaps or something its not micro flaps so we assume that each blade is rigid but actually it flaps a little bit it bends interesting yeah and so the models rely on the fact on the assumption that theyre not rigid on the assumption that theyre actually rigid but thats not true if youre flying really quickly these effects become significant if youre flying close to the ground you get pushed off by the ground right something which every pilot knows when he tries to land or she tries to land this is called a ground effect something very few pilots think about is what happens when you go close to a ceiling or you get sucked into a ceiling there are very few aircrafts that fly close to any kind of ceiling likewise when you go close to a wall there are these wall effects and if youve gone on a train and you pass another train thats traveling in the opposite direction you feel the buffeting and so these kinds of microclimates affect our uav significantly so if you want and theyre impossible to model essentially i wouldnt say theyre impossible to model but the level of sophistication you would need in the model and the software would be tremendous plus to get everything right would be awfully tedious so the way we do this is over time we figure out how to adapt to these conditions so early on we use the form of learning that we call iterative learning so this idea if you want to perform a task there are a few things that you need to change and iterate over a few parameters that over time you can figure out so i could call it policy gradient reinforcement learning but actually it was just iterative learning iterative learning and so this was there way back i think whats interesting is if you look at autonomous vehicles today learning occurs could occur in two pieces one is perception understanding the world second is action taking actions everything that ive seen that is successful is on the perception side of things so in computer vision weve made amazing strides in the last 10 years so recognizing objects actually detecting objects classifying them and tagging them in some sense annotating them this is all done through machine learning on the action side on the other hand i dont know of any examples where there are fielded systems where we actually learn the right behavior outside of single demonstration is successful in the laboratory this is the holy grail can you do end to end learning can you go from pixels to motor currents this is really really hard and i think if you go forward the right way to think about these things is data driven approaches learning based approaches in concert with model based approaches which is the traditional way of doing things so i think theres a piece theres a role for each of these methodologies so what do you think just jumping out on topic since you mentioned autonomous vehicles what do you think are the limits on the perception side so ive talked to elon musk and there on the perception side theyre using primarily computer vision to perceive the environment in your work with because you work with the real world a lot and the physical world what are the limits of computer vision do you think we can solve autonomous vehicles on the perception side focusing on vision alone and machine learning so we also have a spinoff company exxon technologies that works underground in mines so you go into mines theyre dark theyre dirty you fly in a dirty area theres stuff you kick up from by the propellers the downwash kicks up dust i challenge you to get a computer vision algorithm to work there so we use lidars in that setting indoors and even outdoors when we fly through fields i think theres a lot of potential for just solving the problem using computer vision alone but i think the bigger question is can you actually solve or can you actually identify all the corner cases using a single sensing modality and using learning alone so whats your intuition there so look if you have a corner case and your algorithm doesnt work your instinct is to go get data about the corner case and patch it up learn how to deal with that corner case but at some point this is gonna saturate this approach is not viable so today computer vision algorithms can detect 90 of the objects or can detect objects 90 of the time classify them 90 of the time cats on the internet probably can do 95 i dont know but to get from 90 to 99 you need a lot more data and then i tell you well thats not enough because i have a safety critical application i wanna go from 99 to 999 thats even more data so i think if you look at wanting accuracy on the x axis and look at the amount of data on the y axis i believe that curve is an exponential curve wow okay its even hard if its linear its hard if its linear totally but i think its exponential and the other thing you have to think about is that this process is a very very power hungry process to run data farms or servers power do you mean literally power literally power literally power so in 2014 five years ago and i dont have more recent data 2 of us electricity consumption was from data farms so we think about this as an information science and information processing problem actually it is an energy processing problem and so unless we figured out better ways of doing this i dont think this is viable so talking about driving which is a safety critical application and some aspect of flight is safety critical maybe philosophical question maybe an engineering one what problem do you think is harder to solve autonomous driving or autonomous flight thats a really interesting question i think autonomous flight has several advantages that autonomous driving doesnt have so look if i want to go from point a to point b i have a very very safe trajectory go vertically up to a maximum altitude fly horizontally to just about the destination and then come down vertically this is preprogrammed the equivalent of that is very hard to find in the self driving car world because youre on the ground youre in a two dimensional surface and the trajectories on the two dimensional surface are more likely to encounter obstacles i mean this in an intuitive sense but mathematically true thats mathematically as well thats true theres other option on the 2g space of platooning or because theres so many obstacles you can connect with those obstacles and all these kind of options sure but those exist in the three dimensional space as well so they do so the question also implies how difficult are obstacles in the three dimensional space in flight so thats the downside i think in three dimensional space youre modeling three dimensional world not just because you want to avoid it but you want to reason about it and you want to work in the three dimensional environment and thats significantly harder so thats one disadvantage i think the second disadvantage is of course anytime you fly you have to put up with the peculiarities of aerodynamics and their complicated environments how do you negotiate that so thats always a problem do you see a time in the future where there is you mentioned theres agriculture applications so theres a lot of applications of flying robots but do you see a time in the future where theres tens of thousands or maybe hundreds of thousands of delivery drones that fill the sky delivery flying robots i think theres a lot of potential for the last mile delivery and so in crowded cities i dont know if you go to a place like hong kong just crossing the river can take half an hour and while a drone can just do it in five minutes at most i think you look at delivery of supplies to remote villages i work with a nonprofit called weave robotics so they work in the peruvian amazon where the only highways that are available are the only highways or rivers and to get from point a to point b may take five hours while with a drone you can get there in 30 minutes so just delivering drugs retrieving samples for testing vaccines i think theres huge potential here so i think the challenges are not technological but the challenge is economical the one thing ill tell you that nobody thinks about is the fact that weve not made huge strides in battery technology yes its true batteries are becoming less expensive because we have these mega factories that are coming up but theyre all based on lithium based technologies and if you look at the energy density and the power density those are two fundamentally limiting numbers so power density is important because for a uav to take off vertically into the air which most drones do they dont have a runway you consume roughly 200 watts per kilo at the small size thats a lot right in contrast the human brain consumes less than 80 watts the whole of the human brain so just imagine just lifting yourself into the air is like two or three light bulbs which makes no sense to me yeah so youre going to have to at scale solve the energy problem then charging the batteries storing the energy and so on and then the storage is the second problem but storage limits the range but you have to remember that you have to burn a lot of it per given time so the burning is another problem which is a power question yes and do you think just your intuition there are breakthroughs in batteries on the horizon how hard is that problem look there are a lot of companies that are promising flying cars that are autonomous and that are clean i think theyre over promising the autonomy piece is doable the clean piece i dont think so theres another company that i work with called jetoptra they make small jet engines and they can get up to 50 miles an hour very easily and lift 50 kilos but theyre jet engines theyre efficient theyre a little louder than electric vehicles but they can build flying cars so your sense is that theres a lot of pieces that have come together so on this crazy question if you look at companies like kitty hawk working on electric so the clean talking to sebastian thrun right its a crazy dream you know but you work with flight a lot youve mentioned before that manned flights or carrying a human body is very difficult to do so how crazy is flying cars do you think therell be a day when we have vertical takeoff and landing vehicles that are sufficiently affordable that were going to see a huge amount of them and they would look like something like we dream of when we think about flying cars yeah like the jetsons the jetsons yeah so look there are a lot of smart people working on this and you never say something is not possible when you have people like sebastian thrun working on it so i totally think its viable i question again the electric piece the electric piece yeah and again for short distances you can do it and theres no reason to suggest that these all just have to be rotorcrafts you take off vertically but then you morph into a forward flight i think there are a lot of interesting designs the question to me is are these economically viable and if you agree to do this with fossil fuels it instantly immediately becomes viable thats a real challenge do you think its possible for robots and humans to collaborate successfully on tasks so a lot of robotics folks that i talk to and work with i mean humans just add a giant mess to the picture so its best to remove them from consideration when solving specific tasks its very difficult to model theres just a source of uncertainty in your work with these agile flying robots do you think theres a role for collaboration with humans or is it best to model tasks in a way that doesnt have a human in the picture well i dont think we should ever think about robots without human in the picture ultimately robots are there because we want them to solve problems for humans but theres no general solution to this problem i think if you look at human interaction and how humans interact with robots you know we think of these in sort of three different ways one is the human commanding the robot the second is the human collaborating with the robot so for example we work on how a robot can actually pick up things with a human and carry things thats like true collaboration and third we think about humans as bystanders self driving cars whats the humans role and how do self driving cars acknowledge the presence of humans so i think all of these things are different scenarios it depends on what kind of humans what kind of task and i think its very difficult to say that theres a general theory that we all have for this but at the same time its also silly to say that we should think about robots independent of humans so to me human robot interaction is almost a mandatory aspect of everything we do yes but to which degree so your thoughts if we jump to autonomous vehicles for example theres a big debate between whats called level two and level four so semi autonomous and autonomous vehicles and so the tesla approach currently at least has a lot of collaboration between human and machine so the human is supposed to actively supervise the operation of the robot part of the safety definition of how safe a robot is in that case is how effective is the human in monitoring it do you think thats ultimately not a good approach in sort of having a human in the picture not as a bystander or part of the infrastructure but really as part of whats required to make the system safe this is harder than it sounds i think you know if you i mean im sure youve driven before in highways and so on its really very hard to have to relinquish control to a machine and then take over when needed so i think teslas approach is interesting because it allows you to periodically establish some kind of contact with the car toyota on the other hand is thinking about shared autonomy or collaborative autonomy as a paradigm if i may argue these are very very simple ways of human robot collaboration because the task is pretty boring you sit in a vehicle you go from point a to point b i think the more interesting thing to me is for example search and rescue ive got a human first responder robot first responders i gotta do something its important i have to do it in two minutes the building is burning theres been an explosion its collapsed how do i do it i think to me those are the interesting things where its very very unstructured and whats the role of the human whats the role of the robot clearly theres lots of interesting challenges and theres a field i think were gonna make a lot of progress in this area yeah its an exciting form of collaboration youre right in autonomous driving the main enemy is just boredom of the human yes as opposed to in rescue operations its literally life and death and the collaboration enables the effective completion of the mission so its exciting in some sense were also doing this you think about the human driving a car and almost invariably the humans trying to estimate the state of the car they estimate the state of the environment and so on but what if the car were to estimate the state of the human so for example im sure you have a smartphone and the smartphone tries to figure out what youre doing and send you reminders and oftentimes telling you to drive to a certain place although you have no intention of going there because it thinks that thats where you should be because of some gmail calendar entry or something like that and its trying to constantly figure out who you are what youre doing if a car were to do that maybe that would make the driver safer because the car is trying to figure out is the driver paying attention looking at his or her eyes looking at circadian movements so i think the potential is there but from the reverse side its not robot modeling but its human modeling its more on the human right and i think the robots can do a very good job of modeling humans if you really think about the framework that you have a human sitting in a cockpit surrounded by sensors all staring at him in addition to be staring outside but also staring at him i think theres a real synergy there yeah i love that problem because its the new 21st century form of psychology actually ai enabled psychology a lot of people have sci fi inspired fears of walking robots like those from boston dynamics if you just look at shows on netflix and so on or flying robots like those you work with how would you how do you think about those fears how would you alleviate those fears do you have inklings echoes of those same concerns you know anytime we develop a technology meaning to have positive impact in the world theres always the worry that you know somebody could subvert those technologies and use it in an adversarial setting and robotics is no exception right so i think its very easy to weaponize robots i think we talk about swarms one thing i worry a lot about is so you know for us to get swarms to work and do something reliably its really hard but suppose i have this challenge of trying to destroy something and i have a swarm of robots where only one out of the swarm needs to get to its destination so that suddenly becomes a lot more doable and so i worry about you know this general idea of using autonomy with lots and lots of agents i mean having said that look a lot of this technology is not very mature my favorite saying is that if somebody had to develop this technology wouldnt you rather the good guys do it so the good guys have a good understanding of the technology so they can figure out how this technology is being used in a bad way or could be used in a bad way and try to defend against it so we think a lot about that so we have were doing research on how to defend against swarms for example thats interesting theres in fact a report by the national academies on counter uas technologies this is a real threat but were also thinking about how to defend against this and knowing how swarms work knowing how autonomy works is i think very important so its not just politicians do you think engineers have a role in this discussion absolutely i think the days where politicians can be agnostic to technology are gone i think every politician needs to be literate in technology and i often say technology is the new liberal art understanding how technology will change your life i think is important and every human being needs to understand that and maybe we can elect some engineers to office as well on the other side what are the biggest open problems in robotics and you said were in the early days in some sense what are the problems we would like to solve in robotics i think there are lots of problems right but i would phrase it in the following way if you look at the robots were building theyre still very much tailored towards doing specific tasks and specific settings i think the question of how do you get them to operate in much broader settings where things can change in unstructured environments is up in the air so think of self driving cars today we can build a self driving car in a parking lot we can do level five autonomy in a parking lot but can you do a level five autonomy in the streets of napoli in italy or mumbai in india no so in some sense when we think about robotics we have to think about where theyre functioning what kind of environment what kind of a task we have no understanding of how to put both those things together so were in the very early days of applying it to the physical world and i was just in naples actually and theres levels of difficulty and complexity depending on which area youre applying it to i think so and we dont have a systematic way of understanding that everybody says just because a computer can now beat a human at any board game we certainly know something about intelligence thats not true a computer board game is very very structured it is the equivalent of working in a henry ford factory where things parts come you assemble move on its a very very very structured setting thats the easiest thing and we know how to do that so youve done a lot of incredible work at the upenn university of pennsylvania grasplab youre now dean of engineering at upenn what advice do you have for a new bright eyed undergrad interested in robotics or ai or engineering well i think theres really three things one is you have to get used to the idea that the world will not be the same in five years or four years whenever you graduate right which is really hard to do so this thing about predicting the future every one of us needs to be trying to predict the future always not because youll be any good at it but by thinking about it i think you sharpen your senses and you become smarter so thats number one number two its a corollary of the first piece which is you really dont know whats gonna be important so this idea that im gonna specialize in something which will allow me to go in a particular direction it may be interesting but its important also to have this breadth so you have this jumping off point i think the third thing and this is where i think penn excels i mean we teach engineering but its always in the context of the liberal arts its always in the context of society as engineers we cannot afford to lose sight of that so i think thats important but i think one thing that people underestimate when they do robotics is the importance of mathematical foundations the importance of representations not everything can just be solved by looking for ross packages on the internet or to find a deep neural network that works i think the representation question is key even to machine learning where if you ever hope to achieve or get to explainable ai somehow there need to be representations that you can understand so if you wanna do robotics you should also do mathematics and you said liberal arts a little literature if you wanna build a robot it should be reading dostoyevsky i agree with that very good so vijay thank you so much for talking today it was an honor thank you it was just a very exciting conversation thank you', 'the following is a conversation with francois chollet hes the creator of keras which is an open source deep learning library that is designed to enable fast user friendly experimentation with deep neural networks it serves as an interface to several deep learning libraries most popular of which is tensorflow and it was integrated into the tensorflow main code base a while ago meaning if you want to create train and use neural networks probably the easiest and most popular option is to use keras inside tensorflow aside from creating an exceptionally useful and popular library francois is also a world class ai researcher and software engineer at google and hes definitely an outspoken if not controversial personality in the ai world especially in the realm of ideas around the future of artificial intelligence this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with francois chollet youre known for not sugarcoating your opinions and speaking your mind about ideas in ai especially on twitter its one of my favorite twitter accounts so whats one of the more controversial ideas youve expressed online and gotten some heat for how do you pick how do i pick yeah no i think if you go through the trouble of maintaining a twitter account you might as well speak your mind you know otherwise whats even the point of having a twitter account its like having a nice car and just leaving it in the garage yeah so whats one thing for which i got a lot of pushback perhaps you know that time i wrote something about the idea of intelligence explosion and i was questioning the idea and the reasoning behind this idea and i got a lot of pushback on that i got a lot of flak for it so yeah so intelligence explosion im sure youre familiar with the idea but its the idea that if you were to build general ai problem solving algorithms well the problem of building such an ai that itself is a problem that could be solved by your ai and maybe it could be solved better than what humans can do so your ai could start tweaking its own algorithm could start making a better version of itself and so on iteratively in a recursive fashion and so you would end up with an ai with exponentially increasing intelligence thats right and i was basically questioning this idea first of all because the notion of intelligence explosion uses an implicit definition of intelligence that doesnt sound quite right to me it considers intelligence as a property of a brain that you can consider in isolation like the height of a building for instance but thats not really what intelligence is intelligence emerges from the interaction between a brain a body like embodied intelligence and an environment and if youre missing one of these pieces then you cannot really define intelligence anymore so just tweaking a brain to make it smaller and smaller doesnt actually make any sense to me so first of all youre crushing the dreams of many people right so theres a lets look at like sam harris actually a lot of physicists max tegmark people who think the universe is an information processing system our brain is kind of an information processing system so whats the theoretical limit like it doesnt make sense that there should be some it seems naive to think that our own brain is somehow the limit of the capabilities of this information system im playing devils advocate here this information processing system and then if you just scale it if youre able to build something thats on par with the brain you just the process that builds it just continues and itll improve exponentially so thats the logic thats used actually by almost everybody that is worried about super human intelligence so youre trying to make so most people who are skeptical of that are kind of like this doesnt their thought process this doesnt feel right like thats for me as well so im more like it doesnt the whole thing is shrouded in mystery where you cant really say anything concrete but you could say this doesnt feel right this doesnt feel like thats how the brain works and youre trying to with your blog posts and now making it a little more explicit so one idea is that the brain isnt exist alone it exists within the environment so you cant exponentially you would have to somehow exponentially improve the environment and the brain together almost yeah in order to create something thats much smarter in some kind of of course we dont have a definition of intelligence thats correct thats correct i dont think you should look at very smart people today even humans not even talking about ais i dont think their brain and the performance of their brain is the bottleneck to their expressed intelligence to their achievements you cannot just tweak one part of this system like of this brain body environment system and expect that capabilities like what emerges out of this system to just explode exponentially because anytime you improve one part of a system with many interdependencies like this theres a new bottleneck that arises right and i dont think even today for very smart people their brain is not the bottleneck to the sort of problems they can solve right in fact many very smart people today you know they are not actually solving any big scientific problems theyre not einstein theyre like einstein but you know the patent clerk days like einstein became einstein because this was a meeting of a genius with a big problem at the right time right but maybe this meeting could have never happened and then einstein would have just been a patent clerk right and in fact many people today are probably like genius level smart but you wouldnt know because theyre not really expressing any of that wow thats brilliant so we can think of the world earth but also the universe as just as a space of problems so all these problems and tasks are roaming it of various difficulty and theres agents creatures like ourselves and animals and so on that are also roaming it and then you get coupled with a problem and then you solve it but without that coupling you cant demonstrate your quote unquote intelligence exactly intelligence is the meeting of great problem solving capabilities with a great problem and if you dont have the problem you dont really express any intelligence all youre left with is potential intelligence like the performance of your brain or how high your iq is which in itself is just a number right so you mentioned problem solving capacity yeah what do you think of as problem solving capacity can you try to define intelligence like what does it mean to be more or less intelligent is it completely coupled to a particular problem or is there something a little bit more universal yeah i do believe all intelligence is specialized intelligence even human intelligence has some degree of generality well all intelligent systems have some degree of generality but theyre always specialized in one category of problems so the human intelligence is specialized in the human experience and that shows at various levels that shows in some prior knowledge thats innate that we have at birth knowledge about things like agents goal driven behavior visual priors about what makes an object priors about time and so on that shows also in the way we learn for instance its very very easy for us to pick up language its very very easy for us to learn certain things because we are basically hard coded to learn them and we are specialized in solving certain kinds of problem and we are quite useless when it comes to other kinds of problems for instance we are not really designed to handle very long term problems we have no capability of seeing the very long term we dont have very much working memory so how do you think about long term do you think long term planning are we talking about scale of years millennia what do you mean by long term were not very good well human intelligence is specialized in the human experience and human experience is very short one lifetime is short even within one lifetime we have a very hard time envisioning things on a scale of years its very difficult to project yourself at a scale of five years at a scale of 10 years and so on we can solve only fairly narrowly scoped problems so when it comes to solving bigger problems larger scale problems we are not actually doing it on an individual level so its not actually our brain doing it we have this thing called civilization right which is itself a sort of problem solving system a sort of artificially intelligent system right and its not running on one brain its running on a network of brains in fact its running on much more than a network of brains its running on a lot of infrastructure like books and computers and the internet and human institutions and so on and that is capable of handling problems on a much greater scale than any individual human if you look at computer science for instance thats an institution that solves problems and it is superhuman right it operates on a greater scale it can solve much bigger problems than an individual human could and science itself science as a system as an institution is a kind of artificially intelligent problem solving algorithm that is superhuman yeah its at least computer science is like a theorem prover at a scale of thousands maybe hundreds of thousands of human beings at that scale what do you think is an intelligent agent so theres us humans at the individual level there is millions maybe billions of bacteria in our skin there is thats at the smaller scale you can even go to the particle level as systems that behave you can say intelligently in some ways and then you can look at the earth as a single organism you can look at our galaxy and even the universe as a single organism do you think how do you think about scale in defining intelligent systems and were here at google there is millions of devices doing computation just in a distributed way how do you think about intelligence versus scale you can always characterize anything as a system i think people who talk about things like intelligence explosion tend to focus on one agent is basically one brain like one brain considered in isolation like a brain a jaw thats controlling a body in a very like top to bottom kind of fashion and that body is pursuing goals into an environment so its a very hierarchical view you have the brain at the top of the pyramid then you have the body just plainly receiving orders and then the body is manipulating objects in the environment and so on so everything is subordinate to this one thing this epicenter which is the brain but in real life intelligent agents dont really work like this right there is no strong delimitation between the brain and the body to start with you have to look not just at the brain but at the nervous system but then the nervous system and the body are naturally two separate entities so you have to look at an entire animal as one agent but then you start realizing as you observe an animal over any length of time that a lot of the intelligence of an animal is actually externalized thats especially true for humans a lot of our intelligence is externalized when you write down some notes that is externalized intelligence when you write a computer program you are externalizing cognition so its externalizing books its externalized in computers the internet in other humans its externalizing language and so on so there is no hard delimitation of what makes an intelligent agent its all about context okay but alphago is better at go than the best human player theres levels of skill here so do you think theres such a ability such a concept as intelligence explosion in a specific task and then well yeah do you think its possible to have a category of tasks on which you do have something like an exponential growth of ability to solve that particular problem i think if you consider a specific vertical its probably possible to some extent i also dont think we have to speculate about it because we have real world examples of recursively self improving intelligent systems right so for instance science is a problem solving system a knowledge generation system like a system that experiences the world in some sense and then gradually understands it and can act on it and that system is superhuman and it is clearly recursively self improving because science feeds into technology technology can be used to build better tools better computers better instrumentation and so on which in turn can make science faster right so science is probably the closest thing we have today to a recursively self improving superhuman ai and you can just observe is science is scientific progress to the exploding which itself is an interesting question you can use that as a basis to try to understand what will happen with a superhuman ai that has a science like behavior let me linger on it a little bit more what is your intuition why an intelligence explosion is not possible like taking the scientific all the semi scientific revolutions why cant we slightly accelerate that process so you can absolutely accelerate any problem solving process so a recursively self improvement is absolutely a real thing but what happens with a recursively self improving system is typically not explosion because no system exists in isolation and so tweaking one part of the system means that suddenly another part of the system becomes a bottleneck and if you look at science for instance which is clearly a recursively self improving clearly a problem solving system scientific progress is not actually exploding if you look at science what you see is the picture of a system that is consuming an exponentially increasing amount of resources but its having a linear output in terms of scientific progress and maybe that will seem like a very strong claim many people are actually saying that scientific progress is exponential but when theyre claiming this theyre actually looking at indicators of resource consumption by science for instance the number of papers being published the number of patents being filed and so on which are just completely correlated with how many people are working on science today so its actually an indicator of resource consumption but what you should look at is the output is progress in terms of the knowledge that science generates in terms of the scope and significance of the problems that we solve and some people have actually been trying to measure that like michael nielsen for instance he had a very nice paper i think that was last year about it so his approach to measure scientific progress was to look at the timeline of scientific discoveries over the past you know 100 150 years and for each major discovery ask a panel of experts to rate the significance of the discovery and if the output of science as an institution were exponential you would expect the temporal density of significance to go up exponentially maybe because theres a faster rate of discoveries maybe because the discoveries are you know increasingly more important and what actually happens if you plot this temporal density of significance measured in this way is that you see very much a flat graph you see a flat graph across all disciplines across physics biology medicine and so on and it actually makes a lot of sense if you think about it because think about the progress of physics 110 years ago right it was a time of crazy change think about the progress of technology you know 170 years ago when we started having you know replacing horses with cars when we started having electricity and so on it was a time of incredible change and today is also a time of very very fast change but it would be an unfair characterization to say that today technology and science are moving way faster than they did 50 years ago or 100 years ago and if you do try to rigorously plot the temporal density of the significance yeah of significance sorry you do see very flat curves and you can check out the paper that michael nielsen had about this idea and so the way i interpret it is as you make progress in a given field or in a given subfield of science it becomes exponentially more difficult to make further progress like the very first person to work on information theory if you enter a new field and its still the very early years theres a lot of low hanging fruit you can pick thats right yeah but the next generation of researchers is gonna have to dig much harder actually to make smaller discoveries probably larger number of smaller discoveries and to achieve the same amount of impact youre gonna need a much greater head count and thats exactly the picture youre seeing with science over rule based models is going to be a cornerstone of ai research in the next century and that doesnt mean we are going to drop deep learning deep learning is immensely useful like being able to learn is a very flexible adaptable parametric model so its got to understand thats actually immensely useful all its doing is pattern cognition but being good at pattern cognition given lots of data is just extremely powerful so we are still going to be working on deep learning we are going to be working on program synthesis we are going to be combining the two in increasingly automated ways so lets talk a little bit about data youve tweeted about 10000 deep learning papers have been written about hard coding priors about a specific task in a neural network architecture works better than a lack of a prior basically summarizing all these efforts they put a name to an architecture but really what theyre doing is hard coding some priors that improve the performance of the system but which gets straight to the point is probably true so you say that you can always buy performance by in quotes performance by either training on more data better data or by injecting task information to the architecture of the preprocessing however this isnt informative about the generalization power the techniques use the fundamental ability to generalize do you think we can go far by coming up with better methods for this kind of cheating for better methods of large scale annotation of data so building better priors if you automate it its not cheating anymore right im joking about the cheating but large scale so basically im asking about something that hasnt from my perspective been researched too much is exponential improvement in annotation of data do you often think about i think its actually been researched quite a bit you just dont see publications about it because people who publish papers are going to publish about known benchmarks sometimes theyre going to read a new benchmark people who actually have real world large scale depending on problems theyre going to spend a lot of resources into data annotation and good data annotation pipelines but you dont see any papers about it thats interesting so do you think certainly resources but do you think theres innovation happening oh yeah to clarify the point in the tweet so machine learning in general is the science of generalization you want to generate knowledge that can be reused across different data sets across different tasks and if instead youre looking at one data set and then you are hard coding knowledge about this task into your architecture this is no more useful than training a network and then saying oh i found these weight values perform well so david ha i dont know if you know david he had a paper the other day about weight agnostic neural networks and this is a very interesting paper because it really illustrates the fact that an architecture even without weights an architecture is knowledge about a task it encodes knowledge and when it comes to architectures that are uncrafted by researchers in some cases it is very very clear that all they are doing is artificially reencoding the template that corresponds to the proper way to solve the task encoding a given data set for instance i know if you looked at the baby data set which is about natural language question answering it is generated by an algorithm so this is a question answer pairs that are generated by an algorithm the algorithm is solving a certain template turns out if you craft a network that literally encodes this template you can solve this data set with nearly 100 accuracy but that doesnt actually tell you anything about how to solve question answering in general which is the point the question is just to linger on it whether its from the data side or from the size of the network i dont know if youve read the blog post by rich sutton the bitter lesson where he says the biggest lesson that we can read from 70 years of ai research is that general methods that leverage computation are ultimately the most effective so as opposed to figuring out methods that can generalize effectively do you think we can get pretty far by just having something that leverages computation and the improvement of computation yeah so i think rich is making a very good point which is that a lot of these papers which are actually all about manually hardcoding prior knowledge about a task into some system it doesnt have to be deep learning architecture but into some system these papers are not actually making any impact instead whats making really long term impact is very simple very general systems that are really agnostic to all these tricks because these tricks do not generalize and of course the one general and simple thing that you should focus on is that which leverages computation because computation the availability of large scale computation has been increasing exponentially following moores law so if your algorithm is all about exploiting this then your algorithm is suddenly exponentially improving so i think rich is definitely right however hes right about the past 70 years hes like assessing the past 70 years i am not sure that this assessment will still hold true for the next 70 years it might to some extent i suspect it will not because the truth of his assessment is a function of the context in which this research took place and the context is changing moores law might not be applicable anymore for instance in the future and i do believe that when you tweak one aspect of a system when you exploit one aspect of a system some other aspect starts becoming the bottleneck lets say you have unlimited computation well then data is the bottleneck and i think we are already starting to be in a regime where our systems are so large in scale and so data ingrained that data today and the quality of data and the scale of data is the bottleneck and in this environment the bitter lesson from rich is not going to be true anymore so i think we are going to move from a focus on a computation scale to focus on data efficiency data efficiency so thats getting to the question of symbolic ai but to linger on the deep learning approaches do you have hope for either unsupervised learning or reinforcement learning which are ways of being more data efficient in terms of the amount of data they need that required human annotation so unsupervised learning and reinforcement learning are frameworks for learning but they are not like any specific technique so usually when people say reinforcement learning what they really mean is deep reinforcement learning which is like one approach which is actually very questionable the question i was asking was unsupervised learning with deep neural networks and deep reinforcement learning well these are not really data efficient because youre still leveraging these huge parametric models point by point with gradient descent it is more efficient in terms of the number of annotations the density of annotations you need so the idea being to learn the latent space around which the data is organized and then map the sparse annotations into it and sure i mean thats clearly a very good idea its not really a topic i would be working on but its clearly a good idea so it would get us to solve some problems that it will get us to incremental improvements in labeled data efficiency do you have concerns about short term or long term threats from ai from artificial intelligence yes definitely to some extent and whats the shape of those concerns this is actually something ive briefly written about but the capabilities of deep learning technology can be used in many ways that are concerning from mass surveillance with things like facial recognition in general tracking lots of data about everyone and then being able to making sense of this data to do identification to do prediction thats concerning thats something thats being very aggressively pursued by totalitarian states like china one thing i am very much concerned about is that our lives are increasingly online are increasingly digital made of information made of information consumption and information production our digital footprint i would say and if you absorb all of this data and you are in control of where you consume information social networks and so on recommendation engines then you can build a sort of reinforcement loop for human behavior you can observe the state of your mind at time t you can predict how you would react to different pieces of content how to get you to move your mind in a certain direction and then you can feed you the specific piece of content that would move you in a specific direction and you can do this at scale in terms of doing it continuously in real time you can also do it at scale in terms of scaling this to many many people to entire populations so potentially artificial intelligence even in its current state if you combine it with the internet with the fact that all of our lives are moving to digital devices and digital information consumption and creation what you get is the possibility to achieve mass manipulation of behavior and mass psychological control and this is a very real possibility yeah so youre talking about any kind of recommender system lets look at the youtube algorithm facebook anything that recommends content you should watch next and its fascinating to think that theres some aspects of human behavior that you can say a problem of is this person hold republican beliefs or democratic beliefs and this is a trivial thats an objective function and you can optimize and you can measure and you can turn everybody into a republican or everybody into a democrat i do believe its true so the human mind is very if you look at the human mind as a kind of computer program it has a very large exploit surface it has many many vulnerabilities exploit surfaces yeah ways you can control it for instance when it comes to your political beliefs this is very much tied to your identity so for instance if im in control of your news feed on your favorite social media platforms this is actually where youre getting your news from and of course i can choose to only show you news that will make you see the world in a specific way but i can also create incentives for you to post about some political beliefs and then when i get you to express a statement if its a statement that me as the controller i want to reinforce i can just show it to people who will agree and they will like it and that will reinforce the statement in your mind if this is a statement i want you to this is a belief i want you to abandon i can on the other hand show it to opponents well attack you and because they attack you at the very least next time you will think twice about posting it but maybe you will even start believing this because you got pushback so there are many ways in which social media platforms can potentially control your opinions and today so all of these things are already being controlled by ai algorithms these algorithms do not have any explicit political goal today well potentially they could like if some totalitarian government takes over social media platforms and decides that now we are going to use this not just for mass surveillance but also for mass opinion control and behavior control very bad things could happen but whats really fascinating and actually quite concerning is that even without an explicit intent to manipulate youre already seeing very dangerous dynamics in terms of how these content recommendation algorithms behave because right now the goal the objective function of these algorithms is to maximize engagement which seems fairly innocuous at first however it is not because content that will maximally engage people get people to react in an emotional way get people to click on something it is very often content that is not healthy to the public discourse for instance fake news are far more likely to get you to click on them than real news simply because they are not constrained to reality so they can be as outrageous as surprising as good stories as you want because theyre artificial to me thats an exciting world because so much good can come so theres an opportunity to educate people you can balance peoples worldview with other ideas so theres so many objective functions the space of objective functions that create better civilizations is large arguably infinite but theres also a large space that creates division and destruction civil war a lot of bad stuff and the worry is naturally probably that space is bigger first of all and if we dont explicitly think about what kind of effects are going to be observed from different objective functions then were going to get into trouble but the question is how do we get into rooms and have discussions so inside google inside facebook inside twitter and think about ok how can we drive up engagement and at the same time create a good society is it even possible to have that kind of philosophical discussion i think you can definitely try so from my perspective i would feel rather uncomfortable with companies that are uncomfortable with these new student algorithms with them making explicit decisions to manipulate peoples opinions or behaviors even if the intent is good because thats a very totalitarian mindset so instead what i would like to see is probably never going to happen because its not super realistic but thats actually something i really care about i would like all these algorithms to present configuration settings to their users so that the users can actually make the decision about how they want to be impacted by these information recommendation content recommendation algorithms for instance as a user of something like youtube or twitter maybe i want to maximize learning about a specific topic so i want the algorithm to feed my curiosity which is in itself a very interesting problem so instead of maximizing my engagement it will maximize how fast and how much im learning and it will also take into account the accuracy hopefully of the information im learning so yeah the user should be able to determine exactly how these algorithms are affecting their lives i dont want actually any entity making decisions about in which direction theyre going to try to manipulate me i want technology so ai these algorithms are increasingly going to be our interface to a world that is increasingly made of information and i want everyone to be in control of this interface to interface with the world on their own terms so if someone wants these algorithms to serve their own personal growth goals they should be able to configure these algorithms in such a way yeah but so i know its painful to have explicit decisions but there is underlying explicit decisions which is some of the most beautiful fundamental philosophy that we have before us which is personal growth if i want to watch videos from which i can learn what does that mean so if i have a checkbox that wants to emphasize learning theres still an algorithm with explicit decisions in it that would promote learning what does that mean for me for example ive watched a documentary on flat earth theory i guess i learned a lot im really glad i watched it it was a friend recommended it to me because i dont have such an allergic reaction to crazy people as my fellow colleagues do but it was very eye opening and for others it might not be from others they might just get turned off from that same with republican and democrat and its a non trivial problem and first of all if its done well i dont think its something that wouldnt happen that youtube wouldnt be promoting or twitter wouldnt be its just a really difficult problem how to give people control well its mostly an interface design problem the way i see it you want to create technology thats like a mentor or a coach or an assistant so that its not your boss you are in control of it you are telling it what to do for you and if you feel like its manipulating you its not actually doing what you want you should be able to switch to a different algorithm so thats fine tune control you kind of learn that youre trusting the human collaboration i mean thats how i see autonomous vehicles too is giving as much information as possible and you learn that dance yourself yeah adobe i dont know if you use adobe product for like photoshop theyre trying to see if they can inject youtube into their interface but basically allow you to show you all these videos that everybodys confused about what to do with features so basically teach people by linking to in that way its an assistant that uses videos as a basic element of information okay so what practically should people do to try to fight against abuses of these algorithms or algorithms that manipulate us honestly its a very very difficult problem because to start with there is very little public awareness of these issues very few people would think theres anything wrong with the unused algorithm even though there is actually something wrong already which is that its trying to maximize engagement most of the time which has very negative side effects so ideally so the very first thing is to stop trying to purely maximize engagement try to propagate content based on popularity right instead take into account the goals and the profiles of each user so you will be one example is for instance when i look at topic recommendations on twitter its like you know they have this news tab with switch recommendations its always the worst coverage because its content that appeals to the smallest common denominator to all twitter users because theyre trying to optimize theyre purely trying to optimize popularity theyre purely trying to optimize engagement but thats not what i want so they should put me in control of some setting so that i define whats the objective function that twitter is going to be following to show me this content and honestly so this is all about interface design and we are not its not realistic to give users control of a bunch of knobs that define algorithm instead we should purely put them in charge of defining the objective function like let the user tell us what they want to achieve how they want this algorithm to impact their lives so do you think it is that or do they provide individual article by article reward structure where you give a signal im glad i saw this or im glad i didnt so like a spotify type feedback mechanism it works to some extent im kind of skeptical about it because the only way the algorithm the algorithm will attempt to relate your choices with the choices of everyone else which might you know if you have an average profile that works fine im sure spotify accommodations work fine if you just like mainstream stuff if you dont it can be its not optimal at all actually itll be in an efficient search for the part of the spotify world that represents you so its a tough problem but do note that even a feedback system like what spotify has does not give me control over what the algorithm is trying to optimize for well public awareness which is what were doing now is a good place to start do you have concerns about longterm existential threats of artificial intelligence well as i was saying our world is increasingly made of information ai algorithms are increasingly going to be our interface to this world of information and somebody will be in control of these algorithms and that puts us in any kind of a bad situation right it has risks it has risks coming from potentially large companies wanting to optimize their own goals maybe profit maybe something else also from governments who might want to use these algorithms as a means of control of the population do you think theres existential threat that could arise from that so existential threat so maybe youre referring to the singularity narrative where robots just take over well i dont im not terminating robots and i dont believe it has to be a singularity were just talking to just like you said the algorithm controlling masses of populations the existential threat being hurt ourselves much like a nuclear war would hurt ourselves that kind of thing i dont think that requires a singularity that requires a loss of control over ai algorithm yes so i do agree there are concerning trends honestly i wouldnt want to make any longterm predictions i dont think today we really have the capability to see what the dangers of ai are going to be in 50 years in 100 years i do see that we are already faced with concrete and present dangers surrounding the negative side effects of content recombination systems of newsfeed algorithms concerning algorithmic bias as well so we are delegating more and more decision processes to algorithms some of these algorithms are uncrafted some are learned from data but we are delegating control sometimes its a good thing sometimes not so much and there is in general very little supervision of this process right so we are still in this period of very fast change even chaos where society is restructuring itself turning into an information society which itself is turning into an increasingly automated information passing society and well yeah i think the best we can do today is try to raise awareness around some of these issues and i think were actually making good progress if you look at algorithmic bias for instance three years ago even two years ago very very few people were talking about it and now all the big companies are talking about it they are often not in a very serious way but at least it is part of the public discourse you see people in congress talking about it and it all started from raising awareness right so in terms of alignment problem trying to teach as we allow algorithms just even recommender systems on twitter encoding human values and morals decisions that touch on ethics how hard do you think that problem is how do we have lost functions in neural networks that have some component some fuzzy components of human morals well i think this is really all about objective function engineering which is probably going to be increasingly a topic of concern in the future like for now were just using very naive loss functions because the hard part is not actually what youre trying to minimize its everything else but as the everything else is going to be increasingly automated were going to be focusing our human attention on increasingly high level components like whats actually driving the whole learning system like the objective function so loss function engineering is going to be loss function engineer is probably going to be a job title in the future and then the tooling youre creating with keras essentially takes care of all the details underneath and basically the human expert is needed for exactly that thats the idea keras is the interface between the data youre collecting and the business goals and your job as an engineer is going to be to express your business goals and your understanding of your business or your product your system as a kind of loss function or a kind of set of constraints does the possibility of creating an agi system excite you or scare you or bore you so intelligence can never really be general you know at best it can have some degree of generality like human intelligence it also always has some specialization in the same way that human intelligence is specialized in a certain category of problems is specialized in the human experience and when people talk about agi im never quite sure if theyre talking about very very smart ai so smart that its even smarter than humans or theyre talking about human like intelligence because these are different things lets say presumably im oppressing you today with my humanness so imagine that i was in fact a robot so what does that mean that im impressing you with natural language processing maybe if you werent able to see me maybe this is a phone call so that kind of system companion so thats very much about building human like ai and youre asking me you know is this an exciting perspective yes i think so yes not so much because of what artificial human like intelligence could do but you know from an intellectual perspective i think if you could build truly human like intelligence that means you could actually understand human intelligence which is fascinating right human like intelligence is going to require emotions its going to require consciousness which is not things that would normally be required by an intelligent system if you look at you know we were mentioning earlier like science as a superhuman problem solving agent or system it does not have consciousness it doesnt have emotions in general so emotions i see consciousness as being on the same spectrum as emotions it is a component of the subjective experience that is meant very much to guide behavior generation right its meant to guide your behavior in general human intelligence and animal intelligence has evolved for the purpose of behavior generation right including in a social context so thats why we actually need emotions thats why we need consciousness an artificial intelligence system developed in a different context may well never need them may well never be conscious like science well on that point i would argue its possible to imagine that theres echoes of consciousness in science when viewed as an organism that science is consciousness so i mean how would you go about testing this hypothesis how do you probe the subjective experience of an abstract system like science well the point of probing any subjective experience is impossible because im not science im lex so i cant probe another entity its no more than bacteria on my skin youre lex i can ask you questions about your subjective experience and you can answer me and thats how i know youre conscious yes but thats because we speak the same language you perhaps we have to speak the language of science in order to ask it honestly i dont think consciousness just like emotions of pain and pleasure is not something that inevitably arises from any sort of sufficiently intelligent information processing it is a feature of the mind and if youve not implemented it explicitly it is not there so you think its an emergent feature of a particular architecture so do you think its a feature in the same sense so again the subjective experience is all about guiding behavior if the problems youre trying to solve dont really involve an embodied agent maybe in a social context generating behavior and pursuing goals like this and if you look at science thats not really whats happening even though it is it is a form of artificial ai artificial intelligence in the sense that it is solving problems it is accumulating knowledge accumulating solutions and so on so if youre not explicitly implementing a subjective experience implementing certain emotions and implementing consciousness its not going to just spontaneously emerge yeah but so for a system like human like intelligence system that has consciousness do you think it needs to have a body yes definitely i mean it doesnt have to be a physical body right and theres not that much difference between a realistic simulation in the real world so there has to be something you have to preserve kind of thing yes but human like intelligence can only arise in a human like context intelligence needs other humans in order for you to demonstrate that you have human like intelligence essentially yes so what kind of tests and demonstration would be sufficient for you to demonstrate human like intelligence yeah just out of curiosity youve talked about in terms of theorem proving and program synthesis i think youve written about that theres no good benchmarks for this yeah thats one of the problems so lets talk program synthesis so what do you imagine is a good i think its related questions for human like intelligence and for program synthesis whats a good benchmark for either or both right so i mean youre actually asking two questions which is one is about quantifying intelligence and comparing the intelligence of an artificial system to the intelligence for human and the other is about the degree to which this intelligence is human like its actually two different questions so you mentioned earlier the turing test well i actually dont like the turing test because its very lazy its all about completely bypassing the problem of defining and measuring intelligence and instead delegating to a human judge or a panel of human judges so its a total copout right if you want to measure how human like an agent is i think you have to make it interact with other humans maybe its not necessarily a good idea to have these other humans be the judges maybe you should just observe behavior and compare it to what a human would actually have done when it comes to measuring how smart how clever an agent is and comparing that to the degree of human intelligence so were already talking about two things right the degree kind of like the magnitude of an intelligence and its direction right like the norm of a vector and its direction and the direction is like human likeness and the magnitude the norm is intelligence you could call it intelligence right so the direction your sense the space of directions that are human like is very narrow yeah so the way you would measure the magnitude of intelligence in a system in a way that also enables you to compare it to that of a human well if you look at different benchmarks for intelligence today theyre all too focused on skill at a given task like skill at playing chess skill at playing go skill at playing dota and i think thats not the right way to go about it because you can always beat a human at one specific task the reason why our skill at playing go or juggling or anything is impressive is because we are expressing this skill within a certain set of constraints if you remove the constraints the constraints that we have one lifetime that we have this body and so on if you remove the context if you have unlimited string data if you can have access to you know for instance if you look at juggling if you have no restriction on the hardware then achieving arbitrary levels of skill is not very interesting and says nothing about the amount of intelligence youve achieved so if you want to measure intelligence you need to rigorously define what intelligence is which in itself you know its a very challenging problem and do you think thats possible to define intelligence yes absolutely i mean you can provide many people have provided you know some definition i have my own definition where does your definition begin where does your definition begin if it doesnt end well i think intelligence is essentially the efficiency with which you turn experience into generalizable programs so what that means is its the efficiency with which you turn a sampling of experience space into the ability to process a larger chunk of experience space so measuring skill can be one proxy across many different tasks can be one proxy for measuring intelligence but if you want to only measure skill you should control for two things you should control for the amount of experience that your system has and the priors that your system has but if you look at two agents and you give them the same priors and you give them the same amount of experience there is one of the agents that is going to learn programs representations something a model that will perform well on the larger chunk of experience space than the other and that is the smaller agent yeah so if you fix the experience which generate better programs better meaning more generalizable thats really interesting thats a very nice clean definition of oh by the way in this definition it is already very obvious that intelligence has to be specialized because youre talking about experience space and youre talking about segments of experience space youre talking about priors and youre talking about experience all of these things define the context in which intelligence emerges and you can never look at the totality of experience space right so intelligence has to be specialized but it can be sufficiently large the experience space even though its specialized theres a certain point when the experience space is large enough to where it might as well be general it feels general it looks general sure i mean its very relative like for instance many people would say human intelligence is general in fact it is quite specialized we can definitely build systems that start from the same innate priors as what humans have at birth because we already understand fairly well what sort of priors we have as humans like many people have worked on this problem most notably elisabeth spelke from harvard i dont know if you know her shes worked a lot on what she calls core knowledge and it is very much about trying to determine and describe what priors we are born with like language skills and so on all that kind of stuff exactly so we have some pretty good understanding of what priors we are born with so we could so ive actually been working on a benchmark for the past couple years you know on and off i hope to be able to release it at some point thats exciting the idea is to measure the intelligence of systems by countering for priors countering for amount of experience and by assuming the same priors as what humans are born with so that you can actually compare these scores to human intelligence you can actually have humans pass the same test in a way thats fair yeah and so importantly such a benchmark should be such that any amount of practicing does not increase your score so try to picture a game where no matter how much you play this game that does not change your skill at the game can you picture that as a person who deeply appreciates practice i cannot actually theres actually a very simple trick so in order to come up with a task so the only thing you can measure is skill at the task yes all tasks are going to involve priors yes the trick is to know what they are and to describe that and then you make sure that this is the same set of priors as what humans start with so you create a task that assumes these priors that exactly documents these priors so that the priors are made explicit and there are no other priors involved and then you generate a certain number of samples in experience space for this task right and this for one task assuming that the task is new for the agent passing it thats one test of this definition of intelligence that we set up and now you can scale that to many different tasks that each task should be new to the agent passing it right and also it should be human interpretable and understandable so that you can actually have a human pass the same test and then you can compare the score of your machine and the score of your human which could be a lot of stuff you could even start a task like mnist just as long as you start with the same set of priors so the problem with mnist humans are already trying to recognize digits right but lets say were considering objects that are not digits some completely arbitrary patterns well humans already come with visual priors about how to process that so in order to make the game fair you would have to isolate these priors and describe them and then express them as computational rules having worked a lot with vision science people thats exceptionally difficult a lot of progress has been made theres been a lot of good tests and basically reducing all of human vision into some good priors were still probably far away from that perfectly but as a start for a benchmark thats an exciting possibility yeah so elisabeth spelke actually lists objectness as one of the core knowledge priors objectness cool objectness yeah so we have priors about objectness like about the visual space about time about agents about goal oriented behavior we have many different priors but whats interesting is that sure we have this pretty diverse and rich set of priors but its also not that diverse right we are not born into this world with a ton of knowledge about the world with only a small set of core knowledge yeah sorry do you have a sense of how it feels to us humans that that set is not that large but just even the nature of time that we kind of integrate pretty effectively through all of our perception all of our reasoning maybe how you know do you have a sense of how easy it is to encode those priors maybe it requires building a universe and then the human brain in order to encode those priors or do you have a hope that it can be listed like an axiomatic i dont think so so you have to keep in mind that any knowledge about the world that we are born with is something that has to have been encoded into our dna by evolution at some point right and dna is a very very low bandwidth medium like its extremely long and expensive to encode anything into dna because first of all you need some sort of evolutionary pressure to guide this writing process and then you know the higher level of information youre trying to write the longer its going to take and the thing in the environment that youre trying to encode knowledge about has to be stable over this duration so you can only encode into dna things that constitute an evolutionary advantage so this is actually a very small subset of all possible knowledge about the world you can only encode things that are stable that are true over very very long periods of time typically millions of years for instance we might have some visual prior about the shape of snakes right but what makes a face whats the difference between a face and an art face but consider this interesting question do we have any innate sense of the visual difference between a male face and a female face what do you think for a human i mean i would have to look back into evolutionary history when the genders emerged but yeah most i mean the faces of humans are quite different from the faces of great apes great apes right yeah thats interesting yeah you couldnt tell the face of a female chimpanzee from the face of a male chimpanzee probably yeah and i dont think most humans have all that ability so we do have innate knowledge of what makes a face but its actually impossible for us to have any dna encoded knowledge of the difference between a female human face and a male human face because that knowledge that information came up into the world actually very recently if you look at the slowness of the process of encoding knowledge into dna yeah so thats interesting thats a really powerful argument that dna is a low bandwidth and it takes a long time to encode that naturally creates a very efficient encoding but one important consequence of this is that so yes we are born into this world with a bunch of knowledge sometimes high level knowledge about the world like the shape the rough shape of a snake of the rough shape of a face but importantly because this knowledge takes so long to write almost all of this innate knowledge is shared with our cousins with great apes right so it is not actually this innate knowledge that makes us special but to throw it right back at you from the earlier on in our discussion its that encoding might also include the entirety of the environment of earth to some extent so it can include things that are important to survival and production so for which there is some evolutionary pressure and things that are stable constant over very very very long time periods and honestly its not that much information theres also besides the bandwidths constraint and the constraints of the writing process theres also memory constraints like dna the part of dna that deals with the human brain its actually fairly small its like you know on the order of megabytes right theres not that much high level knowledge about the world you can encode thats quite brilliant and hopeful for a benchmark that youre referring to of encoding priors i actually look forward to im skeptical whether you can do it in the next couple of years but hopefully ive been working so honestly its a very simple benchmark and its not like a big breakthrough or anything its more like a fun side project right but these fun so is imagenet these fun side projects could launch entire groups of efforts towards creating reasoning systems and so on and i think yeah thats the goal its trying to measure strong generalization to measure the strength of abstraction in our minds well in our minds and in artificial intelligence agencies and if theres anything true about this science organism is its individual cells love competition so and benchmarks encourage competition so thats an exciting possibility if you do you think an ai winter is coming and how do we prevent it not really so an ai winter is something that would occur when theres a big mismatch between how we are selling the capabilities of ai and the actual capabilities of ai and today some deep learning is creating a lot of value and it will keep creating a lot of value in the sense that these models are applicable to a very wide range of problems that are relevant today and we are only just getting started with applying these algorithms to every problem they could be solving so deep learning will keep creating a lot of value for the time being whats concerning however is that theres a lot of hype around deep learning and around ai there are lots of people are overselling the capabilities of these systems not just the capabilities but also overselling the fact that they might be more or less you know brain like like given the kind of a mystical aspect these technologies and also overselling the pace of progress which you know it might look fast in the sense that we have this exponentially increasing number of papers but again thats just a simple consequence of the fact that we have ever more people coming into the field it doesnt mean the progress is actually exponentially fast lets say youre trying to raise money for your startup or your research lab you might want to tell you know a grandiose story to investors about how deep learning is just like the brain and how it can solve all these incredible problems like self driving and robotics and so on and maybe you can tell them that the field is progressing so fast and we are going to have agi within 15 years or even 10 years and none of this is true and every time youre like saying these things and an investor or you know a decision maker believes them well this is like the equivalent of taking on credit card debt but for trust right and maybe this will you know this will be what enables you to raise a lot of money but ultimately you are creating damage you are damaging the field so thats the concern is that that debt thats what happens with the other ai winters is the concern is you actually tweeted about this with autonomous vehicles right theres almost every single company now have promised that they will have full autonomous vehicles by 2021 2022 thats a good example of the consequences of over hyping the capabilities of ai and the pace of progress so because i work especially a lot recently in this area i have a deep concern of what happens when all of these companies after ive invested billions have a meeting and say how much do we actually first of all do we have an autonomous vehicle the answer will definitely be no and second will be wait a minute weve invested one two three four billion dollars into this and we made no profit and the reaction to that may be going very hard in other directions that might impact even other industries and thats what we call an ai winter is when there is backlash where no one believes any of these promises anymore because theyve turned that to be big lies the first time around and this will definitely happen to some extent for autonomous vehicles because the public and decision makers have been convinced that around 2015 theyve been convinced by these people who are trying to raise money for their startups and so on that l5 driving was coming in maybe 2016 maybe 2017 maybe 2018 now were in 2019 were still waiting for it and so i dont believe we are going to have a full on ai winter because we have these technologies that are producing a tremendous amount of real value but there is also too much hype so there will be some backlash especially there will be backlash so some startups are trying to sell the dream of agi and the fact that agi is going to create infinite value like agi is like a free lunch like if you can develop an ai system that passes a certain threshold of iq or something then suddenly you have infinite value and well there are actually lots of investors buying into this idea and they will wait maybe 10 15 years and nothing will happen and the next time around well maybe there will be a new generation of investors no one will care human memory is fairly short after all i dont know about you but because ive spoken about agi sometimes poetically i get a lot of emails from people giving me theyre usually like a large manifestos of theyve they say to me that they have created an agi system or they know how to do it and theres a long write up of how to do it i get a lot of these emails yeah theyre a little bit feel like its generated by an ai system actually but theres usually no diagram you have a transformer generating crank papers about agi so the question is about because youve been such a good you have a good radar for crank papers how do we know theyre not onto something how do i so when you start to talk about agi or anything like the reasoning benchmarks and so on so something that doesnt have a benchmark its really difficult to know i mean i talked to jeff hawkins whos really looking at neuroscience approaches to how and theres some theres echoes of really interesting ideas in at least jeffs case which hes showing how do you usually think about this like preventing yourself from being too narrow minded and elitist about deep learning it has to work on these particular benchmarks otherwise its trash well you know the thing is intelligence does not exist in the abstract intelligence has to be applied so if you dont have a benchmark if you have an improvement in some benchmark maybe its a new benchmark right maybe its not something weve been looking at before but you do need a problem that youre trying to solve youre not going to come up with a solution without a problem so you general intelligence i mean youve clearly highlighted generalization if you want to claim that you have an intelligence system it should come with a benchmark it should yes it should display capabilities of some kind it should show that it can create some form of value even if its a very artificial form of value and thats also the reason why you dont actually need to care about telling which papers have actually some hidden potential and which do not because if there is a new technique thats actually creating value this is going to be brought to light very quickly because its actually making a difference so its the difference between something that is ineffectual and something that is actually useful and ultimately usefulness is our guide not just in this field but if you look at science in general maybe there are many many people over the years that have had some really interesting theories of everything but they were just completely useless and you dont actually need to tell the interesting theories from the useless theories all you need is to see is this actually having an effect on something else is this actually useful is this making an impact or not thats beautifully put i mean the same applies to quantum mechanics to string theory to the holographic principle we are doing deep learning because it works before it started working people considered people working on neural networks as cranks very much no one was working on this anymore and now its working which is what makes it valuable its not about being right its about being effective and nevertheless the individual entities of this scientific mechanism just like yoshua banjo or jan lekun they while being called cranks stuck with it right yeah and so us individual agents even if everyones laughing at us just stick with it if you believe you have something you should stick with it and see it through thats a beautiful inspirational message to end on francois thank you so much for talking today that was amazing thank you that the number of scientists and engineers is in fact increasing exponentially the amount of computational resources that are available to science is increasing exponentially and so on so the resource consumption of science is exponential but the output in terms of progress in terms of significance is linear and the reason why is because and even though science is regressively self improving meaning that scientific progress turns into technological progress which in turn helps science if you look at computers for instance our products of science and computers are tremendously useful in speeding up science the internet same thing the internet is a technology thats made possible by very recent scientific advances and itself because it enables scientists to network to communicate to exchange papers and ideas much faster it is a way to speed up scientific progress so even though youre looking at a regressively self improving system it is consuming exponentially more resources to produce the same amount of problem solving very much so thats a fascinating way to paint it and certainly that holds for the deep learning community if you look at the temporal what did you call it the temporal density of significant ideas if you look at in deep learning i think id have to think about that but if you really look at significant ideas in deep learning they might even be decreasing so i do believe the per paper significance is decreasing but the amount of papers is still today exponentially increasing so i think if you look at an aggregate my guess is that you would see a linear progress if you were to sum the significance of all papers you would see roughly in your progress and in my opinion it is not a coincidence that youre seeing linear progress in science despite exponential resource consumption i think the resource consumption is dynamically adjusting itself to maintain linear progress because we as a community expect linear progress meaning that if we start investing less and seeing less progress it means that suddenly there are some lower hanging fruits that become available and someones gonna step up and pick them right so its very much like a market for discoveries and ideas but theres another fundamental part which youre highlighting which as a hypothesis as science or like the space of ideas any one path you travel down it gets exponentially more difficult to get a new way to develop new ideas and your sense is thats gonna hold across our mysterious universe yes well exponential progress triggers exponential friction so that if you tweak one part of the system suddenly some other part becomes a bottleneck right for instance lets say you develop some device that measures its own acceleration and then it has some engine and it outputs even more acceleration in proportion of its own acceleration and you drop it somewhere its not gonna reach infinite speed because it exists in a certain context so the air around it is gonna generate friction and its gonna block it at some top speed and even if you were to consider the broader context and lift the bottleneck there like the bottleneck of friction then some other part of the system would start stepping in and creating exponential friction maybe the speed of flight or whatever and this definitely holds true when you look at the problem solving algorithm that is being run by science as an institution science as a system as you make more and more progress despite having this recursive self improvement component you are encountering exponential friction the more researchers you have working on different ideas the more overhead you have in terms of communication across researchers if you look at you were mentioning quantum mechanics right well if you want to start making significant discoveries today significant progress in quantum mechanics there is an amount of knowledge you have to ingest which is huge so theres a very large overhead to even start to contribute theres a large amount of overhead to synchronize across researchers and so on and of course the significant practical experiments are going to require exponentially expensive equipment because the easier ones have already been run right so in your senses theres no way escaping theres no way of escaping this kind of friction with artificial intelligence systems yeah no i think science is a very good way to model what would happen with a superhuman recursive research improving ai thats your sense i mean the thats my intuition its not like a mathematical proof of anything thats not my point like im not trying to prove anything im just trying to make an argument to question the narrative of intelligence explosion which is quite a dominant narrative and you do get a lot of pushback if you go against it because so for many people right ai is not just a subfield of computer science its more like a belief system like this belief that the world is headed towards an event the singularity past which you know ai will become will go exponential very much and the world will be transformed and humans will become obsolete and if you go against this narrative because it is not really a scientific argument but more of a belief system it is part of the identity of many people if you go against this narrative its like youre attacking the identity of people who believe in it its almost like saying god doesnt exist or something so you do get a lot of pushback if you try to question these ideas first of all i believe most people they might not be as eloquent or explicit as youre being but most people in computer science are most people who actually have built anything that you could call ai quote unquote would agree with you they might not be describing in the same kind of way its more so the pushback youre getting is from people who get attached to the narrative from not from a place of science but from a place of imagination thats correct thats correct so why do you think thats so appealing because the usual dreams that people have when you create a superintelligence system past the singularity that what people imagine is somehow always destructive do you have if you were put on your psychology hat whats why is it so appealing to imagine the ways that all of human civilization will be destroyed i think its a good story you know its a good story and very interestingly it mirrors a religious stories right religious mythology if you look at the mythology of most civilizations its about the world being headed towards some final events in which the world will be destroyed and some new world order will arise that will be mostly spiritual like the apocalypse followed by a paradise probably right its a very appealing story on a fundamental level and we all need stories we all need stories to structure the way we see the world especially at timescales that are beyond our ability to make predictions right so on a more serious non exponential explosion question do you think there will be a time when well create something like human level intelligence or intelligent systems that will make you sit back and be just surprised at damn how smart this thing is that doesnt require exponential growth or an exponential improvement but whats your sense of the timeline and so on that youll be really surprised at certain capabilities and well talk about limitations and deep learning so do you think in your lifetime youll be really damn surprised around 2013 2014 i was many times surprised by the capabilities of deep learning actually that was before we had assessed exactly what deep learning could do and could not do and it felt like a time of immense potential and then we started narrowing it down but i was very surprised i would say it has already happened was there a moment there mustve been a day in there where your surprise was almost bordering on the belief of the narrative that we just discussed was there a moment because youve written quite eloquently about the limits of deep learning was there a moment that you thought that maybe deep learning is limitless no i dont think ive ever believed this what was really shocking is that it worked it worked at all yeah but theres a big jump between being able to do really good computer vision and human level intelligence so i dont think at any point i wasnt under the impression that the results we got in computer vision meant that we were very close to human level intelligence i dont think were very close to human level intelligence i do believe that theres no reason why we wont achieve it at some point i also believe that its the problem with talking about human level intelligence that implicitly youre considering like an axis of intelligence with different levels but thats not really how intelligence works intelligence is very multi dimensional and so theres the question of capabilities but theres also the question of being human like and its two very different things like you can build potentially very advanced intelligent agents that are not human like at all and you can also build very human like agents and these are two very different things right right lets go from the philosophical to the practical can you give me a history of keras and all the major deep learning frameworks that you kind of remember in relation to keras and in general tensorflow theano the old days can you give a brief overview wikipedia style history and your role in it before we return to agi discussions yeah thats a broad topic so i started working on keras it was the name keras at the time i actually picked the name like just the day i was going to release it so i started working on it in february 2015 and so at the time there werent too many people working on deep learning maybe like fewer than 10000 the software tooling was not really developed so the main deep learning library was cafe which was mostly c why do you say cafe was the main one cafe was vastly more popular than theano in late 2014 early 2015 cafe was the one library that everyone was using for computer vision and computer vision was the most popular problem in deep learning at the time absolutely like convnets was like the subfield of deep learning that everyone was working on so myself so in late 2014 i was actually interested in rnns in recurrent neural networks which was a very niche topic at the time right it really took off around 2016 and so i was looking for good tools i had used torch 7 i had used theano used theano a lot in kaggle competitions i had used cafe and there was no like good solution for rnns at the time like there was no reusable open source implementation of an lstm for instance so i decided to build my own and at first the pitch for that was it was gonna be mostly around lstm recurrent neural networks it was gonna be in python an important decision at the time that was kind of not obvious is that the models would be defined via python code which was kind of like going against the mainstream at the time because cafe pylon 2 and so on like all the big libraries were actually going with the approach of setting configuration files in yaml to define models so some libraries were using code to define models like torch 7 obviously but that was not python lasagne was like a theano based very early library that was i think developed i dont remember exactly probably late 2014 its python as well its python as well it was like on top of theano and so i started working on something and the value proposition at the time was that not only what i think was the first reusable open source implementation of lstm you could combine rnns and covenants with the same library which is not really possible before like cafe was only doing covenants and it was kind of easy to use because so before i was using theano i was actually using scikitlin and i loved scikitlin for its usability so i drew a lot of inspiration from scikitlin when i made keras its almost like scikitlin for neural networks the fit function exactly the fit function like reducing a complex string loop to a single function call right and of course some people will say this is hiding a lot of details but thats exactly the point right the magic is the point so its magical but in a good way its magical in the sense that its delightful yeah yeah im actually quite surprised i didnt know that it was born out of desire to implement rnns and lstms it was thats fascinating so you were actually one of the first people to really try to attempt to get the major architectures together and its also interesting you made me realize that that was a design decision at all is defining the model and code just im putting myself in your shoes whether the yaml especially if cafe was the most popular it was the most popular by far if i was if i were yeah i dont i didnt like the yaml thing but it makes more sense that you will put in a configuration file the definition of a model thats an interesting gutsy move to stick with defining it in code just if you look back other libraries were doing it as well but it was definitely the more niche option yeah okay keras and then so i released keras in march 2015 and it got users pretty much from the start so the deep learning community was very very small at the time lots of people were starting to be interested in lstm so it was gonna release it at the right time because it was offering an easy to use lstm implementation exactly at the time where lots of people started to be intrigued by the capabilities of rnn rnns for nlp so it grew from there then i joined google about six months later and that was actually completely unrelated to keras so i actually joined a research team working on image classification mostly like computer vision so i was doing computer vision research at google initially and immediately when i joined google i was exposed to the early internal version of tensorflow and the way it appeared to me at the time and it was definitely the way it was at the time is that this was an improved version of theano so i immediately knew i had to port keras to this new tensorflow thing and i was actually very busy as a noobler as a new googler so i had not time to work on that but then in november i think it was november 2015 tensorflow got released and it was kind of like my wake up call that hey i had to actually go and make it happen so in december i ported keras to run on top of tensorflow but it was not exactly a port it was more like a refactoring where i was abstracting away all the backend functionality into one module so that the same code base could run on top of multiple backends so on top of tensorflow or theano and for the next year theano stayed as the default option it was easier to use somewhat less buggy it was much faster especially when it came to audience but eventually tensorflow overtook it and tensorflow the early tensorflow has similar architectural decisions as theano right so it was a natural transition yeah absolutely so what i mean that still keras is a side almost fun project right yeah so it was not my job assignment it was not i was doing it on the side and even though it grew to have a lot of users for a deep learning library at the time like stroud 2016 but i wasnt doing it as my main job so things started changing in i think it must have been maybe october 2016 so one year later so rajat who was the lead on tensorflow basically showed up one day in our building where i was doing like so i was doing research and things like so i did a lot of computer vision research also collaborations with christian zighetti and deep learning for theorem proving it was a really interesting research topic and so rajat was saying hey we saw keras we like it we saw that youre at google why dont you come over for like a quarter and work with us and i was like yeah that sounds like a great opportunity lets do it and so i started working on integrating the keras api into tensorflow more tightly so what followed up is a sort of like temporary tensorflow only version of keras that was in tensorflowcom trib for a while and finally moved to tensorflow core and ive never actually gotten back to my old team doing research well its kind of funny that somebody like you who dreams of or at least sees the power of ai systems that reason and theorem proving well talk about has also created a system that makes the most basic kind of lego building that is deep learning super accessible super easy so beautifully so its a funny irony that youre both youre responsible for both things but so tensorflow 20 is kind of theres a sprint i dont know how long itll take but theres a sprint towards the finish what do you look what are you working on these days what are you excited about what are you excited about in 20 i mean eager execution theres so many things that just make it a lot easier to work what are you excited about and whats also really hard what are the problems you have to kind of solve so ive spent the past year and a half working on tensorflow 20 and its been a long journey im actually extremely excited about it i think its a great product its a delightful product compared to tensorflow 10 weve made huge progress so on the keras side what im really excited about is that so previously keras has been this very easy to use high level interface to do deep learning but if you wanted to if you wanted a lot of flexibility the keras framework was probably not the optimal way to do things compared to just writing everything from scratch so in some way the framework was getting in the way and in tensorflow 20 you dont have this at all actually you have the usability of the high level interface but you have the flexibility of this lower level interface and you have this spectrum of workflows where you can get more or less usability and flexibility trade offs depending on your needs right you can write everything from scratch and you get a lot of help doing so by subclassing models and writing some train loops using ego execution its very flexible its very easy to debug its very powerful but all of this integrates seamlessly with higher level features up to the classic keras workflows which are very scikit learn like and are ideal for a data scientist machine learning engineer type of profile so now you can have the same framework offering the same set of apis that enable a spectrum of workflows that are more or less low level more or less high level that are suitable for profiles ranging from researchers to data scientists and everything in between yeah so thats super exciting i mean its not just that its connected to all kinds of tooling you can go on mobile you can go with tensorflow lite you can go in the cloud or serving and so on it all is connected together now some of the best software written ever is often done by one person sometimes two so with a google youre now seeing sort of keras having to be integrated in tensorflow im sure has a ton of engineers working on and theres im sure a lot of tricky design decisions to be made how does that process usually happen from at least your perspective what are the debates like is there a lot of thinking considering different options and so on yes so a lot of the time i spend at google is actually discussing design discussions right writing design docs participating in design review meetings and so on this is as important as actually writing a code right so theres a lot of thought theres a lot of thought and a lot of care that is taken in coming up with these decisions and taking into account all of our users because tensorflow has this extremely diverse user base right its not like just one user segment where everyone has the same needs we have small scale production users large scale production users we have startups we have researchers you know its all over the place and we have to cater to all of their needs if i just look at the standard debates of c or python theres some heated debates do you have those at google i mean theyre not heated in terms of emotionally but theres probably multiple ways to do it right so how do you arrive through those design meetings at the best way to do it especially in deep learning where the field is evolving as youre doing it is there some magic to it is there some magic to the process i dont know if theres magic to the process but there definitely is a process so making design decisions is about satisfying a set of constraints but also trying to do so in the simplest way possible because this is what can be maintained this is what can be expanded in the future so you dont want to naively satisfy the constraints by just you know for each capability you need available youre gonna come up with one argument in your api and so on you want to design apis that are modular and hierarchical so that they have an api surface that is as small as possible right and you want this modular hierarchical architecture to reflect the way that domain experts think about the problem because as a domain expert when you are reading about a new api youre reading a tutorial or some docs pages you already have a way that youre thinking about the problem you already have like certain concepts in mind and youre thinking about how they relate together and when youre reading docs youre trying to build as quickly as possible a mapping between the concepts featured in your api and the concepts in your mind so youre trying to map your mental model as a domain expert to the way things work in the api so you need an api and an underlying implementation that are reflecting the way people think about these things so in minimizing the time it takes to do the mapping yes minimizing the time the cognitive load there is in ingesting this new knowledge about your api an api should not be self referential or referring to implementation details it should only be referring to domain specific concepts that people already understand brilliant so whats the future of keras and tensorflow look like what does tensorflow 30 look like so thats kind of too far in the future for me to answer especially since im not even the one making these decisions okay but so from my perspective which is just one perspective among many different perspectives on the tensorflow team im really excited by developing even higher level apis higher level than keras im really excited by hyperparameter tuning by automated machine learning automl i think the future is not just you know defining a model like you were assembling lego blocks and then collect fit on it its more like an automagical model that would just look at your data and optimize the objective youre after right so thats what im looking into yeah so you put the baby into a room with the problem and come back a few hours later with a fully solved problem exactly its not like a box of legos its more like the combination of a kid thats really good at legos and a box of legos its just building the thing on its own very nice so thats an exciting future i think theres a huge amount of applications and revolutions to be had under the constraints of the discussion we previously had but what do you think of the current limits of deep learning if we look specifically at these function approximators that tries to generalize from data youve talked about local versus extreme generalization you mentioned that neural networks dont generalize well and humans do so theres this gap and youve also mentioned that extreme generalization requires something like reasoning to fill those gaps so how can we start trying to build systems like that right yeah so this is by design right deep learning models are like huge parametric models differentiable so continuous that go from an input space to an output space and theyre trained with gradient descent so theyre trained pretty much point by point they are learning a continuous geometric morphing from an input vector space to an output vector space and because this is done point by point a deep neural network can only make sense of points in experience space that are very close to things that it has already seen in string data at best it can do interpolation across points but that means in order to train your network you need a dense sampling of the input cross output space almost a point by point sampling which can be very expensive if youre dealing with complex real world problems like autonomous driving for instance or robotics its doable if youre looking at the subset of the visual space but even then its still fairly expensive you still need millions of examples and its only going to be able to make sense of things that are very close to what it has seen before and in contrast to that well of course you have human intelligence but even if youre not looking at human intelligence you can look at very simple rules algorithms if you have a symbolic rule it can actually apply to a very very large set of inputs because it is abstract it is not obtained by doing a point by point mapping for instance if you try to learn a sorting algorithm using a deep neural network well youre very much limited to learning point by point what the sorted representation of this specific list is like but instead you could have a very very simple sorting algorithm written in a few lines maybe its just two nested loops and it can process any list at all because it is abstract because it is a set of rules so deep learning is really like point by point geometric morphings train with good and decent and meanwhile abstract rules can generalize much better and i think the future is we need to combine the two so how do we do you think combine the two how do we combine good point by point functions with programs which is what the symbolic ai type systems at which levels the combination happen i mean obviously were jumping into the realm of where theres no good answers its just kind of ideas and intuitions and so on well if you look at the really successful ai systems today i think they are already hybrid systems that are combining symbolic ai with deep learning for instance successful robotics systems are already mostly model based rule based things like planning algorithms and so on at the same time theyre using deep learning as perception modules sometimes theyre using deep learning as a way to inject fuzzy intuition into a rule based process if you look at the system like in a self driving car its not just one big end to end neural network you know that wouldnt work at all precisely because in order to train that you would need a dense sampling of experience base when it comes to driving which is completely unrealistic obviously instead the self driving car is mostly symbolic you know its software its programmed by hand so its mostly based on explicit models in this case mostly 3d models of the environment around the car but its interfacing with the real world using deep learning modules right so the deep learning there serves as a way to convert the raw sensory information to something usable by symbolic systems okay well lets linger on that a little more so dense sampling from input to output you said its obviously very difficult is it possible in the case of self driving you mean lets say self driving right self driving for many people lets not even talk about self driving lets talk about steering so staying inside the lane lane following yeah its definitely a problem you can solve with an end to end deep learning model but thats like one small subset hold on a second yeah i dont know why youre jumping from the extreme so easily because i disagree with you on that i think well its not obvious to me that you can solve lane following no its not obvious i think its doable i think in general there is no hard limitations to what you can learn with a deep neural network as long as the search space is rich enough is flexible enough and as long as you have this dense sampling of the input cross output space the problem is that this dense sampling could mean anything from 10000 examples to like trillions and trillions so thats my question so whats your intuition and if you could just give it a chance and think what kind of problems can be solved by getting a huge amounts of data and thereby creating a dense mapping so lets think about natural language dialogue the turing test do you think the turing test can be solved with a neural network alone well the turing test is all about tricking people into believing theyre talking to a human and i dont think thats actually very difficult because its more about exploiting human perception and not so much about intelligence theres a big difference between mimicking intelligent behavior and actual intelligent behavior so okay lets look at maybe the alexa prize and so on the different formulations of the natural language conversation that are less about mimicking and more about maintaining a fun conversation that lasts for 20 minutes thats a little less about mimicking and thats more about i mean its still mimicking but its more about being able to carry forward a conversation with all the tangents that happen in dialogue and so on do you think that problem is learnable with a neural network that does the point to point mapping so i think it would be very very challenging to do this with deep learning i dont think its out of the question either i wouldnt rule it out the space of problems that can be solved with a large neural network whats your sense about the space of those problems so useful problems for us in theory its infinite right you can solve any problem in practice well deep learning is a great fit for perception problems in general any problem which is naturally amenable to explicit handcrafted rules or rules that you can generate by exhaustive search over some program space so perception artificial intuition as long as you have a sufficient training dataset and thats the question i mean perception theres interpretation and understanding of the scene which seems to be outside the reach of current perception systems so do you think larger networks will be able to start to understand the physics and the physics of the scene the three dimensional structure and relationships of objects in the scene and so on or really thats where symbolic ai has to step in well its always possible to solve these problems with deep learning its just extremely inefficient a model would be an explicit rule based abstract model would be a far better more compressed representation of physics then learning just this mapping between in this situation this thing happens if you change the situation slightly then this other thing happens and so on do you think its possible to automatically generate the programs that would require that kind of reasoning or does it have to so the way the expert systems fail theres so many facts about the world had to be hand coded in do you think its possible to learn those logical statements that are true about the world and their relationships do you think i mean thats kind of what theorem proving at a basic level is trying to do right yeah except its much harder to formulate statements about the world compared to formulating mathematical statements statements about the world tend to be subjective so can you learn rule based models yes definitely thats the field of program synthesis however today we just dont really know how to do it so its very much a grass search or tree search problem and so we are limited to the sort of tree session grass search algorithms that we have today personally i think genetic algorithms are very promising so almost like genetic programming genetic programming exactly can you discuss the field of program synthesis like how many people are working and thinking about it where we are in the history of program synthesis and what are your hopes for it well if it were deep learning this is like the 90s so meaning that we already have existing solutions we are starting to have some basic understanding of what this is about but its still a field that is in its infancy there are very few people working on it there are very few real world applications so the one real world application im aware of is flash fill in excel its a way to automatically learn very simple programs to format cells in an excel spreadsheet from a few examples for instance learning a way to format a date things like that oh thats fascinating yeah you know ok thats a fascinating topic i always wonder when i provide a few samples to excel what its able to figure out like just giving it a few dates what are you able to figure out from the pattern i just gave you thats a fascinating question and its fascinating whether thats learnable patterns and youre saying theyre working on that how big is the toolbox currently are we completely in the dark so if you said the 90s in terms of program synthesis no so i would say so maybe 90s is even too optimistic because by the 90s we already understood back prop we already understood the engine of deep learning even though we couldnt really see its potential quite today i dont think we have found the engine of program synthesis so were in the winter before back prop yeah in a way yes so i do believe program synthesis and general discrete search', 'the following is a conversation with colin angle hes the ceo and co founder of irobot a robotics company that for 29 years has been creating robots that operate successfully in the real world not as a demo or on a scale of dozens but on a scale of thousands and millions as of this year irobot has sold more than 25 million robots to consumers including the roomba vacuum cleaning robot the bravo floor mopping robot and soon the terra lawn mowing robot 29 million robots successfully operating autonomously in real peoples homes to me is an incredible accomplishment of science engineering logistics and all kinds of general entrepreneurial innovation most robotics companies fail irobot has survived and succeeded for 29 years i spent all day at irobot including a long tour and conversation with colin about the history of irobot and then sat down for this podcast conversation that would have been much longer if i didnt spend all day learning about and playing with the various robots and the companys history ill release the video of the tour separately colin irobot its founding team its current team and its mission has been and continues to be an inspiration to me and thousands of engineers who are working hard to create ai systems that help real people this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with colin angle in his 1942 short story runaround from his irobot collection asimov proposed the three laws of robotics in order dont harm humans obey orders protect yourself so two questions first does the roomba follow these three laws and also more seriously what role do you hope to see robots take in modern society and in the future world so the three laws are very thought provoking and require such a profound understanding of the world a robot lives in the ramifications of its action and its own sense of self that its not a relevant bar at least it wont be a relevant bar for decades to come and so if roomba follows the three laws and i believe it does it is designed to help humans not hurt them its designed to be inherently safe and we designed it to last a long time its not through any ai or intent on the robots part its because following the three laws is aligned with being a good robot product so i guess it does but not by explicit design so then the bigger picture what role do you hope to see robotics robots take in whats currently mostly a world of humans we need robots to help us continue to improve our standard of living we need robots because the average age of humanity is increasing very quickly and simply the number of people young enough and spry enough to care for the elder growing demographic is inadequate and so what is the role of robots today the role is to make our lives a little easier a little cleaner maybe a little healthier but in time robots are going to be the difference between real gut wrenching declines in our ability to live independently and maintain our standard of living and a future that is the bright one where we have more control over our lives can spend more of our time focused on activities we choose and im so honored and excited to be playing a role in that journey so youve given me a tour it showed me some of the long histories now 29 years that irobot has been at it creating some incredible robots you showed me pacbot you showed me a bunch of other stuff that led up to roomba that led to braava and terra so lets skip that incredible history in the interest of time cause we already talked about it ill show this incredible footage you mentioned elderly and robotics in society i think the home is a fascinating place for robots to be so where do you see robots in the home currently i would say once again probably most homes in the world dont have a robot so how do you see that changing what do you think is the big initial value add that robots can do so irobot has sort of over the years narrowed in on the home the consumers home as the place where we want to innovate and deliver tools that will help a home be a more automatically maintained place a healthier place a safer place and perhaps even a more efficient place to be and today we vacuum we mop soon well be mowing your lawn but where things are going is when do we get to the point where the home not just the robots that live in your home but the home itself becomes part of a system that maintains itself and plays an active role in caring for and helping the people live in that home and i see everything that were doing as steps along the path toward that future so what are the steps so if we can summarize some of the history of roomba youve mentioned and maybe you can elaborate on it but you mentioned that the early days were really taking a robot from something that works either in the lab or something that works in the field that helps soldiers do the difficult work they do to actually be in the hands of consumers and tens of thousands hundreds of thousands of robots that dont break down over how much people love them over months of very extensive use so that was the big first step and then the second big step was the ability to sense the environment to build a map to localize to be able to build a picture of the home that the human can then attach labels to in terms of giving some semantic knowledge to the robot about its environment okay so thats like a huge two big huge steps maybe you can comment on them but also what is the next step of making a robot part of the home sure so the goal is to make a home that takes care of itself takes care of the people in the home and gives the user an experience of just living their life and the home is somehow doing the right thing turning on and off lights when you leave cleaning up the environment and we went from robots that were great in the lab but were both too expensive and not sufficiently capable to ever do an acceptable job of anything other than being a toy or a curio in your home to something that was both affordable and sufficiently effective to drive be above threshold and drive purchase intent now weve disrupted the entire vacuuming industry the number one selling vacuums for example in the us are roombas so not robot vacuums but vacuums and thats really crazy and weird we need to pause that i mean thats incredible thats incredible that a robot is the number one selling thing that does something yep something as essential as vacuuming yep congratulations thank you its still kind of fun to say but just because this was a crazy idea that just started you know in a room here were like do you think we can do this so hey lets give it a try but now the robots are starting to understand their environment and if you think about the next step theres two dimensions ive been working so hard since the beginning of irobot to make robots are autonomous that you know theyre smart enough and understand their task enough they can just go do it without human involvement now what im really excited and working on is how do i make them less autonomous meaning that the robot is supposed to be your partner not this automaton that just goes and does what a robot does and so that if you tell it hey i just dropped some flour by the fridge in the kitchen can you deal with it wouldnt it be awesome if the right thing just happened based on that utterance and to some extent thats less autonomous because its actually listening to you understanding the context and intent of the sentence mapping it against its understanding of the home it lives in and knowing what to do and so thats an area of research its an area where were starting to roll out features you can now tell your robot to clean up the kitchen and it knows what the kitchen is and can do that and thats sort of 10 of where were going the other cool thing is that were starting to know where stuff is and why is that important well robots are supposed to have arms right data had an arm rosie had an arm robbie the robot had an arm i mean robots are you know they are physical things that move around in an environment and theyre supposed to like do work and if you think about it if a robot doesnt know where anything is why should it have an arm but with this new dawn of home understanding that were starting to go enjoy i know where the kitchen is i might in the future know where the refrigerator is i might if i had an arm be able to find the handle open it and even get myself a beer obviously thats one of the true dreams of robotics is to have robots bringing us a beer while we watch television but you know i think that that new category of tasks where physical manipulation robot arms is just a potpourri of new opportunity and excitement and you see humans as a crucial part of that so you kind of mentioned that and i personally find that a really compelling idea i think full autonomy can only take us so far especially in the home so you see humans as helping the robot understand or give deeper meaning to the spatial information right its a partnership the robot is supposed to operate according to descriptors that you would use to describe your own home the robot is supposed to in lieu of better direction kind of go about its routine which ought to be basically right and lead to a home maintained in a way that its learned you like but also be perpetually ready to take direction that would activate a different set of behaviors or actions to meet a current need to the extent it could actually perform that task so i got to ask you i think this is a fundamental and a fascinating question because irobot has been a successful company and a rare successful robotics company so anki jibo mayfield robotics with their robot curry scifi works rethink robotics these are robotics companies that were founded and run by brilliant people but all very unfortunately at least for us roboticists all went out of business recently so why do you think they didnt last longer why do you think it is so hard to keep a robotics company alive you know i say this only partially in jest that back in the day before roomba you know i was a high tech entrepreneur building robots but it wasnt until i became a vacuum cleaner salesman that we had any success so i mean the point is technology alone doesnt equal a successful business we need to go and find the compelling need where the robot that were creating can deliver clearly more value to the end user than it costs and this is not a marginal thing where youre looking at the scale and youre like yeah its close maybe we can hold our breath and make it work its clearly more value than the cost of the robot to bring you know in the store and i think that the challenge has been finding those businesses where thats true in a sustainable fashion you know when you get into entertainment style things you could be the cats meow one year but 85 of toys regardless of their merit fail to make it to their second season its just super hard to do so and so thats just a tough business and there has been a lot of experimentation around what is the right type of social companion what is the right robot in the home that is doing something other than tasks people do every week that theyd rather not do and im not sure weve got it all figured out right and so that you get brilliant roboticists with super interesting robots that ultimately dont quite have that magical user experience and thus that value benefit equation remains ambiguous so you as somebody who dreams of robots changing the world whats your estimate how big is the space of applications that fit the criteria that you just described where you can really demonstrate an obvious significant value over the alternative non robotic solution well i think that were just about none of the way to achieving the potential of robotics at home but we have to do it in a really eyes wide open honest fashion and so another way to put that is the potential is infinite because we did take a few steps but youre saying those steps are just very initial steps so the roomba is a hugely successful product but youre saying thats just the very very beginning thats just the very very beginning its the foot in the door and i think i was lucky that in the early days of robotics people would ask me when are you going to clean my floor it was something that i grew up saying i got all these really good ideas but everyone seems to want their floor clean and so maybe we should do that yeah your good ideas earn the right to do the next thing after that so the good ideas have to match with the desire of the people and then the actual cost has to like the business the financial aspect has to all match together yeah during our partnership back a number of years ago with johnson wax they would explain to me that they would go into homes and just watch how people lived and try to figure out what were they doing that they really didnt really like to do but they had to do it frequently enough that it was top of mind and understood as a burden hey lets make a product or come up with a solution to make that pain point less challenging and sometimes we do certain burdens so often as a society that we actually dont even realize like its actually hard to see that that burden is something that could be removed so it does require just going into the home and staring at wait how do i actually live life what are the pain points yeah and getting those insights is a lot harder than it would seem it should be in retrospect so how hard on that point i mean one of the big challenges of robotics is driving the cost down to something that consumers people would afford so people would be less likely to buy a roomba if it cost 500000 which is probably sort of what a roomba would cost several decades ago so how do you drive which i mentioned is very difficult how do you drive the cost of a roomba or a robot down such that people would want to buy it when i started building robots the cost of the robot had a lot to do with the amount of time it took to build it and so that we build our robots out of aluminum i would go spend my time in the machine shop on the milling machine cutting out the parts and so forth and then when we got into the toy industry i realized that if we were building at scale i could determine the cost of the roomba instead of adding up all the hours to mill out the parts but by weighing it and thats liberating you can say wow the world has just changed as i think about construction in a different way the 3d cad tools that are available to us today the operating at scale where i can do tooling and injection mold an arbitrarily complicated part and the cost is going to be basically the weight of the plastic in that part is incredibly exciting and liberating and opens up all sorts of opportunities and for the sensing part of it where we are today is instead of trying to build skin which is really hard for a long time i spent creating strategies and ideas around how could we duplicate the skin on the human body because its such an amazing sensor instead of going down that path why dont we focus on vision and how many of the problems that face a robot trying to do real work could be solved with a cheap camera and a big ass computer moores law continues to work the cell phone industry the mobile industry is giving us better and better tools that can run on these embedded computers and i think we passed an important moment maybe two years ago where you could put machine vision capable processors on robots at consumer price points and i was waiting for it to happen we avoided putting lasers on our robots to do navigation and instead spent years researching how to do vision based navigation because you could just see where these technology trends were going and between injection molded plastic and a camera with a computer capable of running machine learning and visual object recognition i could build an incredibly affordable incredibly capable robot and thats going to be the future so on that point with a small tangent but i think an important one another industry in which i would say the only other industry in which there is automation actually touching peoples lives today is autonomous vehicles what the vision you just described of using computer vision and using cheap camera sensors theres a debate on that of lidar versus computer vision and the elon musk famously said that lidar is a crutch that really in the long term camera only is the right solution which echoes some of the ideas youre expressing of course the domain in terms of its safety criticality is different but what do you think about that approach in the autonomous vehicle space and in general do you see a connection between the incredible real world challenges you have to solve in the home with roomba and i saw a demonstration of some of them corner cases literally and autonomous vehicles so theres absolutely a tremendous overlap between both the problems a robot vacuum and an autonomous vehicle are trying to solve and the tools and the types of sensors that are being applied in the pursuit of the solutions in my world my environment is actually much harder than the environment an automobile travels we dont have roads we have t shirts we have steps we have a near infinite number of patterns and colors and surface textures on the floor especially from a visual perspective so the way the world looks is an infinitely variable on the other hand safety is way easier on the inside my robots theyre not very heavy theyre not very fast if they bump into your foot you think its funny and autonomous vehicles kind of have the inverse problem and so that for me saying vision is the future i can say that without reservation for autonomous vehicles i think i believe what elons saying about the future is ultimately going to be vision maybe if we put a cheap lighter on there as a backup sensor it might not be the worst idea in the world so the stakes are much higher the stakes are much higher you have to be much more careful thinking through how far away that future is right but i think that the primary environmental understanding sensor is going to be a visual system visual system so on that point well let me ask do you hope theres an irobot robot in every home in the world one day i expect there to be at least one irobot robot in every home weve sold 25 million robots so were in about 10 of us homes which is a great start but i think that when we think about the numbers of things that robots can do today i can vacuum your floor mop your floor cut your lawn or soon well be able to cut your lawn but there are more things that we could do in the home and i hope that we continue using the techniques i described around exploiting computer vision and low cost manufacturing that well be able to create these solutions at affordable price points so let me ask on that point of a robot in every home thats my dream as well id love to see that i think the possibilities there are indeed infinite positive possibilities but in our current culture no thanks to science fiction and so on theres a serious kind of hesitation anxiety concern about robots and also a concern about privacy and its a fascinating question to me why that concern is amongst a certain group of people is as intense as it is so you have to think about it because its a serious concern but i wonder how you address it best so from a perspective of vision sensors so robots that move about the home and sense the world how do you alleviate peoples privacy concerns how do you make sure that they can trust irobot and the robots that they share their home with i think thats a great question and weve really leaned way forward on this because given our vision as to the role the company intends to play in the home really for us make or break is can our approach be trusted to protecting the data and the privacy of the people who have our robots and so weve gone out publicly with a privacy manifesto stating well never sell your data weve adopted gdpr not just where gdpr is required but globally we have ensured that images dont leave the robot so processing data from the visual sensors happens locally on the robot and only semantic knowledge of the home with the consumers consent is sent up we show you what we know and are trying to go use data as an enabler for the performance of the robots with the informed consent and understanding of the people who own those robots we take it very seriously and ultimately we think that by showing a customer that if you let us build a semantic map of your home and know where the rooms are well then you can say clean the kitchen if you dont want the robot to do that dont make the map itll do its best job cleaning your home but it wont be able to do that and if you ever want us to forget that we know that its your kitchen you can have confidence that we will do that for you so were trying to go and be a data 20 perspective company where we treat the data that the robots have of the consumers home as if it were the consumers data and that they have rights to it so we think by being the good guys on this front we can build the trust and thus be entrusted to enable robots to do more things that are thoughtful you think peoples worries will diminish over time as a society broadly speaking do you think you can win over trust not just for the company but just the comfort that people have with ai in their home enriching their lives in some way i think were in an interesting place today where its less about winning them over and more about finding a way to talk about privacy in a way that more people can understand i would tell you that today when theres a privacy breach people get very upset and then go to the store and buy the cheapest thing paying no attention to whether or not the products that theyre buying honor privacy standards or not in fact if i put on the package of my roomba the privacy commitments that we have i would sell less than i would if i did nothing at all and that needs to change so its not a question about earning trust i think thats necessary but not sufficient we need to figure out how to have a comfortable set of what is the grade a meat standard applied to privacy that customers can trust and understand and then use in their buying decisions that will reward companies for good behavior and that will ultimately be how this moves forward and maybe be part of the conversation between regular people about what it means what privacy means if you have some standards you can say you can start talking about whos following them who does not have more because most people are actually quite clueless about all aspects of artificial intelligence the data collection and so on it would be nice to change that for people to understand the good that ai can do and its not some system thats trying to steal all the most sensitive data do you think do you dream of a roomba with human level intelligence one day so youve mentioned a very successful localization and mapping of the environment being able to do some basic communication to say go clean the kitchen do you see in your maybe more bored moments once you get the beer to sit back with that beer and have a chat on a friday night with a roomba about how your day went so to your latter question absolutely to your former question as to whether a roomba can have human level intelligence not in my lifetime you can have you i think you can have a great conversation a meaningful conversation with a roomba without it having anything that resembles human level intelligence and i think that as long as you realize that conversation is not about the robot and making the robot feel good that conversation is about you learning interesting things that make you feel like the conversation that you had with the robot is a pretty awesome way of learning something and it could be about what kind of day your pet had it could be about how can i make my home more energy efficient it could be about if im thinking about climbing mount everest what should i know and thats a very doable thing but if i think that that conversation im going to have with the robot is im going to be rewarded by making the robot happy well i could just put a button on the robot that you could push and the robot would smile and that sort of thing so i think you need to think about the question in the right way and robots can be awesomely effective at helping people feel less isolated learn more about the home that they live in and fill some of those lonely gaps that we wish we were engaged learning cool stuff about our world last question if you could hang out for a day with a robot from science fiction movies books and safely pick its brain for that day who would you pick data data from star trek i think that a data is really smart data has been through a lot trying to go and save the galaxy and im really interested actually in emotion and robotics and i think youd have a lot to say about that because i believe actually that emotion plays an incredibly useful role in doing reasonable things in situations where we have imperfect understanding of whats going on in social situations when theres imperfect information in social situations also in competitive or dangerous situations that we have emotion for a reason and so that ultimately my theory is that as robots get smarter and smarter theyre actually going to get more emotional because you cant actually survive on pure logic because only a very tiny fraction of the situations we find ourselves in can be resolved reasonably with logic and so i think data would have a lot to say about that and so i could find out whether he agrees if you could ask data one question you would get a deep honest answer to what would you ask whats captain picard really like ok i think thats the perfect way to end it colin thank you so much for talking today i really appreciate it my pleasure', 'the following is a conversation with regina barzilay shes a professor at mit and a world class researcher in natural language processing and applications of deep learning to chemistry and oncology or the use of deep learning for early diagnosis prevention and treatment of cancer she has also been recognized for teaching of several successful ai related courses at mit including the popular introduction to machine learning course this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with regina barzilay in an interview youve mentioned that if theres one course you would take it would be a literature course with a friend of yours that a friend of yours teaches just out of curiosity because i couldnt find anything on it are there books or ideas that had profound impact on your life journey books and ideas perhaps outside of computer science and the technical fields i think because im spending a lot of my time at mit and previously in other institutions where i was a student i have limited ability to interact with people so a lot of what i know about the world actually comes from books and there were quite a number of books that had profound impact on me and how i view the world let me just give you one example of such a book ive maybe a year ago read a book called the emperor of all melodies its a book about its kind of a history of science book on how the treatments and drugs for cancer were developed and that book despite the fact that i am in the business of science really opened my eyes on how imprecise and imperfect the discovery process is and how imperfect our current solutions and what makes science succeed and be implemented and sometimes its actually not the strengths of the idea but devotion of the person who wants to see it implemented so this is one of the books that you know at least for the last year quite changed the way im thinking about scientific process just from the historical perspective and what do i need to do to make my ideas really implemented let me give you an example of a book which is not kind of which is a fiction book its a book called americana and this is a book about a young female student who comes from africa to study in the united states and it describes her past you know within her studies and her life transformation that you know in a new country and kind of adaptation to a new culture and when i read this book i saw myself in many different points of it but it also kind of gave me the lens on different events and some of it that i never actually paid attention one of the funny stories in this book is how she arrives to her new college and she starts speaking in english and she had this beautiful british accent because thats how she was educated in her country this is not my case and then she notices that the person who talks to her you know talks to her in a very funny way in a very slow way and shes thinking that this woman is disabled and shes also trying to kind of to accommodate her and then after a while when she finishes her discussion with this officer from her college she sees how she interacts with the other students with american students and she discovers that actually she talked to her this way because she saw that she doesnt understand english and i thought wow this is a funny experience and literally within few weeks i went to la to a conference and i asked somebody in the airport you know how to find like a cab or something and then i noticed that this person is talking in a very strange way and my first thought was that this person have some you know pronunciation issues or something and im trying to talk very slowly to him and i was with another professor ernst frankel and hes like laughing because its funny that i dont get that the guy is talking in this way because he thinks that i cannot speak so it was really kind of mirroring experience and it led me think a lot about my own experiences moving you know from different countries so i think that books play a big role in my understanding of the world on the science question you mentioned that it made you discover that personalities of human beings are more important than perhaps ideas is that what i heard its not necessarily that they are more important than ideas but i think that ideas on their own are not sufficient and many times at least at the local horizon its the personalities and their devotion to their ideas is really that locally changes the landscape now if youre looking at ai like lets say 30 years ago you know dark ages of ai or whatever what is symbolic times you can use any word you know there were some people now were looking at a lot of that work and were kind of thinking this was not really maybe a relevant work but you can see that some people managed to take it and to make it so shiny and dominate the academic world and make it to be the standard if you look at the area of natural language processing it is well known fact that the reason that statistics in nlp took such a long time to become mainstream because there were quite a number of personalities which didnt believe in this idea and didnt stop research progress in this area so i do not think that you know kind of asymptotically maybe personalities matters but i think locally it does make quite a bit of impact and its generally you know speeds up the rate of adoption of the new ideas yeah and the other interesting question is in the early days of particular discipline i think you mentioned in that book is ultimately a book of cancer its called the emperor of all melodies yeah and those melodies included the trying to the medicine was it centered around so it was actually centered on you know how people thought of curing cancer like for me it was really a discovery how people what was the science of chemistry behind drug development that it actually grew up out of dying like coloring industry that people who developed chemistry in 19th century in germany and britain to do you know the really new dyes they looked at the molecules and identified that they do certain things to cells and from there the process started and you know like historically saying yeah this is fascinating that they managed to make the connection and look under the microscope and do all this discovery but as you continue reading about it and you read about how chemotherapy drugs which were developed in boston and some of them were developed and farber dr farber from dana farber you know how the experiments were done that you know there was some miscalculation lets put it this way and they tried it on the patients and they just and those were children with leukemia and they died and then they tried another modification you look at the process how imperfect is this process and you know like if were again looking back like 60 years ago 70 years ago you can kind of understand it but some of the stories in this book which were really shocking to me were really happening you know maybe decades ago and we still dont have a vehicle to do it much more fast and effective and you know scientific the way im thinking computer science scientific so from the perspective of computer science youve gotten a chance to work the application to cancer and to medicine in general from a perspective of an engineer and a computer scientist how far along are we from understanding the human body biology of being able to manipulate it in a way we can cure some of the maladies some of the diseases so this is very interesting question and if youre thinking as a computer scientist about this problem i think one of the reasons that we succeeded in the areas we as a computer scientist succeeded is because we dont have we are not trying to understand in some ways like if youre thinking about like ecommerce amazon amazon doesnt really understand you and thats why it recommends you certain books or certain products correct and you know traditionally when people were thinking about marketing you know they divided the population to different kind of subgroups identify the features of this subgroup and come up with a strategy which is specific to that subgroup if youre looking about recommendation system theyre not claiming that theyre understanding somebody theyre just managing to from the patterns of your behavior to recommend you a product now if you look at the traditional biology and obviously i wouldnt say that i at any way you know educated in this field but you know what i see theres really a lot of emphasis on mechanistic understanding and it was very surprising to me coming from computer science how much emphasis is on this understanding and given the complexity of the system maybe the deterministic full understanding of this process is you know beyond our capacity and the same ways in computer science when were doing recognition when you do recommendation and many other areas its just probabilistic matching process and in some way maybe in certain cases we shouldnt even attempt to understand or we can attempt to understand but in parallel we can actually do this kind of matchings that would help us to find key role to do early diagnostics and so on and i know that in these communities its really important to understand but im sometimes wondering you know what exactly does it mean to understand here well theres stuff that works and but that can be like you said separate from this deep human desire to uncover the mysteries of the universe of science of the way the body works the way the mind works its the dream of symbolic ai of being able to reduce human knowledge into logic and be able to play with that logic in a way thats very explainable and understandable for us humans i mean thats a beautiful dream so i understand it but it seems that what seems to work today and well talk about it more is as much as possible reduce stuff into data reduce whatever problem youre interested in to data and try to apply statistical methods apply machine learning to that on a personal note you were diagnosed with breast cancer in 2014 what did facing your mortality make you think about how did it change you you know this is a great question and i think that i was interviewed many times and nobody actually asked me this question i think i was 43 at a time and the first time i realized in my life that i may die and i never thought about it before and there was a long time since youre diagnosed until you actually know what you have and how severe is your disease for me it was like maybe two and a half months and i didnt know where i am during this time because i was getting different tests and one would say its bad and i would say no it is not so until i knew where i am i really was thinking about all these different possible outcomes were you imagining the worst or were you trying to be optimistic or it would be really i dont remember what was my thinking it was really a mixture with many components at the time speaking in our terms and one thing that i remember and every test comes and then youre saying oh it could be this or it may not be this and youre hopeful and then youre desperate so its like there is a whole slew of emotions that goes through you but what i remember is that when i came back to mit i was kind of going the whole time through the treatment to mit but my brain was not really there but when i came back really finished my treatment and i was here teaching and everything i look back at what my group was doing what other groups was doing and i saw these trivialities its like people are building their careers on improving some parts around two or 3 or whatever i was its like seriously i did a work on how to decipher ugaritic like a language that nobody speak and whatever like what is significance when all of a sudden i walked out of mit which is when people really do care what happened to your iclr paper what is your next publication to acl to the world where people you see a lot of suffering that im kind of totally shielded on it on daily basis and its like the first time ive seen like real life and real suffering and i was thinking why are we trying to improve the parser or deal with trivialities when we have capacity to really make a change and it was really challenging to me because on one hand i have my graduate students really want to do their papers and their work and they want to continue to do what they were doing which was great and then it was me who really kind of reevaluated what is the importance and also at that point because i had to take some break i look back into like my years in science and i was thinking like 10 years ago this was the biggest thing i dont know topic models we have like millions of papers on topic models and variation of topics models now its totally like irrelevant and you start looking at this what do you perceive as important at different point of time and how it fades over time and since we have a limited time all of us have limited time on us its really important to prioritize things that really matter to you maybe matter to you at that particular point but its important to take some time and understand what matters to you which may not necessarily be the same as what matters to the rest of your scientific community and pursue that vision so that moment did it make you cognizant you mentioned suffering of just the general amount of suffering in the world is that what youre referring to so as opposed to topic models and specific detailed problems in nlp did you start to think about other people who have been diagnosed with cancer is that the way you started to see the world perhaps oh absolutely and it actually creates because like for instance there is parts of the treatment where you need to go to the hospital every day and you see the community of people that you see and many of them are much worse than i was at a time and you all of a sudden see it all and people who are happier someday just because they feel better and for people who are in our normal realm you take it totally for granted that you feel well that if you decide to go running you can go running and youre pretty much free to do whatever you want with your body like i saw like a community my community became those people and i remember one of my friends dina katabi took me to prudential to buy me a gift for my birthday and it was like the first time in months that i went to kind of to see other people and i was like wow first of all these people they are happy and theyre laughing and theyre very different from these other my people and second of thing i think its totally crazy theyre like laughing and wasting their money on some stupid gifts and they may die they already may have cancer and they dont understand it so you can really see how the mind changes that you can see that before that you can ask didnt you know that youre gonna die of course i knew but it was a kind of a theoretical notion it wasnt something which was concrete and at that point when you really see it and see how little means sometimes the system has to have them you really feel that we need to take a lot of our brilliance that we have here at mit and translate it into something useful yeah and you still couldnt have a lot of definitions but of course alleviating suffering alleviating trying to cure cancer is a beautiful mission so i of course know theoretically the notion of cancer but just reading more and more about its 17 million new cancer cases in the united states every year 600000 cancer related deaths every year so this has a huge impact united states globally when broadly before we talk about how machine learning how mit can help when do you think we as a civilization will cure cancer how hard of a problem is it from everything youve learned from it recently i cannot really assess it what i do believe will happen with the advancement in machine learning is that a lot of types of cancer we will be able to predict way early and more effectively utilize existing treatments i think i hope at least that with all the advancements in ai and drug discovery we would be able to much faster find relevant molecules what im not sure about is how long it will take the medical establishment and regulatory bodies to kind of catch up and to implement it and i think this is a very big piece of puzzle that is currently not addressed thats the really interesting question so first a small detail that i think the answer is yes but is cancer one of the diseases that when detected earlier thats a significantly improves the outcomes so like cause we will talk about theres the cure and then there is detection and i think where machine learning can really help is earlier detection so does detection help detection is crucial for instance the vast majority of pancreatic cancer patients are detected at the stage that they are incurable thats why they have such a terrible survival rate that machine understands you and you can complete the rest that he kind of stopped this research and went into kind of trying to understand what this artificial intelligence can do to our brains so my point is you know how much its not how good is the technology its how ready we are to believe that it delivers the goods that we are trying to get thats a really beautiful way to put it i by the way im not horrified by that possibility but inspired by it because i mean human connection whether its through language or through love it seems like its very amenable to machine learning and the rest is just challenges of psychology like you said the secretaries who enjoy spending hours i would say i would describe most of our lives as enjoying spending hours with those we love for very silly reasons all were doing is keyword matching as well so im not sure how much intelligence we exhibit to each other with the people we love that were close with so its a very interesting point of what it means to pass the turing test with language i think youre right in terms of conversation i think machine translation has very clear performance and improvement right what it means to have a fulfilling conversation is very person dependent and context dependent and so on thats yeah its very well put but in your view whats a benchmark in natural language a test thats just out of reach right now but we might be able to thats exciting is it in perfecting machine translation or is there other is it summarization whats out there just out of reach i think it goes across specific application its more about the ability to learn from few examples for real what we call few short learning and all these cases because the way we publish these papers today we say if we have like naively we get 55 but now we had a few example and we can move to 65 none of these methods actually are realistically doing anything useful you cannot use them today and the ability to be able to generalize and to move or to be autonomous in finding the data that you need to learn to be able to perfect new tasks or new language this is an area where i think we really need to move forward to and we are not yet there are you at all excited curious by the possibility of creating human level intelligence is this cause youve been very in your discussion so if we look at oncology youre trying to use machine learning to help the world in terms of alleviating suffering if you look at natural language processing youre focused on the outcomes of improving practical things like machine translation but human level intelligence is a thing that our civilization has dreamed about creating super human level intelligence do you think about this do you think its at all within our reach so as you said yourself elie talking about how do you perceive our communications with each other that were matching keywords and certain behaviors and so on so at the end whenever one assesses lets say relations with another person you have separate kind of measurements and outcomes inside your head that determine what is the status of the relation so one way this is this classical level what is the intelligence is it the fact that now we are gonna do the same way as human is doing when we dont even understand what the human is doing or we now have an ability to deliver these outcomes but not in one area not in nlp not just to translate or just to answer questions but across many many areas that we can achieve the functionalities that humans can achieve with their ability to learn and do other things i think this is and this we can actually measure how far we are and thats what makes me excited that we in my lifetime at least so far what weve seen its like tremendous progress across these different functionalities and i think it will be really exciting to see where we will be and again one way to think about it there are machines which are improving their functionality another one is to think about us with our brains which are imperfect how they can be accelerated by this technology as it becomes stronger and stronger coming back to another book that i love flowers for algernon have you read this book yes so there is this point that the patient gets this miracle cure which changes his brain and all of a sudden they see life in a different way and can do certain things better but certain things much worse so you can imagine this kind of computer augmented cognition where it can bring you that now in the same way as the cars enable us to get to places where weve never been before can we think differently can we think faster and we already see a lot of it happening in how it impacts us but i think we have a long way to go there so thats sort of artificial intelligence and technology affecting our augmenting our intelligence as humans yesterday a company called neuralink announced they did this whole demonstration i dont know if you saw it its they demonstrated brain computer brain machine interface where theres like a sewing machine for the brain do you you know a lot of that is quite out there in terms of things that some people would say are impossible but theyre dreamers and want to engineer systems like that do you see based on what you just said a hope for that more direct interaction with the brain i think there are different ways one is a direct interaction with the brain and again there are lots of companies that work in this space and i think there will be a lot of developments but im just thinking that many times we are not aware of our feelings of motivation what drives us like let me give you a trivial example our attention there are a lot of studies that demonstrate that it takes a while to a person to understand that they are not attentive anymore and we know that there are people who really have strong capacity to hold attention there are other end of the spectrum people with add and other issues that they have problem to regulate their attention imagine to yourself that you have like a cognitive aid that just alerts you based on your gaze that your attention is now not on what you are doing and instead of writing a paper youre now dreaming of what youre gonna do in the evening so even this kind of simple measurement things how they can change us and i see it even in simple ways with myself i have my zone app that i got in mit gym it kind of records you know how much did you run and you have some points and you can get some status whatever like i said what is this ridiculous thing who would ever care about some status in some app guess what so to maintain the status you have to do set a number of points every month and not only is that i do it every single month for the last 18 months it went to the point that i was injured and when i could run again in two days i did like some humongous amount of running just to complete the points it was like really not safe it was like im not gonna lose my status because i want to get there so you can already see that this direct measurement and the feedback is you know were looking at video games and see why you know the addiction aspect of it but you can imagine that the same idea can be expanded to many other areas of our life when we really can get feedback and imagine in your case in relations when we are doing keyword matching imagine that the person who is generating the keywords that person gets direct feedback before the whole thing explodes is it maybe at this happy point we are going in the wrong direction maybe it will be really a behavior modifying moment so yeah its a relationship management too so yeah thats a fascinating whole area of psychology actually as well of seeing how our behavior has changed with basically all human relations now have other nonhuman entities helping us out so you teach a large a huge machine learning course here at mit i can ask you a million questions but youve seen a lot of students what ideas do students struggle with the most as they first enter this world of machine learning actually this year was the first time i started teaching a small machine learning class and it came as a result of what i saw in my big machine learning class that tomi yakel and i built maybe six years ago what weve seen that as this area become more and more popular more and more people at mit want to take this class and while we designed it for computer science majors there were a lot of people who really are interested to learn it but unfortunately their background was not enabling them to do well in the class and many of them associated machine learning with the word struggle and failure primarily for non majors and thats why we actually started a new class which we call machine learning from algorithms to modeling which emphasizes more the modeling aspects of it and focuses on it has majors and non majors so we kind of try to extract the relevant parts and make it more accessible because the fact that were teaching 20 classifiers in standard machine learning class its really a big question to really need it but it was interesting to see this from first generation of students when they came back from their internships and from their jobs what different and exciting things they can do i would never think that you can even apply machine learning to some of them are like matching the relations and other things like variety everything is amenable as the machine learning that actually brings up an interesting point of computer science in general it almost seems maybe im crazy but it almost seems like everybody needs to learn how to program these days if youre 20 years old or if youre starting school even if youre an english major it seems like programming unlocks so much possibility in this world so when you interacted with those non majors is there skills that they were simply lacking at the time that you wish they had and that they learned in high school and so on like how should education change in this computerized world that we live in i think because i knew that there is a python component in the class their python skills were okay and the class isnt really heavy on programming they primarily kind of add parts to the programs i think it was more of the mathematical barriers and the class again with the design on the majors was using the notation like big o for complexity and others people who come from different backgrounds just dont have it in the lexical so necessarily very challenging notion but they were just not aware so i think that kind of linear algebra and probability the basics the calculus multivariate calculus things that can help what advice would you give to students interested in machine learning interested youve talked about detecting curing cancer drug design if they want to get into that field what should they do get into it and succeed as researchers and entrepreneurs the first good piece of news is that right now there are lots of resources that are created at different levels and you can find online in your school classes which are more mathematical more applied and so on so you can find a kind of a preacher which preaches in your own language where you can enter the field and you can make many different types of contribution depending of what is your strengths and the second point i think its really important to find some area which you really care about and it can motivate your learning and it can be for somebody curing cancer or doing self driving cars or whatever but to find an area where there is data where you believe there are strong patterns and we should be doing it and were still not doing it or you can do it better and just start there and see where it can bring you so youve been very successful in many directions in life but you also mentioned flowers of argonon and i think ive read or listened to you mention somewhere that researchers often get lost in the details of their work this is per our original discussion with cancer and so on and dont look at the bigger picture bigger questions of meaning and so on so let me ask you the impossible question of whats the meaning of this thing of life of your life of research why do you think we descendant of great apes are here on this spinning ball you know i dont think that i have really a global answer you know maybe thats why i didnt go to humanities and i didnt take humanities classes in my undergrad but the way im thinking about it each one of us inside of them have their own set of you know things that we believe are important and it just happens that we are busy with achieving various goals busy listening to others and to kind of try to conform and to be part of the crowd that we dont listen to that part and you know we all should find some time to understand what is our own individual missions and we may have very different missions and to make sure that while we are running 10000 things we are not you know missing out and were putting all the resources to satisfy our own mission and if i look over my time when i was younger most of these missions you know i was primarily driven by the external stimulus you know to achieve this or to be that and now a lot of what i do is driven by really thinking what is important for me to achieve independently of the external recognition and you know i dont mind to be viewed in certain ways the most important thing for me is to be true to myself to what i think is right how long did it take how hard was it to find the you that you have to be true to so it takes time and even now sometimes you know the vanity and the triviality can take you know at mit yeah it can everywhere you know its just the vanity at mit is different the vanity in different places but we all have our piece of vanity but i think actually for me many times the place to get back to it is you know when im alone and also when i read and i think by selecting the right books you can get the right questions and learn from what you read so but again its not perfect like vanity sometimes dominates well thats a beautiful way to end thank you so much for talking today thank you that was fun that was fun its like just few percent over five years its pretty much today the sentence but if you can discover this disease early there are mechanisms to treat it and in fact i know a number of people who were diagnosed and saved just because they had food poisoning they had terrible food poisoning they went to er they got scan there were early signs on the scan and that would save their lives but this wasnt really an accidental case so as we become better we would be able to help to many more people that are likely to develop diseases and i just want to say that as i got more into this field i realized that cancer is of course terrible disease but there are really the whole slew of terrible diseases out there like neurodegenerative diseases and others so we of course a lot of us are fixated on cancer because its so prevalent in our society and you see these people where there are a lot of patients with neurodegenerative diseases and the kind of aging diseases that we still dont have a good solution for and i felt as a computer scientist we kind of decided that its other peoples job to treat these diseases because its like traditionally people in biology or in chemistry or mds are the ones who are thinking about it and after kind of start paying attention i think that its really a wrong assumption and we all need to join the battle so how it seems like in cancer specifically that theres a lot of ways that machine learning can help so whats the role of machine learning in the diagnosis of cancer so for many cancers today we really dont know what is your likelihood to get cancer and for the vast majority of patients especially on the younger patients it really comes as a surprise like for instance for breast cancer 80 of the patients are first in their families its like me and i never saw that i had any increased risk because nobody had it in my family and for some reason in my head it was kind of inherited disease but even if i would pay attention the very simplistic statistical models that are currently used in clinical practice they really dont give you an answer so you dont know and the same true for pancreatic cancer the same true for non smoking lung cancer and many others so what machine learning can do here is utilize all this data to tell us early who is likely to be susceptible and using all the information that is already there be it imaging be it your other tests and eventually liquid biopsies and others where the signal itself is not sufficiently strong for human eye to do good discrimination because the signal may be weak but by combining many sources machine which is trained on large volumes of data can really detect it early and thats what weve seen with breast cancer and people are reporting it in other diseases as well that really boils down to data right and in the different kinds of sources of data and you mentioned regulatory challenges so what are the challenges in gathering large data sets in this space again another great question so it took me after i decided that i want to work on it two years to get access to data any data like any significant data set any significant amount like right now in this country there is no publicly available data set of modern mammograms that you can just go on your computer sign a document and get it it just doesnt exist i mean obviously every hospital has its own collection of mammograms there are data that came out of clinical trials what were talking about here is a computer scientist who just wants to run his or her model and see how it works this data like imagenet doesnt exist and there is a set which is called like florida data set which is a film mammogram from 90s which is totally not representative of the current developments whatever youre learning on them doesnt scale up this is the only resource that is available and today there are many agencies that govern access to data like the hospital holds your data and the hospital decides whether they would give it to the researcher to work with this data or not individual hospital yeah i mean the hospital may you know assuming that youre doing research collaboration you can submit you know there is a proper approval process guided by rb and if you go through all the processes you can eventually get access to the data but if you yourself know our oei community there are not that many people who actually ever got access to data because its very challenging process and sorry just in a quick comment mgh or any kind of hospital are they scanning the data are they digitally storing it oh it is already digitally stored you dont need to do any extra processing steps its already there in the right format is that right now there are a lot of issues that govern access to the data because the hospital is legally responsible for the data and you know they have a lot to lose if they give the data to the wrong person but they may not have a lot to gain if they give it as a hospital as a legal entity has given it to you and the way you know what i would imagine happening in the future is the same thing that happens when youre getting your driving license you can decide whether you want to donate your organs you can imagine that whenever a person goes to the hospital they it should be easy for them to donate their data for research and it can be different kind of do they only give you a test results or only mammogram or only imaging data or the whole medical record because at the end we all will benefit from all this insights and its not like you say i want to keep my data private but i would really love to get it from other people because other people are thinking the same way so if there is a mechanism to do this donation and the patient has an ability to say how they want to use their data for research it would be really a game changer people when they think about this problem theres a it depends on the population depends on the demographics but theres some privacy concerns generally not just medical data just any kind of data its what you said my data it should belong kind of to me im worried how its going to be misused how do we alleviate those concerns because that seems like a problem that needs to be that problem of trust of transparency needs to be solved before we build large data sets that help detect cancer help save those very people in the future so i think there are two things that could be done there is a technical solutions and there are societal solutions so on the technical end we today have ability to improve disambiguation like for instance for imaging its you know for imaging you can do it pretty well whats disambiguation and disambiguation sorry disambiguation removing the identification removing the names of the people there are other data like if it is a raw tax you cannot really achieve 999 but there are all these techniques that actually some of them are developed at mit how you can do learning on the encoded data where you locally encode the image you train a network which only works on the encoded images and then you send the outcome back to the hospital and you can open it up so those are the technical solutions there are a lot of people who are working in this space where the learning happens in the encoded form we are still early but this is an interesting research area where i think well make more progress there is a lot of work in natural language processing community how to do the identification better but even today there are already a lot of data which can be deidentified perfectly like your test data for instance correct where you can just you know the name of the patient you just want to extract the part with the numbers the big problem here is again hospitals dont see much incentive to give this data away on one hand and then there is general concern now when im talking about societal benefits and about the education the public needs to understand that i think that there are situation and i still remember myself when i really needed an answer i had to make a choice there was no information to make a choice youre just guessing and at that moment you feel that your life is at the stake but you just dont have information to make the choice and many times when i give talks i get emails from women who say you know im in this situation can you please run statistic and see what are the outcomes we get almost every week a mammogram that comes by mail to my office at mit im serious that people ask to run because they need to make life changing decisions and of course im not planning to open a clinic here but we do run and give them the results for their doctors but the point that im trying to make that we all at some point or our loved ones will be in the situation where you need information to make the best choice and if this information is not available you would feel vulnerable and unprotected and then the question is you know what do i care more because at the end everything is a trade off correct yeah exactly just out of curiosity it seems like one possible solution id like to see what you think of it based on what you just said based on wanting to know answers for when youre yourself in that situation is it possible for patients to own their data as opposed to hospitals owning their data of course theoretically i guess patients own their data but can you walk out there with a usb stick containing everything or upload it to the cloud where a company you know i remember microsoft had a service like i try i was really excited about and google health was there i tried to give i was excited about it basically companies helping you upload your data to the cloud so that you can move from hospital to hospital from doctor to doctor do you see a promise of that kind of possibility i absolutely think this is you know the right way to exchange the data i dont know now whos the biggest player in this field but i can clearly see that even for totally selfish health reasons when you are going to a new facility and many of us are sent to some specialized treatment they dont easily have access to your data and today you know we might want to send this mammogram need to go to the hospital find some small office which gives them the cd and they ship as a cd so you can imagine were looking at kind of decades old mechanism of data exchange so i definitely think this is an area where hopefully all the right regulatory and technical forces will align and we will see it actually implemented its sad because unfortunately and i need to research why that happened but im pretty sure google health and microsoft health vault or whatever its called both closed down which means that there was either regulatory pressure or theres not a business case or theres challenges from hospitals which is very disappointing so when you say you dont know what the biggest players are the two biggest that i was aware of closed their doors so im hoping id love to see why and id love to see who else can come up it seems like one of those elon musk style problems that are obvious needs to be solved and somebody needs to step up and actually do this large scale data collection so i know there is an initiative in massachusetts i think which you led by the governor to try to create this kind of health exchange system where at least to help people who kind of when you show up in emergency room and there is no information about what are your allergies and other things so i dont know how far it will go but another thing that you said and i find it very interesting is actually who are the successful players in this space and the whole implementation how does it go to me it is from the anthropological perspective its more fascinating that ai that today goes in healthcare weve seen so many attempts and so very little successes and its interesting to understand that ive by no means have knowledge to assess it why we are in the position where we are yeah its interesting because data is really fuel for a lot of successful applications and when that data acquires regulatory approval like the fda or any kind of approval it seems that the computer scientists are not quite there yet in being able to play the regulatory game understanding the fundamentals of it i think that in many cases when even people do have data we still dont know what exactly do you need to demonstrate to change the standard of care like let me give you an example related to my breast cancer research so in traditional breast cancer risk assessment there is something called density which determines the likelihood of a woman to get cancer and this pretty much says how much white do you see on the mammogram the whiter it is the more likely the tissue is dense and the idea behind density its not a bad idea in 1967 a radiologist called wolf decided to look back at women who were diagnosed and see what is special in their images can we look back and say that theyre likely to develop so he come up with some patterns and it was the best that his human eye can identify then it was kind of formalized and coded into four categories and thats what we are using today and today this density assessment is actually a federal law from 2019 approved by president trump and for the previous fda commissioner where women are supposed to be advised by their providers if they have high density putting them into higher risk category and in some states you can actually get supplementary screening paid by your insurance because youre in this category now you can say how much science do we have behind it whatever biological science or epidemiological evidence so it turns out that between 40 and 50 of women have dense breasts so about 40 of patients are coming out of their screening and somebody tells them you are in high risk now what exactly does it mean if you as half of the population in high risk its from saying maybe im not or what do i really need to do with it because the system doesnt provide me a lot of the solutions because there are so many people like me we cannot really provide very expensive solutions for them and the reason this whole density became this big deal its actually advocated by the patients who felt very unprotected because many women went and did the mammograms which were normal and then it turns out that they already had cancer quite developed cancer so they didnt have a way to know who is really at risk and what is the likelihood that when the doctor tells you youre okay you are not okay so at the time and it was 15 years ago this maybe was the best piece of science that we had and it took quite 15 16 years to make it federal law but now this is a standard now with a deep learning model we can so much more accurately predict who is gonna develop breast cancer just because youre trained on a logical thing and instead of describing how much white and what kind of white machine can systematically identify the patterns which was the original idea behind the thought of the cardiologist machines can do it much more systematically and predict the risk when youre training the machine to look at the image and to say the risk in one to five years now you can ask me how long it will take to substitute this density which is broadly used across the country and really is not helping to bring this new models and i would say its not a matter of the algorithm algorithms use already orders of magnitude better than what is currently in practice i think its really the question who do you need to convince how many hospitals do you need to run the experiment what you know all this mechanism of adoption and how do you explain to patients and to women across the country that this is really a better measure and again i dont think its an ai question we can work more and make the algorithm even better but i dont think that this is the current you know the barrier the barrier is really this other piece that for some reason is not really explored its like anthropological piece and coming back to your question about books there is a book that im reading its called american sickness by elizabeth rosenthal and i got this book from my clinical collaborator dr connie lehman and i said i know everything that i need to know about american health system but you know every page doesnt fail to surprise me and i think there is a lot of interesting and really deep lessons for people like us from computer science who are coming into this field to really understand how complex is the system of incentives in the system to understand how you really need to play to drive adoption you just said its complex but if were trying to simplify it who do you think most likely would be successful if we push on this group of people is it the doctors is it the hospitals is it the governments or policymakers is it the individual patients consumers who needs to be inspired to most likely lead to adoption or is there no simple answer theres no simple answer but i think there is a lot of good people in medical system who do want to make a change and i think a lot of power will come from us as consumers because we all are consumers or future consumers of healthcare services and i think we can do so much more in explaining the potential and not in the hype terms and not saying that we now killed all alzheimer and im really sick of reading this kind of articles which make these claims but really to show with some examples what this implementation does and how it changes the care because i cant imagine it doesnt matter what kind of politician it is we all are susceptible to these diseases there is no one who is free and eventually we all are humans and were looking for a way to alleviate the suffering and this is one possible way where we currently are under utilizing which i think can help so it sounds like the biggest problems are outside of ai in terms of the biggest impact at this point but are there any open problems in the application of ml to oncology in general so improving the detection or any other creative methods whether its on the detection segmentations or the vision perception side or some other clever of inference yeah what in general in your view are the open problems in this space yeah i just want to mention that beside detection not the area where i am kind of quite active and i think its really an increasingly important area in healthcare is drug design absolutely because its fine if you detect something early but you still need to get drugs and new drugs for these conditions and today all of the drug design ml is non existent there we dont have any drug that was developed by the ml model or even not developed but at least even knew that ml model plays some significant role i think this area with all the new ability to generate molecules with desired properties to do in silica screening is really a big open area to be totally honest with you when we are doing diagnostics and imaging primarily taking the ideas that were developed for other areas and you applying them with some adaptation the area of drug design is really technically interesting and exciting area you need to work a lot with graphs and capture various 3d properties there are lots and lots of opportunities to be technically creative and i think there are a lot of open questions in this area were already getting a lot of successes even with kind of the first generation of these models but there is much more new creative things that you can do and whats very nice to see is that actually the more powerful the more interesting models actually do do better so there is a place to innovate in machine learning in this area and some of these techniques are really unique to lets say to graph generation and other things so what just to interrupt really quick im sorry graph generation or graphs drug discovery in general how do you discover a drug is this chemistry is this trying to predict different chemical reactions or is it some kind of what do graphs even represent in this space oh sorry sorry and whats a drug okay so lets say youre thinking there are many different types of drugs but lets say youre gonna talk about small molecules because i think today the majority of drugs are small molecules so small molecule is a graph the molecule is just where the node in the graph is an atom and then you have the bonds so its really a graph representation if you look at it in 2d correct you can do it 3d but lets say lets keep it simple and stick in 2d so pretty much my understanding today how it is done at scale in the companies without machine learning you have high throughput screening so you know that you are interested to get certain biological activity of the compound so you scan a lot of compounds like maybe hundreds of thousands some really big number of compounds you identify some compounds which have the right activity and then at this point the chemists come and theyre trying to now to optimize this original heat to different properties that you want it to be maybe soluble you want it to decrease toxicity you want it to decrease the side effects are those sorry again to interrupt can that be done in simulation or just by looking at the molecules or do you need to actually run reactions in real labs with lab coats and stuff so when you do high throughput screening you really do screening its in the lab its really the lab screening you screen the molecules correct i dont know what screening is the screening is just check them for certain property like in the physical space in the physical world like actually theres a machine probably thats actually running the reaction actually running the reactions yeah so there is a process where you can run and thats why its called high throughput that it become cheaper and faster to do it on very big number of molecules you run the screening you identify potential good starts and then when the chemists come in who have done it many times and then they can try to look at it and say how can you change the molecule to get the desired profile in terms of all other properties so maybe how do i make it more bioactive and so on and there the creativity of the chemists really is the one that determines the success of this design because again they have a lot of domain knowledge of what works how do you decrease the ccd and so on and thats what they do so all the drugs that are currently in the fda approved drugs or even drugs that are in clinical trials they are designed using these domain experts which goes through this combinatorial space of molecules or graphs or whatever and find the right one or adjust it to be the right ones it sounds like the breast density heuristic from 67 to the same echoes its not necessarily that its really driven by deep understanding its not like they just observe it i mean they do deeply understand chemistry and they do understand how different groups and how does it changes the properties so there is a lot of science that gets into it and a lot of kind of simulation how do you want it to behave its very very complex so theyre quite effective at this design obviously now effective yeah we have drugs like depending on how do you measure effective if you measure it in terms of cost its prohibitive if you measure it in terms of times we have lots of diseases for which we dont have any drugs and we dont even know how to approach and dont need to mention few drugs or neurodegenerative disease drugs that fail so there are lots of trials that fail in later stages which is really catastrophic from the financial perspective so is it the effective the most effective mechanism absolutely no but this is the only one that currently works and i was closely interacting with people in pharmaceutical industry i was really fascinated on how sharp and what a deep understanding of the domain do they have its not observation driven there is really a lot of science behind what they do but if you ask me can machine learning change it i firmly believe yes because even the most experienced chemists cannot hold in their memory and understanding everything that you can learn from millions of molecules and reactions and the space of graphs is a totally new space i mean its a really interesting space for machine learning to explore graph generation yeah so there are a lot of things that you can do here so we do a lot of work so the first tool that we started with was the tool that can predict properties of the molecules so you can just give the molecule and the property it can be by activity property or it can be some other property and you train the molecules and you can now take a new molecule and predict this property now when people started working in this area it is something very simple they do kind of existing fingerprints which is kind of handcrafted features of the molecule when you break the graph to substructures and then you run it in a feed forward neural network and what was interesting to see that clearly this was not the most effective way to proceed and you need to have much more complex models that can induce a representation which can translate this graph into the embeddings and do these predictions so this is one direction then another direction which is kind of related is not only to stop by looking at the embedding itself but actually modify it to produce better molecules so you can think about it as machine translation that you can start with a molecule and then there is an improved version of molecule and you can again with encoder translate it into the hidden space and then learn how to modify it to improve the in some ways version of the molecules so thats its kind of really exciting we already have seen that the property prediction works pretty well and now we are generating molecules and there is actually labs which are manufacturing this molecule so well see where it will get us okay thats really exciting theres a lot of promise speaking of machine translation and embeddings i think you have done a lot of really great research in nlp natural language processing can you tell me your journey through nlp what ideas problems approaches were you working on were you fascinated with did you explore before this magic of deep learning reemerged and after so when i started my work in nlp it was in 97 this was very interesting time it was exactly the time that i came to acl and at the time i could barely understand english but it was exactly like the transition point because half of the papers were really rule based approaches where people took more kind of heavy linguistic approaches for small domains and try to build up from there and then there were the first generation of papers which were corpus based papers and they were very simple in our terms when you collect some statistics and do prediction based on them and i found it really fascinating that one community can think so very differently about the problem and i remember my first paper that i wrote it didnt have a single formula it didnt have evaluation it just had examples of outputs and this was a standard of the field at the time in some ways i mean people maybe just started emphasizing the empirical evaluation but for many applications like summarization you just show some examples of outputs and then increasingly you can see that how the statistical approaches dominated the field and weve seen increased performance across many basic tasks the sad part of the story maybe that if you look again through this journey we see that the role of linguistics in some ways greatly diminishes and i think that you really need to look through the whole proceeding to find one or two papers which make some interesting linguistic references its really big today yeah today today this was definitely one of the things like syntactic trees just even basically against our conversation about human understanding of language which i guess what linguistics would be structured hierarchical representing language in a way thats human explainable understandable is missing today i dont know if it is what is explainable and understandable in the end we perform functions and its okay to have machine which performs a function like when youre thinking about your calculator correct your calculator can do calculation very different from you would do the calculation but its very effective in it and this is fine if we can achieve certain tasks with high accuracy doesnt necessarily mean that it has to understand it the same way as we understand in some ways its even naive to request because you have so many other sources of information that are absent when you are training your system so its okay is it delivered and i would tell you one application that is really fascinating in 97 when it came to acl there were some papers on machine translation they were like primitive like people were trying really really simple and the feeling my feeling was that you know to make real machine translation system its like to fly at the moon and build a house there and the garden and live happily ever after i mean its like impossible i never could imagine that within you know 10 years we would already see the system working and now you know nobody is even surprised to utilize the system on daily basis so this was like a huge huge progress saying that people for very long time tried to solve using other mechanisms and they were unable to solve it thats why coming back to your question about biology that you know in linguistics people try to go this way and try to write the syntactic trees and try to abstract it and to find the right representation and you know they couldnt get very far with this understanding while these models using you know other sources actually capable to make a lot of progress now im not naive to think that we are in this paradise space in nlp and sure as you know that when we slightly change the domain and when we decrease the amount of training it can do like really bizarre and funny thing but i think its just a matter of improving generalization capacity which is just a technical question wow so thats the question how much of language understanding can be solved with deep neural networks in your intuition i mean its unknown i suppose but as we start to creep towards romantic notions of the spirit of the turing test and conversation and dialogue and something that maybe to me or to us so the humans feels like it needs real understanding how much can that be achieved with these neural networks or statistical methods so i guess i am very much driven by the outcomes can we achieve the performance which would be satisfactory for us for different tasks now if you again look at machine translation system which are trained on large amounts of data they really can do a remarkable job relatively to where theyve been a few years ago and if you project into the future if it will be the same speed of improvement you know this is great now does it bother me that its not doing the same translation as we are doing now if you go to cognitive science we still dont really understand what we are doing i mean there are a lot of theories and theres obviously a lot of progress and studying but our understanding what exactly goes on in our brains when we process language is still not crystal clear and precise that we can translate it into machines what does bother me is that you know again that machines can be extremely brittle when you go out of your comfort zone of when there is a distributional shift between training and testing and it have been years and years every year when i teach an lp class now show them some examples of translation from some newspaper in hebrew or whatever it was perfect and then i have a recipe that tomi yakels system sent me a while ago and it was written in finnish of karelian pies and its just a terrible translation you cannot understand anything what it does its not like some syntactic mistakes its just terrible and year after year i tried and will translate and year after year it does this terrible work because i guess you know the recipes are not a big part of their training repertoire so but in terms of outcomes thats a really clean good way to look at it i guess the question i was asking is do you think imagine a future do you think the current approaches can pass the turing test in the way in the best possible formulation of the turing test which is would you wanna have a conversation with a neural network for an hour oh god no no there are not that many people that i would want to talk for an hour but there are some people in this world alive or not that you would like to talk to for an hour could a neural network achieve that outcome so i think it would be really hard to create a successful training set which would enable it to have a conversation a contextual conversation for an hour do you think its a problem of data perhaps i think in some ways its not a problem of data its a problem both of data and the problem of the way were training our systems their ability to truly to generalize to be very compositional in some ways its limited in the current capacity at least we can translate well we can find information well we can extract information so there are many capacities in which its doing very well and you can ask me would you trust the machine to translate for you and use it as a source i would say absolutely especially if were talking about newspaper data or other data which is in the realm of its own training set i would say yes but having conversations with the machine its not something that i would choose to do but i would tell you something talking about turing tests and about all this kind of elisa conversations i remember visiting tencent in china and they have this chat board and they claim there is really humongous amount of the local population which for hours talks to the chat board to me it was i cannot believe it but apparently its documented that there are some people who enjoy this conversation and it brought to me another mit story about elisa and weisenbaum i dont know if youre familiar with the story so weisenbaum was a professor at mit and when he developed this elisa which was just doing string matching very trivial like restating of what you said with very few rules no syntax apparently there were secretaries at mit that would sit for hours and converse with this trivial thing and at the time there was no beautiful interfaces so you actually need to go through the pain of communicating and weisenbaum himself was so horrified by this phenomenon that people can believe enough to the machine that you just need to give them the hint', 'the following is a conversation with leonard susskind hes a professor of theoretical physics at stanford university and founding director of stanford institute of theoretical physics he is widely regarded as one of the fathers of string theory and in general as one of the greatest physicists of our time both as a researcher and an educator this is the artificial intelligence podcast perhaps you noticed that the people ive been speaking with are not just computer scientists but philosophers mathematicians writers psychologists physicists and soon other disciplines to me ai is much bigger than deep learning bigger than computing it is our civilizations journey into understanding the human mind and creating echoes of it in the machine if you enjoy the podcast subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a m and now heres my conversation with leonard susskind you worked and were friends with richard feynman how has he influenced you changed you as a physicist and thinker what i saw i think what i saw was somebody who could do physics in this deeply intuitive way his style was almost to close his eyes and visualize the phenomena that he was thinking about and through visualization outflank the mathematical the highly mathematical and very very sophisticated technical arguments that people would use i think that was also natural to me but i saw somebody who was actually successful at it who could do physics in a way that i regarded as simpler more direct more intuitive and while i dont think he changed my way of thinking i do think he validated it he made me look at it and say yeah thats something you can do and get away with practically didnt get away with it so do you find yourself whether youre thinking about quantum mechanics or black holes or string theory using intuition as a first step or step throughout using visualization yeah very much so very much so i tend not to think about the equations i tend not to think about the symbols i tend to try to visualize the phenomena themselves and then when i get an insight that i think is valid i might try to convert it to mathematics but im not a natural mathematician im good enough at it im good enough at it but im not a great mathematician so for me the way of thinking about physics is first intuitive first visualization scribble a few equations maybe but then try to convert it to mathematics experience is that other people are better at converting it to mathematics than i am and yet youve worked with very counterintuitive ideas no thats true thats true you can visualize something counterintuitive how do you dare by rewiring your brain in new ways yeah quantum mechanics is not intuitive very little of modern physics is intuitive intuitive what does intuitive mean it means the ability to think about it with basic classical physics the physics that we evolved with throwing stones or splashing water whatever it happens to be quantum physics general relativity quantum field theory are deeply unintuitive in that way but after time and getting familiar with these things you develop new intuitions i always said you rewire and its to the point where me and many of my friends i and many of my friends can think more easily quantum mechanically than we can classically weve gotten so used to it i mean yes our neural wiring in our brain is such that we understand rocks and stones and water and so on we sort of evolved for that evolved for it do you think its possible to create a wiring of neuron like state devices that more naturally understand quantum mechanics understand wave function understand these weird things well im not sure i think many of us have evolved the ability to think quantum mechanically to some extent but that doesnt mean you can think like an electron that doesnt mean another example forget for a minute quantum mechanics just visualizing four dimensional space or five dimensional space or six dimensional space i think were fundamentally wired to visualize three dimensions i cant even visualize two dimensions or one dimension without thinking about it as embedded in three dimensions if i wanna visualize a line i think of the line as being a line in three dimensions or i think of the line as being a line on a piece of paper with a piece of paper being in three dimensions i never seem to be able to in some abstract and pure way visualize in my head the one dimension the two dimension the four dimension the five dimensions and i dont think thats ever gonna happen the reason is i think our neural wiring is just set up for that on the other hand we do learn ways to think about five six seven dimensions we learn ways we learn mathematical ways and we learn ways to visualize them but theyre different and so yeah i think we do rewire ourselves whether we can ever completely rewire ourselves to be completely comfortable with these concepts i doubt so that its completely natural to where its completely natural so im sure theres somewhat you could argue creatures that live in a two dimensional space yeah maybe there are and while its romanticizing the notion of curse were all living as far as we know in three dimensional space but how do those creatures imagine 3d space well probably the way we imagine 4d by using some mathematics and some equations and some tricks okay so jumping back to feynman just for a second he had a little bit of an ego yes why do you think ego is powerful or dangerous in science i think both both both i think you have to have both arrogance and humility you have to have the arrogance to say i can do this nature is difficult nature is very very hard im smart enough i can do it i can win the battle with nature on the other hand i think you also have to have the humility to know that youre very likely to be wrong on any given occasion everything youre thinking could suddenly change young people can come along and say things you wont understand and youll be lost and flabbergasted so i think its a combination of both you better recognize that youre very limited and you better be able to say to yourself im not so limited that i cant win this battle with nature it takes a special kind of person who can manage both of those i would say and i would say theres echoes of that in your own work a little bit of ego a little bit of outside of the box humble thinking i hope so so was there a time where you felt you looked at yourself and asked am i completely wrong about this oh yeah about the whole thing or about specific things the whole thing what do you mean wait which whole thing me and me and my ability to do this thing oh those kinds of doubts first of all did you have those kinds of doubts no i had different kind of doubts i came from a very working class background and i was uncomfortable in academia for oh for a long time but they werent doubts about my ability or my they were just the discomfort in being in an environment that my family hadnt participated in i knew nothing about as a young person i didnt learn that there was such a thing called physics until i was almost 20 years old yeah so i did have certain kind of doubts but not about my ability i dont think i was too worried about whether i would succeed or not i never felt this insecurity am i ever gonna get a job that had never occurred to me that i wouldnt maybe you could speak a little bit to this sense of what is academia because i too feel a bit uncomfortable in it theres something i cant put quite into words what you have thats not doesnt if we call it music you play a different kind of music than a lot of academia how have you joined this orchestra how do you think about it i dont know that i thought about it as much as i just felt it thinking is one thing feeling is another thing i felt like an outsider until a certain age when i suddenly found myself the ultimate insider in academic physics and that was a sharp transition and i wasnt a young man i was probably 50 years old so you were never quite it was a phase transition you were never quite in the middle yeah thats right i wasnt i always felt a little bit of an outsider in the beginning a lot an outsider my way of thinking was different my approach to mathematics was different but also my social background that i came from was different now these days half the young people i meet theyre parents or professors that was not my case but then all of a sudden at some point i found myself at very much the center of maybe not the only one at the center but certainly one of the people in the center of a certain kind of physics and all that went away it went away in a flash so maybe a little bit with feynman but in general how do you develop ideas do you work through ideas alone do you brainstorm with others oh both both very definitely both the younger time i spent more time with myself now because im at stanford because i have a lot of ex students and people who are interested in the same thing i am i spend a good deal of time almost on a daily basis interacting brainstorming as you said its a very important part i spend less time probably completely self focused than with a piece of paper and just sitting there staring at it what are your hopes for quantum computers so machines that are based on that have some elements of leverage quantum mechanical ideas yeah its not just leveraging quantum mechanical ideas you can simulate quantum systems on a classical computer simulate them means solve the schrodinger equation for them or solve the equations of quantum mechanics or solve the equations of quantum mechanics on a computer on a classical computer but the classical computer is not doing is not a quantum mechanical system itself of course it is everythings made of quantum mechanics but its not functioning its not functioning as a quantum system its just solving equations the quantum computer is truly a quantum system which is actually doing the things that youre programming it to do you want to program a quantum field theory if you do it in classical physics that program is not actually functioning in the computer as a quantum field theory its just solving some equations physically its not doing the things that the quantum system would do the quantum computer is really a quantum mechanical system which is actually carrying out the quantum operations you can measure it at the end it intrinsically satisfies the uncertainty principle it is limited in the same way that quantum systems are limited by uncertainty and so forth and it really is a quantum system that means that what youre doing when you program something for a quantum system is youre actually building a real version of the system the limits of a classical computer classical computers are enormously limited when it comes to the quantum systems theyre enormously limited because youve probably heard this before but in order to store the amount of information thats in a quantum state of 400 spins thats not very many 400 i can put in my pocket i can put 400 pennies in my pocket to be able to simulate the quantum state of 400 elementary quantum systems qubits we call them to do that would take more information than can possibly be stored in the entire universe if it were packed so tightly that you couldnt pack any more in 400 qubits on the other hand if your quantum computer is composed of 400 qubits it can do everything 400 qubits can do what kind of space if you just intuitively think about the space of algorithms that that unlocks for us so theres a whole complexity theory around classical computers measuring the running time of things and p so on what kind of algorithms just intuitively do you think it unlocks for us okay so we know that there are a handful of algorithms that can seriously beat classical computers and which can have exponentially more power this is a mathematical statement nobodys exhibited this in the laboratory its a mathematical statement we know thats true but it also seems more and more that the number of such things is very limited only very very special problems exhibit that much advantage for a quantum computer of standard problems to my mind as far as i can tell the great power of quantum computers will actually be to simulate quantum systems if youre interested in a certain quantum system and its too hard to simulate classically you simply build a version of the same system you build a version of it you build a model of it thats actually functioning as the system you run it and then you do the same thing you would do to the quantum system you make measurements on it quantum measurements on it the advantage is you can run it much slower you could say why bother why not just use the real system why not just do experiments on the real system well real systems are kind of limited you cant change them you cant manipulate them you cant slow them down so that you can poke into them you cant modify them in arbitrary kinds of ways to see what would happen if i change the system a little bit i think that quantum computers will be extremely valuable in understanding quantum systems at the lowest level of the fundamental laws theyre actually satisfying the same laws as the systems that theyre simulating okay so on the one hand you have things like factoring factoring is the great thing of quantum computers factoring large numbers that doesnt seem that much to do with quantum mechanics it seems to be almost a fluke that a quantum computer can solve the factoring problem in a short time and those problems seem to be extremely special rare and its not clear to me that theres gonna be a lot of them on the other hand there are a lot of quantum systems chemistry theres solid state physics theres material science theres quantum gravity theres all kinds of quantum field theory and some of these are actually turning out to be applied sciences as well as very fundamental sciences so we probably will run out of the ability to solve equations for these things solve equations by the standard methods of pencil and paper solve the equations by the method of classical computers and so what well do is well build versions of these systems run them and run them under controlled circumstances where we can change them manipulate them make measurements on them and find out all the things we wanna know so in finding out the things we wanna know about very small systems is there something that we can also find out about the macro level about something about the function forgive me of our brain biological systems the stuff thats about one meter in size versus much much smaller well what all the excitement is about among the people that i interact with is understanding black holes black holes black holes are big things they are many many degrees of freedom there is another kind of quantum system that is big its a large quantum computer and one of the things weve learned is that the physics of large quantum computers is in some ways similar to the physics of large quantum black holes and were using that relationship now you asked you didnt ask about quantum computers or systems you didnt ask about black holes you asked about brains yeah about stuff thats in the middle of the two its different so black holes are theres something fundamental about black holes that feels to be very different than a brain yes and they also function in a very quantum mechanical way right okay it is first of all unclear to me but of course its unclear to me im not a neuroscientist i have i dont even have very many friends who are neuroscientists i would like to have more friends who are neuroscientists i just dont run into them very often among the few neuroscientists ive ever talked about about this they are pretty convinced that the brain functions classically that it is not intrinsically a quantum mechanical system or it doesnt make use of the special features entanglement coherence superposition are they right i dont know i sort of hope theyre wrong just because i like the romantic idea that the brain is a quantum system but i think probably not the other thing big systems can be composed of lots of little systems materials the materials that we work with and so forth are can be large systems a large piece of material but theyre made out of quantum systems now one of the things thats been happening over the last good number of years is were discovering materials and quantum systems which function much more quantum mechanically than we imagined topological insulators this kind of thing that kind of thing those are macroscopic systems but theyre just superconductors superconductors have a lot of quantum mechanics in them you can have a large chunk of superconductor so its a big piece of material on the other hand its functioning and its properties depend very very strongly on quantum mechanics and to analyze them you need the tools of quantum mechanics if we can go on to black holes and looking at the universe as a information processing system as a computer as a giant computer its a giant computer whats the power of thinking of the universe as an information processing system or what is perhaps its use besides the mathematical use of discussing black holes and your famous debates and ideas around that to human beings or life in general as information processing systems well all systems are information processing systems you poke them they change a little bit they evolve all systems are information processing systems so theres no extra magic to us humans it certainly feels consciousness intelligence feels like magic it sure does where does it emerge from if we look at information processing what are the emergent phenomena that come from viewing the world as an information processing system here is what i think my thoughts are not worth much in this if you ask me about physics my thoughts may be worth something if you ask me about this im not sure my thoughts are worth anything but as i said earlier i think when we do introspection when we imagine doing introspection and try to figure out what it is when we do when were thinking i think we get it wrong im pretty sure we get it wrong everything ive heard about the way the brain functions is so counterintuitive for example you have neurons which detect vertical lines you have different neurons which detect lines at 45 degrees you have different neurons i never imagined that there were whole circuits which were devoted to vertical lines in my brain doesnt seem to be the way my brain works my brain seems to work if i put my finger up vertically or if i put it horizontally or if i put it this way or that way it seems to me its the same circuits its not the way it works the way the brain is compartmentalized seems to be very very different than what i would have imagined if i were just doing psychological introspection about how things work my conclusion is that we wont get it right that way that how will we get it right i think maybe computer scientists will get it right eventually i dont think there are any ways near it i dont even think theyre thinking about it but eventually we will build machines perhaps which are complicated enough and partly engineered partly evolved maybe evolved by machine learning and so forth this machine learning is very interesting by machine learning we will evolve systems and we may start to discover mechanisms that have implications for how we think and for what this consciousness thing is all about and well be able to do experiments on them and perhaps answer questions that we cant possibly answer by introspection so thats a really interesting point in many cases if you look at even a string theory when you first think about a system it seems really complicated like the human brain and through some basic reasoning and trying to discover fundamental low level behavior of the system you find out that its actually much simpler do you one have you is that generally the process and two do you have that also hope for biological systems as well for all the kinds of stuff were studying at the human level of course physics always begins by trying to find the simplest version of something and analyze it yeah i mean there are lots of examples where physics has taken very complicated systems analyzed them and found simplicity in them for sure i said superconductors before its an obvious one a superconductor seems like a monstrously complicated thing with all sorts of crazy electrical properties magnetic properties and so forth and when it finally is boiled down to its simplest elements its a very simple quantum mechanical phenomenon called spontaneous symmetry breaking and which we in other contexts we learned about and were very familiar with so yeah i mean yes we do take complicated things make them simple but what we dont want to do is take things which are intrinsically complicated and fool ourselves into thinking that we can make them simple we dont want to make i dont know who said this but we dont want to make them simpler than they really are okay is the brain a thing which ultimately functions by some simple rules or is it just complicated in terms of artificial intelligence nobody really knows what are the limits of our current approaches you mentioned machine learning how do we create human level intelligence it seems that theres a lot of very smart physicists who perhaps oversimplify the nature of intelligence and think of it as information processing and therefore there doesnt seem to be any theoretical reason why we cant artificially create human level or superhuman level intelligence in fact the reasoning goes if you create human level intelligence the same approach you just used to create human level intelligence should allow you to create superhuman level intelligence very easily exponentially so what do you think that way of thinking that comes from physicists is all about i wish i knew but theres a particular reason why i wish i knew i have a second job i consult for google not for google for google x i am the senior academic advisor to a group of machine learning physicists now that sounds crazy because i know nothing about the subject i know very little about the subject on the other hand im good at giving advice so i give them advice on things anyway i see these young physicists who are approaching the machine learning problem there is a real machine learning problem namely why does it work as well as it does nobody really seems to understand why it is capable of doing the kind of generalizations that it does and so forth and there are three groups of people who have thought about this there are the engineers the engineers are incredibly smart but they tend not to think as hard about why the thing is working as much as they do how to use it obviously they provided a lot of data and it is they who demonstrated that machine learning can work much better than you have any right to expect the machine learning systems are systems the systems not too different than the kind of systems that physicists study theres not all that much difference between quantum in the structure of mathematics physically yes but in the structure of mathematics between a tensor network designed to describe a quantum system on the one hand and the kind of networks that are used in machine learning so there are more and more i think young physicists are being drawn to this field of machine learning some very very good ones i work with a number of very good ones not on machine learning but on having lunch on having lunch right yeah and i can tell you they are super smart they dont seem to be so arrogant about their physics backgrounds that they think they can do things that nobody else can do but the physics way of thinking i think will add great value to or will bring value to the machine learning i believe it will and i think it already has at what time scale do you think predicting the future becomes useless in your long experience and being surprised at new discoveries well sometimes a day sometimes 20 years there are things which i thought we were very far from understanding which practically in a snap of the fingers or a blink of the eye suddenly became understood completely surprising to me there are other things which i looked at and i said were not gonna understand these things for 500 years in particular quantum gravity the scale for that was 20 years 25 years and we understand a lot and we dont understand it completely now by any means but i thought it was 500 years to make any progress it turned out to be very very far from that it turned out to be more like 20 or 25 years from the time when i thought it was 500 years so if we may can we jump around quantum gravity some basic ideas in physics what is the dream of string theory mathematically what is the hope where does it come from what problem is it trying to solve i dont think the dream of string theory is any different than the dream of fundamental theoretical physics altogether understanding a unified theory of everything i dont like thinking of string theory as a subject unto itself with people called string theorists who are the practitioners of this thing called string theory i much prefer to think of them as theoretical physicists trying to answer deep fundamental questions about nature in particular gravity in particular gravity and its connection with quantum mechanics and who at the present time find string theory a useful tool rather than saying theres a subject called string theorists i dont like being referred to as a string theorist yes but as a tool is it useful to think about our nature in multiple dimensions the strings vibrating i believe it is useful ill tell you what the main use of it has been up till now well it has had a number of main uses originally string theory was invented and i know that i was there i was right at the spot where it was being invented literally and it was being invented to understand hadrons hadrons are subnuclear particles protons neutrons mesons and at that time the late 60s early 70s it was clear from experiment that these particles called hadrons could vibrate could rotate could do all the things that a little closed string can do and it was and is a valid and correct theory of these hadrons its been experimentally tested and that is a done deal it had a second life as a theory of gravity the same basic mathematics except on a very very much smaller distance scale the objects of gravitation are 19 orders of magnitude or orders of magnitude smaller than a proton but the same mathematics turned up the same mathematics turned up what has been its value its value is that its mathematically rigorous in many ways and enabled us to find mathematical structures which have both quantum mechanics and gravity with rigor we can test out ideas we can test out ideas we cant test them in the laboratory theyre 19 orders of magnitude too small are things that were interested in but we can test them out mathematically and analyze their internal consistency by now 40 years ago 35 years ago and so forth people very very much questioned the consistency between gravity and quantum mechanics stephen hawking was very famous for it rightly so now nobody questions that consistency anymore they dont because we have mathematically precise string theories which contain both gravity and quantum mechanics in a consistent way so its provided that certainty that quantum mechanics and gravity can coexist thats not a small thing its a very big thing its a huge thing einstein would be proud einstein he might be appalled i dont know he didnt like it he didnt like it he might not be appalled i dont know he didnt like quantum mechanics very much but he would certainly be struck by it i think that may be at this time its biggest contribution to physics in illustrating almost definitively that quantum mechanics and gravity are very closely related and not inconsistent with each other is there a possibility of something deeper more profound that still is consistent with string theory but is deeper that is to be found well you could ask the same thing about quantum mechanics is there something exactly yeah yeah i think string theory is just an example of a quantum mechanical system that contains both gravitation and quantum mechanics so is there something underlying quantum mechanics perhaps something deterministic perhaps something deterministic my friend ferad etouf whose name you may know hes a very famous physicist dutch not as famous as he should be but hard to spell his name its hard to say his name no its easy to spell his name apostrophe hes the only person i know whose name begins with an apostrophe and hes one of my heroes in physics hes a little younger than me but hes nevertheless one of my heroes etouf believes that there is some substructure to the world which is classical in character deterministic in character which somehow by some mechanism that he has a hard time spelling out emerges as quantum mechanics i dont the wave function is somehow emergent the wave function not just the wave function but the whole thing that goes with quantum mechanics uncertainty entanglement all these things are emergent so you think quantum mechanics is the bottom of the well is the here i think is where you have to be humble heres where humility comes i dont think anybody should say anything is the bottom of the well at this time i think we can reasonably say i can reasonably say when i look into the well i cant see past quantum mechanics i cant see past quantum mechanics i dont see any reason for there to be anything beyond quantum mechanics i think etouf has asked very interesting and deep questions i dont like his answers well again let me ask if we look at the deepest nature of reality with whether its deterministic or when observed as probabilistic what does that mean for our human level of ideas of free will is there any connection whatsoever from this perception perhaps illusion of free will that we have and the fundamental nature of reality the only thing i can say is i am puzzled by that as much as you are the illusion of it the illusion of consciousness the illusion of free will the illusion of self does that connect to how can a physical system do that and i am as puzzled as anybody theres echoes of it in the observer effect so do you understand what it means to be an observer i understand it at a technical level an observer is a system with enough degrees of freedom that it can record information and which can become entangled with the thing that its measuring entanglement is the key when a system which we call an apparatus or an observer same thing interacts with the system that its observing it doesnt just look at it it becomes physically entangled with it and its that entanglement which we call an observation or a measurement now does that satisfy me personally as an observer yes and no i find it very satisfying that we have a mathematical representation of what it means to observe a system you are observing stuff right now the conscious level do you think theres echoes of that kind of entanglement in our macro scale yes absolutely for sure were entangled with quantum mechanically entangled with everything in this room if we werent then it would just well we wouldnt be observing it but on the other hand you can ask do i really am i really comfortable with it and im uncomfortable with it in the same way that i can never get comfortable with five dimensions my brain isnt wired for it are you comfortable with four dimensions a little bit more because i can always imagine the fourth dimension is time so the arrow of time are you comfortable with that arrow do you think time is an emergent phenomena or is it fundamental to nature that is a big question in physics right now all the physics that we do or at least that the people that i am comfortable with talking to my friends my friends no we all ask the same question that you just asked space we have a pretty good idea is emergent and it emerges out of entanglement and other things time always seems to be built into our equations as just what newton pretty much would have thought newton modified a little bit by einstein would have called time and mostly in our equations it is not emergent time in physics is completely symmetric forward and backward right its symmetric so you dont really need to think about the arrow of time for most physical phenomena for most microscopic phenomena no its only when the phenomena involve systems which are big enough for thermodynamics to become important for entropy to become important for a small system entropy is not a good concept entropy is something which emerges out of large numbers its a probabilistic idea or its a statistical idea and its a thermodynamic idea thermodynamics requires lots and lots and lots of little substructures okay so its not until you emerge at the thermodynamic level that theres an arrow of time do we understand it yeah i think we understand better than most people think they have most people say they think we understand it yeah i think we understand it its a statistical idea you mean like second law of thermodynamics entropy and so on yeah take a pack of cards and you fling it in the air and you look what happens to it it gets random we understand it it doesnt go from random to simple it goes from simple to random but do you think it ever breaks down what i think you can do is in a laboratory setting you can take a system which is somewhere intermediate between being small and being large and make it go backward a thing which looks like it only wants to go forward because of statistical mechanical reasons because of the second law you can very very carefully manipulate it to make it run backward i dont think you can take an egg a humpty dumpty who fell on the floor and reverse that but you can in a very controlled situation you can take systems which appear to be evolving statistically toward randomness stop them reverse them and make them go back whats the intuition behind that how do we do that how do we reverse it youre saying a closed system yeah pretty much closed system yes did you just say that time travel is possible no i didnt say time travel is possible i said you can make a system go backward in time you can make it go back you can make it reverse its steps you can make it reverse its trajectory yeah how do we do it whats the intuition there does it have is it just a fluke thing that we can do at a small scale in the lab that doesnt have well what im saying is you can do it a little bit better than a small scale you can certainly do it with a simple small system small systems dont have any sense of the arrow of time atoms atoms are no sense of an arrow of time theyre completely reversible its only when you have you know the second law of thermodynamics is the law of large numbers so you can break the law because its not a deterministic law you can break it you can break it but its hard it requires great care the bigger the system is the more care the more the harder it is you have to overcome whats called chaos and thats hard and it requires more and more precision for 10 particles you might be able to do it with some effort for a hundred particles its really hard for a thousand or a million particles forget it but not for any fundamental reason just because its technologically too hard to make the system go backward so no time travel for engineering reasons oh no no no no what is time travel time travel to the future thats easy you just close your eyes go to sleep and you wake up in the future yeah yeah a good nap gets you there yeah a good nap gets you there right but reversing the second law of thermodynamics going backward in time for anything thats human scale is a very difficult engineering effort i wouldnt call that time travel because it gets too mixed up with what science fiction calls time travel this is just the ability to reverse a system you take the system and you reverse the direction of motion of every molecule in it that you can do it with one molecule if you find a particle moving in a certain direction lets not say a particle a baseball you stop it dead and then you simply reverse its motion in principle thats not too hard and itll go back along its trajectory in the backward direction just running the program backwards running the program backward yeah okay if you have two baseballs colliding well you can do it but you have to be very very careful to get it just right if you have 10 baseballs really really better yet 10 billiard balls on an idealized frictionless billiard table okay so you start the balls all on a triangle right and you whack them depending on the game youre playing you either whack them or youre really careful but you whack them and they go flying off in all possible directions okay try to reverse that try to reverse that imagine trying to take every billiard ball stopping it dead at some point and reversing its motion so that it was going in the opposite direction if you did that with tremendous care it would reassemble itself back into the triangle okay that is a fact and you can probably do it with two billiard balls maybe with three billiard balls if youre really lucky but what happens is as the system gets more and more complicated you have to be more and more precise not to make the tiniest error because the tiniest errors will get magnified and youll simply not be able to do the reversal so yeah but i wouldnt call that time travel yeah thats something else but if you think of it it just made me think if you think the unrolling of state thats happening as a program if we look at the world silly idea of looking at the world as a simulation as a computer but its not a computer its just a single program a question arises that might be useful how hard is it to have a computer that runs the universe okay so there are mathematical universes that we know about one of them is called anti de sitter space where we and its quantum mechanics i think we could simulate it in a computer in a quantum computer classical computer all you can do is solve its equations you cant make it work like the real system if we could build a quantum computer a big enough one a robust enough one we could probably simulate a universe a small version of an anti de sitter universe anti de sitter is a kind of cosmology so i think we know how to do that the trouble is the universe that we live in is not the anti de sitter geometry its the de sitter geometry and we dont really understand its quantum mechanics at all so at the present time i would say we wouldnt have the vaguest idea how to simulate a universe similar to our own no we can ask could we build in the laboratory a small version a quantum mechanical version the collection of quantum computers and tangled and coupled together which would reproduce the phenomena that go on in the universe even on a small scale yes if it were anti de sitter space no if its de sitter space can you slightly describe de sitter space and anti de sitter space yeah what are the geometric properties of they differ by the sign of a single constant called the cosmological constant one of them is negatively curved the other is positively curved anti de sitter space which is the negatively curved one you can think of as an isolated system in a box with reflecting walls you could think of it as a system of quantum mechanical system isolated in an isolated environment de sitter space is the one we really live in and thats the one thats exponentially expanding exponential expansion dark energy whatever we wanna call it and we dont understand that mathematically do we understand not everybody would agree with me but i dont understand they would agree with me they definitely would agree with me that i dont understand it what about is there an understanding of the birth the origin the big bang so theres one problem with the other no no theres theories there are theories my favorite is the one called eternal inflation the infinity can be on both sides on one of the sides and none of the sides so whats eternal infinity okay infinity on both sides oh boy yeah yeah thats why is that your favorite because its the most just mind blowing no because we want a beginning no why do we want a beginning in practice there was a beginning of course in practice there was a beginning but could it have been a random fluctuation in an otherwise infinite time maybe in any case the eternal inflation theory i think if correctly understood would be infinite in both directions how do you think about infinity oh god so okay of course you can think about it mathematically i just finished this discussion with my friend sergei brin how do you think about infinity i say well sergei brin is infinitely rich how do you test that hypothesis okay such a good line right yeah so theres really no way to visualize some of these things yeah no this is a very good question does physics have any does infinity have any place in physics right right and all i can say is very good question so what do you think of the recent first image of a black hole visualized from the horizon telescope its an incredible triumph of science in itself the fact that there are black holes which collide is not a surprise and they seem to work exactly the way theyre supposed to work will we learn a great deal from it i dont know we might but the kind of things well learn wont really be about black holes why there are black holes in nature of that particular mass scale and why theyre so common may tell us something about the structure evolution of structure in the universe but i dont think its gonna tell us anything new about black holes but its a triumph in the sense that you go back 100 years and it was a continuous development general relativity the discovery of black holes ligo the incredible technology that went into ligo it is something that i never would have believed was gonna happen 30 40 years ago and i think its a magnificent structure magnificent thing this evolution of general relativity ligo high precision ability to measure things on a scale of 10 to the minus 21 so astonishing so youre just in awe that this path took us to this picture is it different youve thought a lot about black holes how did you visualize them in your mind and is the picture different than youve visualized it no its simply confirmed its a magnificent triumph to have confirmed a direct observation that einsteins theory of gravity at the level of black hole collisions actually works is awesome it is really awesome i know some of the people who are involved in that theyre just ordinary people and the idea that they could carry this out i just im shocked yeah just these little homo sapiens yeah just these little monkeys yeah got together and took a picture of slightly advanced limers i think what kind of questions can science not currently answer but you hope might be able to soon well youve already addressed them what is consciousness for example you think thats within the reach of science i think its somewhat within the reach of science but i think that now i think its in the hands of the computer scientists and the neuroscientists not a physicist with the help perhaps at some point but i think physicists will try to simplify it down to something that they can use their methods and maybe theyre not appropriate maybe we simply need to do more machine learning on bigger scales evolve machines machines not only that learn but evolve their own architecture as a process of learning evolve in architecture not under our control only partially under our control but under the control of machine learning ill tell you another thing that i find awesome you know this google thing that they taught the computers how to play chess yeah yeah okay they taught the computers how to play chess not by teaching them how to play chess but just having them play against each other against each other self play against each other this is a form of evolution these machines evolved they evolved in intelligence they evolved in intelligence without anybody telling them how to do it they were not engineered they just played against each other and got better and better and better that makes me think that machines can evolve intelligence what exact kind of intelligence i dont know but in understanding that better and better maybe well get better clues as to what goes on in our own intelligence what life in intelligence is last question what kind of questions can science not currently answer and may never be able to answer yeah yeah is there an intelligence out there thats underlies the whole thing you can call them with a g word if you want i can say are we a computer simulation with a purpose is there an agent an intelligent agent that underlies or is responsible for the whole thing does that intelligent agent satisfy the laws of physics does it satisfy the laws of quantum mechanics is it made of atoms and molecules yeah theres a lot of questions and i dont see it seems to me a real question its an answerable question well i dont know if its answerable the questions have to be answerable to be real some philosophers would say that a question is not a question unless its answerable this question doesnt seem to me answerable by any known method but it seems to me real theres no better place to end leonard thank you so much for talking today okay good', 'the following is a conversation with peter norvig hes the director of research at google and the coauthor with stuart russell of the book artificial intelligence a modern approach that educated and inspired a whole generation of researchers including myself to get into the field of artificial intelligence this is the artificial intelligence podcast if you enjoy it subscribe on youtube give five stars on itunes support on patreon or simply connect with me on twitter im lex friedman spelled f r i d m a n and now heres my conversation with peter norvig most researchers in the ai community including myself own all three editions red green and blue of the artificial intelligence a modern approach its a field defining textbook as many people are aware that you wrote with stuart russell how has the book changed and how have you changed in relation to it from the first edition to the second to the third and now fourth edition as you work on it yeah so its been a lot of years a lot of changes one of the things changing from the first to maybe the second or third was just the rise of computing power right so i think in the first edition we said heres predicate logic but that only goes so far because pretty soon you have millions of short little predicate expressions and they can possibly fit in memory so were gonna use first order logic thats more concise and then we quickly realized oh predicate logic is pretty nice because there are really fast sat solvers and other things and look theres only millions of expressions and that fits easily into memory or maybe even billions fit into memory now so that was a change of the type of technology we needed just because the hardware expanded even to the second edition resource constraints were loosened significantly for the second and that was early 2000s second edition right so 95 was the first and then 2000 2001 or so and then moving on from there i think were starting to see that again with the gpus and then more specific type of machinery like the tpus and youre seeing custom asics and so on for deep learning so were seeing another advance in terms of the hardware then i think another thing that we especially noticed this time around is in all three of the first editions we kind of said well were gonna find ai as maximizing expected utility and you tell me your utility function and now weve got 27 chapters where the cool techniques for how to optimize that i think in this edition were saying more you know what maybe that optimization part is the easy part and the hard part is deciding what is my utility function what do i want and if im a collection of agents or a society what do we want as a whole so you touched that topic in this edition you get a little bit more into utility yeah thats really interesting on a technical level were almost pushing the philosophical i guess it is philosophical right so weve always had a philosophy chapter which i was glad that we were supporting and now its less kind of the chinese room type argument and more of these ethical and societal type issues so we get into the issues of fairness and bias and just the issue of aggregating utilities so how do you encode human values into a utility function is this something that you can do purely through data in a learned way or is there some systematic obviously theres no good answers yet theres just beginnings to this to even opening the doors to these questions so there is no one answer yes there are techniques to try to learn that so we talk about inverse reinforcement learning right so reinforcement learning you take some actions you get some rewards and you figure out what actions you should take and inverse reinforcement learning you observe somebody taking actions and you figure out well this must be what they were trying to do if they did this action it must be because they want it of course theres restrictions to that right so lots of people take actions that are self destructive or theyre suboptimal in certain ways so you dont wanna learn that you wanna somehow learn the perfect actions rather than the ones they actually take so thats a challenge for that field then another big part of it is just kind of theoretical of saying what can we accomplish and so you look at like this work on the programs to predict recidivism and decide who should get parole or who should get bail or whatever and how are you gonna evaluate that and one of the big issues is fairness across protected classes protected classes being things like sex and race and so on and so two things you want is you wanna say well if i get a score of say six out of 10 then i want that to mean the same whether no matter what race im on right yes right so i wanna have a 60 chance of reoccurring regardless and one of the makers of a commercial program to do that says thats what were trying to optimize and look we achieved that weve reached that kind of balance and then on the other side you also wanna say well if it makes mistakes i want that to affect both sides of the protected class equally and it turns out they dont do that right so theyre twice as likely to make a mistake that would harm a black person over a white person so that seems unfair so youd like to say well i wanna achieve both those goals and then it turns out you do the analysis and its theoretically impossible to achieve both those goals so you have to trade them off one against the other so that analysis is really helpful to know what you can aim for and how much you can get you cant have everything but the analysis certainly cant tell you where should we make that trade off point but nevertheless then we can as humans deliberate where that trade off should be yeah so at least we now were arguing in an informed way were not asking for something impossible were saying heres where we are and heres what we aim for and this strategy is better than that strategy so thats i would argue is a really powerful and really important first step but its a doable one sort of removing undesirable degrees of bias in systems in terms of protected classes and then theres something i listened to your commencement speech or theres some fuzzier things like you mentioned angry birds do you wanna create systems that feed the dopamine enjoyment that feed that optimize for you returning to the system enjoying the moment of playing the game of getting likes or whatever this kind of thing or some kind of longterm improvement right are you even thinking about that thats really going to the philosophical area no i think thats a really important issue too certainly thinking about that i dont think about that as an ai issue as much but as you say the point is weve built this society and this infrastructure where we say we have a marketplace for attention and weve decided as a society that we like things that are free and so we want all the apps on our phone to be free and that means theyre all competing for your attention and then eventually they make some money some way through ads or in game sales or whatever but they can only win by defeating all the other apps by instilling your attention and we build a marketplace where it seems like theyre working against you rather than working with you and id like to find a way where we can change the playing field so you feel more like well these things are on my side yes theyre letting me have some fun in the short term but theyre also helping me in the long term rather than competing against me and those arent necessarily conflicting objectives theyre just the incentives the direct current incentives as we try to figure out this whole new world seem to be on the easier part of that which is feeding the dopamine the rush right but so maybe taking a quick step back at the beginning of the artificial intelligence the modern approach book of writing so here you are in the 90s when you first sat down with stuart to write the book to cover an entire field which is one of the only books thats successfully done that for ai and actually in a lot of other computer science fields its a huge undertaking so it mustve been quite daunting what was that process like did you envision that you would be trying to cover the entire field was there a systematic approach to it that was more step by step how was how did it feel so i guess it came about go to lunch with the other ai faculty at berkeley and wed say the field is changing it seems like the current books are a little bit behind nobodys come out with a new book recently we should do that and everybody said yeah yeah thats a great thing to do and we never did anything right and then i ended up heading off to industry i went to sun labs so i thought well thats the end of my possible academic publishing career but i met stuart again at a conference like a year later and said you know that book we were always talking about you guys must be half done with it by now right and he said well we keep talking we never do anything so i said well you know we should do it and i think the reason is that we all felt it was a time where the field was changing and that was in two ways so you know the good old fashioned ai was based primarily on boolean logic and you had a few tricks to deal with uncertainty and it was based primarily on knowledge engineering that the way you got something done is you went out you interviewed an expert and you wrote down by hand everything they knew and we saw in 95 that the field was changing in two ways one were moving more towards probability rather than boolean logic and were moving more towards machine learning rather than knowledge engineering and the other books hadnt caught that way if they were still in the more in the old school although so certainly they had part of that on the way but we said if we start now completely taking that point of view we can have a different kind of book and we were able to put that together and what was literally the process if you remember did you start writing a chapter did you outline yeah i guess we did an outline and then we sort of assigned chapters to each person at the time i had moved to boston and stuart was in berkeley so basically we did it over the internet and you know that wasnt the same as doing it today it meant you know dial up lines and telnetting in and you know you telnet it into one shell and you type cat file name and you hoped it was captured at the other end and certainly youre not sending images and figures back and forth right right that didnt work but you know did you anticipate where the field would go from that day from the 90s did you see the growth into learning based methods and to data driven methods that followed in the future decades we certainly thought that learning was important i guess we missed it as being as important as it is today we missed this idea of big data we missed that the idea of deep learning hadnt been invented yet we could have taken the book from a complete machine learning point of view right from the start we chose to do it more from a point of view of were gonna first develop different types of representations and were gonna talk about different types of environments is it fully observable or partially observable and is it deterministic or stochastic and so on and we made it more complex along those axes rather than focusing on the machine learning axis first do you think you know theres some sense in which the deep learning craze is extremely successful for a particular set of problems and you know eventually its going to in the general case hit challenges so in terms of the difference between perception systems and robots that have to act in the world do you think were gonna return to ai modern approach type breadth in addition five and six in future decades do you think deep learning will take its place as a chapter in this bigger view of ai yeah i think we dont know yet how its all gonna play out so in the new edition we have a chapter on deep learning we got ian goodfellow to be the guest author for that chapter so he said he could condense his whole deep learning book into one chapter i think he did a great job we were also encouraged that hes you know we gave him the old neural net chapter and said modernize that and he said you know half of that was okay that certainly theres lots of new things that have been developed but some of the core was still the same so i think well gain a better understanding of what you can do there i think well need to incorporate all the things we can do with the other technologies right so deep learning started out with convolutional networks and very close to perception and its since moved to be able to do more with actions and some degree of longer term planning but we need to do a better job with representation than reasoning and one shot learning and so on and i think we dont know yet how thats gonna play out so do you think looking at some success but certainly eventual demise a partial demise of experts to symbolic systems in the 80s do you think there is kernels of wisdom and the work that was done there with logic and reasoning and so on that will rise again in your view so certainly i think the idea of representation and reasoning is crucial that sometimes you just dont have enough data about the world to learn de novo so youve got to have some idea of representation whether that was programmed in or told or whatever and then be able to take steps of reasoning i think the problem with the good old fashioned ai was one we tried to base everything on these symbols that were atomic and thats great if youre like trying to define the properties of a triangle right because they have necessary and sufficient conditions but things in the real world dont the real world is messy and doesnt have sharp edges and atomic symbols do so that was a poor match and then the other aspect was that the reasoning was universal and applied anywhere which in some sense is good but it also means theres no guidance as to where to apply and so you started getting these paradoxes like well if i have a mountain and i remove one grain of sand then its still a mountain but if i do that repeatedly at some point its not right and with logic theres nothing to stop you from applying things repeatedly but maybe with something like deep learning and i dont really know what the right name for it is we could separate out those ideas so one we could say a mountain isnt just an atomic notion its some sort of something like a word embedding that has a more complex representation and secondly we could somehow learn yeah theres this rule that you can remove one grain of sand and you can do that a bunch of times but you cant do it a near infinite amount of times but on the other hand when youre doing induction on the integer sure then its fine to do it an infinite number of times and if we could somehow we have to learn when these strategies are applicable rather than having the strategies be completely neutral and available everywhere anytime you use neural networks anytime you learn from data form representation from data in an automated way its not very explainable as to or its not introspective to us humans in terms of how this neural network sees the world where why does it succeed so brilliantly in so many cases and fail so miserably in surprising ways and small so what do you think is the future there can simply more data better data more organized data solve that problem or is there elements of symbolic systems that need to be brought in which are a little bit more explainable yeah so i prefer to talk about trust and validation and verification rather than just about explainability and then i think explanations are one tool that you use towards those goals and i think it is an important issue that we dont wanna use these systems unless we trust them and we wanna understand where they work and where they dont work and an explanation can be part of that right so i apply for a loan and i get denied i want some explanation of why and you have in europe we have the gdpr that says youre required to be able to get that but on the other hand the explanation alone is not enough right so we are used to dealing with people some of that were seeing due to ai a lot of it you dont need ai and i dont know whats a worst threat if its an autonomous drone or its crispr technology becoming available or we have lots of threats to face and some of them involve ai and some of them dont so the threats that technology presents are you for the most part optimistic about technology also alleviating those threats or creating new opportunities or protecting us from the more detrimental effects of these new technologies i dont know again its hard to predict the future and as a society so far weve survived nuclear bombs and other things of course only societies that have survived are having this conversation so maybe thats survivorship bias there what problem stands out to you as exciting challenging impactful to work on in the near future for yourself for the community and broadly so we talked about these assistance and conversation i think thats a great area i think combining common sense reasoning with the power of data is a great area in which application in conversation or just broadly speaking just in general yeah as a programmer im interested in programming tools both in terms of the current systems we have today with tensorflow and so on can we make them much easier to use for a broader class of people and also can we apply machine learning to the more traditional type of programming so when you go to google and you type in a query and you spell something wrong it says did you mean and the reason were able to do that is because lots of other people made a similar error and then they corrected it we should be able to go into our code bases and our bug fix bases and when i type a line of code it should be able to say did you mean such and such if you type this today youre probably going to type in this bug fix tomorrow yeah thats a really exciting application of almost an assistant for the coding programming experience at every level so i think i could safely speak for the entire ai community first of all for thanking you for the amazing work youve done certainly for the amazing work youve done with ai and modern approach book i think were all looking forward very much for the fourth edition and then the fifth edition and so on so peter thank you so much for talking today yeah thank you my pleasure and with organizations and corporations and so on and they can give you an explanation and you have no guarantee that that explanation relates to reality right so the bank can tell me well you didnt get the loan because you didnt have enough collateral and that may be true or it may be true that they just didnt like my religion or something else i cant tell from the explanation and thats true whether the decision was made by a computer or by a person so i want more i do wanna have the explanations and i wanna be able to have a conversation to go back and forth and said well you gave this explanation but what about this and what would have happened if this had happened and what would i need to change that so i think a conversation is a better way to think about it than just an explanation as a single output and i think we need testing of various kinds right so in order to know was the decision really based on my collateral or was it based on my religion or skin color or whatever i cant tell if im only looking at my case but if i look across all the cases then i can detect the pattern right so you wanna have that kind of capability you wanna have these adversarial testing right so we thought we were doing pretty good at object recognition in images we said look were at sort of pretty close to human level performance on imagenet and so on and then you start seeing these adversarial images and you say wait a minute that part is nothing like human performance you can mess with it really easily you can mess with it really easily right and yeah you can do that to humans too right so we in a different way perhaps right humans dont know what color the dress was right and so theyre vulnerable to certain attacks that are different than the attacks on the machines but the attacks on the machines are so striking they really change the way you think about what weve done right and the way i think about it is i think part of the problem is were seduced by our low dimensional metaphors right yeah i like that phrase you look in a textbook and you say okay now weve mapped out the space and a cat is here and dog is here and maybe theres a tiny little spot in the middle where you cant tell the difference but mostly weve got it all covered and if you believe that metaphor then you say well were nearly there and theres only gonna be a couple adversarial images but i think thats the wrong metaphor and what you should really say is its not a 2d flat space that weve got mostly covered its a million dimension space and a cat is this string that goes out in this crazy path and if you step a little bit off the path in any direction youre in nowheres land and you dont know whats gonna happen and so i think thats where we are and now weve got to deal with that so it wasnt so much an explanation but it was an understanding of what the models are and what theyre doing and now we can start exploring how do you fix that yeah validating the robustness of the system and so on but take it back to this word trust do you think were a little too hard on our robots in terms of the standards we apply so you know theres a dance in nonverbal and verbal communication between humans if we apply the same kind of standard in terms of humans we trust each other pretty quickly you know you and i havent met before and theres some degree of trust right that nothings gonna go crazy wrong and yet to ai when we look at ai systems or we seem to approach skepticism always always and its like they have to prove through a lot of hard work that theyre even worthy of even inkling of our trust what do you think about that how do we break that barrier close that gap i think thats right i think thats a big issue just listening my friend mark moffat is a naturalist and he says the most amazing thing about humans is that you can walk into a coffee shop or a busy street in a city and theres lots of people around you that youve never met before and you dont kill each other yeah he says chimpanzees cannot do that yeah right right if a chimpanzees in a situation where heres some that arent from my tribe bad things happen especially in a coffee shop theres delicious food around you know yeah yeah but we humans have figured that out right and you know for the most part for the most part we still go to war we still do terrible things but for the most part weve learned to trust each other and live together so thats gonna be important for our ai systems as well and also i think a lot of the emphasis is on ai but in many cases ai is part of the technology but isnt really the main thing so a lot of what weve seen is more due to communications technology than ai technology yeah you wanna make these good decisions but the reason were able to have any kind of system at all is weve got the communication so that were collecting the data and so that we can reach lots of people around the world i think thats a bigger change that were dealing with speaking of reaching a lot of people around the world on the side of education one of the many things in terms of education youve done youve taught the intro to artificial intelligence course that signed up 160000 students theres one of the first successful example of a mooc massive open online course what did you learn from that experience what do you think is the future of moocs of education online yeah it was a great fun doing it particularly being right at the start just because it was exciting and new but it also meant that we had less competition right so one of the things you hear about well the problem with moocs is the completion rates are so low so there must be a failure and i gotta admit im a prime contributor right i probably started 50 different courses that i havent finished but i got exactly what i wanted out of them because i had never intended to finish them i just wanted to dabble in a little bit either to see the topic matter or just to see the pedagogy of how are they doing this class so i guess the main thing i learned is when i came in i thought the challenge was information saying if im just take the stuff i want you to know and im very clear and explain it well then my job is done and good things are gonna happen and then in doing the course i learned well yeah you gotta have the information but really the motivation is the most important thing that if students dont stick with it it doesnt matter how good the content is and i think being one of the first classes we were helped by sort of exterior motivation so we tried to do a good job of making it enticing and setting up ways for the community to work with each other to make it more motivating but really a lot of it was hey this is a new thing and im really excited to be part of a new thing and so the students brought their own motivation and so i think this is great because theres lots of people around the world who have never had this before would never have the opportunity to go to stanford and take a class or go to mit or go to one of the other schools but now we can bring that to them and if they bring their own motivation they can be successful in a way they couldnt before but thats really just the top tier of people that are ready to do that the rest of the people just dont see or dont have the motivation and dont see how if they push through and were able to do it what advantage that would get them so i think we got a long way to go before we were able to do that and i think some of it is based on technology but more of its based on the idea of community you gotta actually get people together some of the getting together can be done online i think some of it really has to be done in person in order to build that type of community and trust you know theres an intentional mechanism that weve developed a short attention span especially younger people because sort of shorter and shorter videos online theres a whatever the way the brain is developing now and with people that have grown up with the internet they have quite a short attention span so and i would say i had the same when i was growing up too probably for different reasons so i probably wouldnt have learned as much as i have if i wasnt forced to sit in a physical classroom sort of bored sometimes falling asleep but sort of forcing myself through that process so sometimes extremely difficult computer science courses whats the difference in your view between in person education experience which you first of all yourself had and you yourself taught and online education and how do we close that gap if its even possible yeah so i think theres two issues one is whether its in person or online so its sort of the physical location and then the other is kind of the affiliation right so you stuck with it in part because you were in the classroom and you saw everybody else was suffering the same way you were but also because you were enrolled you had paid tuition sort of everybody was expecting you to stick with it society parents peers and so those are two separate things i mean you could certainly imagine i pay a huge amount of tuition and everybody signed up and says yes youre doing this but then im in my room and my classmates are in different rooms right we could have things set up that way so its not just the online versus offline i think whats more important is the commitment that youve made and certainly it is important to have that kind of informal you know i meet people outside of class we talk together because were all in it together i think thats really important both in keeping your motivation and also thats where some of the most important learning goes on so you wanna have that maybe you know especially now we start getting into higher bandwidths and augmented reality and virtual reality you might be able to get that without being in the same physical place do you think its possible well see a course at stanford for example that for students enrolled students is only online in the near future or literally sort of its part of the curriculum and there is no yeah so youre starting to see that i know georgia tech has a masters thats done that way oftentimes its sort of theyre creeping in in terms of a masters program or sort of further education considering the constraints of students and so on but i mean literally is it possible that we you know stanford mit berkeley all these places go online only in the next few decades yeah probably not because you know theyve got a big commitment to a physical campus sure so theres a momentum thats both financial and culturally right and then there are certain things thats just hard to do virtually right so you know were in a field where if you have your own computer and your own paper and so on you can do the work anywhere but if youre in a biology lab or something you know you dont have all the right stuff at home right so our field programming youve also done a lot of programming yourself in 2001 you wrote a great article about programming called teach yourself programming in 10 years sort of response to all the books that say teach yourself programming in 21 days so if you were giving advice to someone getting into programming today this is a few years since youve written that article whats the best way to undertake that journey i think theres lots of different ways and i think programming means more things now and i guess you know when i wrote that article i was thinking more about becoming a professional software engineer and i thought thats a you know sort of a career long field of study but i think theres lots of things now that people can do where programming is a part of solving what they wanna solve without achieving that professional level status right so im not gonna be going and writing a million lines of code but you know im a biologist or a physicist or something or even a historian and ive got some data and i wanna ask a question of that data and i think for that you dont need 10 years right so there are many shortcuts to being able to answer those kinds of questions and you know you see today a lot of emphasis on learning to code teaching kids how to code i think thats great but i wish they would change the message a little bit right so i think code isnt the main thing i dont really care if you know the syntax of javascript or if you can connect these blocks together in this visual language but what i do care about is that you can analyze a problem you can think of a solution you can carry out you know make a model run that model test the model see the results verify that theyre reasonable ask questions and answer them right so its more modeling and problem solving and you use coding in order to do that but its not just learning coding for its own sake thats really interesting so its actually almost in many cases its learning to work with data to extract something useful out of data so when you say problem solving you really mean taking some kind of maybe collecting some kind of data set cleaning it up and saying something interesting about it which is useful in all kinds of domains and you know and i see myself being stuck sometimes in kind of the old ways right so you know ill be working on a project maybe with a younger employee and we say oh well heres this new package that could help solve this problem and ill go and ill start reading the manuals and you know ill be two hours into reading the manuals and then my colleague comes back and says im done you know i downloaded the package i installed it i tried calling some things the first one didnt work the second one worked now im done and i say but i have a hundred questions about how does this work and how does that work and they say who cares right i dont need to understand the whole thing i answered my question its a big complicated package i dont understand the rest of it but i got the right answer and im just its hard for me to get into that mindset i want to understand the whole thing and you know if they wrote a manual i should probably read it and but thats not necessarily the right way i think i have to get used to dealing with more being more comfortable with uncertainty and not knowing everything yeah so i struggle with the same instead of the spectrum between donald and don knuth yeah its kind of the very you know before he can say anything about a problem he really has to get down to the machine code assembly yeah and that forces exactly what you said of several students in my group that you know 20 years old and they can solve almost any problem within a few hours that would take me probably weeks because i would try to as you said read the manual so do you think the nature of mastery youre mentioning biology sort of outside disciplines applying programming but computer scientists so over time theres higher and higher levels of abstraction available now so with this week theres the tensorflow summit right so if youre not particularly into deep learning but youre still a computer scientist you can accomplish an incredible amount with tensorflow without really knowing any fundamental internals of machine learning do you think the nature of mastery is changing even for computer scientists like what it means to be an expert programmer yeah i think thats true you know we never really should have focused on programmer right because its still its the skill and what we really want to focus on is the result so we built this ecosystem where the way you can get stuff done is by programming it yourself at least when i started you know library functions meant you had square root and that was about it right everything else you built from scratch and then we built up an ecosystem where a lot of times well you can download a lot of stuff that does a big part of what you need and so now its more a question of assembly rather than manufacturing and thats a different way of looking at problems from another perspective in terms of mastery and looking at programmers or people that reason about problems in a computational way so google you know from the hiring perspective from the perspective of hiring or building a team of programmers how do you determine if someones a good programmer or if somebody again so i want to deviate from i want to move away from the word programmer but somebody who could solve problems of large scale data and so on whats how do you build a team like that through the interviewing process yeah and i think as a company grows you get more expansive in the types of people youre looking for right so i think you know in the early days wed interview people and the question we were trying to ask is how close are they to jeff dean and most people were pretty far away but we take the ones that were not that far away and so we got kind of a homogeneous group of people who were really great programmers then as a company grows you say well we dont want everybody to be the same to have the same skill set and so now were hiring biologists in our health areas and were hiring physicists were hiring mechanical engineers were hiring you know social scientists and ethnographers and people with different backgrounds who bring different skills so you have mentioned that you still may partake in code reviews given that you have a wealth of experience as youve also mentioned what errors do you often see and tend to highlight in the code of junior developers of people coming up now given your background from blisp to a couple of decades of programming yeah thats a great question you know sometimes i try to look at the flexibility of the design of yes you know this api solves this problem but where is it gonna go in the future who else is gonna wanna call this and you know are you making it easier for them to do that thats a matter of design is it documentation is it sort of an amorphous thing you cant really put into words its just how it feels if you put yourself in the shoes of a developer would you use this kind of thing i think it is how you feel right and so yeah documentation is good but its more a design question right if you get the design right then people will figure it out whether the documentation is good or not and if the designs wrong then itd be harder to use how have you yourself changed as a programmer over the years in a way you already started to say sort of you want to read the manual you want to understand the core of the syntax to how the language is supposed to be used and so on but whats the evolution been like from the 80s 90s to today i guess one thing is you dont have to worry about the small details of efficiency as much as you used to right so like i remember i did my list book in the 90s and one of the things i wanted to do was say heres how you do an object system and basically were going to make it so each object is a hash table and you look up the methods and heres how it works and then i said of course the real common lisp object system is much more complicated its got all these efficiency type issues and this is just a toy and nobody would do this in real life and it turns out python pretty much did exactly what i said and said objects are just dictionaries and yeah they have a few little tricks as well but mostly the thing that would have been 100 times too slow in the 80s is now plenty fast for most everything so you had to as a programmer let go of perhaps an obsession that i remember coming up with of trying to write efficient code yeah to say what really matters is the total time it takes to get the project done and most of thats gonna be the programmer time so if youre a little bit less efficient but it makes it easier to understand and modify then thats the right trade off so youve written quite a bit about lisp your book on programming is in lisp you have a lot of code out there thats in lisp so myself and people who dont know what lisp is should look it up its my favorite language for many ai researchers it is a favorite language the favorite language they never use these days so what part of lisp do you find most beautiful and powerful so i think the beautiful part is the simplicity that in half a page you can define the whole language and other languages dont have that so you feel like you can hold everything in your head and then a lot of people say well then thats too simple heres all these things i wanna do and my java or python or whatever has 100 or 200 or 300 different syntax rules and dont i need all those and lisps answer was no were only gonna give you eight or so syntax rules but were gonna allow you to define your own and so that was a very powerful idea and i think this idea of saying i can start with my problem and with my data and then i can build the language i want for that problem and for that data and then i can make lisp define that language so youre sort of mixing levels and saying im simultaneously a programmer in a language and a language designer and that allows a better match between your problem and your eventual code and i think lisp had done that better than other languages yeah its a very elegant implementation of functional programming but why do you think lisp has not had the mass adoption and success of languages like python is it the parentheses is it all the parentheses yeah so i think a couple things so one was i think it was designed for a single programmer or a small team and a skilled programmer who had the good taste to say well i am doing language design and i have to make good choices and if you make good choices thats great if you make bad choices you can hurt yourself and it can be hard for other people on the team to understand it so i think there was a limit to the scale of the size of a project in terms of number of people that lisp was good for and as an industry we kind of grew beyond that i think it is in part the parentheses you know one of the jokes is the acronym for lisp is lots of irritating silly parentheses my acronym was lisp is syntactically pure saying all you need is parentheses and atoms but i remember you know as we had the ai textbook and because we did it in the nineties we had pseudocode in the book but then we said well well have lisp online because thats the language of ai at the time and i remember some of the students complaining because they hadnt had lisp before and they didnt quite understand what was going on and i remember one student complained i dont understand how this pseudocode corresponds to this lisp and there was a one to one correspondence between the symbols in the code and the pseudocode and the only thing difference was the parentheses so i said it must be that for some people a certain number of left parentheses shuts off their brain yeah its very possible in that sense and python just goes the other way so that was the point at which i said okay cant have only lisp as a language cause i dont wanna you know you only got 10 or 12 or 15 weeks or whatever it is to teach ai and i dont want to waste two weeks of that teaching lisp so i say i gotta have another language java was the most popular language at the time i started doing that and then i said its really hard to have a one to one correspondence between the pseudocode and the java because java is so verbose so then i said im gonna do a survey and find the language thats most like my pseudocode and it turned out python basically was my pseudocode somehow i had channeled guido designed a pseudocode that was the same as python although i hadnt heard of python at that point and from then on thats what ive been using cause its been a good match so whats the story in python behind pytudes your github repository with puzzles and exercises in python is pretty fun yeah just it it seems like fun you know i like doing puzzles and i like being an educator i did a class with udacity udacity 212 i think it was it was basically problem solving using python and looking at different problems does pytudes feed that class in terms of the exercises i was wondering what the yeah so the class came first some of the stuff thats in pytudes was write ups of what was in the class and then some of it was just continuing to work on new problems so whats the organizing madness of pytudes is it just a collection of cool exercises just whatever i thought was fun okay awesome so you were the director of search quality at google from 2001 to 2005 in the early days when theres just a few employees and when the company was growing like crazy right so i mean google revolutionized the way we discover share and aggregate knowledge so just this is one of the fundamental aspects of civilization right is information being shared and theres different mechanisms throughout history but google has just 10x improved that right and youre a part of that right people discovering that information so what were some of the challenges on a philosophical or the technical level in those early days it definitely was an exciting time and as you say we were doubling in size every year and the challenges were we wanted to get the right answers right and we had to figure out what that meant we had to implement that and we had to make it all efficient and we had to keep on testing and seeing if we were delivering good answers and now when you say good answers it means whatever people are typing in in terms of keywords in terms of that kind of thing that the results they get are ordered by the desirability for them of those results like theyre like the first thing they click on will likely be the thing that they were actually looking for right one of the metrics we had was focused on the first thing some of it was focused on the whole page some of it was focused on top three or so so we looked at a lot of different metrics for how well we were doing and we broke it down into subclasses of maybe heres a type of query that were not doing well on and we try to fix that early on we started to realize that we were in an adversarial position right so we started thinking well were kind of like the card catalog in the library right so the books are here and were off to the side and were just reflecting whats there and then we realized every time we make a change the webmasters make a change and its game theoretic and so we had to think not only of is this the right move for us to make now but also if we make this move whats the counter move gonna be is that gonna get us into a worse place in which case we wont make that move well make a different move and did you find i mean i assume with the popularity and the growth of the internet that people were creating new content so youre almost helping guide the creation of new content yeah so thats certainly true right so we definitely changed the structure of the network so if you think back in the very early days larry and sergey had the pagerank paper and john kleinberg had this hubs and authorities model which says the web is made out of these hubs which will be my page of cool links about dogs or whatever and people would just list links and then thered be authorities which were the page about dogs that most people linked to that doesnt happen anymore people dont bother to say my page of cool links because we took over that function right so we changed the way that worked did you imagine back then that the internet would be as massively vibrant as it is today i mean it was already growing quickly but its just another i dont know if youve ever today if you sit back and just look at the internet with wonder the amount of content thats just constantly being created constantly being shared and deployed yeah its always been surprising to me i guess im not very good at predicting the future and i remember being a graduate student in 1980 or so and we had the arpanet and then there was this proposal to commercialize it and have this internet and this crazy senator gore thought that might be a good idea and i remember thinking oh come on you cant expect a commercial company to understand this technology theyll never be able to do it yeah okay we can have thiscom domain but it wont go anywhere so i was wrong al gore was right at the same time the nature of what it means to be a commercial company has changed too so google in many ways at its founding is different than what companies were before i think right so theres all these business models that are so different than what was possible back then so in terms of predicting the future what do you think it takes to build a system that approaches human level intelligence youve talked about of course that we shouldnt be so obsessed about creating human level intelligence we just create systems that are very useful for humans but what do you think it takes to approach that level right so certainly i dont think human level intelligence is one thing right so i think theres lots of different tasks lots of different capabilities i also dont think that should be the goal right so i wouldnt wanna create a calculator that could do multiplication at human level right that would be a step backwards and so for many things we should be aiming far beyond human level for other things maybe human level is a good level to aim at and for others wed say well lets not bother doing this because we already have humans can take on those tasks so as you say i like to focus on whats a useful tool and in some cases being at human level is an important part of crossing that threshold to make the tool useful so we see in things like these personal assistants now that you get either on your phone or on a speaker that sits on the table you wanna be able to have a conversation with those and i think as an industry we havent quite figured out what the right model is for what these things can do and were aiming towards well you just have a conversation with them the way you can with a person but we havent delivered on that model yet right so you can ask it whats the weather you can ask it play some nice songs and five or six other things and then you run out of stuff that it can do in terms of a deep meaningful connection so youve mentioned the movie her as one of your favorite ai movies do you think its possible for a human being to fall in love with an ai assistant as you mentioned so taking this big leap from whats the weather to having a deep connection yeah i think as people thats what we love to do and i was at a showing of her where we had a panel discussion and somebody asked me what other movie do you think her is similar to and my answer was life of brian which is not a science fiction movie but both movies are about wanting to believe in something thats not necessarily real yeah by the way for people that dont know its monty python yeah its been brilliantly put right so i think thats just the way we are we want to trust we want to believe we want to fall in love and it doesnt necessarily take that much right so my kids fell in love with their teddy bear and the teddy bear was not very interactive so thats all us pushing our feelings onto our devices and our things and i think that thats what we like to do so well continue to do that so yeah as human beings we long for that connection and just ai has to do a little bit of work to catch us in the other end yeah and certainly if you can get to dog level a lot of people have invested a lot of love in their pets in their pets some people as ive been told in working with autonomous vehicles have invested a lot of love into their inanimate cars so it really doesnt take much so what is a good test to linger on a topic that may be silly or a little bit philosophical what is a good test of intelligence in your view is natural conversation like in the turing test a good test put another way what would impress you if you saw a computer do it these days yeah i mean i get impressed all the time go playing starcraft playing those are all pretty cool and i think sure conversation is important i think we sometimes have these tests where its easy to fool the system where you can have a chat bot that can have a conversation but it never gets into a situation where it has to be deep enough that it really reveals itself as being intelligent or not i think turing suggested that but i think if he were alive hed say you know i didnt really mean that seriously and i think this is just my opinion but i think turings point was not that this test of conversation is a good test i think his point was having a test is the right thing so rather than having the philosophers say oh no ai is impossible you should say well well just have a test and then the result of that will tell us the answer and it doesnt necessarily have to be a conversation test thats right and coming up a new better test as the technology evolves is probably the right way do you worry as a lot of the general public does about not a lot but some vocal part of the general public about the existential threat of artificial intelligence so looking farther into the future as you said most of us are not able to predict much so when shrouded in such mystery theres a concern of well you start thinking about worst case is that something that occupies your mind space much so i certainly think about threats i think about dangers and i think any new technology has positives and negatives and if its a powerful technology it can be used for bad as well as for good so im certainly not worried about the robot apocalypse and the terminator type scenarios i am worried about change in employment and are we going to be able to react fast enough to deal with that i think were already seeing it today where a lot of people are disgruntled about the way income inequality is working and automation could help accelerate those kinds of problems i see powerful technologies can always be used as weapons whether theyre robots or drones or whatever', 'the following is a conversation with gary marcus hes a professor emeritus at nyu founder of robust ai and geometric intelligence the latter is a machine learning company that was acquired by uber in 2016 hes the author of several books unnatural and artificial intelligence including his new book rebooting ai building machines we can trust gary has been a critical voice highlighting the limits of deep learning and ai in general and discussing the challenges before our ai community that must be solved in order to achieve artificial general intelligence as im having these conversations i try to find paths toward insight towards new ideas i try to have no ego in the process it gets in the way ill often continuously try on several hats several roles one for example is the role of a three year old who understands very little about anything and asks big what and why questions the other might be a role of a devils advocate who presents counter ideas with the goal of arriving at greater understanding through debate hopefully both are useful interesting and even entertaining at times i ask for your patience as i learn to have better conversations this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with gary marcus do you think human civilization will one day have to face an ai driven technological singularity that will in a societal way modify our place in the food chain of intelligent living beings on this planet i think our place in the food chain has already changed so there are lots of things people used to do by hand that they do with machine if you think of a singularity as like one single moment which is i guess what it suggests i dont know if itll be like that but i think that theres a lot of gradual change and ai is getting better and better i mean im here to tell you why i think its not nearly as good as people think but the overall trend is clear maybe rick hertzweil thinks its an exponential and i think its linear in some cases its close to zero right now but its all gonna happen i mean we are gonna get to human level intelligence or whatever you want artificial general intelligence at some point and thats certainly gonna change our place in the food chain because a lot of the tedious things that we do now were gonna have machines do and a lot of the dangerous things that we do now were gonna have machines do i think our whole lives are gonna change from people finding their meaning through their work through people finding their meaning through creative expression so the singularity will be a very gradual in fact removing the meaning of the word singularity itll be a very gradual transformation in your view i think that itll be somewhere in between and i guess it depends what you mean by gradual and sudden i dont think its gonna be one day i think its important to realize that intelligence is a multidimensional variable so people sort of write this stuff as if iq was one number and the day that you hit 262 or whatever you displace the human beings and really theres lots of facets to intelligence so theres verbal intelligence and theres motor intelligence and theres mathematical intelligence and so forth machines in their mathematical intelligence far exceed most people already in their ability to play games they far exceed most people already in their ability to understand language they lag behind my five year old far behind my five year old so there are some facets of intelligence that machines have grasped and some that they havent and we have a lot of work left to do to get them to say understand natural language or to understand how to flexibly approach some kind of novel macgyver problem solving kind of situation and i dont know that all of these things will come at once i think there are certain vital prerequisites that were missing now so for example machines dont really have common sense now so they dont understand that bottles contain water and that people drink water to quench their thirst and that they dont wanna dehydrate they dont know these basic facts about human beings and i think that thats a rate limiting step for many things its a great limiting step for reading for example because stories depend on things like oh my god that persons running out of water thats why they did this thing or if they only had water they could put out the fire so you watch a movie and your knowledge about how things work matter and so a computer cant understand that movie if it doesnt have that background knowledge same thing if you read a book and so there are lots of places where if we had a good machine interpretable set of common sense many things would accelerate relatively quickly but i dont think even that is a single point theres many different aspects of knowledge and we might for example find that we make a lot of progress on physical reasoning getting machines to understand for example how keys fit into locks or that kind of stuff or how this gadget here works and so forth and so on and so machines might do that long before they do really good psychological reasoning because its easier to get kind of labeled data or to do direct experimentation on a microphone stand than it is to do direct experimentation on human beings to understand the levers that guide them thats a really interesting point actually whether its easier to gain common sense knowledge or psychological knowledge i would say the common sense knowledge includes both physical knowledge and psychological knowledge and the argument i was making well you said physical versus psychological yeah physical versus psychological and the argument i was making is physical knowledge might be more accessible because you could have a robot for example lift a bottle try putting a bottle cap on it see that it falls off if it does this and see that it could turn it upside down and so the robot could do some experimentation we do some of our psychological reasoning by looking at our own minds so i can sort of guess how you might react to something based on how i think i would react to it and robots dont have that intuition and they also cant do experiments on people in the same way or well probably shut them down so if we wanted to have robots figure out how i respond to pain by pinching me in different ways like thats probably its not gonna make it past the human subjects board and companies are gonna get sued or whatever so theres certain kinds of practical experience that are limited or off limits to robots thats a really interesting point what is more difficult to gain a grounding in because to play devils advocate i would say that human behavior is easier expressed in data and digital form and so when you look at facebook algorithms they get to observe human behavior so you get to study and manipulate even a human behavior in a way that you perhaps cannot study or manipulate the physical world so its true why you said pain is like physical pain but thats again the physical world emotional pain might be much easier to experiment with perhaps unethical but nevertheless some would argue its already going on i think that youre right for example that facebook does a lot of experimentation in psychological reasoning in fact zuckerberg talked about ai at a talk that he gave in nips i wasnt there but the conference has been renamed neurips but he used to be called nips when he gave the talk and he talked about facebook basically having a gigantic theory of mind so i think it is certainly possible i mean facebook does some of that i think they have a really good idea of how to addict people to things they understand what draws people back to things i think they exploit it in ways that im not very comfortable with but even so i think that there are only some slices of human experience that they can access through the kind of interface they have and of course theyre doing all kinds of vr stuff and maybe thatll change and theyll expand their data and im sure that thats part of their goal so it is an interesting question i think love fear insecurity all of the things that i would say some of the deepest things about human nature and the human mind could be explored through digital form its that youre actually the first person just now that brought up i wonder what is more difficult because i think folks who are the slow and well talk a lot about deep learning but the people who are thinking beyond deep learning are thinking about the physical world youre starting to think about robotics in the home robotics how do we make robots manipulate objects which requires an understanding of the physical world and then requires common sense reasoning and that has felt to be like the next step for common sense reasoning but youve now brought up the idea that theres also the emotional part and its interesting whether thats hard or easy i think some parts of it are and some arent so my company that i recently founded with rod brooks from mit for many years and so forth were interested in both were interested in physical reasoning and psychological reasoning among many other things and there are pieces of each of these that are accessible so if you want a robot to figure out whether it can fit under a table thats a relatively accessible piece of physical reasoning if you know the height of the table and you know the height of the robot its not that hard if you wanted to do physical reasoning about jenga it gets a little bit more complicated and you have to have higher resolution data in order to do it with psychological reasoning its not that hard to know for example that people have goals and they like to act on those goals but its really hard to know exactly what those goals are but ideas of frustration i mean you could argue its extremely difficult to understand the sources of human frustration as theyre playing jenga with you or not you could argue that its very accessible theres some things that are gonna be obvious and some not so i dont think anybody really can do this well yet but i think its not inconceivable to imagine machines in the not so distant future being able to understand that if people lose in a game that they dont like that thats not such a hard thing to program and its pretty consistent across people most people dont enjoy losing and so that makes it relatively easy to code on the other hand if you wanted to capture everything about frustration well people can get frustrated for a lot of different reasons they might get sexually frustrated they might get frustrated they can get their promotion at work all kinds of different things and the more you expand the scope the harder it is for anything like the existing techniques to really do that so im talking to garret kasparov next week and he seemed pretty frustrated with his game against deep blue so yeah well im frustrated with my game against him last year because i played him i had two excuses ill give you my excuses up front but it wont mitigate the outcome i was jet lagged and i hadnt played in 25 or 30 years but the outcome is he completely destroyed me and it wasnt even close have you ever been beaten in any board game by a machine i have i actually played the predecessor to deep blue deep thought i believe it was called and that too crushed me and that was and after that you realize its over for us well theres no point in my playing deep blue i mean its a waste of deep blues computation i mean i played kasparov because we both gave lectures this same event and he was playing 30 people i forgot to mention that not only did he crush me but he crushed 29 other people at the same time i mean but the actual philosophical and emotional experience of being beaten by a machine i imagine is a i mean to you who thinks about these things may be a profound experience or no it was a simple mathematical experience yeah i think a game like chess particularly where you have perfect information its two player closed end and theres more computation for the computer its no surprise the machine wins i mean im not sad when a computer im not sad when a computer calculates a cube root faster than me like i know i cant win that game im not gonna try well with a system like alphago or alphazero do you see a little bit more magic in a system like that even though its simply playing a board game but because theres a strong learning component you know i find you should mention that in the context of this conversation because kasparov and i are working on an article thats gonna be called ai is not magic and you know neither one of us thinks that its magic and part of the point of this article is that ai is actually a grab bag of different techniques and some of them have or they each have their own unique strengths and weaknesses so you know you read media accounts and its like ooh ai it must be magical or it can solve any problem well no some problems are really accessible like chess and go and other problems like reading are completely outside the current technology and its not like you can take the technology that drives alphago and apply it to reading and get anywhere you know deepmind has tried that a bit they have all kinds of resources you know they built alphago and they have you know i wrote a piece recently that they lost and you can argue about the word lost but they spent 530 million more than they made last year so you know theyre making huge investments they have a large budget and they have applied the same kinds of techniques to reading or to language its just much less productive there because its a fundamentally different kind of problem chess and go and so forth are closed end problems the rules havent changed in 2500 years theres only so many moves you can make you can talk about the exponential as you look at the combinations of moves but fundamentally you know the go board has 361 squares thats it thats the only you know those intersections are the only places that you can place your stone whereas when youre reading the next sentence could be anything you know its completely up to the writer what theyre gonna do next thats fascinating that you think this way youre clearly a brilliant mind who points out the emperor has no clothes but so ill play the role of a person who says youre gonna put clothes on the emperor good luck with it it romanticizes the notion of the emperor period suggesting that clothes dont even matter okay so thats really interesting that youre talking about language so theres the physical world of being able to move about the world making an omelet and coffee and so on theres language where you first understand whats being written and then maybe even more complicated than that having a natural dialogue and then theres the game of go and chess i would argue that language is much closer to go than it is to the physical world like it is still very constrained when you say the possibility of the number of sentences that could come it is huge but it nevertheless is much more constrained it feels maybe im wrong than the possibilities that the physical world brings us theres something to what you say in some ways in which i disagree so one interesting thing about language is that it abstracts away this bottle i dont know if it would be in the field of view is on this table and i use the word on here and i can use the word on here maybe not here but that one word encompasses in analog space sort of infinite number of possibilities so there is a way in which language filters down the variation of the world and theres other ways so we have a grammar and more or less you have to follow the rules of that grammar you can break them a little bit but by and large we follow the rules of grammar and so thats a constraint on language so there are ways in which language is a constrained system on the other hand there are many arguments that say theres an infinite number of possible sentences and you can establish that by just stacking them up so i think theres water on the table you think that i think theres water on the table your mother thinks that you think that i think that waters on the table your brother thinks that maybe your mom is wrong to think that you think that i think right so we can make sentences of infinite length or we can stack up adjectives this is a very silly example a very very silly example a very very very very very very silly example and so forth so there are good arguments that theres an infinite range of sentences in any case its vast by any reasonable measure and for example almost anything in the physical world we can talk about in the language world and interestingly many of the sentences that we understand we can only understand if we have a very rich model of the physical world so i dont ultimately want to adjudicate the debate that i think you just set up but i find it interesting maybe the physical world is even more complicated than language i think thats fair but language is really really complicated its really really hard well its really really hard for machines for linguists people trying to understand it its not that hard for children and thats part of whats driven my whole career i was a student of steven pinkers and we were trying to figure out why kids could learn language when machines couldnt i think were gonna get into language were gonna get into communication intelligence and neural networks and so on but let me return to the high level the futuristic for a brief moment so youve written in your book in your new book it would be arrogant to suppose that we could forecast where ai will be or the impact it will have in a thousand years or even 500 years so let me ask you to be arrogant what do ai systems with or without physical bodies look like 100 years from now if you would just you cant predict but if you were to philosophize and imagine do can i first justify the arrogance before you try to push me beyond it sure i mean there are examples like people figured out how electricity worked they had no idea that that was gonna lead to cell phones i mean things can move awfully fast once new technologies are perfected even when they made transistors they werent really thinking that cell phones would lead to social networking there are nevertheless predictions of the future which are statistically unlikely to come to be but nevertheless is the best youre asking me to be wrong asking you to be statistically in which way would i like to be wrong pick the least unlikely to be wrong thing even though its most very likely to be wrong i mean heres some things that we can safely predict i suppose we can predict that ai will be faster than it is now it will be cheaper than it is now it will be better in the sense of being more general and applicable in more places it will be pervasive i mean these are easy predictions im sort of modeling them in my head on jeff bezoss famous predictions he says i cant predict the future not in every way im paraphrasing but i can predict that people will never wanna pay more money for their stuff theyre never gonna want it to take longer to get there so you cant predict everything but you can predict something sure of course its gonna be faster and better but what we cant really predict is the full scope of where ai will be in a certain period i mean i think its safe to say that although im very skeptical about current ai that its possible to do much better you know theres no in principled argument that says ai is an insolvable problem that theres magic inside our brains that will never be captured i mean ive heard people make those kind of arguments i dont think theyre very good so ais gonna come and probably 500 years is plenty to get there and then once its here it really will change everything so when you say ais gonna come but i would say that its a pretty interesting set of things that we are equipped with that allows us to do a lot of interesting things so i would argue or guess based on my reading of the developmental psychology literature which ive also participated in that children are born with a notion of space time other agents places and also this kind of mental algebra that i was describing before no certain causation if i didnt just say that so at least those kinds of things theyre like frameworks for learning the other things are they disjoint in your view or is it just somehow all connected youve talked a lot about language is it all kind of connected in some mesh thats language like if understanding concepts all together or i dont think we know for people how theyre represented and machines just dont really do this yet so i think its an interesting open question both for science and for engineering some of it has to be at least interrelated in the way that the interfaces of a software package have to be able to talk to one another so the systems that represent space and time cant be totally disjoint because a lot of the things that we reason about are the relations between space and time and cause so i put this on and i have expectations about whats gonna happen with the bottle cap on top of the bottle and those span space and time if the cap is over here i get a different outcome if the timing is different if i put this here after i move that then i get a different outcome that relates to causality so obviously these mechanisms whatever they are can certainly communicate with each other so i think evolution had a significant role to play in the development of this whole kluge right how efficient do you think is evolution oh its terribly inefficient except that okay well can we do better well ill come to that in a sec its inefficient except that once it gets a good idea it runs with it so it took i guess a billion years if i went roughly a billion years to evolve to a vertebrate brain plan and once that vertebrate brain plan evolved it spread everywhere so fish have it and dogs have it and we have it we have adaptations of it and specializations of it but and the same thing with a primate brain plan so monkeys have it and apes have it and we have it so there are additional innovations like color vision and those spread really rapidly so it takes evolution a long time to get a good idea but and im being anthropomorphic and not literal here but once it has that idea so to speak which cashes out into one set of genes or in the genome those genes spread very rapidly and theyre like subroutines or libraries i guess the word people might use nowadays or be more familiar with theyre libraries that get used over and over again so once you have the library for building something with multiple digits you can use it for a hand but you can also use it for a foot you just kind of reuse the library with slightly different parameters evolution does a lot of that which means that the speed over time picks up so evolution can happen faster because you have bigger and bigger libraries and what i think has happened in attempts at evolutionary computation is that people start with libraries that are very very minimal like almost nothing and then progress is slow and its hard for someone to get a good phd thesis out of it and they give up if we had richer libraries to begin with if you were evolving from systems that had an rich innate structure to begin with then things might speed up or more phd students if the evolutionary process is indeed in a meta way runs away with good ideas you need to have a lot of ideas pool of ideas in order for it to discover one that you can run away with and phd students representing individual ideas as well yeah i mean you could throw a billion phd students at it yeah the monkeys are typewriters with shakespeare yep well i mean those arent cumulative right thats just random and part of the point that im making is that evolution is cumulative so if you have a billion monkeys independently you dont really get anywhere but if you have a billion monkeys and i think dawkins made this point originally or probably other people dawkins made it very nice and either a selfish gene or blind watchmaker if there is some sort of fitness function that can drive you towards something i guess thats dawkins point and my point which is a variation on that is that if the evolution is cumulative i mean the related points then you can start going faster do you think something like the process of evolution is required to build intelligent systems so if we not logically so all the stuff that evolution did a good engineer might be able to do so for example evolution made quadrupeds which distribute the load across a horizontal surface a good engineer could come up with that idea i mean sometimes good engineers come up with ideas by looking at biology theres lots of ways to get your ideas part of what im suggesting is we should look at biology a lot more we should look at the biology of thought and understanding and the biology by which creatures intuitively reason about physics or other agents or like how do dogs reason about people like theyre actually pretty good at it if we could understand at my college we joked dognition if we could understand dognition well and how it was implemented that might help us with our ai so do you think its possible that the kind of timescale that evolution took is the kind of timescale that will be needed to build intelligent systems or can we significantly accelerate that process inside a computer i mean i think the way that we accelerate that process is we borrow from biology not slavishly but i think we look at how biology has solved problems and we say does that inspire any engineering solutions here try to mimic biological systems and then therefore have a shortcut yeah i mean theres a field called biomimicry and people do that for like material science all the time we should be doing the analog of that for ai and the analog for that for ai is to look at cognitive science or the cognitive sciences which is psychology maybe neuroscience linguistics and so forth look to those for insight what do you think is a good test of intelligence in your view so i dont think theres one good test in fact i tried to organize a movement towards something called a turing olympics and my hope is that francois is actually gonna take francois chollet is gonna take over this i think hes interested and i dont i just dont have place in my busy life at this moment but the notion is that thered be many tests and not just one because intelligence is multifaceted there cant really be a single measure of it because it isnt a single thing like just the crudest level the sat has a verbal component and a math component because theyre not identical and howard gardner has talked about multiple intelligences like kinesthetic intelligence and verbal intelligence and so forth there are a lot of things that go into intelligence and people can get good at one or the other i mean in some sense like every expert has developed a very specific kind of intelligence and then there are people that are generalists and i think of myself as a generalist with respect to cognitive science which doesnt mean i know anything about quantum mechanics but i know a lot about the different facets of the mind and theres a kind of intelligence to thinking about intelligence i like to think that i have some of that but social intelligence im just okay there are people that are much better at that than i am sure but what would be really impressive to you i think the idea of a touring olympics is really interesting especially if somebody like francois is running it but to you in general not as a benchmark but if you saw an ai system being able to accomplish something that would impress the heck out of you what would that thing be would it be natural language conversation for me personally i would like to see a kind of comprehension that relates to what you just said so i wrote a piece in the new yorker in i think 2015 right after eugene guestman which was a software package won a version of the turing test and the way that it did this is it be well the way you win the turing test so called win it is the turing test is you fool a person into thinking that a machine is a person is youre evasive you pretend to have limitations so you dont have to answer certain questions and so forth so this particular system pretended to be a 13 year old boy from odessa who didnt understand english and was kind of sarcastic and wouldnt answer your questions and so forth and so judges got fooled into thinking briefly with a very little exposure it was a 13 year old boy and it docked all the questions turing was actually interested in which is like how do you make the machine actually intelligent so that test itself is not that good and so in new yorker i proposed an alternative i guess and the one that i proposed there was a comprehension test and i must like breaking bad because ive already given you one breaking bad example and in that article i have one as well which was something like if walter you should be able to watch an episode of breaking bad or maybe you have to watch the whole series to be able to answer the question and say if walter white took a hit out on jesse why did he do that so if you could answer kind of arbitrary questions about characters motivations i would be really impressed with that and he built software to do that they could watch a film or there are different versions and so ultimately i wrote this up with praveen paritosh in a special issue of ai magazine that basically was about the turing olympics there were like 14 tests proposed the one that i was pushing was a comprehension challenge and praveen whos at google was trying to figure out like how we would actually run it and so we wrote a paper together and you could have a text version too or you could have an auditory podcast version you could have a written version but the point is that you win at this test if you can do lets say human level or better than humans at answering kind of arbitrary questions why did this person pick up the stone what were they thinking when they picked up the stone were they trying to knock down glass and i mean ideally these wouldnt be multiple choice either because multiple choice is pretty easily gamed so if you could have relatively open ended questions and you can answer why people are doing this stuff i would be very impressed and of course humans can do this right if you watch a well constructed movie and somebody picks up a rock everybody watching the movie knows why they picked up the rock right they all know oh my gosh hes gonna hit this character or whatever we have an example in the book about when a whole bunch of people say i am spartacus you know this famous scene the viewers understand first of all that everybody or everybody minus one has to be lying they cant all be spartacus we have enough common sense knowledge to know they couldnt all have the same name we know that theyre lying and we can infer why theyre lying right theyre lying to protect someone and to protect things they believe in you get a machine that can do that they can say this is why these guys all got up and said i am spartacus i will sit down and say ai has really achieved a lot thank you without cheating any part of the system yeah i mean if you do it there are lots of ways you could cheat you could build a spartacus machine that works on that film thats not what im talking about im talking about you can do this with essentially arbitrary films or from a large set even beyond films because its possible such a system would discover that the number of narrative arcs in film is limited to 1930 well theres a famous thing about the classic seven plots or whatever i dont care if you wanna build in the system boy meets girl boy loses girl boy finds girl thats fine i dont mind having some head stories on it and they acknowledge okay good i mean you could build it in innately or you could have your system watch a lot of films again if you can do this at all but with a wide range of films not just one film in one genre but even if you could do it for all westerns id be reasonably impressed yeah so in terms of being impressed just for the fun of it because youve put so many interesting ideas out there in your book challenging the community for further steps is it possible on the deep learning front that youre wrong about its limitations that deep learning will unlock yann lecun next year will publish a paper that achieves this comprehension so do you think that way often as a scientist do you consider that your intuition that deep learning could actually run away with it im more worried about rebranding as a kind of political thing so i mean whats gonna happen i think is the deep learning is gonna start to encompass symbol manipulation so i think hintons just wrong hinton says we dont want hybrids i think people will work towards hybrids and they will relabel their hybrids as deep learning weve already seen some of that so alphago is often described as a deep learning system but its more correctly described as a system that has deep learning but also monte carlo tree search which is a classical ai technique and people will start to blur the lines in the way that ibm blurred watson first watson meant this particular system and then it was just anything that ibm built in their cognitive division but purely let me ask for sure thats a branding question and thats like a giant mess i mean purely a single neural network being able to accomplish reasonable comprehension i dont stay up at night worrying that thats gonna happen and ill just give you two examples one is a guy at deepmind thought he had finally outfoxed me at zergilord i think is his twitter handle and he said he specifically made an example marcus said that such and such he fed it into gp2 which is the ai system that is so smart that openai couldnt release it because it would destroy the world right you remember that a few months ago so he feeds it into gpt2 and my example was something like a rose is a rose a tulip is a tulip a lily is a blank and he got it to actually do that which was a little bit impressive and i wrote back and i said thats impressive but can i ask you a few questions i said was that just one example can it do it generally and can it do it with novel words which was part of what i was talking about in 1998 when i first raised the example so a dax is a dax right and he sheepishly wrote back about 20 minutes later and the answer was well it had some problems with those so i made some predictions 21 years ago that still hold in the world of computer science thats amazing right because theres a thousand or a million times more memory and computations a million times do million times more operations per second spread across a cluster and theres been advances in replacing sigmoids with other functions and so forth theres all kinds of advances but the fundamental architecture hasnt changed and the fundamental limit hasnt changed and what i said then is kind of still true then heres a second example i recently had a piece in wired thats adapted from the book and the book went to press before gp2 came out but we described this childrens story and all the inferences that you make in this story about a boy finding a lost wallet and for fun in the wired piece we ran it through gp2 gpt2 something called talktotransformercom and your viewers can try this experiment themselves go to the wired piece that has the link and it has the story and the system made perfectly fluent text that was totally inconsistent with the conceptual underpinnings of the story right this is what again i predicted in 1998 and for that matter chomsky and miller made the same prediction in 1963 i was just updating their claim for a slightly new text so those particular architectures that dont have any built in knowledge theyre basically just a bunch of layers doing correlational stuff theyre not gonna solve these problems so 20 years ago you said the emperor has no clothes today the emperor still has no clothes the lightings better though the lighting is better and i think you yourself are also i mean and we found out some things to do with naked emperors i mean its not like stuff is worthless i mean theyre not really naked its more like theyre in their briefs than everybody thinks they are and so like i mean they are great at speech recognition but the problems that i said were hard i didnt literally say the emperor has no clothes i said this is a set of problems that humans are really good at and it wasnt couched as ai it was couched as cognitive science but i said if you wanna build a neural model of how humans do certain class of things youre gonna have to change the architecture and i stand by those claims so and i think people should understand youre quite entertaining in your cynicism but youre also very optimistic and a dreamer about the future of ai too so youre both its just theres a famous saying about being people overselling technology in the short run and underselling it in the long run and so i actually end the book ernie davis and i end our book with an optimistic chapter which kind of killed ernie because hes even more pessimistic than i am he describes me as a contrarian and him as a pessimist but i persuaded him that we should end the book with a look at what would happen if ai really did incorporate for example the common sense reasoning and the nativism and so forth the things that we counseled for and we wrote it and its an optimistic chapter that ai suitably reconstructed so that we could trust it which we cant now could really be world changing so on that point if you look at the future trajectories of ai people have worries about negative effects of ai whether its at the large existential scale or smaller short term scale of negative impact on society so you write about trustworthy ai how can we build ai systems that align with our values that make for a better world that we can interact with that we can trust the first thing we have to do is to replace deep learning with deep understanding so you cant have alignment with a system that traffics only in correlations and doesnt understand concepts like bottles or harm so asimov talked about these famous laws and the first one was first do no harm and you can quibble about the details of asimovs laws but we have to if were gonna build real robots in the real world have something like that that means we have to program in a notion thats at least something like harm that means we have to have these more abstract ideas that deep learning is not particularly good at they have to be in the mix somewhere and you could do statistical analysis about probabilities of given harms or whatever but you have to know what a harm is in the same way that you have to understand that a bottle isnt just a collection of pixels and also be able to youre implying that you need to also be able to communicate that to humans so the ai systems would be able to prove to humans that they understand that they know what harm means i might run it in the reverse direction but roughly speaking i agree with you so we probably need to have committees of wise people ethicists and so forth think about what these rules ought to be and we shouldnt just leave it to software engineers it shouldnt just be software engineers and it shouldnt just be people who own large mega corporations that are good at technology ethicists and so forth should be involved but there should be some assembly of wise people as i was putting it that tries to figure out what the rules ought to be and those have to get translated into code you can argue or code or neural networks or something they have to be translated into something that machines can work with and that means there has to be a way of working the translation and right now we dont we dont have a way so lets say you and i were the committee and we decide that asimovs first law is actually right and lets say its not just two white guys which would be kind of unfortunate that we have abroad and so weve representative sample of the world or however we wanna do this and the committee decides eventually okay asimovs first law is actually pretty good there are these exceptions to it we wanna program in these exceptions but lets start with just the first one and then well get to the exceptions first one is first do no harm well somebody has to now actually turn that into a computer program or a neural network or something and one way of taking the whole book the whole argument that im making is that we just dont have to do that yet and were fooling ourselves if we think that we can build trustworthy ai if we cant even specify in any kind of we cant do it in python and we cant do it in tensorflow were fooling ourselves in thinking that we can make trustworthy ai if we cant translate harm into something that we can execute and if we cant then we should be thinking really hard how could we ever do such a thing because if were gonna use ai in the ways that we wanna use it to make job interviews or to do surveillance not that i personally wanna do that or whatever i mean if were gonna use ai in ways that have practical impact on peoples lives or medicine its gotta be able to understand stuff like that so one of the things your book highlights is that a lot of people in the deep learning community but also the general public politicians just people in all general groups and walks of life have different levels of misunderstanding of ai so when you talk about committees whats your advice to our society how do we grow how do we learn about ai such that such committees could emerge where large groups of people could have a productive discourse about how to build successful ai systems part of the reason we wrote the book was to try to inform those committees so part of the reason we wrote the book was to inspire a future generation of students to solve what we think are the important problems so a lot of the book is trying to pinpoint what we think are the hard problems where we think effort would most be rewarded and part of it is to try to train people who talk about ai but arent experts in the field to understand whats realistic and whats not one of my favorite parts in the book is the six questions you should ask anytime you read a media account so like number one is if somebody talks about something look for the demo if theres no demo dont believe it like the demo that you can try if you cant try it at home maybe it doesnt really work that well yet so if we dont have this example in the book but if sundar pinchai says we have this thing that allows it to sound like human beings in conversation you should ask can i try it and you should ask how general it is and it turns out at that time im alluding to google duplex when it was announced it only worked on calling hairdressers restaurants and finding opening hours thats not very general thats narrow ai and im not gonna ask your thoughts about sophia but yeah i understand thats a really good question to ask of any kind of hype top idea sophia has very good material written for her but she doesnt understand the things that shes saying so a while ago youve written a book on the science of learning which i think is fascinating but the learning case studies of playing guitar thats called guitar zero i love guitar myself ive been playing my whole life so let me ask a very important question what is your favorite song rock song to listen to or try to play well those would be different but ill say that my favorite rock song to listen to is probably all along the watchtower the jimi hendrix version the jimi hendrix version it feels magic to me ive actually recently learned it i love that song ive been trying to put it on youtube myself singing singing is the scary part if you could party with a rock star for a weekend living or dead who would you choose and pick their mind its not necessarily about the partying thanks for the clarification i guess john lennons such an intriguing person and i think a troubled person but an intriguing one beautiful well imagine is one of my favorite songs also one of my favorite songs thats a beautiful way to end it gary thank you so much for talking to me thanks so much for having me are you talking about human level intelligence so maybe i i like the term general intelligence so i dont think that the ultimate ai if there is such a thing is gonna look just like humans i think its gonna do some things that humans do better than current machines like reason flexibly and understand language and so forth but it doesnt mean they have to be identical to humans so for example humans have terrible memory and they suffer from what some people call motivated reasoning so they like arguments that seem to support them and they dismiss arguments that they dont like theres no reason that a machine should ever do that so you see that those limitations of memory as a bug not a feature absolutely ill say two things about that one is i was on a panel with danny kahneman the nobel prize winner last night and we were talking about this stuff and i think what we converged on is that humans are a low bar to exceed they may be outside of our skill right now but as ai programmers but eventually ai will exceed it so were not talking about human level ai were talking about general intelligence that can do all kinds of different things and do it without some of the flaws that human beings have the other thing ill say is i wrote a whole book actually about the flaws of humans its actually a nice bookend to the or counterpoint to the current book so i wrote a book called cluj which was about the limits of the human mind the current book is kind of about those few things that humans do a lot better than machines do you think its possible that the flaws of the human mind the limits of memory our mortality our bias is a strength not a weakness that that is the thing that enables from which motivation springs and meaning springs or not ive heard a lot of arguments like this ive never found them that convincing i think that theres a lot of making lemonade out of lemons so we for example do a lot of free association where one idea just leads to the next and theyre not really that well connected and we enjoy that and we make poetry out of it and we make kind of movies with free associations and its fun and whatever i dont think thats really a virtue of the system i think that the limitations in human reasoning actually get us in a lot of trouble like for example politically we cant see eye to eye because we have the motivational reasoning i was talking about and something related called confirmation bias so we have all of these problems that actually make for a rougher society because we cant get along because we cant interpret the data in shared ways and then we do some nice stuff with that so my free associations are different from yours and youre kind of amused by them and thats great and hence poetry so there are lots of ways in which we take a lousy situation and make it good another example would be our memories are terrible so we play games like concentration where you flip over two cards try to find a pair can you imagine a computer playing that computers like this is the dullest game in the world i know where all the cards are i see it once i know where it is what are you even talking about so we make a fun game out of having this terrible memory so we are imperfect in discovering and optimizing some kind of utility function but you think in general there is a utility function theres an objective function thats better than others i didnt say that but see the presumption when you say i think you could design a better memory system you could argue about utility functions and how you wanna think about that but objectively it would be really nice to do some of the following things to get rid of memories that are no longer useful objectively that would just be good and were not that good at it so when you park in the same lot every day you confuse where you parked today with where you parked yesterday with where you parked the day before and so forth so you blur together a series of memories theres just no way that thats optimal i mean ive heard all kinds of wacky arguments of people trying to defend that but in the end of the day i dont think any of them hold water its just above or memories of traumatic events would be possibly a very nice feature to have to get rid of those itd be great if you could just be like im gonna wipe this sector im done with that i didnt have fun last night i dont wanna think about it anymore whoop bye bye im gone but we cant do you think its possible to build a system so you said human level intelligence is a weird concept but well im saying i prefer general intelligence general intelligence i mean human level intelligence is a real thing and you could try to make a machine that matches people or something like that im saying that per se shouldnt be the objective but rather that we should learn from humans the things they do well and incorporate that into our ai just as we incorporate the things that machines do well that people do terribly so i mean its great that ai systems can do all this brute force computation that people cant and one of the reasons i work on this stuff is because i would like to see machines solve problems that people cant that combine the strength or that in order to be solved would combine the strengths of machines to do all this computation with the ability lets say of people to read so id like machines that can read the entire medical literature in a day 7000 new papers or whatever the numbers comes out every day theres no way for any doctor or whatever to read them all a machine that could read would be a brilliant thing and that would be strengths of brute force computation combined with kind of subtlety and understanding medicine that a good doctor or scientist has so if we can linger a little bit on the idea of general intelligence so yann lecun believes that human intelligence isnt general at all its very narrow how do you think i dont think that makes sense we have lots of narrow intelligences for specific problems but the fact is like anybody can walk into lets say a hollywood movie and reason about the content of almost anything that goes on there so you can reason about what happens in a bank robbery or what happens when someone is infertile and wants to go to ivf to try to have a child or you can the list is essentially endless and not everybody understands every scene in the movie but theres a huge range of things that pretty much any ordinary adult can understand his argument is is that actually the set of things seems large for us humans because were very limited in considering the kind of possibilities of experiences that are possible but in fact the amount of experience that are possible is infinitely larger well i mean if you wanna make an argument that humans are constrained in what they can understand i have no issue with that i think thats right but its still not the same thing at all as saying heres a system that can play go its been trained on five million games and then i say can it play on a rectangular board rather than a square board and you say well if i retrain it from scratch on another five million games it can thats really really narrow and thats where we are we dont have even a system that could play go and then without further retraining play on a rectangular board which any human could do with very little problem so thats what i mean by narrow and so its just wordplay to say that is semantics yeah then its just words then yeah you mean general in a sense that you can do all kinds of go board shapes flexibly well that would be like a first step in the right direction but obviously thats not what it really meaning youre kidding what i mean by general is that you could transfer the knowledge you learn in one domain to another so if you learn about bank robberies in movies and theres chase scenes then you can understand that amazing scene in breaking bad when walter white has a car chase scene with only one person hes the only one in it and you can reflect on how that car chase scene is like all the other car chase scenes youve ever seen and totally different and why thats cool and the fact that the number of domains you can do that with is finite doesnt make it less general so the idea of general is you could just do it on a lot of dont transfer it across a lot of domains yeah i mean im not saying humans are infinitely general or that humans are perfect i just said a minute ago its a low bar but its just its a low bar but right now like the bar is here and were there and eventually well get way past it so speaking of low bars youve highlighted in your new book as well but a couple of years ago wrote a paper titled deep learning a critical appraisal that lists 10 challenges faced by current deep learning systems so let me summarize them as data efficiency transfer learning hierarchical knowledge open ended inference explainability integrating prior knowledge cause of reasoning modeling on a stable world robustness adversarial examples and so on and then my favorite probably is reliability in the engineering of real world systems so whatever people can read the paper they should definitely read the paper should definitely read your book but which of these challenges is solved in your view has the biggest impact on the ai community its a very good question and im gonna be evasive because i think that they go together a lot so some of them might be solved independently of others but i think a good solution to ai starts by having real what i would call cognitive models of whats going on so right now we have a approach thats dominant where you take statistical approximations of things but you dont really understand them so you know that bottles are correlated in your data with bottle caps but you dont understand that theres a thread on the bottle cap that fits with the thread on the bottle and then thats what tightens it if i tighten enough that theres a seal and the water wont come out like theres no machine that understands that and having a good cognitive model of that kind of everyday phenomena is what we call common sense and if you had that then a lot of these other things start to fall into at least a little bit better place right now youre like learning correlations between pixels when you play a video game or something like that and it doesnt work very well it works when the video game is just the way that you studied it and then you alter the video game in small ways like you move the paddle and break out a few pixels and the system falls apart because it doesnt understand it doesnt have a representation of a paddle a ball a wall a set of bricks and so forth and so its reasoning at the wrong level so the idea of common sense its full of mystery youve worked on it but its nevertheless full of mystery full of promise what does common sense mean what does knowledge mean so the way youve been discussing it now is very intuitive it makes a lot of sense that that is something we should have and thats something deep learning systems dont have but the argument could be that were oversimplifying it because were oversimplifying the notion of common sense because thats how it feels like we as humans at the cognitive level approach problems so maybe a lot of people arent actually gonna read my book but if they did read the book one of the things that might come as a surprise to them is that we actually say common sense is really hard and really complicated so they would probably my critics know that i like common sense but that chapter actually starts by us beating up not on deep learning but kind of on our own home team as it will so ernie and i are first and foremost people that believe in at least some of what good old fashioned ai tried to do so we believe in symbols and logic and programming things like that are important and we go through why even those tools that we hold fairly dear arent really enough so we talk about why common sense is actually many things and some of them fit really well with those classical sets of tools so things like taxonomy so i know that a bottle is an object or its a vessel lets say and i know a vessel is an object and objects are material things in the physical world so i can make some inferences if i know that vessels need to not have holes in them then i can infer that in order to carry their contents then i can infer that a bottle shouldnt have a hole in it in order to carry its contents so you can do hierarchical inference and so forth and we say thats great but its only a tiny piece of what you need for common sense we give lots of examples that dont fit into that so another one that we talk about is a cheese grater youve got holes in a cheese grater youve got a handle on top you can build a model in the game engine sense of a model so that you could have a little cartoon character flying around through the holes of the grater but we dont have a system yet taxonomy doesnt help us that much that really understands why the handle is on top and what you do with the handle or why all of those circles are sharp or how youd hold the cheese with respect to the grater in order to make it actually work do you think these ideas are just abstractions that could emerge on a system like a very large deep neural network im a skeptic that that kind of emergence per se can work so i think that deep learning might play a role in the systems that do what i want systems to do but it wont do it by itself ive never seen a deep learning system really extract an abstract concept what they do principled reasons for that stemming from how back propagation works how the architectures are set up one example is deep learning people actually all build in something called convolution which jan lacune is famous for which is an abstraction they dont have their systems learn this so the abstraction is an object that looks the same if it appears in different places and what lacune figured out and why essentially why he was a co winner of the turing award was that if you programmed this in innately then your system would be a whole lot more efficient in principle this should be learnable but people dont have systems that kind of reify things and make them more abstract and so what youd really wind up with if you dont program that in advance is a system that kind of realizes that this is the same thing as this but then i take your little clock there and i move it over and it doesnt realize that the same thing applies to the clock so the really nice thing youre right that convolution is just one of the things thats like its an innate feature thats programmed by the human expert we need more of those not less yes but the nice feature is it feels like that requires coming up with that brilliant idea can get you a turing award but it requires less effort than encoding and something well talk about the expert system so encoding a lot of knowledge by hand so it feels like theres a huge amount of limitations which you clearly outline with deep learning but the nice feature of deep learning whatever it is able to accomplish it does a lot of stuff automatically without human intervention well and thats part of why people love it right but i always think of this quote from bertrand russell which is it has all the advantages of theft over honest toil its really hard to program into a machine a notion of causality or even how a bottle works or what containers are ernie davis and i wrote a i dont know 45 page academic paper trying just to understand what a container is which i dont think anybody ever read the paper but its a very detailed analysis of all the things well not even all of it some of the things you need to do in order to understand a container it would be a whole lot nice and im a coauthor on the paper i made it a little bit better but ernie did the hard work for that particular paper and it took him like three months to get the logical statements correct and maybe thats not the right way to do it its a way to do it but on that way of doing it its really hard work to do something as simple as understanding containers and nobody wants to do that hard work even ernie didnt want to do that hard work everybody would rather just like feed their system in with a bunch of videos with a bunch of containers and have the systems infer how containers work it would be like so much less effort let the machine do the work and so i understand the impulse i understand why people want to do that i just dont think that it works ive never seen anybody build a system that in a robust way can actually watch videos and predict exactly which containers would leak and which ones wouldnt or something like and i know someones gonna go out and do that since i said it and i look forward to seeing it but getting these things to work robustly is really really hard so yann lecun who was my colleague at nyu for many years thinks that the hard work should go into defining an unsupervised learning algorithm that will watch videos use the next frame basically in order to tell it whats going on and he thinks thats the royal road and hes willing to put in the work in devising that algorithm then he wants the machine to do the rest and again i understand the impulse my intuition based on years of watching this stuff and making predictions 20 years ago that still hold even though theres a lot more computation and so forth is that we actually have to do a different kind of hard work which is more like building a design specification for what we want the system to do doing hard engineering work to figure out how we do things like what yann did for convolution in order to figure out how to encode complex knowledge into the systems the current systems dont have that much knowledge other than convolution which is again this objects being in different places and having the same perception i guess ill say same appearance people dont want to do that work they dont see how to naturally fit one with the other i think thats yes absolutely but also on the expert system side theres a temptation to go too far the other way so were just having an expert sort of sit down and encode the description the framework for what a container is and then having the system reason the rest from my view one really exciting possibility is of active learning where its continuous interaction between a human and machine as the machine theres kind of deep learning type extraction of information from data patterns and so on but humans also guiding the learning procedures guiding both the process and the framework of how the machine learns whatever the task is i was with you with almost everything you said except the phrase deep learning what i think you really want there is a new form of machine learning so lets remember deep learning is a particular way of doing machine learning most often its done with supervised data for perceptual categories there are other things you can do with deep learning some of them quite technical but the standard use of deep learning is i have a lot of examples and i have labels for them so here are pictures this ones the eiffel tower this ones the sears tower this ones the empire state building this ones a cat this ones a pig and so forth you just get millions of examples millions of labels and deep learning is extremely good at that its better than any other solution that anybody has devised but it is not good at representing abstract knowledge its not good at representing things like bottles contain liquid and have tops to them and so forth its not very good at learning or representing that kind of knowledge it is an example of having a machine learn something but its a machine that learns a particular kind of thing which is object classification its not a particularly good algorithm for learning about the abstractions that govern our world there may be such a thing part of what we counsel in the book is maybe people should be working on devising such things so one possibility just i wonder what you think about it is that deep neural networks do form abstractions but theyre not accessible to us humans in terms of we cant theres some truth in that so is it possible that either current or future neural networks form very high level abstractions which are as powerful as our human abstractions of common sense we just cant get a hold of them and so the problem is essentially we need to make them explainable this is an astute question but i think the answer is at least partly no one of the kinds of classical neural network architecture is what we call an auto associator it just tries to take an input goes through a set of hidden layers and comes out with an output and its supposed to learn essentially the identity function that your input is the same as your output so you think of it as binary numbers youve got the one the two the four the eight the 16 and so forth and so if you want to input 24 you turn on the 16 you turn on the eight its like binary one one and a bunch of zeros so i did some experiments in 1998 with the precursors of contemporary deep learning and what i showed was you could train these networks on all the even numbers and they would never generalize to the odd number a lot of people thought that i was i dont know an idiot or faking the experiment or it wasnt true or whatever but it is true that with this class of networks that we had in that day that they would never ever make this generalization and its not that the networks were stupid its that they see the world in a different way than we do they were basically concerned what is the probability that the rightmost output node is going to be one and as far as they were concerned in everything theyd ever been trained on it was a zero that node had never been turned on and so they figured why turn it on now whereas a person would look at the same problem and say well its obvious were just doing the thing that corresponds the latin for it is mutatis mutandis well change what needs to be changed and we do this this is what algebra is so i can do f of x equals y plus two and i can do it for a couple of values i can tell you if y is three then x is five and if y is four x is six and now i can do it with some totally different number like a million then you can say well obviously its a million and two because you have an algebraic operation that youre applying to a variable and deep learning systems kind of emulate that but they dont actually do it the particular example you could fudge a solution to that particular problem the general form of that problem remains that what they learn is really correlations between different input and output nodes and theyre complex correlations with multiple nodes involved and so forth ultimately theyre correlative theyre not structured over these operations over variables now someday people may do a new form of deep learning that incorporates that stuff and i think it will help a lot and theres some tentative work on things like differentiable programming right now that fall into that category but the sort of classic stuff like people use for imagenet doesnt have it and you have people like hinton going around saying symbol manipulation like what marcus what i advocate is like the gasoline engine its obsolete we should just use this cool electric power that weve got with the deep learning and thats really destructive because we really do need to have the gasoline engine stuff that represents i mean i dont think its a good analogy but we really do need to have the stuff that represents symbols yeah and hinton as well would say that we do need to throw out everything and start over hinton said that to axios and i had a friend who interviewed him and tried to pin him down on what exactly we need to throw out and he was very evasive well of course because we cant if he knew then hed throw it out himself but i mean you cant have it both ways you cant be like i dont know what to throw out but i am gonna throw out the symbols i mean and not just the symbols but the variables and the operations over variables dont forget the operations over variables the stuff that im endorsing and which john mccarthy did when he founded ai that stuff is the stuff that we build most computers out of there are people now who say we dont need computer programmers anymore not quite looking at the statistics of how much computer programmers actually get paid right now we need lots of computer programmers and most of them they do a little bit of machine learning but they still do a lot of code right code where its like if the value of x is greater than the value of y then do this kind of thing like conditionals and comparing operations over variables like theres this fantasy you can machine learn anything theres some things you would never wanna machine learn i would not use a phone operating system that was machine learned like you made a bunch of phone calls and you recorded which packets were transmitted and you just machine learned it itd be insane or to build a web browser by taking logs of keystrokes and images screenshots and then trying to learn the relation between them nobody would ever no rational person would ever try to build a browser that made they would use symbol manipulation the stuff that i think ai needs to avail itself of in addition to deep learning can you describe your view of symbol manipulation in its early days can you describe expert systems and where do you think they hit a wall or a set of challenges sure so i mean first i just wanna clarify im not endorsing expert systems per se youve been kind of contrasting them there is a contrast but thats not the thing that im endorsing so expert systems tried to capture things like medical knowledge with a large set of rules so if the patient has this symptom and this other symptom then it is likely that they have this disease so there are logical rules and they were symbol manipulating rules of just the sort that im talking about and the problem they encode a set of knowledge that the experts then put in and very explicitly so so youd have somebody interview an expert and then try to turn that stuff into rules and at some level im arguing for rules but the difference is those guys did in the 80s was almost entirely rules almost entirely handwritten with no machine learning what a lot of people are doing now is almost entirely one species of machine learning with no rules and what im counseling is actually a hybrid im saying that both of these things have their advantage so if youre talking about perceptual classification how do i recognize a bottle deep learning is the best tool weve got right now if youre talking about making inferences about what a bottle does something closer to the expert systems is probably still the best available alternative and probably we want something that is better able to handle quantitative and statistical information than those classical systems typically were so we need new technologies that are gonna draw some of the strengths of both the expert systems and the deep learning but are gonna find new ways to synthesize them how hard do you think it is to add knowledge at the low level so mine human intellects to add extra information to symbol manipulating systems in some domains its not that hard but its often really hard partly because a lot of the things that are important people wouldnt bother to tell you so if you pay someone on amazon mechanical turk to tell you stuff about bottles they probably wont even bother to tell you some of the basic level stuff thats just so obvious to a human being and yet so hard to capture in machines theyre gonna tell you more exotic things and theyre all well and good but theyre not getting to the root of the problem so untutored humans arent very good at knowing and why should they be what kind of knowledge the computer system developers actually need i dont think that thats an irremediable problem i think its historically been a problem people have had crowdsourcing efforts and they dont work that well theres one at mit were recording this at mit called virtual home where and we talk about this in the book find the exact example there but people were asked to do things like describe an exercise routine and the things that the people describe are at a very low level and dont really capture whats going on so theyre like go to the room with the television and the weights turn on the television press the remote to turn on the television lift weight put weight down whatever its like very micro level and its not telling you what an exercise routine is really about which is like i wanna fit a certain number of exercises in a certain time period i wanna emphasize these muscles you want some kind of abstract description the fact that you happen to press the remote control in this room when you watch this television isnt really the essence of the exercise routine but if you just ask people like what did they do then they give you this fine grain and so it takes a level of expertise about how the ai works in order to craft the right kind of knowledge so theres this ocean of knowledge that we all operate on some of them may not even be conscious or at least were not able to communicate it effectively yeah most of it we would recognize if somebody said it if it was true or not but we wouldnt think to say that its true or not thats a really interesting mathematical property this ocean has the property that every piece of knowledge in it we will recognize it as true if were told but were unlikely to retrieve it in the reverse so that interesting property i would say theres a huge ocean of that knowledge whats your intuition is it accessible to ai systems somehow can we so you said this i mean most of it is not well ill give you an asterisk on this in a second but most of it has not ever been encoded in machine interpretable form and so i mean if you say accessible theres two meanings of that one is like could you build it into a machine yes the other is like is there some database that we could go download and stick into our machine but the first thing could we whats your intuition i think we could i think it hasnt been done right you know the closest and this is the asterisk is the cyc psych system tried to do this a lot of logicians worked for doug lennon for 30 years on this project i think they stuck too closely to logic didnt represent enough about probabilities tried to hand code it there are various issues and it hasnt been that successful that is the closest existing system to trying to encode this why do you think theres not more excitement slash money behind this idea currently there was people view that project as a failure i think that they confuse the failure of a specific instance that was conceived 30 years ago for the failure of an approach which they dont do for deep learning so in 2010 people had the same attitude towards deep learning theyre like this stuff doesnt really work and all these other algorithms work better and so forth and then certain key technical advances were made but mostly it was the advent of graphics processing units that changed that it wasnt even anything foundational in the techniques and there was some new tricks but mostly it was just more compute and more data things like imagenet that didnt exist before that allowed deep learning and it could be to work it could be that cyc just needs a few more things or something like cyc but the widespread view is that that just doesnt work and people are reasoning from a single example they dont do that with deep learning they dont say nothing that existed in 2010 and there were many many efforts in deep learning was really worth anything i mean really theres no model from 2010 in deep learning or the predecessors of deep learning that has any commercial value whatsoever at this point theyre all failures but that doesnt mean that there wasnt anything there i have a friend i was getting to know him and he said i had a company too i was talking about i had a new company he said i had a company too and it failed and i said well what did you do and he said deep learning and the problem was he did it in 1986 or something like that and we didnt have the tools then or 1990 we didnt have the tools then not the algorithms his algorithms werent that different from model algorithms but he didnt have the gpus to run it fast enough he didnt have the data and so it failed it could be that symbol manipulation per se with modern amounts of data and compute and maybe some advance in compute for that kind of compute might be great my perspective on it is not that we want to resuscitate that stuff per se but we want to borrow lessons from it bring together with other things that weve learned and it might have an imagenet moment where it would spark the worlds imagination and therell be an explosion of symbol manipulation efforts yeah i think that people at ai2 paul allens ai institute are trying to build data sets well theyre not doing it for quite the reason that you say but theyre trying to build data sets that at least spark interest in common sense reasoning to create benchmarks benchmarks for common sense thats a large part of what the ai2org is working on right now so speaking of compute rich sutton wrote a blog post titled bitter lesson i dont know if youve read it but he said that the biggest lesson that can be read from so many years of ai research is that general methods that leverage computation are ultimately the most effective do you think that the most effective at what right so they have been most effective for perceptual classification problems and for some reinforcement learning problems and he works on reinforcement learning well no let me push back on that youre actually absolutely right but i would also say they have been most effective generally because everything weve done up to would you argue against that is to me deep learning is the first thing that has been successful at anything in ai and youre pointing out that this success is very limited folks but has there been something truly successful before deep learning sure i mean i want to make a larger point but on the narrower point classical ai is used for example in doing navigation instructions its very successful everybody on the planet uses it now like multiple times a day thats a measure of success right so i dont think classical ai was wildly successful but there are cases like that theyre just used all the time nobody even notices them because theyre so pervasive so there are some successes for classical ai i think deep learning has been more successful but my usual line about this and i didnt invent it but i like it a lot is just because you can build a better ladder doesnt mean you can build a ladder to the moon so the bitter lesson is if you have a perceptual classification problem throwing a lot of data at it is better than anything else but that has not given us any material progress in natural language understanding common sense reasoning like a robot would need to navigate a home problems like that theres no actual progress there so flip side of that if we remove data from the picture another bitter lesson is that you just have a very simple algorithm and you wait for compute to scale it doesnt have to be learning it doesnt have to be deep learning it doesnt have to be data driven but just wait for the compute so my question for you do you think compute can unlock some of the things with either deep learning or symbol manipulation that sure but ill put a proviso on that i think more computes always better nobodys gonna argue with more compute its like having more money i mean theres the data theres diminishing returns on more money exactly theres diminishing returns on more money but nobodys gonna argue if you wanna give them more money right except maybe the people who signed the giving pledge and some of them have a problem theyve promised to give away more money than theyre able to but the rest of us if you wanna give me more money fine im saying more money more problems but okay thats true too what i would say to you is your brain uses like 20 watts and it does a lot of things that deep learning doesnt do or that symbol manipulation doesnt do that ai just hasnt figured out how to do so its an existence proof that you dont need server resources that are google scale in order to have an intelligence i built with a lot of help from my wife two intelligences that are 20 watts each and far exceed anything that anybody else has built at a silicon speaking of those two robots what have you learned about ai from having well theyre not robots but sorry intelligent agents those two intelligent agents ive learned a lot by watching my two intelligent agents i think that whats fundamentally interesting well one of the many things thats fundamentally interesting about them is the way that they set their own problems to solve so my two kids are a year and a half apart theyre both five and six and a half they play together all the time and theyre constantly creating new challenges thats what they do is they make up games and theyre like well what if this or what if that or what if i had this superpower or what if you could walk through this wall so theyre doing these what if scenarios all the time and thats how they learn something about the world and grow their minds and machines dont really do that so thats interesting and youve talked about this youve written about it youve thought about it nature versus nurture so what innate knowledge do you think were born with and what do we learn along the way in those early months and years can i just say how much i like that question you phrased it just right and almost nobody ever does which is what is the innate knowledge and whats learned along the way so many people dichotomize it and they think its nature versus nurture when it is obviously has to be nature and nurture they have to work together you cant learn this stuff along the way unless you have some innate stuff but just because you have the innate stuff doesnt mean you dont learn anything and so many people get that wrong including in the field people think if i work in machine learning the learning side i must not be allowed to work on the innate side or that will be cheating exactly people have said that to me and its just absurd so thank you but you could break that apart more ive talked to folks who studied the development of the brain and the growth of the brain in the first few days in the first few months in the womb all of that is that innate so that process of development from a stem cell to the growth of the central nervous system and so on to the information thats encoded through the long arc of evolution so all of that comes into play and its unclear its not just whether its a dichotomy or not its where most or where the knowledge is encoded so whats your intuition about the innate knowledge the power of it whats contained in it what can we learn from it one of my earlier books was actually trying to understand the biology of this the book was called the birth of the mind like how is it the genes even build innate knowledge and from the perspective of the conversation were having today theres actually two questions one is what innate knowledge or mechanisms or what have you people or other animals might be endowed with i always like showing this video of a baby ibex climbing down a mountain that baby ibex a few hours after its birth knows how to climb down a mountain that means that it knows not consciously something about its own body and physics and 3d geometry and all of this kind of stuff so theres one question about what does biology give its creatures and what has evolved in our brains how is that represented in our brains the question i thought about in the book the birth of the mind and then theres a question of what ai should have and they dont have to be the same', 'the following is a conversation with david feroci he led the team that built watson the ibm question answering system that beat the top humans in the world at the game of jeopardy for spending a couple hours with david i saw a genuine passion not only for abstract understanding of intelligence but for engineering it to solve real world problems under real world deadlines and resource constraints where science meets engineering is where brilliant simple ingenuity emerges people who work adjoining it to have a lot of wisdom earned through failures and eventual success david is also the founder ceo and chief scientist of elemental cognition a company working to engineer ai systems that understand the world the way people do this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with david ferrucci your undergrad was in biology with an eye toward medical school before you went on for the phd in computer science so let me ask you an easy question what is the difference between biological systems and computer systems in your when you sit back look at the stars and think philosophically i often wonder whether or not there is a substantive difference i mean i think the thing that got me into computer science and into artificial intelligence was exactly this presupposition that if we can get machines to think or i should say this question this philosophical question if we can get machines to think to understand to process information the way we do so if we can describe a procedure describe a process even if that process were the intelligence process itself then what would be the difference so from a philosophical standpoint im not sure im convinced that there is i mean you can go in the direction of spirituality you can go in the direction of the soul but in terms of what we can experience from an intellectual and physical perspective im not sure there is clearly there are different implementations but if you were to say is a biological information processing system fundamentally more capable than one we might be able to build out of silicon or some other substrate i dont know that there is how distant do you think is the biological implementation so fundamentally they may have the same capabilities but is it really a far mystery where a huge number of breakthroughs are needed to be able to understand it or is it something that for the most part in the important aspects echoes of the same kind of characteristics yeah thats interesting i mean so your question presupposes that theres this goal to recreate what we perceive as biological intelligence im not sure thats the im not sure thats how i would state the goal i mean i think that studying what is the goal good so i think there are a few goals i think that understanding the human brain and how it works is important for us to be able to diagnose and treat issues treat issues for us to understand our own strengths and weaknesses both intellectual psychological and physical so neuroscience and understanding the brain from that perspective theres a clear goal there from the perspective of saying i wanna mimic human intelligence that ones a little bit more interesting human intelligence certainly has a lot of things we envy its also got a lot of problems too so i think were capable of sort of stepping back and saying what do we want out of an intelligence how do we wanna communicate with that intelligence how do we want it to behave how do we want it to perform now of course its somewhat of an interesting argument because im sitting here as a human with a biological brain and im critiquing the strengths and weaknesses of human intelligence and saying that we have the capacity to step back and say gee what is intelligence and what do we really want out of it and that in and of itself suggests that human intelligence is something quite enviable that it can introspect that way and the flaws you mentioned the flaws humans have flaws yeah but i think that flaws that human intelligence has is extremely prejudicial and biased in the way it draws many inferences do you think those are sorry to interrupt do you think those are features or are those bugs do you think the prejudice the forgetfulness the fear what are the flaws list them all what love maybe thats a flaw you think those are all things that can be gotten get in the way of intelligence or the essential components of intelligence well again if you go back and you define intelligence as being able to sort of accurately precisely rigorously reason develop answers and justify those answers in an objective way yeah then human intelligence has these flaws in that it tends to be more influenced by some of the things you said and its largely an inductive process meaning it takes past data uses that to predict the future very advantageous in some cases but fundamentally biased and prejudicial in other cases because its gonna be strongly influenced by its priors whether theyre right or wrong from some objective reasoning perspective youre gonna favor them because those are the decisions or those are the paths that succeeded in the past and i think that mode of intelligence makes a lot of sense for when your primary goal is to act quickly and survive and make fast decisions and i think those create problems when you wanna think more deeply and make more objective and reasoned decisions of course humans capable of doing both they do sort of one more naturally than they do the other but theyre capable of doing both youre saying they do the one that responds quickly more naturally right because thats the thing we kind of need to not be eaten by the predators in the world for example but then weve learned to reason through logic weve developed science we train people to do that i think thats harder for the individual to do i think it requires training and teaching i think we are the human mind certainly is capable of it but we find it more difficult and then there are other weaknesses if you will as you mentioned earlier just memory capacity and how many chains of inference can you actually go through without like losing your way so just focus and so the way you think about intelligence and were really sort of floating in this philosophical space but i think youre like the perfect person to talk about this because well get to jeopardy and beyond thats like one of the most incredible accomplishments in ai in the history of ai but hence the philosophical discussion so let me ask youve kind of alluded to it but let me ask again what is intelligence underlying the discussions well have with jeopardy and beyond how do you think about intelligence is it a sufficiently complicated problem being able to reason your way through solving that problem is that kind of how you think about what it means to be intelligent so i think of intelligence primarily two ways one is the ability to predict so in other words if i have a problem can i predict whats gonna happen next whether its to predict the answer of a question or to say look im looking at all the market dynamics and im gonna tell you whats gonna happen next or youre in a room and somebody walks in and youre gonna predict what theyre gonna do next or what theyre gonna say next youre in a highly dynamic environment full of uncertainty be able to predict the more variables the more complex the more possibilities the more complex but can i take a small amount of prior data and learn the pattern and then predict whats gonna happen next accurately and consistently thats certainly a form of intelligence what do you need for that by the way you need to have an understanding of the way the world works in order to be able to unroll it into the future right what do you think is needed to predict depends what you mean by understanding i need to be able to find that function this is very much what deep learning does machine learning does is if you give me enough prior data and you tell me what the output variable is that matters im gonna sit there and be able to predict it and if i can predict it accurately so that i can get it right more often than not im smart if i can do that with less data and less training time im even smarter if i can figure out whats even worth predicting im smarter meaning im figuring out what path is gonna get me toward a goal what about picking a goal sorry you left again well thats interesting about picking a goal sort of an interesting thing i think thats where you bring in what are you preprogrammed to do we talk about humans and well humans are preprogrammed to survive so its sort of their primary driving goal what do they have to do to do that and that can be very complex right so its not just figuring out that you need to run away from the ferocious tiger but we survive in a social context as an example so understanding the subtleties of social dynamics becomes something thats important for surviving finding a mate reproducing right so were continually challenged with complex sets of variables complex constraints rules if you will or patterns and we learn how to find the functions and predict the things in other words represent those patterns efficiently and be able to predict whats gonna happen and thats a form of intelligence that doesnt really require anything specific other than the ability to find that function and predict that right answer thats certainly a form of intelligence but then when we say well do we understand each other in other words would you perceive me as intelligent beyond that ability to predict so now i can predict but i cant really articulate how im going through that process what my underlying theory is for predicting and i cant get you to understand what im doing so that you can figure out how to do this yourself if you did not have for example the right pattern matching machinery that i did and now we potentially have this breakdown where in effect im intelligent but im sort of an alien intelligence relative to you youre intelligent but nobody knows about it or i cant well i can see the output so youre saying lets sort of separate the two things one is you explaining why you were able to predict the future and the second is me being able to impressing me that youre intelligent me being able to know that you successfully predicted the future do you think thats well its not impressing you that im intelligent in other words you may be convinced that im intelligent in some form so how what would convince because of my ability to predict so i would look at the metrics when you cant id say wow youre right more times than i am youre doing something interesting thats a form of intelligence but then what happens is if i say how are you doing that and you cant communicate with me and you cant describe that to me now i may label you a savant i may say well youre doing something weird and its just not very interesting to me because you and i cant really communicate and so now so this is interesting right because now this is youre in this weird place where for you to be recognized as intelligent the way im intelligent then you and i sort of have to be able to communicate and then my we start to understand each other and then my respect and my appreciation my ability to relate to you starts to change so now youre not an alien intelligence anymore youre a human intelligence now because you and i can communicate and so i think when we look at animals for example animals can do things we cant quite comprehend we dont quite know how they do them but they cant really communicate with us they cant put what theyre going through in our terms and so we think of them as sort of well theyre these alien intelligences and theyre not really worth necessarily what were worth we dont treat them the same way as a result of that but its hard because who knows whats going on so just a quick elaboration on that the explaining that youre intelligent the explaining the reasoning that went into the prediction is not some kind of mathematical proof if we look at humans look at political debates and discourse on twitter its mostly just telling stories so your task is sorry your task is not to tell an accurate depiction of how you reason but to tell a story real or not that convinces me that there was a mechanism by which you ultimately thats what a proof is i mean even a mathematical proof is that because ultimately the other mathematicians have to be convinced by your proof otherwise in fact there have been thats the metric for success yeah there have been several proofs out there where mathematicians would study for a long time before they were convinced that it actually proved anything right you never know if it proved anything until the community of mathematicians decided that it did so i mean but its a real thing right and thats sort of the point right is that ultimately this notion of understanding us understanding something is ultimately a social concept in other words i have to convince enough people that i did this in a reasonable way i did this in a way that other people can understand and replicate and that it makes sense to them so human intelligence is bound together in that way were bound up in that sense we sort of never really get away with it until we can sort of convince others that our thinking process makes sense did you think the general question of intelligence is then also a social construct so if we ask questions of an artificial intelligence system is this system intelligent the answer will ultimately be a socially constructed i think so i think im making two statements im saying we can try to define intelligence in this super objective way that says heres this data i wanna predict this type of thing learn this function and then if you get it right often enough we consider you intelligent but thats more like a sub bond i think it is it doesnt mean its not useful it could be incredibly useful it could be solving a problem we cant otherwise solve and can solve it more reliably than we can but then theres this notion of can humans take responsibility for the decision that youre making can we make those decisions ourselves can we relate to the process that youre going through and now you as an agent whether youre a machine or another human frankly are now obliged to make me understand how it is that youre arriving at that answer and allow me me or obviously a community or a judge of people to decide whether or not that makes sense and by the way that happens with the humans as well youre sitting down with your staff for example and you ask for suggestions about what to do next and someone says oh i think you should buy and i actually think you should buy this much or whatever or sell or whatever it is or i think you should launch the product today or tomorrow or launch this product versus that product whatever the decision may be and you ask why and the person says i just have a good feeling about it and youre not very satisfied now that person could be you might say well youve been right before but im gonna put the company on the line can you explain to me why i should believe this right and that explanation may have nothing to do with the truth you just the ultimate its gotta convince the other person still be wrong still be wrong shes gotta be convincing but its ultimately gotta be convincing and thats why im saying its were bound together right our intelligences are bound together in that sense we have to understand each other and if for example youre giving me an explanation i mean this is a very important point right youre giving me an explanation and im not good and then im not good at reasoning well and being objective and following logical paths and consistent paths and im not good at measuring and sort of computing probabilities across those paths what happens is collectively were not gonna do well how hard is that problem the second one so i think well talk quite a bit about the first on a specific objective metric benchmark performing well but being able to explain the steps the reasoning how hard is that problem i think thats very hard i mean i think that thats well its hard for humans the thing thats hard for humans as you know may not necessarily be hard for computers and vice versa so sorry so how hard is that problem for computers i think its hard for computers and the reason why i related to or saying that its also hard for humans is because i think when we step back and we say we wanna design computers to do that one of the things we have to recognize is were not sure how to do it well im not sure we have a recipe for that and even if you wanted to learn it its not clear exactly what data we use and what judgments we use to learn that well i was doing the open domain question answering stuff but i was coming off a couple other projects i had a lot more time to put into this and i argued that it could be done and i argue it would be crazy not to do this can i you can be honest at this point so even though you argued for it whats the confidence that you had yourself privately that this could be done was we just told the story how you tell stories to convince others how confident were you what was your estimation of the problem at that time so i thought it was possible and a lot of people thought it was impossible i thought it was possible the reason why i thought it was possible was because i did some brief experimentation i knew a lot about how we were approaching open domain factoid question answering ive been doing it for some years i looked at the jeopardy stuff i said this is gonna be hard for a lot of the points that we mentioned earlier hard to interpret the question hard to do it quickly enough hard to compute an accurate confidence none of this stuff had been done well enough before but a lot of the technologies were building were the kinds of technologies that should work but more to the point what was driving me was i was in ibm research i was a senior leader in ibm research and this is the kind of stuff we were supposed to do in other words we were basically supposed to this is the moonshot this is the we were supposed to take things and say this is an active research area its our obligation to kind of if we have the opportunity to push it to the limits and if it doesnt work to understand more deeply why we cant do it and so i was very committed to that notion saying folks this is what we do its crazy not to do this this is an active research area weve been in this for years why wouldnt we take this grand challenge and push it as hard as we can at the very least wed be able to come out and say heres why this problem is way hard heres what we tried and heres how we failed so i was very driven as a scientist from that perspective and then i also argued based on what we did a feasibility study why i thought it was hard but possible and i showed examples of where it succeeded where it failed why it failed and sort of a high level architecture approach for why we should do it but for the most part at that point the execs really were just looking for someone crazy enough to say yes because for several years at that point everyone had said no im not willing to risk my reputation and my career on this thing clearly you did not have such fears okay i did not so you dived right in and yet for what i understand it was performing very poorly in the beginning so what were the initial approaches and why did they fail well there were lots of hard aspects to it i mean one of the reasons why prior approaches that we had worked on in the past failed was because the questions were difficult to interpret like what are you even asking for right very often like if the question was very direct like what city or what even then it could be tricky but what city or what person is often when it would name it very clearly you would know that and if there were just a small set of them in other words were gonna ask about these five types like its gonna be an answer and the answer will be a city in this state or a city in this country the answer will be a person of this type right like an actor or whatever it is but it turns out that in jeopardy there were like tens of thousands of these things and it was a very very long tail meaning that it just went on and on and so even if you focused on trying to encode the types at the very top like theres five that were the most lets say five of the most frequent you still cover a very small percentage of the data so you couldnt take that approach of saying im just going to try to collect facts about these five or 10 types or 20 types or 50 types or whatever so that was like one of the first things like what do you do about that and so we came up with an approach toward that and the approach looked promising and we continued to improve our ability to handle that problem throughout the project the other issue was that right from the outside i said were not going to i committed to doing this in three to five years so we did it in four so i got lucky but one of the things that that putting that like stake in the ground was and i knew how hard the language understanding problem was i said were not going to actually understand language to solve this problem we are not going to interpret the question and the domain of knowledge that the question refers to and reason over that to answer these questions obviously were not going to be doing that at the same time simple search wasnt good enough to confidently answer with a single correct answer first of all thats like brilliant thats such a great mix of innovation and practical engineering three four eight so youre not trying to solve the general nlu problem youre saying lets solve this in any way possible oh yeah no i was committed to saying look were going to solving the open domain question answering problem were using jeopardy as a driver for that thats a big benchmark good enough big benchmark exactly and now were how do we do it we could just like whatever like just figure out what works because i want to be able to go back to the academic science community and say heres what we tried heres what worked heres what didnt work great i dont want to go in and say oh i only have one technology i have a hammer im only going to use this im going to do whatever it takes im like im going to think out of the box and do whatever it takes one and i also there was another thing i believed i believed that the fundamental nlp technologies and machine learning technologies would be adequate and this was an issue of how do we enhance them how do we integrate them how do we advance them so i had one researcher who came to me who had been working on question answering with me for a very long time who had said were going to need maxwells equations for question answering and i said if we need some fundamental formula that breaks new ground in how we understand language were screwed were not going to get there from here like i am not counting my assumption is im not counting on some brand new invention what im counting on is the ability to take everything it has done before to figure out an architecture on how to integrate it well and then see where it breaks and make the necessary advances we need to make until this thing works push it hard to see where it breaks and then patch it up i mean thats how people change the world i mean thats the elon musk approach to the rockets spacex thats the henry ford and so on i love it and i happen to be in this case i happen to be right but like we didnt know but you kind of have to put a stake in the rest of how youre going to run the project so yeah and backtracking to search so if you were to do whats the brute force solution what would you search over so you have a question how would you search the possible space of answers look web search has come a long way even since then but at the time first of all i mean there were a couple of other constraints around the problem which is interesting so you couldnt go out to the web you couldnt search the internet in other words the ai experiment was we want a self contained device if the device is as big as a room fine its as big as a room but we want a self contained device youre not going out to the internet you dont have a lifeline to anything so it had to kind of fit in a shoe box if you will or at least a size of a few refrigerators whatever it might be see but also you couldnt just get out there you couldnt go off network right to kind of go so there was that limitation but then we did but the basic thing was go do web search problem was even when we went and did a web search i dont remember exactly the numbers but somewhere in the order of 65 of the time the answer would be somewhere you know in the top 10 or 20 documents so first of all thats not even good enough to play jeopardy you know the words even if you could pull the even if you could perfectly pull the answer out of the top 20 documents top 10 documents whatever it was which we didnt know how to do but even if you could do that youd be and you knew it was right unless you had enough confidence in it right so youd have to pull out the right answer youd have to have confidence it was the right answer and then youd have to do that fast enough to now go buzz in and youd still only get 65 of them right which doesnt even put you in the winners circle winners circle you have to be up over 70 and you have to do it really quick and you have to do it really quickly but now the problem is well even if i had somewhere in the top 10 documents how do i figure out where in the top 10 documents that answer is and how do i compute a confidence of all the possible candidates so its not like i go in knowing the right answer and i have to pick it i dont know the right answer i have a bunch of documents somewhere in there is the right answer how do i as a machine go out and figure out which ones right and then how do i score it so and now how do i deal with the fact that i cant actually go out to the web first of all if you pause on that just think about it if you could go to the web do you think that problem is solvable if you just pause on it just thinking even beyond jeopardy do you think the problem of reading text defined where the answer is well we solved that in some definition of solves given the jeopardy challenge how did you do it for jeopardy so how do you take a body of work in a particular topic and extract the key pieces of information so now forgetting about the huge volumes that are on the web right so now we have to figure out we did a lot of source research in other words what body of knowledge is gonna be small enough but broad enough to answer jeopardy and we ultimately did find the body of knowledge that did that i mean it included wikipedia and a bunch of other stuff so like encyclopedia type of stuff i dont know if you can speak to it encyclopedias dictionaries different types of semantic resources like wordnet and other types of semantic resources like that as well as like some web crawls in other words where we went out and took that content and then expanded it based on producing statistically producing seeds using those seeds for other searches and then expanding that so using these like expansion techniques we went out and had found enough content and were like okay this is good and even up until the end we had a thread of research it was always trying to figure out what content could we efficiently include i mean theres a lot of popular like what is the church lady well i think was one of the like what where do you i guess thats probably an encyclopedia so so that was an encyclopedia but then we would take that stuff and we would go out and we would expand in other words wed go find other content that wasnt in the core resources and expand it the amount of content we grew it by an order of magnitude but still again from a web scale perspective this is very small amount of content its very select we then took all that content we preanalyzed the crap out of it meaning we parsed it broke it down into all those individual words and then we did semantic syntactic and semantic parses on it had computer algorithms that annotated it and we indexed that in a very rich and very fast index so we have a relatively huge amount of lets say the equivalent of for the sake of argument two to 5 million bucks weve now analyzed all that blowing up its size even more because now we have all this metadata and then we richly indexed all of that and by the way in a giant in memory cache so watson did not go to disk so the infrastructure component there if you could just speak to it how tough it i mean i know 2000 maybe this is 2008 nine thats kind of a long time ago how hard is it to use multiple machines how hard is the infrastructure component the hardware component so we used ibm hardware we had something like i forgot exactly but close to 3000 cores completely connected so you had a switch where every cpu was connected to every other cpu and they were sharing memory in some kind of way large shared memory right and all this data was preanalyzed and put into a very fast indexing structure that was all in memory and then we took that question we would analyze the question so all the content was now preanalyzed so if i went and tried to find a piece of content it would come back with all the metadata that we had precomputed how do you shove that question how do you connect the big knowledge base with the metadata and thats indexed to the simple little witty confusing question right so therein lies the watson architecture right so we would take the question we would analyze the question so which means that we would parse it and interpret it a bunch of different ways wed try to figure out what is it asking about so we had multiple strategies to kind of determine what was it asking for that might be represented as a simple string a character string or something we would connect back to different semantic types that were from existing resources so anyway the bottom line is we would do a bunch of analysis in the question and question analysis had to finish and had to finish fast so we do the question analysis because then from the question analysis we would now produce searches so we would and we had built using open source search engines we modified them but we had a number of different search engines we would use that had different characteristics we went in there and engineered and modified those search engines ultimately to now take our question analysis produce multiple queries based on different interpretations of the question and fire out a whole bunch of searches in parallel and they would come back with passages so these are passive search algorithms they would come back with passages and so now lets say you had a thousand passages now for each passage you parallelize again so you went out and you parallelize the search each search would now come back with a whole bunch of passages maybe you had a total of a thousand or 5000 whatever passages for each passage now youd go and figure out whether or not there was a candidate wed call it candidate answer in there so you had a whole bunch of other algorithms that would find candidate answers possible answers to the question and so you had candidate answer called candidate answer generators a whole bunch of those so for every one of these components the team was constantly doing research coming up better ways to generate search queries from the questions better ways to analyze the question better ways to generate candidates and speed so better is accuracy and speed correct so right speed and accuracy for the most part were separated we handle that sort of in separate ways like i focus purely on accuracy end to end accuracy are we ultimately getting more questions and producing more accurate confidences and then a whole nother team that was constantly analyzing the workflow to find the bottlenecks and then figuring out how to both parallelize and drive the algorithm speed but anyway so now think of it like you have this big fan out now right because you had multiple queries now you have thousands of candidate answers for each candidate answer youre gonna score it so youre gonna use all the data that built up youre gonna use the question analysis youre gonna use how the query was generated youre gonna use the passage itself and youre gonna use the candidate answer that was generated and youre gonna score that so now we have a group of researchers coming up with scores there are hundreds of different scores so now youre getting a fan out of it again from however many candidate answers you have to all the different scores so if you have 200 different scores and you have a thousand candidates now you have 200000 scores and so now you gotta figure out how do i now rank these answers based on the scores that came back and i wanna rank them based on the likelihood that theyre a correct answer to the question so every scorer was its own research project what do you mean by scorer so is that the annotation process of basically a human being saying that this answer has a quality of think of it if you wanna think of it what youre doing you know if you wanna think about what a human would be doing human would be looking at a possible answer theyd be reading the you know emily dickinson theyd be reading the passage in which that occurred theyd be looking at the question and theyd be making a decision of how likely it is that emily dickinson given this evidence in this passage is the right answer to that question got it so thats the annotation task thats the annotation process thats the scoring task but scoring implies zero to one kind of continuous thats right you give it a zero to one score so its not a binary no you give it a score give it a zero to yeah exactly zero to one score but humans give different scores so you have to somehow normalize and all that kind of stuff that deal with all that complexity it depends on what your strategy is we both we it could be relative too it could be we actually looked at the raw scores as well as standardized scores because humans are not involved in this humans are not involved sorry so im misunderstanding the process here this is passages where is the ground truth coming from ground truth is only the answers to the questions so its end to end its end to end so i was always driving end to end performance its a very interesting a very interesting engineering approach and ultimately scientific research approach always driving end to end now thats not to say we wouldnt make hypotheses that individual component performance was related in some way to end to end performance of course we would because people would have to build individual components but ultimately to get your component integrated to the system you have to show impact on end to end performance question answering performance so theres many very smart people working on this and theyre basically trying to sell their ideas as a component that should be part of the system thats right and they would do research on their component and they would say things like im gonna improve this as a candidate generator or im gonna improve this as a question score or as a passive scorer im gonna improve this or as a parser and i can improve it by 2 on its component metric like a better parse or a better candidate or a better type estimation whatever it is and then i would say i need to understand how the improvement on that component metric is gonna affect the end to end performance if you cant estimate that and cant do experiments to demonstrate that it doesnt get in thats like the best run ai project ive ever heard thats awesome okay what breakthrough would you say like im sure theres a lot of day to day breakthroughs but was there like a breakthrough that really helped improve performance like where people began to believe or is it just a gradual process well i think it was a gradual process but one of the things that i think gave people confidence that we can get there was that as we follow this procedure of different ideas build different components plug them into the architecture run the system see how we do do the error analysis start off new research projects to improve things and the very important idea that the individual component work did not have to deeply understand everything that was going on with every other component and this is where we leverage machine learning in a very important way so while individual components could be statistically driven machine learning components some of them were heuristic some of them were machine learning components the system has a whole combined all the scores using machine learning this was critical because that way you can divide and conquer so you can say okay you work on your candidate generator or you work on this approach to answer scoring you work on this approach to type scoring you work on this approach to passage search or to pass a selection and so forth but when we just plug it in and we had enough training data to say now we can train and figure out how do we weigh all the scores relative to each other based on the predicting the outcome which is right or wrong on jeopardy and we had enough training data to do that so this enabled people to work independently and to let the machine learning do the integration beautiful so yeah the machine learning is doing the fusion and then its a human orchestrated ensemble of different approaches thats great still impressive that you were able to get it done in a few years thats not obvious to me that its doable if i just put myself in that mindset but when you look back at the jeopardy challenge again when youre looking up at the stars what are you most proud of looking back at those days im most proud of my my commitment and my teams commitment to be true to the science to not be afraid to fail thats beautiful because theres so much pressure because it is a public event it is a public show that you were dedicated to the idea thats right do you think it was a success in the eyes of the world it was a success by your im sure exceptionally high standards is there something you regret you would do differently it was a success it was a success for our goal our goal was to build the most advanced open domain question answering system we went back to the old problems that we used to try to solve and we did dramatically better on all of them as well as we beat jeopardy so we won at jeopardy so it was a success it was i worry that the community or the world would not understand it as a success because it came down to only one game and i knew statistically speaking this can be a huge technical success and we could still lose that one game and thats a whole nother theme of this of the journey but it was a success it was not a success in natural language understanding but that was not the goal yeah that was but i would argue i understand what youre saying in terms of the science but i would argue that the inspiration of it right the not a success in terms of solving natural language understanding there was a success of being an inspiration to future challenges absolutely that drive future efforts whats the difference between how human being compete in jeopardy and how watson does it thats important in terms of intelligence yeah so that actually came up very early on in the project also in fact i had people who wanted to be on the project who were early on who sort of approached me once i committed to do it had wanted to think about how humans do it and they were from a cognition perspective like human cognition and how that should play and i would not take them on the project because another assumption or another stake i put in the ground was i dont really care how humans do this at least in the context of this project i need to build in the context of this project in nlu and in building an ai that understands how it needs to ultimately communicate with humans i very much care so it wasnt that i didnt care in general in fact as an ai scientist i care a lot about that but im also a practical engineer and i committed to getting this thing done and i wasnt gonna get distracted i had to kind of say like if im gonna get this done im gonna chart this path and this path says were gonna engineer a machine thats gonna get this thing done and we know what search and nlp can do we have to build on that foundation if i come in and take a different approach and start wondering about how the human mind might or might not do this im not gonna get there from here in the timeframe i think thats a great way to lead the team but now that its done and theres one when you look back analyze whats the difference actually so i was a little bit surprised actually to discover over time as this would come up from time to time and wed reflect on it and talking to ken jennings a little bit and hearing ken jennings talk about how he answered questions that it mightve been closer to the way humans answer questions than i mightve imagined previously because humans are probably in the game of jeopardy at the level of ken jennings are probably also cheating their way to winning right not cheating but shallow well theyre doing shallow analysis theyre doing the fastest possible theyre doing shallow analysis so they are very quickly analyzing the question and coming up with some key vectors or cues if you will and theyre taking those cues and theyre very quickly going through like their library of stuff not deeply reasoning about whats going on and then sort of like a lots of different like what we would call these scores would kind of score that in a very shallow way and then say oh boom you know thats what it is and so its interesting as we reflected on that so we may be doing something thats not too far off from the way humans do it but we certainly didnt approach it by saying how would a human do this now in elemental cognition like the project im leading now we ask those questions all the time because ultimately were trying to do something that is to make the intelligence of the machine and the intelligence of the human very compatible well compatible in the sense they can communicate with one another and they can reason with this shared understanding so how they think about things and how they build answers how they build explanations becomes a very important question to consider so whats the difference between this open domain but cold constructed question answering of jeopardy and more something that requires understanding for shared communication with humans and machines yeah well this goes back to the interpretation of what we were talking about before jeopardy the systems not trying to interpret the question and its not interpreting the content its reusing with regard to any particular framework i mean it is parsing it and parsing the content and using grammatical cues and stuff like that so if you think of grammar as a human framework in some sense it has that but when you get into the richer semantic frameworks what do people how do they think what motivates them what are the events that are occurring and why are they occurring and what causes what else to happen and where are things in time and space and like when you start thinking about how humans formulate and structure the knowledge that they acquire in their head and wasnt doing any of that what do you think are the essential challenges of like free flowing communication free flowing dialogue versus question answering even with the framework of the interpretation dialogue yep do you see free flowing dialogue as a fundamentally more difficult than question answering even with shared interpretation so dialogue is important in a number of different ways i mean its a challenge so first of all when i think about the machine that when i think about a machine that understands language and ultimately can reason in an objective way that can take the information that it perceives through language or other means and connect it back to these frameworks reason and explain itself that system ultimately needs to be able to talk to humans or it needs to be able to interact with humans so in some sense it needs to dialogue that doesnt mean that it sometimes people talk about dialogue and they think you know how do humans talk to like talk to each other in a casual conversation and you can mimic casual conversations were not trying to mimic casual conversations were really trying to produce a machine whose goal is to help you think and help you reason about your answers and explain why so instead of like talking to your friend down the street about having a small talk conversation with your friend down the street this is more about like you would be communicating to the computer on star trek where like what do you wanna think about like what do you wanna reason about im gonna tell you the information i have im gonna have to summarize it im gonna ask you questions youre gonna answer those questions im gonna go back and forth with you im gonna figure out what your mental model is im gonna now relate that to the information i have and present it to you in a way that you can understand it and then we could ask followup questions so its that type of dialogue that you wanna construct its more structured its more goal oriented but it needs to be fluid in other words it has to be engaging and fluid it has to be productive and not distracting so there has to be a model of in other words the machine has to have a model of how humans think through things and discuss them so basically a productive rich conversation unlike this podcast id like to think its more similar to this podcast i wasnt joking ill ask you about humor as well actually but whats the hardest part of that because it seems were quite far away as a community from that still to be able to so one is having a shared understanding thats i think a lot of the stuff you said with frameworks is quite brilliant but just creating a smooth discourse it feels clunky right now which aspects of this whole problem that you just specified of having a productive conversation is the hardest and that were or maybe any aspect of it you can comment on because its so shrouded in mystery so i think to do this you kind of have to be creative in the following sense if i were to do this as purely a machine learning approach and someone said learn how to have a good fluent structured knowledge acquisition conversation id go out and say okay i have to collect a bunch of data of people doing that people reasoning well having a good structured conversation that both acquires knowledge efficiently as well as produces answers and explanations as part of the process and you struggle i dont know to collect the data to collect the data because i dont know how much data is like that okay theres one theres a humorous commentary on the lack of rational discourse but also even if its out there say it was out there how do you actually annotate like how do you collect an accessible example right so i think any problem like this where you dont have enough data to represent the phenomenon you want to learn in other words you want if you have enough data you could potentially learn the pattern in an example like this its hard to do this is sort of a human sort of thing to do what recently came out at ibm was the debater projects and its interesting right because now you do have these structured dialogues these debate things where they did use machine learning techniques to generate these debates dialogues are a little bit tougher in my opinion than generating a structured argument where you have lots of other structured arguments like this you could potentially annotate that data and you could say this is a good response this is a bad response in a particular domain here i have to be responsive and i have to be opportunistic with regard to what is the human saying so im goal oriented in saying i want to solve the problem i want to acquire the knowledge necessary but i also have to be opportunistic and responsive to what the human is saying so i think that its not clear that we could just train on the body of data to do this but we could bootstrap it in other words we can be creative and we could say what do we think the structure of a good dialogue is that does this well and we can start to create that if we can create that more programmatically at least to get this process started and i can create a tool that now engages humans effectively i could start generating data i could start the human learning process and i can update my machine but i could also start the automatic learning process as well but i have to understand what features to even learn over so i have to bootstrap the process a little bit first and thats a creative design task that i could then use as input into a more automatic learning task so some creativity in bootstrapping what elements of a conversation do you think you would like to see so one of the benchmarks for me is humor right that seems to be one of the hardest and to me the biggest contrast is sort of watson so one of the greatest sketches comedy sketches of all time right is the snl celebrity jeopardy with alex trebek and sean connery and burt reynolds and so on with sean connery commentating on alex trebeks while theyre alive and i think all of them are in the negative pointwise so theyre clearly all losing in terms of the game of jeopardy but theyre winning in terms of comedy so what do you think about humor in this whole interaction in the dialogue thats productive or even just what humor represents to me is the same idea that youre saying about framework because humor only exists within a particular human framework so what do you think about humor what do you think about things like humor that connect to the kind of creativity you mentioned thats needed i think theres a couple of things going on there so i sort of feel like and i might be too optimistic this way but i think that there are we did a little bit about with puns in jeopardy we literally sat down and said how do puns work and its like wordplay and you could formalize these things so i think theres a lot aspects of humor that you could formalize you could also learn humor you could just say what do people laugh at and if you have enough again if you have enough data to represent the phenomenon you might be able to weigh the features and figure out what humans find funny and what they dont find funny the machine might not be able to explain why the human is funny unless we sit back and think about that more formally i think again i think you do a combination of both and im always a big proponent of that i think robust architectures and approaches are always a little bit combination of us reflecting and being creative about how things are structured how to formalize them and then taking advantage of large data and doing learning and figuring out how to combine these two approaches i think theres another aspect to humor though which goes to the idea that i feel like i can relate to the person telling the story and i think thats an interesting theme in the whole ai theme which is do i feel differently when i know its a robot and when i imagine that the robot is not conscious the way im conscious when i imagine the robot does not actually have the experiences that i experience do i find it funny or do because its not as related i dont imagine that the persons relating it to it the way i relate to it i think this also you see this in the arts and in entertainment where sometimes you have savants who are remarkable at a thing whether its sculpture or its music or whatever but the people who get the most attention are the people who can evoke a similar emotional response who can get you to emote right about the way they are in other words who can basically make the connection from the artifact from the music or the painting of the sculpture to the emotion and get you to share that emotion with them and then and thats when it becomes compelling so theyre communicating at a whole different level theyre just not communicating the artifact theyre communicating their emotional response to the artifact and then you feel like oh wow i can relate to that person i can connect to that i can connect to that person so i think humor has that aspect as well so the idea that you can connect to that person person being the critical thing but were also able to anthropomorphize objects pretty robots and ai systems pretty well so were almost looking to make them human so maybe from your experience with watson maybe you can comment on did you consider that as part well obviously the problem of jeopardy doesnt require anthropomorphization but nevertheless well there was some interest in doing that and thats another thing i didnt want to do because i didnt want to distract from the actual scientific task but youre absolutely right i mean humans do anthropomorphize and without necessarily a lot of work i mean you just put some eyes and a couple of eyebrow movements and youre getting humans to react emotionally and i think you can do that so i didnt mean to suggest that that that connection cannot be mimicked i think that connection can be mimicked and can produce that emotional response i just wonder though if youre told whats really going on if you know that the machine is not conscious not having the same richness of emotional reactions and understanding that it doesnt really share the understanding but its essentially just moving its eyebrow or drooping its eyes or making them bigger whatever its doing just getting the emotional response will you still feel it interesting i think you probably would for a while and then when it becomes more important that theres a deeper share of understanding it may run flat but i dont know im pretty confident that majority of the world even if you tell them how it works well it will not matter especially if the machine herself says that she is conscious thats very possible so you the scientist that made the machine is saying that this is how the algorithm works everybody will just assume youre lying and that theres a conscious being there so youre deep into the science fiction genre now but yeah i dont think its its actually psychology i think its not science fiction i think its reality i think its a really powerful one that well have to be exploring in the next few decades i agree its a very interesting element of intelligence so what do you think weve talked about social constructs of intelligences and frameworks and the way humans kind of interpret information what do you think is a good test of intelligence in your view so theres the alan turing with the turing test watson accomplished something very impressive with jeopardy what do you think is a test that would impress the heck out of you that you saw that a computer could do they would say this is crossing a kind of threshold that gives me pause in a good way my expectations for ai are generally high what does high look like by the way so not the threshold test is a threshold what do you think is the destination what do you think is the ceiling i think machines will in many measures will be better than us will become more effective in other words better predictors about a lot of things than ultimately we can do i think where theyre gonna struggle is what we talked about before which is relating to communicating with and understanding humans in deeper ways and so i think thats a key point like we can create the super parrot what i mean by the super parrot is given enough data a machine can mimic your emotional response can even generate language that will sound smart and what someone else might say under similar circumstances like i would just pause on that like thats the super parrot right so given similar circumstances moves its faces in similar ways changes its tone of voice in similar ways produces strings of language that would similar that a human might say not necessarily being able to produce a logical interpretation or understanding that would ultimately satisfy a critical interrogation or a critical understanding i think you just described me in a nutshell so i think philosophically speaking you could argue that thats all were doing as human beings to work super parrots so i was gonna say its very possible you know humans do behave that way too and so upon deeper probing and deeper interrogation you may find out that there isnt a shared understanding because i think humans do both like humans are statistical language model machines and they are capable reasoners you know theyre both and you dont know which is going on right so and i think its an interesting problem we talked earlier about like where we are in our social and political landscape can you distinguish someone who can string words together and sound like they know what theyre talking about from someone who actually does can you do that without dialogue without interrogative or probing dialogue so its interesting because humans are really good in their own mind justifying or explaining what they hear because they project their understanding onto yours so you could say you could put together a string of words and someone will sit there and interpret it in a way thats extremely biased to the way they wanna interpret it they wanna assume that youre an idiot and theyll interpret it one way they will assume youre a genius and theyll interpret it another way that suits their needs so this is tricky business so i think to answer your question as ai gets better and better better and better mimic you recreate the super parrots were challenged just as we are with were challenged with humans do you really know what youre talking about do you have a meaningful interpretation a powerful framework that you could reason over and justify your answers justify your predictions and your beliefs why you think they make sense can you convince me what the implications are so can you reason intelligently and make me believe that the implications of your prediction and so forth so what happens is it becomes reflective my standard for judging your intelligence depends a lot on mine but youre saying there should be a large group of people with a certain standard of intelligence that would be convinced by this particular ai system then theyll pass there should be but i think depending on the content one of the problems we have there is that if that large community of people are not judging it with regard to a rigorous standard of objective logic and reason you still have a problem like masses of people can be persuaded the millennials yeah to turn their brains off right okay sorry by the way i have nothing against the millennials no i dont im just just so youre a part of one of the great benchmarks challenges of ai history what do you think about alphazero openai5 alphastar accomplishments on video games recently which are also i think at least in the case of go with alphago and alphazero playing go was a monumental accomplishment as well what are your thoughts about that challenge i think it was a giant landmark for ai i think it was phenomenal i mean it was one of those other things nobody thought like solving go was gonna be easy particularly because its hard for particularly hard for humans hard for humans to learn hard for humans to excel at and so it was another measure a measure of intelligence its very cool i mean its very interesting what they did and i loved how they solved the data problem which again they bootstrapped it and got the machine to play itself to generate enough data to learn from i think that was brilliant i think that was great and of course the result speaks for itself i think it makes us think about again it is okay whats intelligence what aspects of intelligence are important can the go machine help me make me a better go player is it an alien intelligence am i even capable of like again if we put in very simple terms it found the function it found the go function can i even comprehend the go function can i talk about the go function can i conceptualize the go function like whatever it might be so one of the interesting ideas of that system is that it plays against itself right but theres no human in the loop there so like youre saying it could have by itself created an alien intelligence how toward a go imagine youre sentencing youre a judge and youre sentencing people or youre setting policy or youre making medical decisions and you cant explain you cant get anybody to understand what youre doing or why so its an interesting dilemma for the applications of ai do we hold ai to this accountability that says humans have to be willing to take responsibility for the decision in other words can you explain why you would do the thing will you get up and speak to other humans and convince them that this was a smart decision is the ai enabling you to do that can you get behind the logic that was made there do you think sorry to land on this point because its a fascinating one its a great goal for ai do you think its achievable in many cases or okay theres two possible worlds that we have in the future one is where ai systems do like medical diagnosis or things like that or drive a car without ever explaining to you why it fails when it does thats one possible world and were okay with it or the other where we are not okay with it and we really hold back the technology from getting too good before its able to explain which of those worlds are more likely do you think and which are concerning to you or not i think the reality is its gonna be a mix im not sure i have a problem with that i mean i think there are tasks that are perfectly fine with machines show a certain level of performance and that level of performance is already better than humans so for example i dont know that i take driverless cars if driverless cars learn how to be more effective drivers than humans but cant explain what theyre doing but bottom line statistically speaking theyre 10 times safer than humans i dont know that i care i think when we have these edge cases when something bad happens and we wanna decide whos liable for that thing and who made that mistake and what do we do about that and i think those edge cases are interesting cases and now do we go to designers of the ai and the ai says i dont know if thats what it learned to do and it says well you didnt train it properly you were negligent in the training data that you gave that machine like how do we drive down the reliability so i think those are interesting questions so the optimization problem there sorry is to create an ai system thats able to explain the lawyers away there you go i think its gonna be interesting i mean i think this is where technology and social discourse are gonna get like deeply intertwined and how we start thinking about problems decisions and problems like that i think in other cases it becomes more obvious where its like why did you decide to give that person a longer sentence or deny them parole again policy decisions or why did you pick that treatment like that treatment ended up killing that guy like why was that a reasonable choice to make and people are gonna demand explanations now theres a reality though here and the reality is that its not im not sure humans are making reasonable choices when they do these things they are using statistical hunches biases or even systematically using statistical averages to make calls this is what happened to my dad and if you saw the talk i gave about that but they decided that my father was brain dead he had went into cardiac arrest and it took a long time for the ambulance to get there and he was not resuscitated right away and so forth and they came and they told me he was brain dead and why was he brain dead because essentially they gave me a purely statistical argument under these conditions with these four features 98 chance hes brain dead i said but can you just tell me not inductively but deductively go there and tell me his brains not functioning is the way for you to do that and the protocol in response was no this is how we make this decision i said this is inadequate for me i understand the statistics and i dont know how theres a 2 chance hes still alive i just dont know the specifics i need the specifics of this case and i want the deductive logical argument about why you actually know hes brain dead so i wouldnt sign the do not resuscitate and i dont know it was like they went through lots of procedures it was a big long story but the bottom was a fascinating story by the way but how i reasoned and how the doctors reasoned through this whole process but i dont know somewhere around 24 hours later or something he was sitting up in bed with zero brain damage i mean what lessons do you draw from that story that experience that the data thats being used to make statistical inferences doesnt adequately reflect the phenomenon so in other words youre getting shit wrong im sorry but youre getting stuff wrong because your model is not robust enough and you might be better off not using statistical inference and statistical averages in certain cases when you know the models insufficient and that you should be reasoning about the specific case more logically and more deductibly and hold yourself responsible and hold yourself accountable to doing that and perhaps ai has a role to say the exact thing what you just said which is perhaps this is a case you should think for yourself you should reason deductively well so its hard because its hard to know that youd have to go back and youd have to have enough data to essentially say and this goes back to how do we this goes back to the case of how do we decide whether the ai is good enough to do a particular task and regardless of whether or not it produces an explanation and what standard do we hold for that so if you look more broadly for example as my father as a medical case the medical system ultimately helped him a lot throughout his life without it he probably would have died much sooner so overall it sort of worked for him in sort of a net net kind of way actually i dont know that thats fair but maybe not in that particular case but overall like the medical system overall does more good than bad yeah the medical system overall was doing more good than bad now theres another argument that suggests that wasnt the case but for the sake of argument lets say like thats lets say a net positive and i think you have to sit there and there and take that into consideration now you look at a particular use case like for example making this decision have you done enough studies to know how good that prediction really is and have you done enough studies to compare it to say well what if we dug in in a more direct lets get the evidence lets do the deductive thing and not use statistics here how often would that have done better so you have to do the studies to know how good the ai actually is and its complicated because it depends how fast you have to make the decision so if you have to make the decision super fast you have no choice if you have more time right but if youre ready to pull the plug and this is a lot of the argument that i had with a doctor i said whats he gonna do if you do it whats gonna happen to him in that room if you do it my way you know well hes gonna die anyway so lets do it my way then i mean it raises questions for our society to struggle with as the case with your father but also when things like race and gender start coming into play when certain when judgments are made based on things that are complicated in our society at least in the discourse and it starts you know i think im safe to say that most of the violent crimes committed by males so if you discriminate based you know its a male versus female saying that if its a male more likely to commit the crime this is one of my very positive and optimistic views of why the study of artificial intelligence the process of thinking and reasoning logically and statistically and how to combine them is so important for the discourse today because its causing a regardless of what state ai devices are or not its causing this dialogue to happen this is one of the most important dialogues that in my view the human species can have right now which is how to think well how to reason well how to understand our own cognitive biases and what to do about them that has got to be one of the most important things we as a species can be doing honestly we are weve created an incredibly complex society weve created amazing abilities to amplify noise faster than we can amplify signal we are challenged we are deeply deeply challenged we have you know big segments of the population getting hit with enormous amounts of information do they know how to do critical thinking do they know how to objectively reason do they understand what they are doing nevermind what their ai is doing this is such an important dialogue to be having and you know we are fundamentally our thinking can be and easily becomes fundamentally bias and there are statistics and we shouldnt blind our we shouldnt discard statistical inference but we should understand the nature of statistical inference as a society as you know we decide to reject statistical inference to favor understanding and deciding on the individual yes we consciously make that choice so even if the statistics said even if the statistics said males are more likely to have you know to be violent criminals we still take each person as an individual and we treat them based on the logic and the knowledge of that situation we purposefully and intentionally reject the statistical inference we do that out of respect for the individual for the individual yeah and that requires reasoning and thinking correct looking forward what grand challenges would you like to see in the future because the jeopardy challenge you know captivated the world alphago alphazero captivated the world deep blue certainly beating kasparov garys bitterness aside captivated the world what do you think do you have ideas for next grand challenges for future challenges of that and so what i mean by that is if you look at the entire enterprise of science science is supposed to be at about objective reason and reason right so we think about gee whos the most intelligent person or group of people in the world do we think about the savants who can close their eyes and give you a number we think about the think tanks or the scientists or the philosophers who kind of work through the details and write the papers and come up with the thoughtful logical proofs and use the scientific method i think its the latter and my point is that how do you train someone to do that and thats what i mean by its hard how do you whats the process of training people to do that well thats a hard process we work as a society we work pretty hard to get other people to understand our thinking and to convince them of things now we could persuade them obviously you talked about this like human flaws or weaknesses we can persuade them through emotional means but to get them to understand and connect to and follow a logical argument is difficult we try it we do it we do it as scientists we try to do it as journalists we try to do it as even artists in many forms as writers as teachers we go through a fairly significant training process to do that and then we could ask well why is that so hard but its hard and for humans it takes a lot of work and when we step back and say well how do we get a machine to do that its a vexing question how would you begin to try to solve that and maybe just a quick pause because theres an optimistic notion in the things youre describing which is being able to explain something through reason but if you look at algorithms that recommend things that well look at next whether its facebook google advertisement based companies their goal is to convince you to buy things based on anything so that could be reason because the best of advertisement is showing you things that you really do need and explain why you need it but it could also be through emotional manipulation the algorithm that describes why a certain decision was made how hard is it to do it through emotional manipulation and why is that a good or a bad thing so youve kind of focused on reason logic really showing in a clear way why something is good one is that even a thing that us humans do and two how do you think of the difference in the reasoning aspect and the emotional manipulation so you call it emotional manipulation but more objectively is essentially saying there are certain features of things that seem to attract your attention i mean it kind of give you more of that stuff manipulation is a bad word yeah i mean im not saying its good right or wrong it works to get your attention and it works to get you to buy stuff and when you think about algorithms that look at the patterns of features that you seem to be spending your money on and say im gonna give you something with a similar pattern so im gonna learn that function because the objective is to get you to click on it or get you to buy it or whatever it is i dont know i mean it is what it is i mean thats what the algorithm does you can argue whether its good or bad it depends what your goal is i guess this seems to be very useful for convincing for telling a story for convincing humans its good because again this goes back to what is the human behavior like how does the human brain respond to things i think theres a more optimistic view of that too which is that if youre searching for certain kinds of things youve already reasoned that you need them and these algorithms are saying look thats up to you to reason whether you need something or not thats your job you may have an unhealthy addiction to this stuff or you may have a reasoned and thoughtful explanation for why its important to you and the algorithms are saying hey thats like whatever like thats your problem all i know is youre buying stuff like that youre interested in stuff like that could be a bad reason could be a good reason thats up to you im gonna show you more of that stuff and i think that its not good or bad its not reasoned or not reasoned the algorithm is doing what it does which is saying you seem to be interested in this im gonna show you more of that stuff and i think were seeing this not just in buying stuff but even in social media youre reading this kind of stuff im not judging on whether its good or bad im not reasoning at all im just saying im gonna show you other stuff with similar features and like and thats it and i wash my hands from it and i say thats all thats going on you know there is people are so harsh on ai systems so one the bar of performance is extremely high and yet we also ask them to in the case of social media to help find the better angels of our nature and help make a better society what do you think about the role of ai there so that i agree with you thats the interesting dichotomy right because on one hand were sitting there and were sort of doing the easy part which is finding the patterns were not building the systems not building a theory that is consumable and understandable to other humans that can be explained and justified and so on one hand to say oh you know ai is doing this why isnt doing this other thing well this other things a lot harder and its interesting to think about why its harder and because youre interpreting the data in the context of prior models in other words understandings of whats important in the world whats not important what are all the other abstract features that drive our decision making whats sensible whats not sensible whats good whats bad whats moral whats valuable what isnt where is that stuff no ones applying the interpretation so when i see you clicking on a bunch of stuff and i look at these simple features the raw features the features that are there in the data like what words are being used or how long the material is or other very superficial features what colors are being used in the material like i dont know why youre clicking on this stuff youre clicking or if its products what the price is or what the categories and stuff like that and i just feed you more of the same stuff thats very different than kind of getting in there and saying what does this mean the stuff youre reading like why are you reading it what assumptions are you bringing to the table are those assumptions sensible does the material make any sense does it lead you to thoughtful good conclusions again theres interpretation and judgment involved in that process that isnt really happening in the ai today thats harder because you have to start getting at the meaning of the stuff of the content you have to get at how humans interpret the content relative to their value system and deeper thought processes so thats what meaning means is not just some kind of deep timeless semantic thing that the statement represents but also how a large number of people are likely to interpret so thats again even meaning is a social construct so you have to try to predict how most people would understand this kind of statement yeah meaning is often relative but meaning implies that the connections go beneath the surface of the artifacts if i show you a painting its a bunch of colors on a canvas what does it mean to you and it may mean different things to different people because of their different experiences it may mean something even different to the artist who painted it as we try to get more rigorous with our communication we try to really nail down that meaning so we go from abstract art to precise mathematics precise engineering drawings and things like that were really trying to say i wanna narrow that space of possible interpretations because the precision of the communication ends up becoming more and more important and so that means that i have to specify and i think thats why this becomes really hard because if im just showing you an artifact and youre looking at it superficially whether its a bunch of words on a page or whether its brushstrokes on a canvas or pixels on a photograph you can sit there and you can interpret lots of different ways at many many different levels but when i wanna align our understanding of that i have to specify a lot more stuff thats actually not directly in the artifact now i have to say well how are you interpreting this image and that image and what about the colors and what do they mean to you what perspective are you bringing to the table you know look i mean i think there are lots of really great ideas for grand challenges im particularly focused on one right now which is you know can you demonstrate that they understand that they could read and understand that they can acquire these frameworks and communicate you know reason and communicate with humans so it is kind of like the turing test but its a little bit more demanding than the turing test its not enough to convince me that you might be human because you could you know you can parrot a conversation i think you know the standard is a little bit higher is for example can you you know the standard is higher and i think one of the challenges of devising this grand challenge is that were not sure what intelligence is were not sure how to determine whether or not two people actually understand each other and in what depth they understand it you know to what depth they understand each other so the challenge becomes something along the lines of can you satisfy me that we have a shared understanding so if i were to probe and probe and you probe me can machines really act like thought partners where they can satisfy me that we have a shared our understanding is shared enough that we can collaborate and produce answers together and that you know they can help me explain and justify those answers so maybe heres an idea so well have ai system run for president and convince thats too easy im sorry go ahead well no you have to convince the voters that they should vote so like i guess what does winning look like again thats why i think this is such a challenge because we go back to the emotional persuasion we go back to you know now were checking off an aspect of human cognition that is in many ways weak or flawed right were so easily manipulated our minds are drawn for often the wrong reasons right not the reasons that ultimately matter to us but the reasons that can easily persuade us i think we can be persuaded to believe one thing or another for reasons that ultimately dont serve us well in the longterm and a good benchmark should not play with those elements of emotional manipulation i dont think so and i think thats where we have to set the higher standard for ourselves of what you know what does it mean this goes back to rationality and it goes back to objective thinking and can you produce can you acquire information and produce reasoned arguments and to those reasoned arguments pass a certain amount of muster and is it and can you acquire new knowledge you know can you for example can you reason i have acquired new knowledge can you identify where its consistent or contradictory with other things youve learned and can you explain that to me and get me to understand that so i think another way to think about it perhaps is can a machine teach you can it help you understand something that you didnt really understand before where its taking you so youre not again its almost like can it teach you can it help you learn and in an arbitrary space so it can open those domain space so can you tell the machine and again this borrows from some science fiction but can you go off and learn about this topic that id like to understand better and then work with me to help me understand it thats quite brilliant what the machine that passes that kind of test do you think it would need to have self awareness or even consciousness what do you think about consciousness and the importance of it maybe in relation to having a body having a presence an entity do you think thats important you know people used to ask me if watson was conscious and i used to say hes conscious of what exactly i mean i think you know maybe it depends what it is that youre conscious of i mean like so you know did it if you you know its certainly easy for it to answer questions about it would be trivial to program it to answer questions about whether or not it was playing jeopardy i mean it could certainly answer questions that would imply that it was aware of things exactly what does it mean to be aware and what does it mean to be conscious of its sort of interesting i mean i think that we differ from one another based on what were conscious of but wait wait a minute yes for sure theres degrees of consciousness in there so well and theres just areas like its not just degrees what are you aware of like what are you not aware of but nevertheless theres a very subjective element to our experience let me even not talk about consciousness let me talk about another to me really interesting topic of mortality fear of mortality watson as far as i could tell did not have a fear of death certainly not most most humans do wasnt conscious of death it wasnt yeah so theres an element of finiteness to our existence that i think like you mentioned survival that adds to the whole thing i mean consciousness is tied up with that that we are a thing its a subjective thing that ends and that seems to add a color and flavor to our motivations in a way that seems to be fundamentally important for intelligence or at least the kind of human intelligence well i think for generating goals again i think you could have you could have an intelligence capability and a capability to learn a capability to predict but i think without i mean again you get fear but essentially without the goal to survive so you think you can just encode that without having to really i think you could encode i mean you could create a robot now and you could say you know plug it in and say protect your power source you know and give it some capabilities and itll sit there and operate to try to protect its power source and survive i mean so i dont know that thats philosophically a hard thing to demonstrate it sounds like a fairly easy thing to demonstrate that you can give it that goal will it come up with that goal by itself i think you have to program that goal in but theres something because i think as we touched on intelligence is kind of like a social construct the fact that a robot will be protecting its power source would add depth and grounding to its intelligence in terms of us being able to respect it i mean ultimately it boils down to us acknowledging that its intelligent and the fact that it can die i think is an important part of that the interesting thing to reflect on is how trivial that would be and i dont think if you knew how trivial that was you would associate that with being intelligence i mean i literally put in a statement of code that says you have the following actions you can take you give it a bunch of actions like maybe you mount a laser gun on it or you give it the ability to scream or screech or whatever and you say if you see your power source threatened then you could program that in and youre gonna take these actions to protect it you know you could train it on a bunch of things so and now youre gonna look at that and you say well you know thats intelligence which is protecting its power source maybe but thats again this human bias that says the thing i identify my intelligence and my conscious so fundamentally with the desire or at least the behaviors associated with the desire to survive that if i see another thing doing that im going to assume its intelligent what timeline year will society have something that would that you would be comfortable calling an artificial general intelligence system well whats your intuition nobody can predict the future certainly not the next few months or 20 years away but whats your intuition how far away are we i dont know its hard to make these predictions i mean i would be guessing and theres so many different variables including just how much we want to invest in it and how important we think it is what kind of investment were willing to make in it what kind of talent we end up bringing to the table the incentive structure all these things so i think it is possible to do this sort of thing i think its i think trying to sort of ignore many of the variables and things like that is it a 10 year thing is it a 23 year probably closer to a 20 year thing i guess but not several hundred years no i dont think its several hundred years i dont think its several hundred years but again so much depends on how committed we are to investing and incentivizing this type of work and its sort of interesting like i dont think its obvious how incentivized we are i think from a task perspective if we see business opportunities to take this technique or that technique to solve that problem i think thats the main driver for many of these things from a general intelligence its kind of an interesting question are we really motivated to do that and like we just struggled ourselves right now to even define what it is so its hard to incentivize when we dont even know what it is were incentivized to create and if you said mimic a human intelligence i just think there are so many challenges with the significance and meaning of that that theres not a clear directive theres no clear directive to do precisely that thing so assistance in a larger and larger number of tasks so being able to a system thats particularly able to operate my microwave and making a grilled cheese sandwich i dont even know how to make one of those and then the same system will be doing the vacuum cleaning and then the same system would be teaching my kids that i dont have math i think that when you get into a general intelligence for learning physical tasks and again i wanna go back to your body question because i think your body question was interesting but you wanna go back to learning the abilities to physical tasks you might have we might get i imagine in that timeframe we will get better and better at learning these kinds of tasks whether its mowing your lawn or driving a car or whatever it is i think we will get better and better at that where its learning how to make predictions over large bodies of data i think were gonna continue to get better and better at that and machines will outpace humans in a variety of those things the underlying mechanisms for doing that may be the same meaning that maybe these are deep nets theres infrastructure to train them reusable components to get them to do different classes of tasks and we get better and better at building these kinds of machines you could argue that the general learning infrastructure in there is a form of a general type of intelligence i think what starts getting harder is this notion of can we effectively communicate and understand and build that shared understanding because of the layers of interpretation that are required to do that and the need for the machine to be engaged with humans at that level in a continuous basis so how do you get the machine in the game how do you get the machine in the intellectual game yeah and to solve agi you probably have to solve that problem you have to get the machine so its a little bit of a bootstrapping thing can we get the machine engaged in the intellectual game but in the intellectual dialogue with the humans are the humans sufficiently in intellectual dialogue with each other to generate enough data in this context and how do you bootstrap that because every one of those conversations every one of those conversations those intelligent interactions require so much prior knowledge that its a challenge to bootstrap it so the question is and how committed so i think thats possible but when i go back to are we incentivized to do that i know were incentivized to do the former are we incentivized to do the latter significantly enough do people understand what the latter really is well enough part of the elemental cognition mission is to try to articulate that better and better through demonstrations and through trying to craft these grand challenges and get people to say look this is a class of intelligence this is a class of ai do we want this what is the potential of this whats the business potential whats the societal potential to that and to build up that incentive system around that yeah i think if people dont understand yet i think they will i think theres a huge business potential here so its exciting that youre working on it we kind of skipped over but im a huge fan of physical presence of things do you think watson had a body do you think having a body adds to the interactive element between the ai system and a human or just in general to intelligence so i think going back to that shared understanding bit humans are very connected to their bodies i mean one of the challenges in getting an ai to kind of be a compatible human intelligence is that our physical bodies are generating a lot of features that make up the input so in other words our bodies are the tool we use to affect output but they also generate a lot of input for our brains so we generate emotion we generate all these feelings we generate all these signals that machines dont have so machines dont have this as the input data and they dont have the feedback that says ive gotten this emotion or ive gotten this idea i now want to process it and then it then affects me as a physical being and i can play that out in other words i could realize the implications of that implications again on my mind body complex i then process that and the implications again our internal features are generated i learn from them they have an effect on my mind body complex so its interesting when we think do we want a human intelligence well if we want a human compatible intelligence probably the best thing to do is to embed it in a human body just to clarify and both concepts are beautiful is humanoid robots so robots that look like humans is one or did you mean actually sort of what elon musk was working with neuralink really embedding intelligence systems to ride along human bodies no i mean riding along is different i meant like if you want to create an intelligence that is human compatible meaning that it can learn and develop a shared understanding of the world around it you have to give it a lot of the same substrate part of that substrate is the idea that it generates these kinds of internal features like sort of emotional stuff it has similar senses it has to do a lot of the same things with those same senses right so i think if you want that again i dont know that you want that thats not my specific goal i think thats a fascinating scientific goal i think it has all kinds of other implications thats sort of not the goal i want to create i think of it as i create intellectual thought partners for humans so that kind of intelligence i know there are other companies that are creating physical thought partners physical partners for humans but thats kind of not where im at but the important point is that a big part of what we process is that physical experience of the world around us on the point of thought partners what role does an emotional connection or forgive me love have to play in that thought partnership is that something youre interested in put another way sort of having a deep connection beyond intellectual with the ai yeah with the ai between human and ai is that something that gets in the way of the rational discourse is that something thats useful i worry about biases obviously so in other words if you develop an emotional relationship with a machine all of a sudden you start are more likely to believe what its saying even if it doesnt make any sense so i worry about that but at the same time i think the opportunity to use machines to provide human companionship is actually not crazy and intellectual and social companionship is not a crazy idea do you have concerns as a few people do elon musk sam harris about long term existential threats of ai and perhaps short term threats of ai we talked about bias we talked about different misuses but do you have concerns about thought partners systems that are able to help us make decisions together as humans somehow having a significant negative impact on society in the long term i think there are things to worry about i think giving machines too much leverage is a problem and what i mean by leverage is is too much control over things that can hurt us whether its socially psychologically intellectually or physically and if you give the machines too much control i think thats a concern you forget about the ai just once you give them too much control human bad actors can hack them and produce havoc so thats a problem and youd imagine hackers taking over the driverless car network and creating all kinds of havoc but you could also imagine given the ease at which humans could be persuaded one way or the other and now we have algorithms that can easily take control over that and amplify noise and move people one direction or another i mean humans do that to other humans all the time and we have marketing campaigns we have political campaigns that take advantage of our emotions or our fears and this is done all the time but with machines machines are like giant megaphones we can amplify this in orders of magnitude and fine tune its control so we can tailor the message we can now very rapidly and efficiently tailor the message to the audience taking advantage of their biases and amplifying them and using them to persuade them in one direction or another in ways that are not fair not logical not objective not meaningful and humans machines empower that so thats what i mean by leverage like its not new but wow its powerful because machines can do it more effectively more quickly and we see that already going on in social media and other places thats scary and thats why i go back to saying one of the most important thats why i go back to saying one of the most important public dialogues we could be having is about the nature of intelligence and the nature of inference and logic and reason and rationality and us understanding our own biases us understanding our own cognitive biases and how they work and then how machines work and how do we use them to compliment basically so that in the end we have a stronger overall system thats just incredibly important i dont think most people understand that so like telling your kids or telling your students this goes back to the cognition heres how your brain works heres how easy it is to trick your brain right there are fundamental cognitive you should appreciate the different types of thinking and how they work and what youre prone to and what do you prefer and under what conditions does this make sense versus does that make sense and then say heres what ai can do heres how it can make this worse and heres how it can make this better and then thats where the ai has a role is to reveal that trade off so if you imagine a system that is able to beyond any definition of the turing test to the benchmark really an agi system as a thought partner that you one day will create what question what topic of discussion if you get to pick one would you have with that system what would you ask and you get to find out the truth together so you threw me a little bit with finding the truth at the end but because the truth is a whole nother topic but i think the beauty of it i think what excites me is the beauty of it is if i really have that system i dont have to pick so in other words i can go to and say this is what i care about today and thats what we mean by like this general capability go out read this stuff in the next three milliseconds and i wanna talk to you about it i wanna draw analogies i wanna understand how this affects this decision or that decision what if this were true what if that were true what knowledge should i be aware of that could impact my decision heres what im thinking is the main implication can you prove that out can you give me the evidence that supports that can you give me evidence that supports this other thing boy would that be incredible would that be just incredible just a long discourse just to be part of whether its a medical diagnosis or whether its the various treatment options or whether its a legal case or whether its a social problem that people are discussing like be part of the dialogue one that holds itself and us accountable to reasons and objective dialogue i get goosebumps talking about it right its like this is what i want so when you create it please come back on the podcast and we can have a discussion together and make it even longer this is a record for the longest conversation in the world it was an honor it was a pleasure david thank you so much for talking to me thanks so much a lot of fun what are your prior experiences with those artifacts what are your fundamental assumptions and values what is your ability to kind of reason to chain together logical implication as youre sitting there and saying well if this is the case then i would conclude this and if thats the case then i would conclude that so your reasoning processes and how they work your prior models and what they are your values and your assumptions all those things now come together into the interpretation getting in sync of that is hard and yet humans are able to intuit some of that without any pre because they have the shared experience and were not talking about shared two people having shared experience i mean as a society thats correct we have the shared experience and we have similar brains so we tend to in other words part of our shared experiences are shared local experience like we may live in the same culture we may live in the same society and therefore we have similar educations we have some of what we like to call prior models about the word prior experiences and we use that as a think of it as a wide collection of interrelated variables and theyre all bound to similar things and so we take that as our background and we start interpreting things similarly but as humans we have a lot of shared experience we do have similar brains similar goals similar emotions under similar circumstances because were both humans so now one of the early questions you asked how is biological and computer information systems fundamentally different well one is humans come with a lot of pre programmed stuff a ton of program stuff and theyre able to communicate because they share that stuff do you think that shared knowledge if we can maybe escape the hard work question how much is encoded in the hardware just the shared knowledge in the software the history the many centuries of wars and so on that came to today that shared knowledge how hard is it to encode do you have a hope can you speak to how hard is it to encode that knowledge systematically in a way that could be used by a computer so i think it is possible to learn to for a machine to program a machine to acquire that knowledge with a similar foundation in other words a similar interpretive foundation for processing that knowledge what do you mean by that so in other words we view the world in a particular way so in other words we have a if you will as humans we have a framework for interpreting the world around us so we have multiple frameworks for interpreting the world around us but if youre interpreting for example socio political interactions youre thinking about where theres people theres collections and groups of people they have goals goals largely built around survival and quality of life there are fundamental economics around scarcity of resources and when humans come and start interpreting a situation like that because you brought up like historical events they start interpreting situations like that they apply a lot of this fundamental framework for interpreting that well who are the people what were their goals what resources did they have how much power influence did they have over the other like this fundamental substrate if you will for interpreting and reasoning about that so i think it is possible to imbue a computer with that stuff that humans like take for granted when they go and sit down and try to interpret things and then with that foundation they acquire they start acquiring the details the specifics in a given situation are then able to interpret it with regard to that framework and then given that interpretation they can do what they can predict but not only can they predict they can predict now with an explanation that can be given in those terms in the terms of that underlying framework that most humans share now you could find humans that come and interpret events very differently than other humans because theyre like using a different framework the movie matrix comes to mind where they decided humans were really just batteries and thats how they interpreted the value of humans as a source of electrical energy so but i think that for the most part we have a way of interpreting the events or the social events around us because we have this shared framework it comes from again the fact that were similar beings that have similar goals similar emotions and we can make sense out of these these frameworks make sense to us so how much knowledge is there do you think so you said its possible well theres a tremendous amount of detailed knowledge in the world you could imagine effectively infinite number of unique situations and unique configurations of these things but the knowledge that you need what i refer to as like the frameworks for you need for interpreting them i dont think i think those are finite you think the frameworks are more important than the bulk of the knowledge so its like framing yeah because what the frameworks do is they give you now the ability to interpret and reason and to interpret and reason to interpret and reason over the specifics in ways that other humans would understand what about the specifics you know you acquire the specifics by reading and by talking to other people so im mostly actually just even if we can focus on even the beginning the common sense stuff the stuff that doesnt even require reading or it almost requires playing around with the world or something just being able to sort of manipulate objects drink water and so on all of that every time we try to do that kind of thing in robotics or ai it seems to be like an onion you seem to realize how much knowledge is really required to perform even some of these basic tasks do you have that sense as well and if so how do we get all those details are they written down somewhere do they have to be learned through experience so i think when like if youre talking about sort of the physics the basic physics around us for example acquiring information about acquiring how that works yeah i mean i think theres a combination of things going i think theres a combination of things going on i think there is like fundamental pattern matching like what we were talking about before where you see enough examples enough data about something and you start assuming that and with similar input im gonna predict similar outputs you cant necessarily explain it at all you may learn very quickly that when you let something go it falls to the ground but you cant necessarily explain that but thats such a deep idea that if you let something go like the idea of gravity i mean people are letting things go and counting on them falling well before they understood gravity but that seems to be thats exactly what i mean is before you take a physics class or study anything about newton just the idea that stuff falls to the ground and then youd be able to generalize that all kinds of stuff falls to the ground it just seems like a non without encoding it like hard coding it in it seems like a difficult thing to pick up it seems like you have to have a lot of different knowledge to be able to integrate that into the framework sort of into everything else so both know that stuff falls to the ground and start to reason about sociopolitical discourse so both like the very basic and the high level reasoning decision making i guess my question is how hard is this problem and sorry to linger on it because again and well get to it for sure as what watson with jeopardy did is take on a problem thats much more constrained but has the same hugeness of scale at least from the outsiders perspective so im asking the general life question of to be able to be an intelligent being and reason in the world about both gravity and politics how hard is that problem so i think its solvable okay now beautiful so what about time travel okay im just saying the same answer not as convinced not as convinced yet okay no i think it is solvable i mean i think that its a learn first of all its about getting machines to learn learning is fundamental and i think were already in a place that we understand for example how machines can learn in various ways right now our learning stuff is sort of primitive in that we havent sort of taught machines to learn the frameworks we dont communicate our frameworks because of how shared they are in some cases we do but we dont annotate if you will all the data in the world with the frameworks that are inherent or underlying our understanding instead we just operate with the data so if we wanna be able to reason over the data in similar terms in the common frameworks we need to be able to teach the computer or at least we need to program the computer to acquire to have access to and acquire learn the frameworks as well and connect the frameworks to the data i think this can be done i think we can start i think machine learning for example with enough examples can start to learn these basic dynamics will they relate them necessarily to the gravity not unless they can also acquire those theories as well and put the experiential knowledge and connect it back to the theoretical knowledge i think if we think in terms of these class of architectures that are designed to both learn the specifics find the patterns but also acquire the frameworks and connect the data to the frameworks if we think in terms of robust architectures like this i think there is a path toward getting there in terms of encoding architectures like that do you think systems that are able to do this will look like neural networks or representing if you look back to the 80s and 90s with the expert systems theyre more like graphs systems that are based in logic able to contain a large amount of knowledge where the challenge was the automated acquisition of that knowledge i guess the question is when you collect both the frameworks and the knowledge from the data what do you think that thing will look like yeah so i mean i think asking the question they look like neural networks is a bit of a red herring i mean i think that they will certainly do inductive or pattern match based reasoning and ive already experimented with architectures that combine both that use machine learning and neural networks to learn certain classes of knowledge in other words to find repeated patterns in order for it to make good inductive guesses but then ultimately to try to take those learnings and marry them in other words connect them to frameworks so that it can then reason over that in terms other humans understand so for example at elemental cognition we do both we have architectures that do both both those things but also have a learning method for acquiring the frameworks themselves and saying look ultimately i need to take this data i need to interpret it in the form of these frameworks so they can reason over it so there is a fundamental knowledge representation like what youre saying like these graphs of logic if you will there are also neural networks that acquire a certain class of information then they then align them with these frameworks but theres also a mechanism to acquire the frameworks themselves yeah so it seems like the idea of frameworks requires some kind of collaboration with humans absolutely so do you think of that collaboration as direct well and lets be clear only for the express purpose that youre designing youre designing an intelligence that can ultimately communicate with humans in the terms of frameworks that help them understand things so to be really clear you can independently create a machine learning system an intelligence that i might call an alien intelligence that does a better job than you with some things but cant explain the framework to you that doesnt mean it might be better than you at the thing it might be that you cannot comprehend the framework that it may have created for itself that is inexplicable to you thats a reality but youre more interested in a case where you can i am yeah my sort of approach to ai is because ive set the goal for myself i want machines to be able to ultimately communicate understanding with humans i want them to be able to acquire and communicate acquire knowledge from humans and communicate knowledge to humans they should be using what inductive machine learning techniques are good at which is to observe patterns of data whether it be in language or whether it be in images or videos or whatever to acquire these patterns to induce the generalizations from those patterns but then ultimately to work with humans to connect them to frameworks interpretations if you will that ultimately make sense to humans of course the machine is gonna have the strength that it has the richer longer memory but it has the more rigorous reasoning abilities the deeper reasoning abilities so itll be an interesting complementary relationship between the human and the machine do you think that ultimately needs explainability like a machine so if we look we study for example tesla autopilot a lot where humans i dont know if youve driven the vehicle are aware of what it is so youre basically the human and machine are working together there and the human is responsible for their own life to monitor the system and the system fails every few miles and so theres hundreds theres millions of those failures a day and so thats like a moment of interaction do you see yeah thats exactly right thats a moment of interaction where the machine has learned some stuff it has a failure somehow the failures communicated the human is now filling in the mistake if you will or maybe correcting or doing something that is more successful in that case the computer takes that learning so i believe that the collaboration between human and machine i mean thats sort of a primitive example and sort of a more another example is where the machines literally talking to you and saying look im reading this thing i know that the next word might be this or that but i dont really understand why i have my guess can you help me understand the framework that supports this and then can kind of acquire that take that and reason about it and reuse it the next time its reading to try to understand something not unlike a human student might do i mean i remember when my daughter was in first grade and she had a reading assignment about electricity and somewhere in the text it says and electricity is produced by water flowing over turbines or something like that and then theres a question that says well how is electricity created and so my daughter comes to me and says i mean i could you know created and produced are kind of synonyms in this case so i can go back to the text and i can copy by water flowing over turbines but i have no idea what that means like i dont know how to interpret water flowing over turbines and what electricity even is i mean i can get the answer right by matching the text but i dont have any framework for understanding what this means at all and framework really is i mean its a set of not to be mathematical but axioms of ideas that you bring to the table and interpreting stuff and then you build those up somehow you build them up with the expectation that theres a shared understanding of what they are sure yeah its the social that us humans do you have a sense that humans on earth in general share a set of like how many frameworks are there i mean it depends on how you bound them right so in other words how big or small like their individual scope but theres lots and there are new ones i think the way i think about it is kind of in a layer i think that the architectures are being layered in that theres a small set of primitives they allow you the foundation to build frameworks and then there may be many frameworks but you have the ability to acquire them and then you have the ability to reuse them i mean one of the most compelling ways of thinking about this is a reasoning by analogy where i can say oh wow ive learned something very similar i never heard of this game soccer but if its like basketball in the sense that the goals like the hoop and i have to get the ball in the hoop and i have guards and i have this and i have that like where are the similarities and where are the differences and i have a foundation now for interpreting this new information and then the different groups like the millennials will have a framework and then you know the democrats and republicans millennials nobody wants that framework well i mean i think right i mean youre talking about political and social ways of interpreting the world around them and i think these frameworks are still largely largely similar i think they differ in maybe what some fundamental assumptions and values are now from a reasoning perspective like the ability to process the framework it might not be that different the implications of different fundamental values or fundamental assumptions in those frameworks may reach very different conclusions so from a social perspective the conclusions may be very different from an intelligence perspective i just followed where my assumptions took me yeah the process itself will look similar but thats a fascinating idea that frameworks really help carve how a statement will be interpreted i mean having a democrat and a republican framework and then read the exact same statement and the conclusions that you derive will be totally different from an ai perspective is fascinating what we would want out of the ai is to be able to tell you that this perspective one perspective one set of assumptions is gonna lead you here another set of assumptions is gonna lead you there and in fact to help people reason and say oh i see where our differences lie i have this fundamental belief about that i have this fundamental belief about that yeah thats quite brilliant from my perspective nlp theres this idea that theres one way to really understand a statement but that probably isnt theres probably an infinite number of ways to understand a statement depending on the question theres lots of different interpretations and the broader the content the richer it is and so you and i can have very different experiences with the same text obviously and if were committed to understanding each other we start and thats the other important point if were committed to understanding each other we start decomposing and breaking down our interpretation to its more and more primitive components until we get to that point where we say oh i see why we disagree and we try to understand how fundamental that disagreement really is but that requires a commitment to breaking down that interpretation in terms of that framework in a logical way otherwise and this is why i think of ai as really complimenting and helping human intelligence to overcome some of its biases and its predisposition to be persuaded by more shallow reasoning in the sense that we get over this idea well im right because im republican or im right because im democratic and someone labeled this as democratic point of view or it has the following keywords in it and if the machine can help us break that argument down and say wait a second what do you really think about this right so essentially holding us accountable to doing more critical thinking were gonna have to sit and think about this fast thats i love that i think thats really empowering use of ai for the public discourse is completely disintegrating currently as we learn how to do it on social media thats right so one of the greatest accomplishments in the history of ai is watson competing in the game of jeopardy against humans and you were a lead in that a critical part of that lets start at the very basics what is the game of jeopardy the game for us humans human versus human right so its to take a question and answer it the game of jeopardy its just the opposite actually well no but its not right its really not its really to get a question and answer but its what we call a factoid question so this notion of like it really relates to some fact that two people would argue whether the facts are true or not in fact most people wouldnt jeopardy kind of counts on the idea that these statements have factual answers and the idea is to first of all determine whether or not you know the answer which is sort of an interesting twist so first of all understand the question you have to understand the question what is it asking and thats a good point because the questions are not asked directly right theyre all like the way the questions are asked is nonlinear its like its a little bit witty its a little bit playful sometimes its a little bit tricky yeah theyre asked in exactly numerous witty tricky ways exactly what theyre asking is not obvious it takes inexperienced humans a while to go what is it even asking and its sort of an interesting realization that you have when somebody says oh whats jeopardy is a question answering show and then hes like oh like i know a lot and then you read it and youre still trying to process the question and the champions have answered and moved on there are three questions ahead by the time you figured out what the question even meant so theres definitely an ability there to just parse out what the question even is so that was certainly challenging its interesting historically though if you look back at the jeopardy games much earlier you know early games like 60s 70s that kind of thing the questions were much more direct they werent quite like that they got sort of more and more interesting the way they asked them that sort of got more and more interesting and subtle and nuanced and humorous and witty over time which really required the human to kind of make the right connections in figuring out what the question was even asking so yeah you have to figure out the questions even asking then you have to determine whether or not you think you know the answer and because you have to buzz in really quickly you sort of have to make that determination as quickly as you possibly can otherwise you lose the opportunity to buzz in you mean even before you really know if you know the answer i think a lot of humans will assume theyll process it very superficially in other words whats the topic what are some keywords and just say do i know this area or not before they actually know the answer then theyll buzz in and think about it so its interesting what humans do now some people who know all things like ken jennings or something or the more recent big jeopardy player i mean theyll just buzz in theyll just assume they know all of jeopardy and theyll just buzz in watson interestingly didnt even come close to knowing all of jeopardy right watson really even at the peak even at its best yeah so for example i mean we had this thing called recall which is like how many of all the jeopardy questions how many could we even find the right answer for anywhere like can we come up with we had a big body of knowledge something in the order of several terabytes i mean from a web scale it was actually very small but from like a book scale were talking about millions of books right so the equivalent of millions of books encyclopedias dictionaries books its still a ton of information and i think it was only 85 was the answer anywhere to be found so youre already down at that level just to get started right so and so it was important to get a very quick sense of do you think you know the right answer to this question so we had to compute that confidence as quickly as we possibly could so in effect we had to answer it and at least spend some time essentially answering it and then judging the confidence that our answer was right and then deciding whether or not we were confident enough to buzz in and that would depend on what else was going on in the game because there was a risk so like if youre really in a situation where i have to take a guess i have very little to lose then youll buzz in with less confidence so that was accounted for the financial standings of the different competitors correct how much of the game was left how much time was left where you were in the standing things like that how many hundreds of milliseconds that were talking about here do you have a sense of what is we targeted yeah we targeted so i mean we targeted answering in under three seconds and buzzing in so the decision to buzz in and then the actual answering are those two different stages yeah they were two different things in fact we had multiple stages whereas like we would say lets estimate our confidence which was sort of a shallow answering process and then ultimately decide to buzz in and then we may take another second or something to kind of go in there and do that but by and large we were saying like we cant play the game we cant even compete if we cant on average answer these questions in around three seconds or less so you stepped in so theres these three humans playing a game and you stepped in with the idea that ibm watson would be one of replace one of the humans and compete against two can you tell the story of watson taking on this game sure it seems exceptionally difficult yeah so the story was that it was coming up i think to the 10 year anniversary of big blue not big blue deep blue ibm wanted to do sort of another kind of really fun challenge public challenge that can bring attention to ibm research and the kind of the cool stuff that we were doing i had been working in ai at ibm for some time i had a team doing whats called open domain factoid question answering which is were not gonna tell you what the questions are were not even gonna tell you what theyre about can you go off and get accurate answers to these questions and it was an area of ai research that i was involved in and so it was a very specific passion of mine language understanding had always been a passion of mine one sort of narrow slice on whether or not you could do anything with language was this notion of open domain and meaning i could ask anything about anything factoid meaning it essentially had an answer and being able to do that accurately and quickly so that was a research area that my team had already been in and so completely independently several ibm executives like what are we gonna do whats the next cool thing to do and ken jennings was on his winning streak this was like whatever it was 2004 i think was on his winning streak and someone thought hey that would be really cool if the computer can play jeopardy and so this was like in 2004 they were shopping this thing around and everyone was telling the research execs no way like this is crazy and we had some pretty senior people in the field and theyre saying no this is crazy and it would come across my desk and i was like but thats kind of what im really interested in doing but there was such this prevailing sense of this is nuts were not gonna risk ibms reputation on this were just not doing it and this happened in 2004 it happened in 2005 at the end of 2006 it was coming around again and i was coming off of a', 'the following is a conversation with michio kaku hes a theoretical physicist futurist and professor at the city college of new york hes the author of many fascinating books that explore the nature of our reality and the future of our civilization they include einsteins cosmos physics of the impossible future of the mind parallel worlds and his latest the future of humanity terraforming mars interstellar travel immortality and our destiny beyond earth i think its beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding that to me is where artificial intelligence is today just outside of our understanding a place we have to reach for if were to uncover the mysteries of the human mind and build human level and superhuman level ai systems that transform our world for the better this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with michio kaku youve mentioned that we just might make contact with aliens or at least hear from them within this century can you elaborate on your intuition behind that optimism well this is pure speculation of course of course given the fact that weve already identified 4000 exoplanets orbiting other stars and we have a census of the milky way galaxy for the first time we know that on average every single star on average has a planet going around it and about one fifth or so of them have earth sized planets going around them so just do the math were talking about out of 100 billion stars in the milky way galaxy were talking about billions of potential earth sized planets and to believe that were the only one is i think rather ridiculous given the odds and how many galaxies are there within sight of the hubble space telescope there are about 100 billion galaxies so do the math how many stars are there in the visible universe 100 billion galaxies times 100 billion stars per galaxy were talking about a number beyond human imagination and to believe that were the only ones i think is rather ridiculous so youve talked about different types of type zero one two three four and five even of the kardashev scale of the different kind of civilizations what do you think it takes if it is indeed a ridiculous notion that were alone in the universe what do you think it takes to reach out first to reach out through communication and connect well first of all we have to understand the level of sophistication of an alien life form if we make contact with them i think in this century well probably pick up signals signals from an extraterrestrial civilization well pick up there i love lucy and there leave it to beaver just ordinary day to day transmissions that they emit and the first thing we wanna do is to a decipher their language of course but b figure out at what level they are advanced on the kardashev scale im a physicist we rank things by two parameters energy and information thats how we rank black holes thats how we rank stars thats how we rank civilizations in outer space so a type one civilization is capable of harnessing planetary power they control the weather for example earthquakes volcanoes they can modify the course of geological events sort of like flash gordon or buck rogers type two would be stellar they play with stars entire stars they use the entire energy output of a star sort of like star trek the federation of planets have colonized the nearby stars so a type two would be somewhat similar to star trek type three would be galactic they roam the galactic space lanes and type three would be like star wars a galactic civilization now one day i was giving this talk in london at the planetarium there and the little boy comes up to me and he says professor youre wrong youre wrong theres type four and i told him look kid there are planets stars and galaxies thats it folks and he kept persisting and saying no theres type four the power of the continuum and i thought about it for a moment and i said to myself is there an extra galactic source of energy the continuum of star trek and the answer is yes there could be a type four and thats dark energy we now know that 73 of the energy of the universe is dark energy dark matter represents maybe 23 or so and we only represent 4 were the oddballs and so you begin to realize that yeah there could be type four maybe even type five so type four youre saying being able to harness sort of like dark energy something that permeates the entire universe so be able to plug into the entire universe as a source of energy thats right and dark energy is the energy of the big bang its why the galaxies are being pushed apart its the energy of nothing the more nothing you have the more dark energy thats repulsive and so the acceleration of the universe is accelerating because the more you have the more you can have and that of course is by definition an exponential curve its called a de sitter expansion and thats the current state of the universe and then type five would that be able to seek energy sources somehow outside of our universe and how crazy is that idea yeah type five will be the multiverse multiverse okay im a quantum physicist and we quantum physicists dont believe that the big bang happened once that would violate the heisenberg uncertainty principle and that means that there could be multiple bangs happening all the time even as we speak today universes are being created and that fits the data the inflationary universe is a quantum theory so theres a certain finite probability that universes are being created all the time and for me this is actually rather aesthetically pleasing because i was raised as a presbyterian but my parents were buddhists and theres two diametrically opposed ideas about the universe in buddhism theres only nirvana theres no beginning theres no end theres only timelessness but in christianity there is the instant when god said let there be light in other words an instant of creation so ive had these two mutually exclusive ideas in my head and i now realize that its possible to meld them into a single theory either the universe had a beginning or it didnt right wrong you see our universe had a beginning our universe had an instant where somebody might have said let there be light but there are other bubble universes out there in a bubble bath of universes and that means that these universes are expanding into a dimension beyond our three dimensional comprehension in other words hyperspace in other words 11 dimensional hyperspace so nirvana would be this timeless 11 dimensional hyperspace where big bangs are happening all the time so we can now combine two mutually exclusive theories of creation and stephen hawking for example even in his last book even said that this is an argument against the existence of god he said there is no god because there was not enough time for god to create the universe because the big bang happened in an instant of time therefore there was no time available for him to create the universe but you see the multiverse idea means that there was a time before time and there are multiple times each bubble has its own time and so it means that there could actually be a universe before the beginning of our universe so if you think of a bubble bath when two bubbles collide or when two bubbles fission to create a baby bubble thats called the big bang so the big bang is nothing but the collision of universes or the budding of universes thats such a beautiful picture of our incredibly mysterious existence so is that humbling to you exciting the idea of multiverses i dont even know how to even begin to wrap my mind around it its exciting for me because what i do for a living is string theory thats my day job i get paid by the city of new york to work on string theory and you see string theory is a multiverse theory so people say first of all what is string theory string theory simply says that all the particles we see in nature the electron the proton the quarks what have you are nothing but vibrations on a musical string on a tiny tiny little string you know g robert oppenheimer the creator of the atomic bomb was so frustrated in the 1950s with all these subatomic particles being created in our atom smashers that he announced he announced one day that the nobel prize in physics should go to the physicist who does not discover a new particle that year well today we think theyre nothing but musical notes on these tiny little vibrating strings so what is physics physics is the harmonies you can write on vibrating strings what is chemistry chemistry is the melodies you can play on these strings what is the universe the universe is a symphony of strings and then what is the mind of god that albert einstein so eloquently wrote about for the last 30 years of his life the mind of god would be cosmic music resonating through 11 dimensional hyperspace so beautifully put what do you think is the mind of einsteins god do you think theres a why that we could untangle from this universe of strings why are we here what is the meaning of it all well steven weinberg winner of the nobel prize once said that the more we learn about the universe the more we learn that its pointless well i dont know i dont profess to understand the great secrets of the universe however let me say two things about what the giants of physics have said about this question einstein believed in two types of god one was the god of the bible the personal god the god that answers prayers walks on waters performs miracles smites the philistines thats the personal god that he didnt believe in he believed in the god of spinoza the god of order simplicity harmony beauty the universe could have been ugly the universe could have been messy random but its gorgeous you realize that on a single sheet of paper we can write down all the known laws of the universe its amazing on one sheet of paper einsteins equation is one inch long string theory is a lot longer and so its a standard model but you could put all these equations on one sheet of paper it didnt have to be that way it could have been messy and so einstein thought of himself as a young boy entering this huge library for the first time being overwhelmed by the simplicity elegance and beauty of this library but all he could do was read the first page of the first volume well that library is the universe with all sorts of mysterious magical things that we have yet to find and then galileo was asked about this galileo said that the purpose of science the purpose of science is to determine how the heavens go the purpose of religion is to determine how to go to heaven so in other words science is about natural law and religion is about ethics how to be a good person how to go to heaven as long as we keep these two things apart were in great shape the problem occurs when people from the natural sciences begin to pontificate about ethics and people from religion begin to pontificate about natural law thats where we get into big trouble you think theyre fundamentally distinct morality and ethics and our idea of what is right and what is wrong thats something thats outside the reach of string theory and physics thats right if you talk to a squirrel about what is right and what is wrong theres no reference frame for a squirrel and realize that aliens from outer space if they ever come visit us theyll try to talk to us like we talk to squirrels in the forest but eventually we get bored talking to the squirrels because they dont talk back to us same thing with aliens from outer space they come down to earth theyll be curious about us to a degree but after a while they just get bored because we have nothing to offer them so our sense of right and wrong what does that mean compared to a squirrels sense of right and wrong now we of course do have an ethics that keeps civilizations in line enriches our life and makes civilization possible and i think thats a good thing but its not mandated by a law of physics so if aliens do alien species were to make contact forgive me for staying on aliens for a bit longer do you think theyre more likely to be friendly to befriend us or to destroy us well i think for the most part theyll pretty much ignore us if youre a deer in the forest who do you fear the most do you fear the hunter with his gigantic 16 gauge shotgun or do you fear the guy with a briefcase and glasses well the guy with the briefcase could be a developer about to basically flatten the entire forest destroying your livelihood so instinctively you may be afraid of the hunter but actually the problem with deers in the forest is that they should fear developers because developers look at deer as simply getting in the way i mean in war of the worlds by hg wells the aliens did not hate us if you read the book the aliens did not have evil intentions toward homo sapiens no we were in the way so i think we have to realize that alien civilizations may view us quite differently than in science fiction novels however i personally believe and i cannot prove any of this i personally believe that theyre probably gonna be peaceful because theres nothing that they want from our world i mean what are they gonna take us what are they gonna take us for gold no gold is a useless metal for the most part its silver i mean its gold in color but that only affects homo sapiens squirrels dont care about gold and so gold is a rather useless element rare earths maybe platinum based elements rare earths for the electronics yeah maybe but other than that we have nothing to offer them i mean think about it for a moment people love shakespeare and they love the arts and poetry but outside of the earth they mean nothing absolutely nothing i mean when i write down an equation in string theory i would hope that on the other side of the galaxy theres an alien writing down that very same equation in different notation but that alien on the other side of the galaxy shakespeare poetry hemingway it would mean nothing to him or her or it when you think about entities thats out there extraterrestrial do you think they would naturally look something that even is recognizable to us as life or would they be radically different well how did we become intelligent basically three things made us intelligent one is our eyesight stereo eyesight we have the eyes of a hunter stereo vision so we lock in on targets and who is smarter predator or prey predators are smarter than prey they have their eyes at the front of their face like lions tigers while rabbits have eyes to the side of their face why is that hunters have to zero in on the target they have to know how to ambush they have to know how to hide camouflage sneak up stealth deceit that takes a lot of intelligence rabbits all they have to do is run so thats the first criterion stereo eyesight of some sort second is the thumb the opposable thumb of some sort could be a claw or a tentacle so hand eye coordination hand eye coordination is the way we manipulate the environment and then three language because mama bear never tells baby bear to avoid the human hunter bears just learn by themselves they never hand out information from one generation to the next so these are the three basic ingredients of intelligence eyesight of some sort an opposable thumb or tentacle or claw of some sort and language now ask yourself a simple question how many animals have all three just us its just us i mean the primates they have a language yeah they may get up to maybe 20 words but a baby learns a word a day several words a day a baby learns and a typical adult knows about almost 5000 words while the maximum number of words that you can teach a gorilla in any language including their own language is about 20 or so and so we see the difference in intelligence so when we meet aliens from outer space chances are they will have been descended from predators of some sort and who wants to glow in the dark at night reading the newspaper so i think there are other ways to do it with solar satellites you can have satellites orbiting mars that beam sunlight onto the polar ice caps melting the polar ice caps mars has plenty of water its just frozen i think you paint an inspiring and a wonderful picture of the future i think youve inspired and educated thousands if not millions michio its been an honor thank you so much for talking today my pleasure theyll have some way to manipulate the environment and communicate their knowledge to the next generation thats it folks so functionally that would be similar that would we would be able to recognize them well not necessarily because i think even with homo sapiens we are eventually going to perhaps become part cybernetic and genetically enhanced already robots are getting smarter and smarter right now robots have the intelligence of a cockroach but in the coming years our robots will be as smart as a mouse then maybe as smart as a rabbit if were lucky maybe as smart as a cat or a dog and by the end of the century who knows for sure our robots will be probably as smart as a monkey now at that point of course they could be dangerous you see monkeys are self aware they know they are monkeys they may have a different agenda than us while dogs dogs are confused you see dogs think that we are a dog that were the top dog theyre the underdog thats why they whimper and follow us and lick us all the time were the top dog monkeys have no illusion at all they know we are not monkeys and so i think that in the future well have to put a chip in their brain to shut them off once our robots have murderous thoughts but thats in a hundred years in 200 years the robots will be smart enough to remove that fail safe chip in their brain and then watch out at that point i think rather than compete with our robots we should merge with them we should become part cybernetic so i think when we meet alien life from outer space they may be genetically and cybernetically enhanced genetically and cybernetically enhanced wow so lets talk about that full range in the near term and 200 years from now how promising in the near term in your view is brain machine interfaces so starting to allow computers to talk directly to the brains elon musk is working on that with neuralink and theres other companies working on this idea do you see promise there do you see hope for near term impact well every technology has pluses and minuses already we can record memories i have a book the future of the mind where i detail some of these breakthroughs we can now record simple memories of mice and send these memories on the internet eventually were gonna do this with primates at wake forest university and also in los angeles and then after that well have a memory chip for alzheimers patients well test it out in alzheimers patients because of course when alzheimers patients lose their memory they wander they create all sorts of havoc wandering around oblivious to their surroundings and theyll have a chip theyll push the button and memories memories will come flooding into their hippocampus and the chip telling them where they live and who they are and so a memory chip is definitely in the cards and i think this will eventually affect human civilization what is the future of the internet the future of the internet is brain net brain net is when we send emotions feelings sensations on the internet and we will telepathically communicate with other humans this way this is gonna affect everything look at entertainment remember the silent movies charlie chaplin was very famous during the era of silent movies but when the talkies came in nobody wanted to see charlie chaplin anymore because he never talked in the movies and so a whole generation of actors lost their job and a new series of actors came in next were gonna have the movies replaced by brain net because in the future people will say who wants to see a screen with images thats it sound and image thats called the movies in our entertainment industry this multi billion dollar industry is based on screens with moving images and sound but what happens when emotions feelings sensations memories can be conveyed on the internet its gonna change everything human relations will change because youll be able to empathize and feel the suffering of other people well be able to communicate telepathically and this is coming you described brain net and future of the mind this is an interesting concept do you think so you mentioned entertainment but what kind of effect would it have on our personal relationships hopefully it will deepen it you realize that for most of human history for over 90 of human history we only knew maybe 20 100 people thats it folks that was your tribe that was everybody you knew in the universe was only maybe 50 or 100 with the coming of towns of course it expanded to a few thousand with the coming of the telephone all of a sudden you could reach thousands of people with a telephone and now with the internet you can reach the entire population of the planet earth and so i think this is a normal progression and you think that kind of sort of connection to the rest of the world and then adding sensations like being able to share telepathically emotions and so on that would just further deepen our connection to our fellow humans thats right in fact i disagree with many scientists on this question most scientists would say that technology is neutral a double edged sword one side of the sword can cut against people the other side of the sword can cut against ignorance and disease i disagree i think technology does have a moral direction look at the internet the internet spreads knowledge awareness and that creates empowerment people act on knowledge when they begin to realize that they dont have to live that way they dont have to suffer under a dictatorship that there are other ways of living under freedom then they begin to take things take power and that spreads democracy and democracies do not war with other democracies im a scientist i believe in data so lets take a sheet of paper and write down every single war you had to learn since you were in elementary school every single war hundreds of them kings queens emperors dictators all these wars were between kings queens emperors and dictators never between two major democracies and so i think with the spread of this technology and which would accelerate with the coming of brain net it means that well we will still have wars wars of course is politics by other means but theyll be less intense and less frequent do you have worries of longer term existential risk from technology from ai so i think thats a wonderful vision of a future where war is a distant memory but now theres another agent theres somebody else thats able to create conflict thats able to create harm ai systems so do you have worry about such ai systems well yes that is an existential risk but again i think an existential risk not for this century i think our grandkids are gonna have to confront this question as robots gradually approach the intelligence of a dog a cat and finally that of a monkey however i think we will digitize ourselves as well not only are we gonna merge with our technology well also digitize our personality our memories our feelings you realize during the middle ages there was something called dualism dualism meant that the soul was separate from the body when the body died the soul went to heaven thats dualism then in the 20th century neuroscience came in and said bah humbug every time we look at the brain its just neurons thats it folks period end of story bunch of neurons firing now were going back to dualism now we realize that we can digitize human memories feelings sensations and create a digital copy of ourselves and thats called the connectome project billions of dollars are now being spent to do not just the genome project of sequencing the genes of our body but the connectome project which is to map the entire connections of the human brain and even before then already in silicon valley today at this very moment you can contact silicon valley companies that are willing to digitize your relatives because some people want to talk to their parents there are unresolved issues with their parents and one day yes firms will digitize people and youll be able to talk to them a reasonable facsimile we leave a digital trail our ancestors did not our ancestors were lucky if they had one line just one line in a church book saying the date they were baptized and the date they died thats it that was their entire digital memory i mean their entire digital existence summarized in just a few letters of the alphabet a whole life now we digitize everything every time you sneeze you digitize it you put it on the internet and so i think that we are gonna digitize ourselves and give us digital immortality well not only have biologic genetic immortality of some sort but also digital immortality and what are we gonna do with it i think we should send it into outer space if you digitize the human brain and put it on a laser beam and shoot it to the moon youre on the moon in one second shoot it to mars youre on mars in 20 minutes shoot it to pluto youre on pluto in eight hours think about it for a moment you can have breakfast in new york and for a morning snack vacation on the moon then zap your way to mars by noontime journey through the asteroid belt of the afternoon and then come back for dinner in new york at night all in a days work at the speed of light now this means that you dont need booster rockets you dont need weightlessness problems you dont need to worry about meteorites and whats on the moon on the moon there is a mainframe that downloads your laser beams information and where does it download the information into an avatar now what does that avatar look like anything you want think about it for a moment you could be superman superwoman on the moon on mars traveling throughout the universe at the speed of light downloading your personality into any vehicle you want now let me stick my neck out so far everything ive been saying is well within the laws of physics well within the laws of physics now let me go outside the laws of physics again here we go i think this already exists i think outside the earth there could be a super highway a laser highway of laser porting with billions of souls of aliens zapping their way across the galaxy now let me ask you a question are we smart enough to determine whether such a thing exists or not no this could exist right outside the orbit of the planet earth and were too stupid in our technology to even prove it or disprove it we would need the aliens on this laser super highway to help us out to send us a human interpretable signal i mean it ultimately boils down to the language of communication but thats an exciting possibility that actually the sky is filled with aliens the aliens could already be here and were just so oblivious that were too stupid to know it see they dont have to be in alien form with little green men they can be in any form they want in an avatar of their creation well in fact they could very well be they can even look like us exactly wed never know one of us could be an alien you know in the zoo did you know that we sometimes have zookeepers that imitate animals we create a fake animal and we put it in so that the animal is not afraid of this fake animal and of course these animals brains their brain is about as big as a walnut they accept these dummies as if they were real so an alien civilization in outer space would say oh yeah human brains are so tiny we could put a dummy on their world an avatar and theyd never know it that would be an entertaining thing to watch from the alien perspective so you kind of implied that with a digital form of our being but also biologically do you think one day technology will allow individual human beings to become immortal besides just through the ability to digitize our essence yeah i think that artificial intelligence will give us the key to genetic immortality you see in the coming decades everyones gonna have their gene sequence well have billions of genomes of old people billions of genomes of young people and what are we gonna do with it were gonna run it through an ai machine which has pattern recognition to look for the age genes in other words the fountain of youth that emperors kings and queens lusted over the fountain of youth will be found by artificial intelligence artificial intelligence will identify where these age genes are located first of all what is aging we now know what aging is aging is the buildup of errors thats all aging is the buildup of genetic errors this means that cells eventually become slower sluggish they go into senescence and they die in fact thats why we die we die because of the buildup of mistakes in our genome in our cellular activity but you see in the future well be able to fix those genes with crispr type technologies and perhaps even live forever so let me ask you a question where does aging take place in a car given a car where does aging take place well its obvious the engine right a thats where you have a lot of moving parts b thats where you have combustion well where in the cell do we have combustion the mitochondria we now know where aging takes place and if we cure many of the mistakes that build up in the mitochondria of the cell we could become immortal let me ask you if you yourself could become immortal would you damn straight no i think about it for a while because of course it depends on how you become immortal you know theres a famous myth of tithonus it turns out that years ago in the greek mythology there was the saga of tithonus and aurora aurora was the goddess of the dawn and she fell in love with a mortal a human called tithonus and so aurora begged zeus to grant her the gift of immortality to give to her lover so zeus took pity on aurora and made tithonus immortal but you see aurora made a mistake a huge mistake she asked for immortality but she forgot to ask for eternal youth so poor tithonus got older and older and older every year decrepit a bag of bones but he could never die never die quality of life is important so i think immortality is a great idea as long as you also have immortal youth as well now i personally believe and i cannot prove this but i personally believe that our grandkids may have the option of reaching the age of 30 and then stopping they may like being age 30 because you have wisdom you have all the benefits of age and maturity and you still live forever with a healthy body our descendants may like being 30 for several centuries is there an aspect of human existence that is meaningful only because were mortal well every waking moment we dont think about it this way but every waking moment actually we are aware of our death and our mortality think about it for a moment when you go to college you realize that you are in a period of time where soon you will reach middle age and have a career and after that youll retire and then youll die and so even as a youth even as a child without even thinking about it you are aware of your own death because it sets limits to your lifespan i gotta graduate from high school i gotta graduate from college why because youre gonna die because unless you graduate from high school unless you graduate from college youre not gonna enter old age with enough money to retire and then die and so yeah people think about it unconsciously because it affects every aspect of your being the fact that you go to high school college get married have kids theres a clock a clock ticking even without your permission it gives a sense of urgency do you yourself i mean theres so much excitement and passion in the way you talk about physics and the way you talk about technology in the future do you yourself meditate on your own mortality do you think about this clock thats ticking well i try not to because it then begins to affect your behavior you begin to alter your behavior to match your expectation of when youre gonna die so lets talk about youth and then lets talk about death okay when i interview scientists on radio i often ask them what made the difference how old were you what changed your life and they always say more or less the same thing no these are nobel prize winners directors of major laboratories very distinguished scientists they always say when i was 10 when i was 10 something happened it was a visit to the planetarium it was a telescope for steven weinberg winner of the nobel prize it was the chemistry kit for heinz pagels it was a visit to the planetarium for isidor rabi it was a book about the planets for albert einstein it was a compass something happened which gives them this existential shock because you see before the age of 10 everything is mommy and daddy mommy and dad thats your universe mommy and daddy around the age of 10 you begin to wonder whats beyond mommy and daddy and thats when you have this epiphany when you realize oh my god theres a universe out there a universe of discovery and that sensation stays with you for the rest of your life you still remember that shock that you felt gazing at the universe and then you hit the greatest destroyer of scientists known to science the greatest destroyer of scientists known to science is junior high school when you hit junior high school folks its all over its all over because in junior high school people say hey stupid i mean you like that nerdy stuff and your friends shun you all of a sudden people think youre a weirdo and scientists made boring richard feynman the nobel prize winner when he was a child his father would take him into the forest and the father would teach him everything about birds why theyre shaped the way they are their wings the coloration the shape of their beak everything about birds so one day a bully comes up to the future nobel prize winner and says hey dick whats the name of that bird over there well he didnt know he knew everything about that bird except its name so he said i dont know and then the bully said whats the matter dick you stupid or something and then in that instant he got it he got it he realized that for most people science is giving names to birds thats what science is you know lots of names of obscure things hey people say youre smart youre smart you know all the names of the dinosaurs you know all the names of the plants no thats not science at all science is about principles concepts physical pictures thats what science is all about my favorite quote from einstein is that unless you can explain the theory to a child the theory is probably worthless meaning that all great theories are not big words all great theories are simple concepts principles basic physical pictures relativity is all about clocks meter sticks rocket ships and locomotives newtons laws of gravity are all about balls and spinning wheels and things like that thats what physics and science is all about not memorizing things and that stays with you for the rest of your life so even in old age ive noticed that these scientists when they sit back they still remember they still remember that flush that flush of excitement they felt with that first telescope that first moment when they encountered the universe that keeps them going that keeps them going by the way i should point out that when i was eight something happened to me as well when i was eight years old it was in all the papers that a great scientist had just died and they put a picture of his desk on the front page thats it just a simple picture of the front page of the newspapers of his desk that desk had a book on it which was opened and the caption said more or less this is the unfinished manuscript from the greatest scientists of our time so i said to myself well why couldnt he finish it whats so hard that you cant finish it if youre a great scientist its a homework problem right you go home you solve it or you ask your mom why couldnt he solve it so to me this was a murder mystery this was greater than any adventure story i had to know why the greatest scientists of our time couldnt finish something and then over the years i found out the guy had a name albert einstein and that book was the theory of everything it was unfinished well today i can read that book i can see all the dead ends and false starts that he made and i began to realize that he lost his way because he didnt have a physical picture to guide him on the third try on the first try he talked about clocks and lightning bolts and meter sticks and that gave us special relativity which gave us the atomic bomb the second great picture was gravity with balls rolling on curved surfaces and that gave us the big bang creation of the universe black holes on the third try he missed it he had no picture at all to guide him in fact theres a quote i have where he said im still looking im still looking for that picture he never found it well today we think that picture is strength theory the strength theory can unify gravity and this mysterious thing that einstein didnt like which is quantum mechanics or couldnt quite pin down and make sense of thats right mother nature has two hands a left hand and a right hand the left hand is a theory of the small the right hand is a theory of the big the theory of the small is the quantum theory the theory of atoms and quarks the theory of the big is relativity the theory of black holes big bangs the problem is the left hand does not talk to the right hand they hate each other the left hand is based on discrete particles the right hand is based on smooth surfaces how do you put these two things together into a single theory they hate each other the greatest minds of our time the greatest minds of our time worked on this problem and failed today the only theory that has survived every challenge so far is string theory that doesnt mean string theory is correct it could very well be wrong but right now its the only game in town some people come up to me and say professor i dont believe in string theory give me an alternative and i tell them there is none get used to it its the best theory we got its the only theory we have its the only theory we have do you see you know the strings kind of inspire a view as did atoms and particles and quarks but especially strings inspire a view of a universe as a kind of information processing system as a computer of sorts do you see the universe in this way no some people think in fact the whole universe is a computer of some sort and they believe that perhaps everything therefore is a simulation yes i dont think so i dont think that there is a super video game where we are nothing but puppets dancing on the screen and somebody hit the play button and here we are talking about simulations no even newtonian mechanics says that the weather the simple weather is so complicated with trillions upon trillions of atoms that it cannot be simulated in a finite amount of time in other words the smallest object which can describe the weather and simulate the weather is the weather itself the smallest object that can simulate a human is the human itself and if you had quantum mechanics it becomes almost impossible to simulate it with a conventional computer this quantum mechanics deals with all possible universes parallel universes a multiverse of universes and so the calculation just spirals out of control now so far theres only one way where you might be able to argue that the universe is a simulation and this is still being debated by quantum physicists it turns out that if you throw the encyclopedia into a black hole the information is not lost eventually it winds up on the surface of the black hole now the surface of the black hole is finite in fact you can calculate the maximum amount of information you can store in a black hole its a finite number its a calculable number believe it or not now if the universe were made out of black holes which is the maximum universe you can conceive of each universe each black hole has a finite amount of information therefore ergo da da ergo the total amount of information in a universe is finite this is mind boggling this i consider mind boggling that all possible universes are countable and all possible universes can be summarized in a number a number you can write on a sheet of paper all possible universes and its a finite number now its huge its a number beyond human imagination its a number based on what is called a planck length but its a number and so if a computer could ever simulate that number then the universe would be a simulation so theoretically because the amount of information is finite well there necessarily must be able to exist a computer its just from an engineering perspective maybe impossible to build yes no computer can build a universe capable of simulating the entire universe except the universe itself so thats your intuition that our universe is very efficient and so theres no shortcuts right two reasons why i believe the universe is not a simulation first the calculational numbers are just incredible no finite turing machine can simulate the universe and second why would any super intelligent being simulate humans if you think about it most humans are kind of stupid i mean we do all sorts of crazy stupid things right and we call it art we call it humor we call it human civilization so why should an advanced civilization go through all that effort just to simulate saturday night live well thats a funny idea but its also do you think its possible that the act of creation cannot anticipate humans you simply set the initial conditions and set a bunch of physical laws and just for the fun of it see what happens you launch the thing so youre not necessarily simulating everything youre not simulating every little bit in the sense that you could predict whats going to happen but you set the initial conditions set the laws and see what kind of fun stuff happens well in some sense thats how life got started in the 1950s stanley did what is called the miller experiment he put a bunch of hydrogen gas methane toxic gases with liquid and a spark in a small glass beaker and then he just walked away for a few weeks came back a few weeks later and bingo out of nothing and chaos came amino acids if he had left it there for a few years he might have gotten protein protein molecules for free thats probably how life got started as a accident and if he had left it there for perhaps a few million years dna might have formed in that beaker and so we think that yeah dna life all that could have been an accident if you wait long enough and remember our universe is roughly 138 billion years old thats plenty of time for lots of random things to happen including life itself yeah we could be just a beautiful little random moment and there could be an infinite number of those throughout the history of the universe many creatures like us we perhaps are not the epitome of what the universe is created for thank god lets hope not just look around yeah look to your left look to your right when do you think the first human will step foot on mars i think its a good chance in the 2030s that we will be on mars in fact theres no physics reason why we cant do it its an engineering problem its a very difficult and dangerous engineering problem but it is an engineering problem and in my book future of humanity i even speculate beyond that that by the end of this century well probably have the first starships the first starships will not look like the enterprise at all theyll probably be small computer chips that are fired by laser beams with parachutes and like what stephen hawking advocated the breakthrough starshot program could send ships to the nearby stars traveling at 20 the speed of light reaching alpha centauri in about 20 years time beyond that we should have fusion power fusion power is in some sense one of the ultimate sources of energy but its unstable and we dont have fusion power today now why is that first of all stars form almost for free you get a bunch of gas large enough it becomes a star i mean you dont even have to do anything to it and it becomes a star why is fusion so difficult to put on the earth because in outer space stars are monopoles they are pole single poles that are spherically symmetric and its very easy to get spherically symmetric configurations of gas to compress into a star it just happens naturally all by itself the problem is magnetism is bipolar you have a north pole and a south pole and its like trying to squeeze a long balloon take a long balloon and try to squeeze it you squeeze one side it bulges out the other side well thats the problem with fusion machines we use magnetism with a north pole and a south pole to squeeze gas and all sorts of anomalies and horrible configurations can take place because were not squeezing something uniformly like in a star stars in some sense are for free fusion on the earth is very difficult but i think its inevitable and itll eventually give us unlimited power from seawater so seawater will be the ultimate source of energy for the planet earth why whats the intuition there because well extract hydrogen from seawater burn hydrogen in a fusion reactor to give us unlimited energy without the meltdown without the nuclear waste why do we have meltdowns we have meltdowns because in the fusion reactors every time you split the uranium atom you get nuclear waste tons of it 30 tons of nuclear waste per reactor per year and its hot its hot for thousands millions of years thats why we have meltdowns but you see the waste product of a fusion reactor is helium gas helium gas is actually commercially valuable you can make money selling helium gas and so the waste product of a fusion reactor is helium not nuclear waste that we find in a commercial fission plant and that controlling mastering and controlling fusion allows us to converts us into a type one i guess civilization right yeah probably the backbone of a type one civilization will be fusion power we by the way are type zero we dont even rate on this scale we get our energy from dead plants for gods sake oil and coal but we are about 100 years from being type one get a calculator in fact carl sagan calculated that we are about 07 fairly close to a 10 for example what is the internet the internet is the beginning of the first type one technology to enter into our century the first planetary technology is the internet what is the language of type one on the internet already english and mandarin chinese are the most dominant languages on the internet and what about the culture were seeing a type one sports soccer the olympics a type one music youth culture rock and roll rap music type one fashion gucci chanel a type one economy the european union nafta what have you so were beginning to see the beginnings of a type one culture in a type one civilization and inevitably it will spread beyond this planet so you talked about sending at 20 the speed of light on a chip into alpha centauri but in a slightly nearer term what do you think about the idea when we still have to send our biological bodies the colonization of planets colonization of mars do you see us becoming a two planet species ever or anytime soon well just remember the dinosaurs did not have a space program and thats why theyre not here today how come there are no dinosaurs in this room today because they didnt have a space program we do have a space program which means that we have an insurance policy now i dont think we should bankrupt the earth or deplete the earth to go to mars thats too expensive and not practical but we need a settlement a settlement on mars in case something bad happens to the planet earth and that means we have to terraform mars now to terraform mars if we could raise the temperature of mars by six degrees six degrees then the polar ice caps begin to melt releasing water vapor water vapor is a greenhouse gas it causes even more melting of the ice caps so it becomes a self fulfilling prophecy it feeds on itself it becomes autocatalytic and so once you hit six degrees rising of the temperature on mars by six degrees it takes off and we melt the polar ice caps and liquid water once again flows in the rivers the canals the channels and the oceans of mars mars once had an ocean we think about the size of the united states and so that is a possibility now how do we get there how do we raise the temperature of mars by six degrees elon musk would like to detonate hydrogen warheads on the polar ice caps well im not sure about that because we dont know that much about the effects of detonating hydrogen warheads to melt the polar ice caps', 'the following is a conversation with gary kasparov hes considered by many to be the greatest chess player of all time from 1986 until his retirement in 2005 he dominated the chess world ranking world number one for most of those 19 years while he has many historical matches against human chess players in the long arc of history he may be remembered for his match against the machine ibms deep blue his initial victories and eventual loss to deep blue captivated the imagination of the world of what role artificial intelligence systems may play in our civilizations future that excitement inspired an entire generation of ai researchers including myself to get into the field gary is also a pro democracy political thinker and leader a fearless human rights activist and author of several books including how life imitates chess which is a book on strategy and decision making winter is coming which is a book articulating his opposition to the putin regime and deep thinking which is a book on the role of both artificial intelligence and human intelligence in defining our future this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with gary kasparov as perhaps the greatest chess player of all time when you look introspectively at your psychology throughout your career what was the bigger motivator the love of winning or the hatred of losing tough question have to confess i never heard it before which is again congratulations its quite an accomplishment losing was always painful for me it was almost like a physical pain because i knew that if i lost the game its just because i made a mistake so i always believed that the result of the game had to be decided by the quality of my play okay you may say it sounds arrogant but it helped me to move forward because i always knew that there was room for improvement so its the was there the fear of the mistake actually fear of mistake guarantees mistakes and the difference between top players at the very top is that its the ability to make a decision without predictable consequences you dont know whats happening its just intuitively i can go this way or that way and there are always hesitations people are like you are just at the crossroad you can go right you can go left you can go straight you can turn and go back and the consequences are just very uncertain yes you have certain ideas what happens on the right or on the left or on just if you go straight but its not enough to make well calculated choice and when you play chess at the very top its about your inner strength so i can make this decision i will stand firm and im not going to waste my time because i have full confidence that i will go through going back to your original question is i would say neither its just its love for winning hate for losing there were important elements psychological elements but the key element i would say the driving force was always my passion for making a difference its just i can move forward and i can always i can always enjoy not just playing but creating something new creating something new how do you think about that its just finding new ideas in the openings some original plan in the middle game its actually that helped me to make the transition from the game of chess where i was on the very top to another life where i knew i would not be number one i would not be necessarily on the top but i could still be very active and productive by my ability to make a difference by influencing people say joining the democratic movement in russia or talking to people about human machine relations theres so many things where i knew my influence may not be as decisive as in chess but still strong enough to help people to make their choices so you can still create something new that makes a difference in the world outside of chess but wait youve kind of painted a beautiful picture of your motivations in chess to create something new to look for those moments of some brilliant new ideas but were you haunted by something see you make it seem like to be at the level youre at you can get away without having demons without having fears without being driven by some of the darker forces i mean you sound almost religious the darker forces spiritual demons i mean do you have a call for a priest thats what im dressing as now just lets go back to these crucial chess moments where i had to make big decisions as i said it was all about my belief from very early days that i can make all the difference by playing well or by making mistakes so yes i always had an opponent across the chess board opposite me but no matter how strong the opponent was whether it just was ordinary player or another world champion like anatoly karpov having all respect for my opponent i still believe that its up to me to make the difference and i knew i was not invincible i made mistakes i made some blunders and with age i made more blunders so i knew it but its still its very much for me to be decisive factor in the game i mean even now look i just my latest chess experience was horrible i mean i played caruana fabi caruana this number two number two number three player in the world these days we played this 960 with the fischer so called fischer random chess reshuffling pieces yeah i lost very badly but its because i made mistakes i mean i had so many winning positions i mean 15 years ago i would have crushed him so and its you know while i lost i was not so much upset i mean i know as i said in the interview i can fight any opponent but not my biological clock so its fighting time is always a losing proposition but even today at age 56 you know i knew that you know i could play great game i couldnt finish it because i didnt have enough energy or just you know i couldnt have the same level of concentration but you know in number of games where i completely outplayed one of the top players in the world i mean gave me a certain amount of pleasure that is even today i havent lost my touch not the same you know okay the jaws are not as strong and the teeth are not as sharp but i could get to him just you know almost you know on the ropes still got it still got it and its you know and its i think its my wife said it well i mean she said look gary its somehow its not just fighting your biological clock its just you know maybe its a signal because you know the goddess of chess since you spoke great about demons the goddess of chess keisha maybe she didnt want you to win because you know if you could beat number two number three player in the world i mean thats one of the top players who just recently played world championship match if you could beat him that would be really bad for the game of chess but just what people will say oh look the game of chess you know its not making any progress the game is just you know its totally devalued because look the guy coming out of retirement you know just you know winning games maybe that was good for chess not good for you but its look ive been following your logic we should always look for you know demons you know superior forces and other things that could you know if not dominate our lives but somehow you know play a significant role in the outcome yeah so the goddess of chess had to send a message yeah thats okay so gary you should do something else time now for a question that you have heard before but give me a chance youve dominated the chess world for 20 years even still got it is there a moment you said you always look to create something new is there games or moments where youre especially proud of in terms of your brilliance of a new creative move youve talked about mikhail tal as somebody who was aggressive and creative chess player in your own game look you mentioned mikhail tal its very aggressive very sharp player famous for his combinations and sacrifices even called magician from riga so for his very unique style but any world champion you know its yeah was a creator some of them were so flamboyant and flash like tal some of them were no just you know less discerned at the chess board like tigran petrosian but every world champion every top player brought something into the game of chess and each contribution was priceless because its not just about sacrifices of course amateurs they enjoy you know the brilliant games where pieces being sacrificed its all just you know its all piece of hanging and its all of a sudden you know being material down a rook down or just you know queen down the weaker side delivers the final blow on just you know mating opponents king but there are other kinds of beauty i mean its a slow positional maneuvering you know looking for weaknesses and just and gradually you know strangling your opponent and eventually delivering sort of a positional masterpiece so i think i made more difference in the game of chess than i could have imagined when i started playing and the reason i thought it was time for me to leave was just i mean i knew that i was not i was not no longer the position to bring the same kind of contribution the same kind of new knowledge into the game so and going back i could immediately look at my games against anatoly karpov its not just i won the match in 1985 and became a world champion at age 22 but there were at least two games in that match of course the last one game 24 that was decisive game of the match i won and became world champion but also the way i won it was a very sharp game and i found a unique maneuver that was absolutely new and it became some sort of just a typical now though just when the move was made was made on the board and put on display a lot of people thought it was ugly and another game game 16 in the match where i just also managed to outplay karpov completely with black pieces just paralyzing his entire army in its own camp technically or psychologically or was that a mix of both in game 16 yeah i think it was a big blow to karpov i think it was a big psychological victory for a number of reasons one the score was equal at the time and the world champion by the rules could retain his title in case of a tie so we still have before game 16 we have nine games to go and also it was some sort of a bluff because neither me nor karpov saw the refutation of this opening idea and i think it says for karpov it was double blow because not that he lost the game i should triple blow he lost the game it was a brilliant game and i played impeccably after just this opening bluff and then they discovered that it was a bluff so its the again i didnt know i was not bluffing so thats why it happens very often some ideas could be refuted and its just what i found out and this is again going back to your spiritual theme is that you could spend a lot of time working and when i say you could its in the 80s in the 90s it doesnt happen these days because everybody has a computer you could immediately see if it works or it doesnt work machine shows your refutation in a split of a second but many of the analysis in the 80s or in the 90s they were not perfect simply because were humans and just you analyze the game you look for some fresh ideas and then just it happens that there was something that you missed because the level of the concentration at the chess board is different from when you analyze the game just moving the pieces around and but somehow if you spend a lot of time at the chess board preparing so in your studies with your coaches hours and hours and hours and nothing of what you found could had materialized on the chess board somehow these hours help i dont know why always helped you its as if the amount of work you did could be transformed into some sort of spiritual energy that helped you to come up with other great ideas during the board again even if there was no direct connection between your preparation and your victory in the game there was always some sort of invisible connection between the amount of work you did your dedication to actually and your passion to discover new ideas and your ability during the game at the chess board when the clock was ticking we still had ticking clock not digital clock at the time so to come up with some brilliance and i also can mention many games from the 90s so its the obviously all amateurs would pick up my game against veselin topalov in 1999 and v konzai again because it was a brilliant game the black king traveled from its own camp to into whites camp across the entire board it doesnt happen often trust me as you know in the games with professional players top professional players so thats why visually it was one of the most impressive victories but i could bring to your attention many other games that were not so impressive for amateurs not so beautiful just because its sacrifice is always beautiful you sacrifice pieces and then eventually you have very few resources left and you use them just to crush your opponent basically you have to make the king because you have almost nothing left at your disposal but up to the very end again less and less but still up to the very end i always had games with some sort of interesting ideas and games that gave me great satisfaction but i think its what happened from 2005 up to these days was also a very big accomplishment since i had to find myself to sort of relocate myself yeah rechannel the creative energies exactly and to find something where i feel comfortable even confident that my participation still makes the difference beautifully put so let me ask perhaps a silly question but sticking on chest for just a little longer where do you put magnus carlsen the current world champion in the list of all time greats in terms of style moments of brilliance consistency its a tricky question the moment you start ranking world champions yeah you lose something i think its not fair because any new generation knows much more about the game than the previous one so when people say oh gary was the greatest fischer was the greatest magnus was the greatest it disregard the fact that the great players of the past whether it was alaskia capoplank alokian i mean they knew so little about chess by todays standards i mean today just any kid that spent a few years with his or her chess computer knows much more about the game simply just because you have access to this information and it has been discovered generation after generation we added more and more knowledge to the game of chess its about the gap between the world champion and the rest of the field so its the now if you look at the gap then probably fischer could be on top but very short period of time then you should also add a time factor i was on top not as big as fischer but much longer so and also unlike fischer i succeeded in beating next generation heres the question lets see if you still got the fire speaking of the next generation because you did succeed beating the next generation its close okay anand short anand the sheer of kramnik is already 12 years younger so thats the next but still yet i competed with them and i just i beat most of them and i was still dominant when i left at age of 41 so back to magnus magnus i mean consistency is phenomenal the reason magnus is on top and it seems unbeatable today magnus is a lethal combination of fischer and karpov which is very its very unusual because fischers style was very dynamic just fighting to the last point just using every resource available karpov was very different its just an unparalleled ability to use every piece with a maximum effect just its minimal resources always produce maximum effect so now imagine that you merge these two styles so its like you know its squeezing every stone for a drop of water but doing it you know just you know for 50 60 70 80 moves i mean magnus could go on as long as fischer with all his passion and energy and at the same time being as meticulous and deadly as karpov by just you know using every little advantage so and he has good you know very good health its important i mean physical conditions are by the way very important so a lot of people dont recognize it their latest study shows that chess players burn thousands of calories during the game so that puts him on the top of this field of the world champions but again its the discussion that is i saw recently on the internet whether garry kasparov of his peak lets say late eighties could beat magnus carlsen today i mean its certainly irrelevant because garry kasparov in 1989 okay has played great chess but still i knew very little about chess compared to magnus carlsen in 2019 who by the way learned from me as well so thats why yeah im extremely cautious in making any judgment that involves you know time gaps you ask you know soccer fans so who is your favorite pele maradona or messi yeah yeah whos your favorite messi messi yeah why because maybe maradona maybe not because youre younger but thats simple your instinctive answer is correct because you saw you didnt see maradona in action i saw all of them in action so thats why but since you know when i was you know just following it you know just pele and maradona they were just you know they were big stars and its messis already just i was gradually losing interest in just other things so i remember pele in 1970 the final match brazil italy so thats the first world cup soccer i watched so thats the and actually my answer when i just when i just you know because i was asked this question as well so i say that its just while its impossible to make a choice i would still probably go with maradona for simple reason the brazilian team in 1970 could have won without pele it was absolutely great still could have won maybe but it is argentinian team in 1986 without maradona would not be in the final so this is and messi he still hasnt won a title you could argue for that for an hour but you could say if you ask maradona if you look in his eyes especially lets say gary kasparov in 1989 he would have said i was sure as hell would beat magnus carlsen just simply because the confidence the fire simply because again they saw me in action so this again its the age factor thats important definitely with the passion and energy and being equipped with all modern ideas but again then you make you know a very just important assumption that you could empower gary kasparov in 1989 with all ideas that have been accumulated over 30 years that would not be gary kasparov that would be someone else because again i belong to 1989 i was way ahead of the field and i beat karpov several times in the world championship matches and i crossed 2800 which by the way if you look at the in the rating which is just even today so this is the rating that i retire so its still you know its just its a top two three so thats caruana and ding its about the same rating now and i crossed 2800 in 1990 well just you look at the inflation when i crossed 2800 in 1990 there was only one player in 2700 category and not only karpov now we had more than 50 so just when you see this so if you add inflation so i think my 2851 it could probably could be more valuable as magnus 2882 which was his highest rating but anyway again too many hypotheticals youre lost to ibm deep blue in 1997 in my eyes that is one of the most seminal moments in the history again i apologize for being romanticizing the notion but in the history of our civilization because humans as the civilizations for centuries saw chess as you know the peak of what man can accomplish of intellectual mastery right and that moment when a machine could beat a human being was inspiring to just an entire anyone who cares about science innovation an entire generation of ai researchers and yet to you that loss at least if reading your face was seemed like a tragedy extremely painful like you said physically painful why when you look back at your psychology of that loss why was it so painful were you not able to see the seminal nature of that moment or was that exactly why it was that painful as i already said losing was painful physically painful and the match i lost in 1997 was not the first match i lost to a machine it was the first match i lost period yeah thats oh wow so oh wow yeah its right yeah that makes all the difference to me yes first time i lost its just now i lost and the reason i was so angry that i just you know i had suspicions that my loss was not just a result of my bad play yes so though i played quite poorly you know just when you started looking at the games today i made tons of mistakes but you know i had all reasons to believe that you know there were other factors that had nothing to do with the game of chess and thats why i was angry but look it was 22 years ago its water under the bridge we can analyze this match and this is with everything you said i agree with probably one exception is that considering chess you know as the sort of as a pinnacle of intellectual activities was our mistake because you know we just thought oh its a game of the highest intellect and its just you know you have to be so you know intelligent and you could see things that you know the ordinary mortals could not see its a game and all machines had to do with this game is just to make fewer mistakes not to solve the game because the game cannot be solved i mean according to kovalevich shannon the number of legal moves is 10 to the 46th power too many zeros so just for any computer to finish the job you know in next few billion years but it doesnt have to its all about making fewer mistakes and i think thats the this match this match actually and whats happened afterwards with other games with go with shoggy with video games its a demonstration that machines will always be humans in what i call closed systems the moment you build a closed system no matter how the systems called chess go shoggy dota machines will prevail simply because they will bring down a number of mistakes machines dont have to solve it they just have to the way they outplay us its not by just being more intelligent its just by doing something else but eventually its just its capitalizing on our mistakes when you look at the chess machines ratings today and compare this to magnus carlsen its the same as comparing ferrari to usain bolt its the the gap is i mean by chess standards is insane 34 3500 to 2800 2850 on magnus its like difference between magnus and an ordinary player from an open international tournament its not because machine understanding is better than magnus carlsen but simply because its steady machine has steady hand and i think that is what we we we we have to learn from 1997 experience and from further encounters with computers and sort of the current state of affairs with alphazero beating other machines the idea that we can compete with computers in so called intellectual fields it was wrong from the very beginning its just its by the way the 1997 match was not the first victory of machines over alphazero or grandmasters or grandmasters no actually its i played against first decent chess computers from late from late 80s so i played with the prototype of deep blue called deep thought in 1989 two rapid chess games in new york i won handily to both games we played against new chess engines like fritz and other programs and then its the it was israeli program junior that appeared in 1995 yeah so there were there were several programs i you know i lost few games in blitz i lost one match against the computer chess engine 1994 rapid chess so i lost one game to deep blue in 1996 match the man the match i won some people you know tend to forget about it that i won the first match yes but its its we we made a very important psychological mistake thinking that the reason we lost blitz matches five five minutes games the reason we lost some of the rapid chess matches 25 minutes chess because we didnt have enough time if you play a longer match we will not make the same mistakes nonsense so this yeah we had more time but we still make mistakes and machine also has more time and machines machine will always you know will always be steady and consistent compared to humans instabilities and inconsistencies and today we are at the point where yes nobody talks about you know humans playing as machines now machines can offer handicap to top players and still you know will will will be favored i think were just learning that its its its no longer human versus machines its about human working with machines thats what i recognized in 1998 just after leaking my wounds and spending one year in just you know ruminating so the so whats happened in this match and i knew that though we still could play against the machines i had two more matches in in 2003 playing both deep fritz and deep junior both matches ended as a tie though these machines were not weaker at least actually probably stronger than deep blue and by the way today chess app on your mobile phone is probably stronger than deep blue im not speaking about chess engines that are so much superior and by the way when you analyze games we played against deep blue in 1997 on your chess engine theyll be laughing so this is and its also shows thats how chess changed because chess commentators they look at some of our games like game four game five brilliant idea now you ask stockfish you ask houdini you ask commodore all the leading chess engines within 30 seconds they will show you how many mistakes both gary and deep blue made in the game that was trumpeted as the as a great chess match in 1997 well okay so youve made an interesting if you can untangle that comment so now in retrospect it was a mistake to see chess as the peak of human intellect nevertheless that was done for centuries so by the way in europe because you know you move to the far east they will go they had show games but games games again some of the games like you know board games yes yeah i agree so if i push back a little bit so now you say that okay but it was a mistake to see chess as the epitome and now and then now theres other things maybe like language that conversation like some of the things that in your view is still way out of reach of computers but inside humans do you think can you talk about what those things might be and do you think just like chess they might fall soon with the same set of approaches if you look at alphazero the same kind of learning approaches as the machines grow in size no no its not about growing in size its about again its about understanding the difference between closed system and open ended system so you think that key difference so the board games are closed in terms of the rule set the actions the state space everything is just constrained you think once you open it the machines are lost not lost but again the effectiveness is very different because machine does not understand the moment its reaching territory of diminishing returns its the to put it in a different way machine doesnt know how to ask right questions it can ask questions but it will never tell you which questions are relevant so theres the its like about the its the its a direction so these its i think its in human machine relations we have to consider so our role and people many people feel uncomfortable that this the territory that belongs to us is shrinking im saying so what you know this is eventually well belong to the last few decimal points but its like having so a very powerful gun thats and all you can do there is slightly you know alter direction of the bullet maybe you know 01 degree of this angle but that means a mile away 10 meters of target so thats we have to recognize that is a certain unique human qualities that machines in a foreseeable future will not be able to reproduce and the effectiveness of this cooperation collaboration depends on our understanding what exactly we can bring into the game so the greatest danger is when we try to interfere with machine superior knowledge so thats why i always say that sometimes youd rather have by reading these pictures in radiology you may probably prefer an experienced nurse than rather than having top professor because she will not try to interfere with machines understanding so its very important to know that if machines knows how to do better things in 95 96 of territory we should not touch it because its happened its like in chess recognize they do it better see where we can make the difference you mentioned alphazero i mean alphazero is its actually a first step into what you may call ai because everything thats being called ai today its just its one or another variation of what claude shannon characterized as a brute force its a type a machine whether its deep blue whether its watson and all these modern technologies that are being trumpeted as ai its still brute force its the all they do its they do optimization its this they are you know they keep you know improving the way to process human generated data now alphazero is the first step towards you know machine produced knowledge which is by the way its quite ironic that the first company that championed that was ibm oh its in backgammon interesting in backgammon yes you should look at ibm its a newer gammon its the scientist called cesaro hes still working at ibm they had it in the early 90s its the program that played you know the alphazero type so just trying to come up with own strategies but because of success of deep blue this project had been not abandoned but just you know it was put on hold and now we just you know its you know everybody talks about this the machines generated knowledge so as revolutionary and it is but theres still you know many open ended questions yes alphazero generates its own data many ideas that alphazero generated in chess were quite intriguing so i looked at these games with not just with interest but with you know it was quite exciting to learn how machine could actually you know juggle all the pieces and just play positions with a broken material balance sacrificing material always being ahead of other programs you know one or two moves ahead by foreseeing the consequences not overcalculating because machines other machines were at least as powerful in calculating but its having this unique knowledge based on discovered patterns after playing 60 million games almost something that feels like intuition exactly but theres one problem yeah now the simple question if alphazero faces superior point lets say another powerful computer accompanied by a human who could help just to discover certain problems because i already i look at many alphazero games i visited their lab you know spoke to demis hassabis and his team and i know theres certain weaknesses there now if these weaknesses are exposed the question is how many games will it take for alphazero to correct it the answer is hundreds of thousands even if it keeps losing it can its just because the whole system is based so its now imagine so this is you can have a human by just making a few tweaks so humans are still more flexible and as long as we recognize what is our role where we can play sort of so the most valuable part in this collaboration so its it will help us to understand what are the next steps in human machine collaboration beautifully put so lets talk about the thing that machines certainly dont know how to do yet which is morality machines and morality its another question that you know just its being asked all the time these days and i think its another phantom that is haunting a general public because its just being fed with this you know illusions is that how can we avoid machines you know having bias being prejudiced you cannot because its like looking in the mirror and complaining about what you see if you have certain bias in the society machine will just follow it its just its you know you look at the mirror you dont like what you see there you can you know you can break it you can try to distort it or you can try to actually change something just by yourself by yourself yes so its very important to understand is that you cannot expect machines to improve the ills of our society and moreover machines will simply you know just you know amplify it yes yeah but the thing is people are more comfortable with other people doing injustice with being biased were not comfortable with machines having the same kind of bias so thats an interesting standard that we place on machines with autonomous vehicles they have to be much safer with automated systems of course theyre much safer statistically theyre much safer than its not of course why would its not of course its not given autonomous vehicles you have to work really hard to make them safer i think it just it goes without saying is the outcome of this i would call it competition with comparison is very clear but the problem is not about being you know safer its the 40000 people or so every year died in car accidents in the united states and its statistics one accident with autonomous vehicle and its front page of a newspaper yes so its again its about psychology so its while people you know kill each other in car accidents because they make mistakes they make more mistakes for me its not a question of course we make more mistakes because were human yes machines are old and by the way no machine will ever reach 100 perfection thats another important fake story that is being fed to the public if machine doesnt reach 100 performance its not safe no all you can ask any computer whether its you know playing chess or doing the stock market calculations or driving your autonomous vehicle its to make fewer mistakes and yes i know its not you know its not easy for us to accept because ah if you know if you have two humans you know colliding in their cars okay its like if one of these cars is autonomous vehicle and by the way even if its humans fault terrible how could you allow a machine to run without a driver at the wheel so you know lets linger that for a second that double standard the way you felt with your first loss against deep blue were you treating the machine differently than you would have a human or so what do you think about that difference between the way we see machines and humans no its the at that time you know for me it was a match and thats why i was angry because i believed that the match was not you know fairly organized so its definitely there were unfair advantages for ibm and i wanted to play another match like a rubber match so your anger or displeasure was aimed more like at the humans behind ibm versus the actual pure algorithm absolutely look i knew at the time and by the way i was objectively speaking i was stronger at that time so that probably added to my anger because i knew i could beat the machine yeah yeah so thats and thats the and as i lost and i knew i was not well prepared so because they i have to give them credit they did some good work from 1996 and i but i still could beat the machine so i made too many mistakes also this is the whole its this the publicity around the match so i underestimated the effect you know just its and being called the you know the brains last stand you know okay no pressure okay well let me ask so i was born also in the soviet union what lessons do you draw from the rise and fall of the soviet union in the 20th century when you just look at this nation that is now pushing forward into what russia is if you look at the long arc of history of the 20th century what do we take away what do we take away from that i think the lesson of history is clear undemocratic systems totalitarian regimes systems that are based on controlling their citizens and just every aspect of their life not offering opportunities to for private initiative central planning systems theyre doomed they just you know they cannot be driving force for innovation so they in the history timeline i mean they could cause certain you know distortion of the concept of progress they by the way they may call themselves progressive but we know that the damage that they caused to humanity is just its yet to be measured but at the end of the day they fail they fail and the end of the cold war was a great triumph of the free world its not that the free world is perfect its very important to recognize the fact that i always like to mention you know one of my favorite books the lord of the rings that theres no absolute good but there is an absolute evil good you know comes in many forms but we all you know its being humans or being even you know humans from fairy tales or just some sort of mythical creatures its the you can always find spots on the songs so this is conducting war and just and fighting for justice there are always things that you know can be easily criticized and human history is the is a never ending quest for perfection but we know that there is absolute evil we know its for me its no clear its i mean nobody argues about hitler being absolute evil but i think its very important to recognize stalin was absolute evil communism caused more damage than any other ideology in the 20th century and unfortunately while we all know that fascism was condemned but there was no nuremberg for communism and thats why we could see you know still the successors of stalin are feeling far more comfortable and putin is one of them you highlight a few interesting connections actually between stalin and hitler i mean in terms of the adjusting or clarifying the history of world war ii which is very interesting of course we dont have time so let me ask you can ask you know i just recently delivered a speech in toronto at 80th anniversary of molotov ribbentrop pact its something that i believe you know just you know has must be taught in the schools that the world war ii had been started by two dictators by signing these criminal treaty collusion of two tyrants in august 1939 that led to the beginning of the world war ii and the fact is that eventually stalin had no choice but to join allies because hitler attacked him so it just doesnt you know eliminate the fact that stalin helped hitler to start world war ii and he was one of the beneficiaries at early stage by annexing a part of eastern europe and as a result of the world war ii he annexed almost entire eastern europe and for many eastern european nations the end of the world war ii was the beginning of communist occupation so putin youve talked about as a man who stands between russia and democracy essentially today youve been a strong opponent and critic of putin let me ask again how much does fear enter your mind and heart so in 2007 theres this interesting comment from oleg kalugin kgb general he said that i do not talk details people who knew them are all dead now because they were vocal im quiet theres only one man whos vocal and he may be in trouble world chess champion kasparov he has been very outspoken in his attacks on putin and i believe hes probably next on the list so clearly your life has been and perhaps continues to be in danger how do you think about having the views you have the ideas you have being in opposition as you are in this kind of context when your life could be in danger thats the reason i live in new york so it was not my first choice but i knew i had to leave russia at one point and among other places new york is the safest is it safe no its the i know what happened what is happening with many of putins enemies but at the end of the day i mean what can i do i could be very proactive by trying to change things i can influence but here are a few facts i cannot stop doing what ive been doing for a long time its the right thing to do i grew up with my family teaching me sort of the wisdom of soviet dissidents do what you must and so be i could try to be cautious by not traveling to certain places where my security could be at risk there are so many invitations to speak at different locations in the world and i have to say that many countries are just now are not destinations that i can afford to travel my mother still lives in moscow i meet her a few times a year she was devastated when i had to leave russia because since my father died in 1971 so she was 33 and she dedicated her entire life to her only son but she recognized in just a year or so since i left russia that it was the only chance for me to continue my normal life so just to i mean to be relatively safe and to do what she taught me to do to make the difference do you think you will ever return to russia or let me ask a different way when even sooner than many people think because i think putins regime is facing unsurmountable difficulties and again i read enough historical books to know that dictatorships they end suddenly its just on sunday dictator feels comfortable he believes hes popular on monday morning hes bust the good news and bad news i mean the bad news is that i dont know when and how putin rule ends the good news he also doesnt know okay well put let me ask a question that seems to preoccupy the american mind from the perspective of russia one did russia interfere in the 2016 us election government sanction and future two will russia interfere in the 2020 us election and what does that interference look like its very old we had such an intelligent conversation and you are ruining everything by asking such a stupid question its insulting for my intellect of course they did interfere of course they did absolutely everything to elect trump i mean they said it many times it is just you know i met enough kgb colonels in my life to tell you that you know just the way putin looks at trump this is the way look and i dont have to hear what he says what trump says it just is i dont need to go through congressional investigations the way putin looks at trump is the way the kgb officers looked at the assets its just and following to 2020 of course they will do absolutely everything to help trump to survive because i think the damage that trumps reelections could cause to america and to the free world its just its beyond ones imagination i think basically if trump is reelected he will ruin nato because hes already heading in this direction but now hes just hes still limited by the reelection hurdles if hes still in the office after november 2020 okay january 2021 i dont want to think about it my problem is not just trump because trump is basically its a symptom but the problem is that i dont see its just its the in american political horizon politicians who could take on trump for all damage that hes doing for the free world not just things that has happened that went wrong in america so theres the it seems to me that the campaign political campaign on the democratic side is fixed on certain important but still secondary issues because when you have the foundation of the republic in jeopardy i mean you cannot talk about healthcare i mean i understand how important it is but its still secondary because the entire framework of american political life is at risk and you have vladimir putin just its having fortunately free hands by attacking america and other free countries and by the way we have so much evidence about russian interference in brexit in elections in almost every european country and thinking that they will be shy of attacking america in 2020 now with trump in the office yeah i think its yeah it definitely diminishes the intellectual quality of our conversation i do what i can last question if you can go back just look at the entirety of your life you accomplished more than most humans will ever do if you could go back and relive a single moment in your life what would that moment be there are moments in my life when i think about what could be done differently but no experience happiness and joy and pride just a touch once again i know i know but its the its the i made many mistakes in my life so i just its the i know that at the end of the day its i believe in the butterfly effect so its the its the i knew moments where i could now if im there at that point in 89 and 93 you pick up a year i could improve my actions by not doing this stupid thing but then how do you know that i will have all other accomplishments i just im im afraid that you know we just have to just follow this if you may call wisdom before is gump you know its the life is this you know its this is its a box of of of of chocolate and you dont know whats inside but you have to go one by one so its the im im happy with who i am and where i am today and i am very proud not only with my chess accomplishments but that i made this transition and since i left chess you know i built my own reputation that had some influence on the game of chess but not its not you know directly derived from from from the game im grateful for my wife so help me to build this life we actually married in 2005 it was my third marriage thats why i said id made mistakes in my life but and by the way im close with two kids from my previous marriages so thats thats the im you know i managed to sort of to balance my life and and here in i live in new york so we have our two kids born here in new york its its new life and its you know its its busy sometimes i wish i could you know i could limit my engagement in many other things that are still you know taking time and energy but life is exciting and as long as i can feel that i have energy i have strengths i have passion to make the difference im happy i think thats a beautiful moment to end on gary thank you very much for talking today thank you', 'the following is a conversation with sean carroll part 2 the second time weve spoken on the podcast you can get the link to the first time in the description this time we focus on quantum mechanics and the many worlds interpretation that he details elegantly in his new book titled something deeply hidden i own and enjoy both the ebook and audiobook versions of it listening to sean read about entanglement complementarity and the emergence of space time reminds me of bob ross teaching the world how to paint on his old television show if you dont know who bob ross is youre truly missing out look him up hell make you fall in love with painting sean carroll is the bob ross of theoretical physics hes the author of several popular books a host of a great podcast called mindscape and is a theoretical physicist at caltech and the santa fe institute specializing in quantum mechanics arrow of time cosmology and gravitation this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with sean carroll isaac newton developed what we now call classical mechanics that you describe very nicely in your new book as you do with a lot of basic concepts in physics so with classical mechanics i can throw a rock and can predict the trajectory of that rocks flight but if we could put ourselves back into newtons time his theories work to predict things but as i understand he himself thought that they were their interpretations of those predictions were absurd perhaps he just said it for religious reasons and so on but in particular sort of a world of interaction without contact so action at a distance it didnt make sense to him on a sort of a human interpretation level does it make sense to you that things can affect other things at a distance it does but that was one of newtons worries youre actually right in a slightly different way about the religious worries he was smart enough this is off the topic but still fascinating newton almost invented chaos theory as soon as he invented classical mechanics he realized that in the solar system so he was able to explain how planets move around the sun but typically you would describe the orbit of the earth ignoring the effects of jupiter and saturn and so forth just doing the earth and the sun he kind of knew even though he couldnt do the math that if you included the effects of jupiter and saturn and the other planets the solar system would be unstable like the orbits of the planets would get out of whack so he thought that god would intervene occasionally to sort of move the planets back into orbit which is the only way you could explain how they were there presumably forever but the worries about classical mechanics were a little bit different the worry about gravity in particular it wasnt a worry about classical mechanics it was a worry about gravity how in the world does the earth know that theres something called the sun 93 million miles away that is exerting gravitational force on it and he literally said you know i leave that for future generations to think about because i dont know what the answer is and in fact people under emphasized this but future generations figured it out pierre simone laplace in circa 1800 showed that you could rewrite newtonian gravity as a field theory so instead of just talking about the force due to gravity you can talk about the gravitational field or the gravitational potential field and then theres no action at a distance its exactly the same theory empirically it makes exactly the same predictions but whats happening is instead of the sun just reaching out across the void there is a gravitational field in between the sun and the earth that obeys an equation laplaces equation cleverly enough and that tells us exactly what the field does so even in newtonian gravity you dont need action at a distance now what many people say is that einstein solved this problem because he invented general relativity and in general relativity theres certainly a field in between the earth and the sun but also theres the speed of light as a limit in laplaces theory which was exactly newtons theory just in a different mathematical language there could still be instantaneous action across the universe whereas in general relativity if you shake something here its gravitational impulse radiates out at the speed of light and we call that a gravitational wave and we can detect those so but i really it rubs me the wrong way to think that we should presume the answer should look one way or the other like if it turned out that there was action at a distance in physics and that was the best way to describe things then i would do it that way its actually a very deep question because when we dont know what the right laws of physics are when were guessing at them when were hypothesizing at what they might be we are often guided by our intuitions about what they should be i mean einstein famously was very guided by his intuitions and he did not like the idea of action at a distance we dont know whether he was right or not it depends on your interpretation of quantum mechanics and it depends on even how you talk about quantum mechanics within any one interpretation so if you see every force as a field or any other interpretation of action at a distance just stepping back to sort of caveman thinking like do you really can you really sort of understand what it means for a force to be a field thats everywhere so if you look at gravity like what do you think about i think so is this something that youve been conditioned by society to think that to map the fact that science is extremely well predictive of something to believing that you actually understand it like you can intuitively the degree that human beings can understand anything that you actually understand it or are you just trusting the beauty and the power of the predictive power of science that depends on what you mean by this idea of truly understanding something right you know i mean can i truly understand fermats last theorem you know its easy to state it but do i really appreciate what it means for incredibly large numbers right i think yes i think i do understand it but like if you want to just push people on well but your intuition doesnt go to the places where andrew wiles needed to go to prove fermats last theorem then i can say fine but i still think i understand the theorem and likewise i think that i do have a pretty good intuitive understanding of fields pervading space time whether its the gravitational field or the electromagnetic field or whatever the higgs field of course ones intuition gets worse and worse as you get trickier in the quantum field theory and all sorts of new phenomena that come up in quantum field theory so our intuitions arent perfect but i think its also okay to say that our intuitions get trained right like you know i have different intuitions now than i had when i was a baby thats okay thats not an intuition is not necessarily intrinsic to who we are we can train it a little bit so thats where im going to bring in noam chomsky for a second who thinks that our cognitive abilities are sort of evolved through time and so theyre biologically constrained and so theres a clear limit as he puts it to our cognitive abilities and its a very harsh limit but you actually kind of said something interesting in nature versus nurture thing here is we can train our intuitions to sort of build up the cognitive muscles to be able to understand some of these tricky concepts so do you think theres limits to our understanding thats deeply rooted hardcoded into our biology that we cant overcome there could be limits to things like our ability to visualize okay but when someone like ed witten proves a theorem about you know 100 dimensional mathematical spaces hes not visualizing it hes doing the math that doesnt stop him from understanding the result i think and i would love to understand this better but my rough feeling which is not very educated is that you know theres some threshold that one crosses in abstraction when one becomes kind of like a turing machine right one has the ability to contain in ones brain logical formal symbolic structures and manipulate them and thats a leap that we can make as human beings that dogs and cats havent made and once you get there im not sure that there are any limits to our ability to understand the scientific world at all maybe there are theres certainly limits in our ability to calculate things right you know people are not very good at taking cube roots of million digit numbers in their head but thats not an element of understanding its certainly not a limit in principle so of course as a human you would say there doesnt feel to be limits to our understanding but sort of have you thought that the universe is actually a lot simpler than it appears to us and we just will never be able to like its outside of our okay so us our cognitive abilities combined with our mathematical prowess and whatever kind of experimental simulation devices we can put together is there limits to that is it possible theres limits to that well of course its possible that there are limits to that is there any good reason to think that were anywhere close to the limits is a harder question look imagine asking this question 500 years ago to the worlds greatest thinkers right like are we approaching the limits of our ability to understand the natural world and by definition there are questions about the natural world that are most interesting to us that are the ones we dont quite yet understand right so theres always were always faced with these puzzles we dont yet know and i dont know what they would have said 500 years ago but they didnt even know about classical mechanics much less quantum mechanics so we know that they were nowhere close to how well they could do right they could do enormously better than they were doing at the time i see no reason why the same thing isnt true for us today so of all the worries that keep me awake at night the human minds inability to rationally comprehend the world is low on the list well put so one interesting philosophical point that quantum mechanics bring up is the that you talk about the distinction between the world as it is and the world as we observe it so staying at the human level for a second how big is the gap between what our perception system allows us to see and the world as it is outside our minds eye sort of sort of not at the quantum mechanical level but as just our these particular tools we have which is the few senses and cognitive abilities to process those senses well that last phrase having the cognitive abilities to process them carries a lot right i mean there is our sort of intuitive understanding of the world you dont need to teach people about gravity for them to know that apples fall from trees right thats something that we figure out pretty quickly project permanence things like that the three dimensionality of space even if we dont have the mathematical language to say that we kind of know that its true on the other hand no one opens their eyes and sees atoms right or molecules or cells for that matter forget about quantum mechanics so but we got there we got to understanding that there are atoms and cells using the combination of our senses and our cognitive capacities so adding the ability of our cognitive capacities to our senses is adding an enormous amount and i dont think it is a hard and fast boundary you know if you believe in cells if you believe that we understand those then theres no reason you believe we cant believe in quantum mechanics just as well what to you is the most beautiful idea in physics conservation of momentum can you elaborate yeah so if you were aristotle when aristotle wrote his book on physics he made the following very obvious point were on video here right so people can see this yeah so if i push the bottle let me cover this bottle so we do not have a mess but okay so i push the bottle it moves and if i stop pushing it stops moving and this kind of thing is repeated a large number of times all over the place if you dont keep pushing things they stop moving this is an indisputably true fact about our everyday environment okay and for aristotle this blew up into a whole picture of the world in which things had natures and teleologies and they had places they wanted to be and when you were pushing them you were moving them away from where they wanted to be and they would return and stuff like that and it took a thousand years or 1500 years for people to say actually if it werent for things like dissipation and air resistance and friction and so forth the natural thing is for things to move forever in a straight line theres a constant velocity right conservation of momentum and the reason why i think thats the most beautiful idea in physics is because it shifts us from a view of natures and teleology to a view of patterns in the world so when you were aristotle you needed to talk a vocabulary of why is this happening whats the purpose of it whats the cause etc because you know its nature does or does not want to do that whereas once you believe in conservation of momentum things just happen they just follow the pattern you give me you have laplaces demon ultimately right you give me the state of the world today i can predict what its going to do in the future i can predict where it was in the past its impersonal and its also instantaneous its not directed toward any future goals its just doing what it does given the current state of the universe i think even more than either classical mechanics or quantum mechanics that is the profound deep insight that gets modern science off the ground you dont need natures and purposes and goals you just need some patterns so its the first moment in our understanding of the way the universe works where you branch from the intuitive physical space to kind of the space of ideas and also the other point you said which is conveniently most of the interesting ideas are acting in the moment you dont need to know the history of time or the future and of course this took a long time to get there right i mean the conservation of momentum itself took hundreds of years its weird because like someone would say something interesting and then the next interesting thing would be said like 150 or 200 years later right they werent even talking to each other they were reading each others books and probably the first person to directly say that in outer space in the vacuum a projectile would move at a constant velocity was avicenna ibn sina in the persian golden age circa 1000 and he didnt like the idea he used that just like schrodinger used schrodingers cat to say surely you dont believe that right ibn sina was saying surely you dont believe there really is a vacuum because if there was a really vacuum things could keep moving forever right but still he got right the idea that there was this conservation of something impetus or mile he would call it and thats 500 years 600 years before classical mechanics and isaac newton so galileo played a big role in this but he didnt exactly get it right and so it just takes a long time for this to sink in because it is so against our everyday experience do you think it was a big leap a brave or a difficult leap of sort of math and science to be able to say that momentum is conserved i do you know i think its an example of human reason in action you know even aristotle knew that his theory had issues because you could fire an arrow and it would go a long way before it stopped so if his theory was things just automatically stop whats going on and he had this elaborate story i dont know if youve heard the story but the arrow would push the air in front of it away and the molecules of air would run around to the back of the arrow and push it again and anyone reading this is going like really thats what you thought but it was that kind of thought experiment that ultimately got people to say like actually no if it werent for the air molecules at all the arrow would just go on by itself and its always this give and take between thought and experience back and forth right theory and experiment we would say today another big question that i think comes up certainly with quantum mechanics is whats the difference between math and physics to you to me you know very very roughly math is about the logical structure of all possible worlds and physics is about our actual world and it just feels like our actual world is a gray area when you start talking about interpretations of quantum mechanics or no im certainly using the word world in the broadest sense all of reality so i think that reality is specific i dont think that theres every possible thing going on in reality i think that there are rules whether its the schrodinger equation or whatever so i think that theres a sensible notion of the set of all possible worlds and we live in one of them the world that were talking about might be a multiverse might be many worlds of quantum mechanics might be much bigger than the world of our everyday experience but its still one physically contiguous world in some sense but so if you look at the overlap of math and physics it feels like when physics tries to reach for understanding of our world it uses the tools of math to sort of reach beyond the limit of our current understanding what do you make of that process of sort of using math to so you start maybe with intuition or you might start with the math and then build up an intuition or but this kind of reaching into the darkness into the mystery of the world with math well i think i would put it a little bit differently i think we have theories theories of the physical world which we then extrapolate and ask you know what do we conclude if we take these seriously well beyond where weve actually tested them it is separately true that math is really really useful when we construct physical theories and you know famously eugene wigner asked about the unreasonable success of mathematics and physics i think thats a little bit wrong because anything that could happen any other theory of physics that wasnt the real world but some other world you could always describe it mathematically its just that it might be a mess the surprising thing is not that math works but that the math is so simple and easy that you can write it down on a t shirt right i mean thats what is amazing thats an enormous compression of information that seems to be valid in the real world so thats an interesting fact about our world which maybe we could hope to explain or just take as a brute fact i dont know but once you have that you know theres this indelible relationship between math and physics but philosophically i do want to separate them what we extrapolate we dont extrapolate math because theres a whole bunch of wrong and quantum gravity and holography and space time doing things like that and when you take any of the other versions of quantum theory they bring along classical baggage all of the other versions of quantum mechanics prejudice or privilege some version of classical reality like locations in space okay and i think that thats a barrier to doing better at understanding the theory of everything and understanding quantum gravity and the emergence of space time whenever if you change your theory from you know heres a harmonic oscillator oh theres a spin heres an electromagnetic field in hidden variable theories or dynamical collapse theories you have to start from scratch you have to say like well what are the hidden variables for this theory or how does it collapse or whatever whereas many worlds is plug and play you tell me the theory and i can give you as many worlds version so when we have a situation like we have with gravity and space time where the classical description seems to break down in a dramatic way then i think you should start from the most quantum theory that you have which is really many worlds so start with the quantum theory and try to build up a model of space time the emergence of space time thats it okay so i thought space time was fundamental yeah i know so this sort of dream that einstein had that everybody had and everybody has of you know the theory of everything so how do we build up from many worlds from quantum mechanics a model of space time model of gravity well yeah i mean let me first mention very quickly why we think its necessary you know weve had gravity in the form that einstein bequeathed it to us for over a hundred years now like 1915 or 1916 he put general relativity in the final form so gravity is the curvature of space time and theres a field that pervades all the universe that tells us how curved space time is and thats a fundamentally classical thats totally classical right exactly but we also have a formalism an algorithm for taking a classical theory and quantizing it this is how we get quantum electrodynamics for example and it could be tricky i mean you think youre quantizing something so that means taking a classical theory and promoting it to a quantum mechanical theory but you can run into problems so they ran into problems and they did that with electromagnetism namely that certain quantities were infinity and you dont like infinity right so feynman and tominaga and schwinger won the nobel prize for teaching us how to deal with the infinities and then ken wilson won another nobel prize for saying you shouldnt have been worried about those infinities after all but still that was the its always the thought that thats how you will make a good quantum theory youll start with a classical theory and quantize it so if we have a classical theory general relativity we can quantize it or we can try to but we run into even bigger problems with gravity than we ran into with electromagnetism and so far those problems are insurmountable weve not been able to get a successful theory of gravity quantum gravity by starting with classical general relativity and quantizing it and theres evidence that theres a good reason why this is true that whatever the quantum theory of gravity is its not a field theory its something that has weird nonlocal features built into it somehow that we dont understand we get this idea from black holes and hawking radiation and information conservation and a whole bunch of other ideas i talk about in the book so if thats true if the fundamental theory isnt even local in the sense that an ordinary quantum field theory would be then we just dont know where to start in terms of getting a classical precursor and quantizing it so the only sensible thing or at least the next obvious sensible thing to me would be to say okay lets just start intrinsically quantum and work backwards see if we can find a classical limit so the idea of locality the fact that locality is not fundamental to the nature of our existence i guess in that sense modeling everything as a field makes sense to me stuff thats close by interacts stuff thats far away doesnt so whats locality and why is it not fundamental and how is that even possible yeah i mean locality is the answer to the question that isaac newton was worried about back in the beginning of our conversation right i mean how can the earth know what the gravitational field of the sun is and the answer as spelled out by laplace and einstein and others is that theres a field in between and the way a field works is that whats happening to the field at this point in space only depends directly on whats happening at points right next to it but whats happening at those points depends on whats happening right next to those right and so you can build up an influence across space through only local interactions thats what locality means what happens here is only affected by whats happening right next to it thats locality the idea of locality is built into every field theory including general relativity as a classical theory it seems to break down when we talk about black holes and you know hawking taught us in the 1970s that black holes radiate they give off they eventually evaporate away theyre not completely black once we take quantum mechanics into account and we think we dont know for sure but most of us think that if you make a black hole out of certain stuff then like laplaces demon taught us you should be able to predict what that black hole will turn into if its just obeying the schrodinger equation and if thats true there are good arguments that cant happen while preserving locality at the same time its just that the information seems to be spread out nonlocally in interesting ways and people should you talk about holography with the leonard susskind on your mindscape podcast oh yes i have a podcast i didnt even mention that this is terrible no im going to im going to ask you questions about that too and ive been not shutting up about it its my favorite science podcast so or not its a its not even a science podcast its like its a scientist doing a podcast thats right thats what it is yeah anyway yeah so holography is this idea when you have a black hole and black hole is a region of space inside of which gravity is so strong that you cant escape and theres this weird feature of black holes that again its totally a thought experiment feature because we havent gone and probed any yet but there seems to be one way of thinking about what happens inside a black hole as seen by an observer whos falling in which is actually pretty normal like everything looks pretty normal until you hit the singularity and you die but from the point of view of the outside observer it seems like all the information that fell in is actually smeared over the horizon in a nonlocal way and thats puzzling and thats so holography because thats a two dimensional surface that is encapsulating the whole three dimensional thing inside right still trying to deal with that still trying to figure out how to get there but its an indication that we need to think a little bit more subtly when we quantize gravity and because you can describe everything thats going on in the three dimensional space by looking at the two dimensional projection of it it means that locality doesnt its not necessary well it means that somehow its only a good approximation its not really whats going on how are we supposed to feel about that were supposed to feel liberated you know space is just a good approximation and this was always going to be true once you started quantizing gravity so were just beginning now to face up to the dramatic implications of quantizing gravity is there other weird stuff that happens to quantum mechanics in black hole i dont think that anything weird has happened with quantum mechanics i think weird things happen with space time i mean thats what it is like quantum mechanics is still just quantum mechanics but our ordinary notions of space time dont really quite work and theres a principle that goes hand in hand with holography called complementarity which says that theres no one unique way to describe whats going on inside a black hole different observers will have different descriptions both of which are accurate but sound completely incompatible with each other so depends on how you look at it the word complementarity in this context is borrowed from niels bohr who points out you can measure the position or you can measure the momentum you cant measure both at the same time in quantum mechanics so a couple of questions on many worlds how does many worlds help us understand our particular branch of reality so okay thats fine and good that is everything is splitting but were just traveling down a single branch of it so how does it help us understand our little unique branch yeah i mean thats a great question but thats the point is that we didnt invent many worlds because we thought it was cool to have a whole bunch of worlds right we invented it because we were trying to account for what we observe here in our world and what we observe here in our world are wave functions collapsing okay we do have a position a situation where the electron seems to be spread out but then when we look at it we dont see it spread out we see it located somewhere so whats going on thats the measurement problem of quantum mechanics thats what we have to face up to so many worlds is just a proposed solution to that problem and the answer is nothing special is happening its still just the schrodinger equation but you have a wave function too and thats a different answer than would be given in hidden variables or dynamical collapse theories or whatever so the entire point of many worlds is to explain what we observe but it tries to explain what we already have observed right its not trying to be different from what weve observed because that would be something other than quantum mechanics but you know the idea that theres worlds that we didnt observe that keep branching off is kind of its stimulating to the imagination so is it possible to hop from you mentioned the branches are independent is it possible to hop from one to the other no so its a physical limit the theory says its impossible theres already a copy of you in the other world dont worry yes leave them alone no but theres a fear of missing out fomo that i feel like immediately start to wonder if that other copy is having more or less fun well the downside to many worlds is that youre missing out on an enormous amount and thats always what its going to be like and i mean theres a certain stage of acceptance in that in terms of rewinding do you think we can rewind the system back sort of the nice thing about many worlds i guess is it really emphasizes the maybe you can correct me but the deterministic nature of a branch and it feels like it could be rewound back is it do you see it as something that could be perfectly rewound back rewinding back yeah if youre at a fancy french restaurant and theres a nice linen white tablecloth and you have your glass of bordeaux and you knock it over and the wine spills across the tablecloth if the world were classical okay it would be possible that if you just lifted the wine glass up youd be lucky enough that every molecule of wine would hop back into the glass right but guess what its not going to happen in the real world and the quantum wave function is exactly the same way it is possible in principle to rewind everything if you start from perfect knowledge of the entire wave function of the universe in practice its never going to happen so time travel not possible nope at least quantum mechanics has no help what about memory does the universe have a memory of itself where we could in in so not time travel but peek back in time and do a little like replay well its exactly the same in quantum mechanics as classical mechanics so whatever you want to say about that you know the fundamental laws of physics in either many worlds quantum mechanics or newtonian physics conserve information so if you have all the information about the quantum state of the world right now your laplace is demon like in your knowledge and calculational capacity you can wind the clock backward but none of us is right and you know so in practice you can never do that you can do experiments over and over again starting from the same initial conditions for small systems but once things get to be large avogadros number of particles right bigger than a cell no chance we weve talked a little bit about arrow of time last time but in many worlds that there is a kind of implied arrow of time right so youve talked about the arrow of time that has to do with the second law of thermodynamics thats the arrow of time thats emergent or fundamental we dont know i guess no its emergent is that does everyone agree on that well nobody agrees with everything they should they should so that arrow of time is that different than the arrow of time thats implied by many worlds its not different actually no in both cases you have fundamental laws of physics that are completely reversible if you give me the state of the universe at one moment in time i can run the clock forward or backward equally well theres no arrow of time built into the laws of physics at the most fundamental level but what we do have are special initial conditions 14 billion years ago near the big bang in thermodynamics those special initial conditions take the form of things were low entropy and entropy has been increasing ever since making the universe more disorganized and chaotic and thats the arrow of time in quantum mechanics the special initial conditions take the form of there was only one branch of the wave function and the universe has been branching more and more ever since okay so if time is emergent so it seems like our human cognitive capacity likes to take things that are emergent and assume and feel like theyre fundamental so what so if time is emergent and locality like is space emergent yes okay but i didnt say time was emergent i said the arrow of time was emergent those are different whats the difference between the arrow of time and time are you using arrow of time to simply mean this theyre synonymous with the second law of thermodynamics no but the arrow of time is the difference between the past and future so theres space but theres no arrow of space you dont feel that space has to have an arrow right you could live in thermodynamic equilibrium thered be no arrow of time but thered still be time thered still be a difference between now and the future or whatever so if nothing changes theres still time well things could even change like if the whole universe consisted of the earth going around the sun it would just go in circles or ellipses right things would change but its not increasing entropy theres no arrow if you took a movie of that and i played you the movie backward you would never know so the arrow of time can theoretically point in the other direction for briefly to the extent that it points in different directions its not a very good arrow i mean the arrow of time in the macroscopic world is so powerful that theres just no chance of going back when you get down to tiny systems with only three or four moving parts then entropy can fluctuate up and down what does it mean for space to be an emergent phenomenon it means that the fundamental description of the world does not include the word space itll be something like a vector in hilbert space right and you have to say well why is there a good approximate description which involves three dimensional space and stuff inside it okay so time and space are emergent we kind of mentioned in the beginning can you elaborate what do you feel hope is fundamental in our universe a wave function living in hilbert space a wave function in hilbert space that we cant intellectualize or visualize really we cant visualize it we can intellectualize it very easily like how do you think about its a vector in a 10 to the 10 to the 122 dimensional vector space its a complex vector unit norm it evolves according to the schrodinger equation got it when you put it that way whats so hard really its like yep quantum computers theres some excitement actually a lot of excitement with people that it will allow us to simulate quantum mechanical systems what kind of questions do you about quantum mechanics about the things weve been talking about do you think do you hope we can answer through quantum simulation well i think that there are theres a whole fascinating frontier of things you can do with quantum computers both sort of practical things with cryptography or money privacy eavesdropping sorting things simulating quantum systems right so its a broader question maybe even outside of quantum computers some of the theories that weve been talking about whats your hope whats most promising to test these theories what are kind of experiments we can conduct whether in simulation or in the physical world that would validate or disprove or expand these theories well i think for theres two parts of that question one is many worlds and the other one is sort of emergent space time for many worlds you know there are experiments ongoing to test whether or not wave functions spontaneously collapse and if they do then that rules out many worlds and that would be falsified if there are hidden variables theres a theorem that seems to indicate that the predictions will always be the same as many worlds im a little skeptical of this theorem im not complete i havent internalized it i havent made it in part of my intuitive view of the world yet so there might be loopholes to that theorem im not sure about that part of me thinks that there should be different experimental predictions if there are hidden variables but im not sure but otherwise its just quantum mechanics all the way down and so theres this cottage industry in science journalism of writing breathless articles that say you know quantum mechanics shown to be more astonishing than ever before thought and really its the same quantum mechanics weve been doing since 1926 whereas with the emergent space time stuff we know a lot less about what the theory is its in a very primitive state we dont even really have a safely written down respectable honest theory yet so there could very well be experimental predictions we just dont know about yet that is one of the things that were trying to figure out yeah for emergent space time you need really big stuff right well or really fast stuff or really energetic stuff we dont know thats the thing you know so there could be violations of the speed of light if you have emergent space time not going faster than the speed of light but the speed of light could be different for light of different wavelengths right that would be a dramatic violation of physics as we know it but it could be possible or not i mean its not an absolute prediction thats the problem the theories are just not well developed enough yet to say is there anything that quantum mechanics can teach us about human nature or the human mind if you think about sort of consciousness and these kinds of topics is there its certainly excessively used as you point out the word quantum is used for everything besides quantum mechanics but in more seriousness is there something that goes to the human level and can help us understand our mind not really is the short answer you know minds are pretty classical i dont think we dont know this for sure but i dont think that phenomena like entanglement are crucial to how the human mind works what about consciousness so you mentioned i think early on in the conversation you said it would be unlikely but incredible if sort of the observer is somehow a fundamental part so observer not to romanticize the notion but seems interlinked to the idea of consciousness so if consciousness as the panpsychists believe is fundamental to the universe is that possible is that weight i mean every everythings possible just like joe rogan likes to say its entirely possible but okay but is it on a spectrum of crazy out there how the statistically speaking how often do you ponder the possibility that consciousness is fundamental or the observer is fundamental to personally dont at all there are people who do im a thorough physicalist when it comes to consciousness i do not think that there are any separate mental states or mental properties i think theyre all emergent just like space time is and space time is hard enough to understand so the fact that we dont yet understand consciousness is not at all surprising to me you as we mentioned have an amazing podcast called mindscape its as i said one of my favorite podcasts sort of both for your explanation of physics which a lot of people love and when you venture out into things that are beyond your expertise but its just a really smart person exploring even questions like morality for example its very interesting i think you did a solo episode and so on i mean theres a lot of really interesting conversations that you have what are some from memory amazing conversations that pop to mind that youve had what did you learn from them something that maybe changed your mind or just inspired you or just what did this whole experience of having conversations what stands out to you its an unfair question totally unfair thats okay thats all right you know its often the ones i feel like the ones i do on physics and closely related science or even philosophy ones are like i know this stuff and im helping people learn about it but i learn more from the ones that have nothing to do with physics or philosophy right so talking to wynton marsalis about jazz or talking to a master sommelier about wine talking to will wilkinson about partisan polarization and the urban rural divide talking to psychologists like carol tavris about cognitive dissonance and how those things work scott derrickson who is the director of the movie dr strange i had a wonderful conversation with him where we went through the mechanics of making a blockbuster superhero movie right and hes also not a naturalist hes an evangelical christian so we talked about the nature of reality there i want to have a couple more you know discussions with highly educated theists who know the theology really well but i havent quite arranged those yet i would love to hear that i mean thats how comfortable are you venturing into questions of religion oh im totally comfortable doing it you know i did talk with alan lightman who is also an atheist but he you know he is trying to rescue the sort of spiritual side of things for atheism and i did talk to very vocal atheists like alex rosenberg so i need to talk to some ive talked to some religious believers but i need to talk to more how have you changed through having all these conversations you know part of the motivation was i had a long stack of books that i hadnt read and i couldnt find time to read them and i figured if i interviewed their authors forced me to read them right and that has totally worked by the way now im annoyed that people write such long books i think im still very much learning how to be a good interviewer i think thats a skill that you know i think i have good questions but you know theres the give and take that is still i think i can be better at like i want to offer something to the conversation but not too much right ive had conversations where i barely talked at all and i have conversations where i talked half the time and i think theres a happy medium in between there so i think i remember listening to without mentioning names some of your conversations where i wish you would have disagreed more as a listener its more fun sometimes well thats a very good question because you know everyone has an attitude toward that like some people are really there to basically give their point of view and their guest is supposed to you know respond accordingly i want to sort of get my view on the record but i dont want to dwell on it when im talking to someone like david chalmers who i disagree with a lot you know i want to say like heres why i disagree with you but you know were here to listen to you like i have an episode every week and youre only on once a week right so i have an upcoming podcast episode with philip goff who is a much more dedicated pan psychist and so there we really get into it i think that i probably have disagreed with him more on that episode than i ever have with another podcast guest but thats what he wanted so it worked very well yeah yeah that kind of debate structure is beautiful when its done right like when youre when you can detect that the intent is that you have fundamental respect for the person yeah that and thats for some reason its super fun to listen to when two really smart people are just arguing and sometimes lose their shit a little bit if i may say so well theres a fine line because i have zero interest in bringing i mean like i mean maybe you implied this i have zero interest in bringing on people for whom i dont have any intellectual respect like i constantly get requests like you know bring on a flat earther or whatever and really slap them down or a creationist like i have zero interest im happy to bring on you know a religious person a believer but i want someone whos smart and can act in good faith and can talk not a charlatan or a lunatic right so i will only i will happily bring on people with whom i disagree but only people from whom i think the audience can learn something interesting so let me ask the idea of charlatan is an interesting idea you might be more educated on this topic than me but theres theres folks for example who argue various aspects of evolution sort of try to approach and say that evolution sort of our current theory of evolution has many holes in it has many flaws and they argue that i think like cambridge cambrian explosion which is like a huge added variability of species doesnt make sense under our current description of evolution and theory of evolution sort of if you had to were to have the conversation with people like that how do you know that theyre the difference in outside the box thinkers and people who are fundamentally unscientific and even bordering on charlatans thats a great question and you know the further you get away from my expertise the harder it is for me to really judge exactly those things and you know yeah i dont have a satisfying answer for that one because i think the example you use of someone who you know believes in the basic structure of natural selection but thinks that you know this particular thing cannot be understood in the terms of our current understanding of darwinism thats a perfect edge case where its hard to tell right and i would have i would try to talk to people who i do respect and who do know things and i would have to you know given that im a physicist i know that physicists will sometimes be too dismissive of alternative points of view i have to take into account that biologists can also be too dismissive of alternative points of view so yeah thats a tricky one have you gotten heat yet i get heat all the time like theres always something i mean its hilarious because i do have i try very hard not to like have the same topic several times in a row i did have like two climate change episodes but they were from very different perspectives but i like to mix it up thats the whole thats why im having fun and every time i do an episode someone says oh the person you should really get on to talk about exactly that is this other person im like well i dont but i did that now i dont want to do that anymore well i hope you keep doing it youre inspiring millions of people your books your podcasts sean its an honor to talk to you thank you so much thank you very much lex math you know that doesnt apply to our world right we extrapolate the physical theory that we best think explains our world again an unanswerable question why do you think our world is so easily compressible into beautiful equations yeah i mean like i just hinted at i dont know if theres an answer to that question there could be what would an answer look like well an answer could look like if you showed that there was something about our world that maximizes something you know the mean of the simplicity and the powerfulness of the laws of physics or you know maybe were just generic maybe in the set of all possible worlds this is what the world would look like right like i dont really know i tend to think not i tend to think that there is something specific and rock bottom about the facts of our world that dont have further explanation like the fact of the world exists at all and furthermore the specific laws of physics that we have i think that in some sense were just going to at some level were going to say and thats how it is and you know we cant explain anything more i dont know how if were anywhere close to that right now but that seems plausible to me and speaking of rock bottom one of the things sort of your book kind of reminded me or revealed to me is that whats fundamental and whats emergent it just feels like i dont even know anymore whats fundamental in physics if theres anything it feels like everything especially with quantum mechanics is revealing to us is that most interesting things that i would as a limited human would think are fundamental can actually be explained as emergent from the more deeper laws i mean we dont know of course you had to get that on the table we dont know what is fundamental we do have reasons to say that certain things are more fundamental than others right atoms and molecules are more fundamental than cells and organs quantum fields are more fundamental than atoms and molecules we dont know if that ever bottoms out i do think that theres sensible ways to think about this if you describe something like this table as a table it has a height and a width and its made of a certain material and it has a certain solidity and weight and so forth thats a very useful description as far as it goes theres a whole other description of this table in terms of a whole collection of atoms strung together in certain ways the language of the atoms is more comprehensive than the language of the table you could break apart the table smash it to pieces still talk about it as atoms but you could no longer talk about it as a table right so i think that this comprehensiveness the domain of validity of a theory gets broader and broader as the theory gets more and more fundamental so what do you think newton would say maybe right in the book review if you read your latest book on quantum mechanics something deeply hidden it would take a long time for him to think that any of this was making any sense you catch him up pretty quick in the beginning yeah you give him a shout out in the beginning thats right he is the man im happy to say that newton was the greatest scientist who ever lived he invented calculus in his spare time which would have made him the greatest mathematician just all by himself all by that one thing but of course its funny because newton was in some sense still a pre modern thinker rocky kolb who is a cosmologist at the university of chicago said that galileo even though he came before newton was a more modern thinker than newton was if you got galileo and brought him to the present day it would take him six months to catch up and then hed be in your office telling you why your most recent paper was wrong whereas newton just thought in this kind of more mystical way he wrote a lot more about the bible and alchemy than he ever did about physics but he was also more brilliant than anybody else and way more mathematically astute than galileo so i really dont know he might have he might just yeah say like give me the textbooks leave me alone for a few months and then be caught up but he might have had mental blocks against seeing the world in this way i really dont know or perhaps find an interesting mystical interpretation of quantum mechanics very possible yeah is there any other scientists or philosophers through history that you would like to know their opinion of your book thats a thats a good question i mean einstein is the obvious one right we all i mean he was not that long ago but i even speculated at the end of my book about what his opinion would be i am curious as to you know what about older philosophers like hume or kant right like what would they have thought or aristotle you know what would they have thought about modern physics because they do in philosophy your predilections end up playing a much bigger role in your ultimate conclusions because youre not as tied down by what the data is in physics you know physics is lucky because we cant stray too far off the reservation as long as were trying to explain the world that we actually see in our telescopes and microscopes but its just not fair to play that game because the people were thinking about didnt know a whole bunch of things that we know right like we lived through a lot that they didnt live through so by the time we got them caught up theyd be different people so let me ask a bunch of basic questions i think it would be interesting useful for people who are not familiar but even for people who are extremely well familiar lets start with what is quantum mechanics quantum mechanics is the paradigm of physics that came into being in the early part of the 20th century that replaced classical mechanics and it replaced classical mechanics in a weird way that were still coming to terms with so in classical mechanics you have an object it has a location it has a velocity and if you know the location and velocity of everything in the world you can say what everythings going to do quantum mechanics has an aspect of it that is kind of on the same lines theres something called the quantum state or the wave function and theres an equation governing what the quantum state does so its very much like classical mechanics the wave function is different its sort of a wave its a vector in a huge dimensional vector space rather than a position and a velocity but okay thats a detail the equation is the schrodinger equation not newtons laws but okay again a detail where quantum mechanics really becomes weird and different is that theres a whole other set of rules in our textbook formulation of quantum mechanics in addition to saying that theres a quantum state and it evolves in time and all these new rules have to do with what happens when you look at the system when you observe it when you measure it in classical mechanics there were no rules about observing you just look at it and you see whats going on that was it right in quantum mechanics the way we teach it theres something profoundly fundamental about the act of measurement or observation and the system dramatically changes its state even though it has a wave function like the electron in an atom is not orbiting in a circle its sort of spread out in a cloud when you look at it you dont see that cloud when you look at it it looks like a particle with a location so it dramatically changes its state right away and the effects of that change can be instantly seen in what the electron does next so again we need to be careful because we dont agree on what quantum mechanics says thats why i need to say like in the textbook view et cetera right but in the textbook view quantum mechanics unlike any other theory of physics gives a fundamental role to the act of measurement so maybe even more basic what is an atom and what is an electron sure this all came together in a few years around the turn of the last century right around the year 1900 atoms predated then of course the word atom goes back to the ancient greeks but it was the chemists in the 1800s that really first got experimental evidence for atoms they realized that there were two different types of tin oxide and in these two different types of tin oxide there was exactly twice as much oxygen in one type as the other and like why is that why is it never 15 times as much right and so dalton said well its because there are tin atoms and oxygen atoms and one form of tin oxide is one atom of tin and one atom of oxygen and the other is one atom of tin and two atoms of oxygen and on the basis of this you know a speculation a theory right a hypothesis but then on the basis of that you make other predictions and the chemists became quickly convinced that atoms were real the physicists took a lot longer to catch on but eventually they did and i mean boltzmann who believed in atoms had a really tough time his whole life because he worked in germany where atoms were not popular they were popular in england but not in germany and there in general the idea of atoms is its the most the smallest building block of the universe for them thats the kind of how they thought it was that was the greek idea but the chemists in the 1800s jumped the gun a little bit so these days an atom is the smallest building block of a chemical element right hydrogen tin oxygen carbon whatever but we know that atoms can be broken up further than that thats what physicists discovered in the early 1900s rutherford especially and his colleagues so the atom that we think about now the cartoon is that picture youve always seen of a little nucleus and then electrons orbiting it like a little solar system and we now know the nucleus is made of protons and neutrons so the weight of the atom the mass is almost all in its nucleus protons and neutrons are something like 1800 times as heavy as electrons are protons are much lighter but because theyre lighter they give all the life to the atoms so when atoms get together combine chemically when electricity flows through a system its all the electrons that are doing all the work and where quantum mechanics steps in as you mentioned with the position of velocity with classical mechanics and quantum mechanics is modeling the behavior of the electron i mean you can model the behavior of anything but the electron because thats where the fun is the electron was the biggest challenge right from the start yeah so whats a wave function you said its an interesting detail but in any interpretation what is the wave function in quantum mechanics well you know we had this idea from rutherford that atoms look like little solar systems but people very quickly realize that cant possibly be right because if an electron is orbiting in a circle it will give off light all the light that we have in this room comes from electrons zooming up and down and wiggling thats what electromagnetic waves are and you can calculate how long would it take for the electron just to spiral into the nucleus and the answer is 10 to the minus 11 seconds okay 100 billionth of a second so thats not right meanwhile people had realized that light which we understood from the 1800s was a wave had properties that were similar to that of particles right this is einstein and planck and stuff like that so if something that we agree was a wave had particle like properties then maybe something we think is a particle the electron has wave like properties right and so a bunch of people eventually came to the conclusion dont think about the electron as a little point particle orbiting like a solar system think of it as a wave that is spread out they cleverly gave this the name the wave function which is the dopiest name in the world for one of the most profound things in the universe theres literally a number at every point in space which is the value of the electrons wave function at that point and theres only one wave function yeah they eventually figured that out that took longer but when you have two electrons you do not have a wave function for electron one and a wave function for electron two you have one combined wave function for both of them and indeed as you say theres only one wave function for the entire universe at once and thats where this beautiful dance can you say what is entanglement it seems one of the most fundamental ideas of quantum mechanics well lets temporarily buy into the textbook interpretation of quantum mechanics and what that says is that this wave function so its very small outside the atom very big in the atom basically the wave function you take it and you square it you square the number that gives you the probability of observing the system at that location so if you say that for two electrons theres only one wave function and that wave function gives you the probability of observing both electrons at once doing something okay so maybe the electron can be here or here here here and the other electron can also be there but we have a wave function set up where we dont know where either electron is going to be seen but we know theyll both be seen in the same place okay so we dont know exactly what were going to see for either electron but theres entanglement between the two of them theres a sort of conditional statement if we see one in one location then we know the other ones going to be doing a certain thing so thats a feature of quantum mechanics that is nowhere to be found in classical mechanics in classical mechanics theres no way i can say well i dont know where either one of these particles is but if i know if i find out where this one is then i know where the other one is that just never happens theyre truly separate i dont know it feels like if you think of a wave function like as a dance floor it seems like entanglement is strongest between things that are dancing together closest so theres a closeness thats important well thats another step we have to be careful here because in principle if youre talking about the entanglement of two electrons for example they can be totally entangled or totally unentangled no matter where they are in the universe theres no relationship between the amount of entanglement and the distance between two electrons but we now know that the reality of our best way of understanding the world is through quantum fields not through particles so even the electron not just gravity and electromagnetism but even the electron and the quarks and so forth are really vibrations in quantum fields so even empty space is full of vibrating quantum fields and those quantum fields in empty space are entangled with each other in exactly the way you just said if theyre nearby if you have like two vibrating quantum fields that are nearby then theyll be highly entangled if theyre far away they will not be entangled so what do quantum fields in a vacuum look like empty space just like empty space its as empty as it can be but theres still a field its just what does nothing look like just like right here this location in space theres a gravitational field which i can detect by dropping something yes i dont see it but there it is so we got a little bit of an idea of entanglement now what is hilbert space and euclidean space yeah you know i think that people are very welcome to go through their lives not knowing what hilbert space is but if you dig into a little bit more into quantum mechanics it becomes necessary you know the english language was invented long before quantum mechanics or various forms of higher mathematics were invented so we use the word space to mean different things of course most of us think of space as this three dimensional world in which we live right i mean some of us just think of it as outer space okay but space around us gives us the three dimensional location of things and objects but mathematicians use any generic abstract collection of elements as a space okay a space of possibilities you know momentum space etc so hilbert space is the space of all possible quantum wave functions either for the universe or for some specific system and it could be an infinite dimensional space or it could be just really really large dimensional but finite we dont know because we dont know the final theory of everything but this abstract hilbert space is really really really big and has no immediate connection to the three dimensional space in which we live what do dimensions in hilbert space mean you know its just a way of mathematically representing how much information is contained in the state of the system how many numbers do you have to give me to specify what the thing is doing so in classical mechanics i give you the location of something by giving you three numbers right up down left x y z coordinates but then i might want to give you its entire state physical state which means both its position and also its velocity the velocity also has three components so its state lives in something called phase space which is six dimensional three dimensions of position three dimensions of velocity and then if it also has an orientation in space thats another three dimensions and so forth so as you describe more and more information about the system you have an abstract mathematical space that has more and more numbers that you need to give and each one of those numbers corresponds to a dimension in that space so in terms of the amount of information what is entropy this mystical word thats overused in math and physics but has a very specific meaning in this context sadly it has more than one very specific meeting this is the reason why it is hard entropy means different things even to different physicists but one way of thinking about it is a measure of how much we dont know about the state of a system so if i have a bottle of water molecules and i know that ok theres a certain number of water molecules i could weigh it and figure out i know the volume of it and i know the temperature and pressure and things like that i certainly dont know the exact position and velocity of every water molecule so theres a certain amount of information i know a certain amount that i dont know that is part of the complete state of the system and thats what the entropy characterizes how much unknown information there is the difference between what i do know about the system and its full exact microscopic state so when we try to describe a quantum mechanical system is it infinite or finite but very large yeah we dont know that depends on the system you know its easy to mathematically write down a system that would have a potentially infinite entropy an infinite dimensional hilbert space so lets go back a little bit we said that the hilbert space was the space in which quantum wave functions lived for different systems that will be different sizes they could be infinite or finite so thats the number of numbers the number of pieces of information you could potentially give me about the system so the bigger hilbert space is the bigger the entropy of that system could be depending on what i know about it if i dont know anything about it then it has a huge entropy right but only up to the size of its hilbert space so we dont know in the real physical world whether or not you know this region of space that contains that water bottle has potentially an infinite entropy or just a finite entropy we have different arguments on different sides so if its infinite how do you think about infinity is this something you can your cognitive abilities are able to process or is it just a mathematical tool its somewhere in between right i mean we can say things about it we can use mathematical tools to manipulate infinity very very accurately we can define what we mean you know for any number n theres a number bigger than it so theres no biggest number right so theres something called the total number of all numbers its infinite but it is hard to wrap your brain around that and i think that gives people pause because we talk about infinity as if its a number but it has plenty of properties that real numbers dont have you know if you multiply infinity by two you get infinity again right thats a little bit different than what were used to okay but are you comfortable with the idea that in thinking of what the real world actually is that infinity could be part of that world are you comfortable that a world in some dimension in some aspect im comfortable with lots of things i mean you know i dont want my level of comfort to affect what i think about the world you know im pretty open minded about what the world could be at the fundamental level yeah but infinity is a tricky one its not almost a question of comfort its a question of is it an overreach of our intuition sort of it could be a convenient almost like when you add a constant to an equation just because itll help it just feels like its useful to at least be able to imagine a concept not directly but in some kind of way that this feels like its a description of the real world think of it this way theres only three numbers that are simple theres zero theres one and theres infinity a number like 318 is just bizarre you need a lot of bits to give me what that number is but zero and one and infinity like once you have 300 things you might as well have infinity things right otherwise you have to say when to stop making the things right so theres a sense in which infinity is a very natural number of things to exist i was never comfortable with infinity because its just such a it was too good to be true because in math it just helps make things work out when things get very large close to infinity things seem to work out nicely its kind of like because my deepest passion is probably psychology and im uncomfortable how in the average the beauty of how much we vary is lost in that same kind of sense infinity seems like a convenient way to erase the details but the thing about infinity is it seems to pop up whether we like it or not right like youre trying to be a computer scientist you ask yourself well how long will it take this program to run and you realize well for some of them the answer is infinitely long its not because you tried to get there you wrote a five line computer program it doesnt halt so coming back to the textbook definition of quantum mechanics this idea that i dont think we talked about can you this one of the most interesting philosophical points we talked at the human level but at the physics level that at least the textbook definition of quantum mechanics separates what is observed and what is real one how does that make you feel and two what does it then mean to observe something and why is it different than what is real yeah you know my personal feeling such as it is is that things like measurement and observers and stuff like that are not going to play a fundamental role in the ultimate laws of physics but my feeling that way is because so far thats where all the evidence has been pointing i could be wrong and theres certainly a sense in which it would be infinitely cool if somehow observation or mental cogitation did play a fundamental role in the nature of reality but i dont think so and again i dont see any evidence for it so im not spending a lot of time worrying about that possibility so what do you do about the fact that in the textbook interpretation of quantum mechanics this idea of measurement or looking at things seems to play an important role well you come up with better interpretations of quantum mechanics and there are several alternatives my favorite is the many worlds interpretation which says two things number one you the observer are just a quantum system like anything else theres nothing special about you dont get so proud of yourself you know youre just a bunch of atoms you have a wave function you obey the schrodinger equation like everything else and number two when you think youre measuring something or observing something whats really happening is youre becoming entangled with that thing so when you think theres a wave function for the electron its all spread out but you look at it and you only see it in one location whats really happening is that theres still the wave function for the electron in all those locations but now its entangled with the wave function of you in the following way theres part of the wave function that says the electron was here and you think you saw it there the electron was there and you think you saw it there the electron was over there and you think you saw it there etc so in all of those different parts of the wave function once they come into being no longer talk to each other they no longer interact or influence each other its as if they are separate worlds so this was the invention of hugh everett iii who was a graduate student at princeton in the 1950s and he said basically look you dont need all these extra rules about looking at things just listen to what the schrodinger equation is telling you its telling you that you have a wave function that you become entangled and that the different versions of you no longer talk to each other so just accept it its just he did therapy more than anything else he said like its okay you dont need all these extra rules all you need to do is believe the schrodinger equation the cost is theres a whole bunch of extra worlds out there so are the worlds being created whether theres an observer or not the worlds are created any time a quantum system thats in a superposition becomes entangled with the outside world whats the outside world it depends lets back up whatever it really says what his theory is is theres a wave function of the universe and it obeys the schrodinger equation all the time thats it thats the full theory right there the question all of the work is how in the world do you map that theory onto reality onto what we observe so part of it is carving up the wave function into these separate worlds saying look it describes a whole bunch of things that dont interact with each other lets call them separate worlds another part is distinguishing between systems and their environments the environment is basically all the degrees of freedom all the things going on in the world that you dont keep track of so again in the bottle of water i might keep track of the total amount of water and the volume i dont keep track of the individual positions and velocities i dont keep track of all the photons or the air molecules in this room so thats the outside world the outside world is all the parts of the universe that youre not keeping track of when youre asking about the behavior of subsystem of it so how many worlds are there yeah we dont know that one either there could be an infinite number there could be only a finite number but its a big number one way or the other its just a very very big number in one of the talks somebody asked well if its finite so actually im not sure exactly the logic you used to derive this but is there going to be overlap a duplicate world that you return to so youve mentioned and id love if you can elaborate on sort of idea that its possible that theres some kind of equilibrium that these splitting worlds arrive at and then maybe over time maybe somehow connected to entropy you get a large number of worlds that are very similar to each other yeah so this question of whether or not hilbert space is finite or infinite dimensional is actually secretly connected to gravity and cosmology this is the part that were still struggling to understand right now but we discovered back in 1998 that our universe is accelerating and what that means if it continues which we think it probably will but were not sure but if it does that means theres a horizon around us because the universe is not only expanding but expanding faster and faster things can get so far away from us that from our perspective it looks like theyre moving away faster in the speed of light we will never see them again so theres literally a horizon around us and that horizon approaches some fixed distance away from us and you can then argue that within that horizon theres only a finite number of things that can possibly happen the finite dimensional hilbert space in fact we even have a guess for what the dimensionality is its 10 to the power of 10 to the power of 122 thats a very large number yes just to compare the age of the universe is something like 10 to the 14 seconds 10 to the 17 or 18 seconds maybe the number of particles in the universe is 10 to the 88th but the number of dimensions of hilbert space is 10 to the 10 to the 122 so thats just crazy big if that story is right that in our observable horizon theres only a finite dimensional hilbert space then this idea of branching of the wave function of the universe into multiple distinct separate branches has to reach a limit at some time once you branch that many times youve run out of room in hilbert space and roughly speaking that corresponds to the universe just expanding and emptying out and cooling off and entering a phase where its just empty space literally forever whats the difference between splitting and copying do you think in terms of a lot of this is an interpretation that helps us sort of model the world so perhaps shouldnt be thought of as like you know philosophically or metaphysically but in even at the physics level do you see a difference between generating new copies of the world or splitting i think its better to think of in quantum mechanics in many worlds the universe splits rather than new copies because people otherwise worry about things like energy conservation and no one who understands quantum mechanics worries about energy conservation because the equation is perfectly clear but if all you know is that someone told you the universe duplicates then you have a reasonable worry about where all the energy for that came from so a pre existing universe splitting into two skinnier universes is a better way of thinking about it and mathematically its just like you know if you draw an x and y axis and you draw a vector of length one 45 degree angle you know that you can write that vector of length one as the sum of two vectors pointing along x and y of length one over the square root of two okay so i write one arrow as the sum of two arrows but theres a conservation of arrowness right like theres now two arrows but the length is the same i just im describing it in a different way and thats exactly what happens when the universe branches the the wave function of the universe is a big old vector so to somebody who brings up a question of saying doesnt this violate the conservation of energy can you give further elaboration right so lets just be super duper perfectly clear theres zero question about whether or not many worlds violates conservation of energy yes it does not great and i say this definitively because there are other questions that i think theres answers to but theyre legitimate questions right about you know where does probability come from and things like that this conservation of energy question we know the answer to it and the answer to it is that energy is conserved all of the effort goes into how best to translate what the equation unambiguously says into plain english right so this idea that theres a universe that has that that the universe comes equipped with a thickness and it sort of divides up into thinner pieces but the total amount of universe is is conserved over time is a reasonably good way of putting english words to the underlying mathematics so one of my favorite things about many worlds is i mean i love that theres something controversial in science and for some reason it makes people actually not like upset but just get excited why do you think it is a controversial idea so theres a lot of its actually one of the cleanest ways to think about quantum mechanics so why do you think theres a discomfort a little bit among certain people well i draw the distinction in my book between two different kinds of simplicity in a physical theory theres simplicity in the theory itself right how we describe whats going on according to the theory by its own rights but then you know theory is just some sort of abstract mathematical formalism you have to map it onto the world somehow right and sometimes like for newtonian physics its pretty obvious like okay here is a bottle and has a center of mass and things like that sometimes its a little bit harder with general relativity curvature of space time is a little bit harder to grasp quantum mechanics is very hard to map what youre the language youre talking in a wave functions and things like that on to reality and many worlds is the version of quantum mechanics where it is hardest to map on the underlying formalism to reality so thats where the lack of simplicity comes in not in the theory but in how we use the theory to map on to reality in fact all of the work in sort of elaborating many worlds quantum mechanics is in the this effort to map it on to the world that we see so its perfectly legitimate to be bugged by that right to say like well no thats just too far away from my experience i am therefore intrinsically skeptical of it of course you should give up on that skepticism if there are no alternatives and this theory always keeps working then eventually you should overcome your skepticism but right now there are alternatives that are that you know people work to make alternatives that are by their nature closer to what we observe directly can you describe the alternatives i dont think we touched on it sort of the copenhagen interpretation and the many worlds maybe theres a difference between the everettian many worlds and many worlds as it is now like has the idea sort of developed and so on and just in general what is the space of promising contenders we have democratic debates now theres a bunch of candidates 12 candidates on stage what are the quantum mechanical candidates on stage for the debate so if you had a debate between quantum mechanical contenders thered be no problem getting 12 people up there on stage but there would still be only three front runners and right now the front runners would be everett hidden variable theories are another one so the hidden variable theories say that the wave function is real but theres something in addition to the wave function the wave function is not everything its part of reality but its not everything what else is there were not sure but in the simplest version of the theory there are literally particles so many worlds says that quantum systems are sometimes are wave like in some ways and particle like in another because they really really are waves but under certain observational circumstances they look like particles whereas hidden variable says they look like waves and particles because there are both waves and particles involved in the dynamics and thats easy to do if your particles are just non relativistic newtonian particles moving around they get pushed around by the wave function roughly it becomes much harder when you take quantum field theory or quantum gravity into account the other big contender are spontaneous collapse theories so in the conventional textbook interpretation we say when you look at a quantum system its wave function collapses and you see it in one location a spontaneous collapse theory says that every particle has a chance per second of having its wave function spontaneously collapse the chance is very small for a typical particle it will take hundreds of millions of years before it happens even once but in a table or some macroscopic object there are way more than a hundred million particles and theyre all entangled with each other so when one of them collapses it brings everything else along with it theres a slight variation of this thats a spontaneous collapse theory there are also induced collapse theories like roger penrose thinks that when the gravitational difference between two parts of the wave function becomes too large the wave function collapses automatically so those are basically in my mind the three big alternatives many worlds which is just theres a wave function and always obeys the schrodinger equation hidden variables theres a wave function that always obeys the schrodinger equation but there are also new variables or collapse theories which the wave function sometimes obeys the schrodinger equation and sometimes it collapses so you can see that the alternatives are more complicated in their formalism than many worlds is but they are closer to our experience so just this moment of collapse do you think of it as a wave function fundamentally sort of a probabilistic description of the world and this collapse sort of reducing that part of the world into something deterministic where again you can now describe the position and the velocity in this simple classical model well there is is that how you think about collapse there is a fourth category theres a fourth contender theres a mayor pete of quantum mechanical interpretations which are called epistemic interpretations and what they say is all the wave function is is a way of making predictions for experimental outcomes its not mapping onto an element of reality in any real sense and in fact two different people might have two different wave functions for the same physical system because they know different things about it right the wave function is really just a prediction mechanism and then the problem with those epistemic interpretations is if you say okay but its predicting about what like what is the thing that is being predicted and they say no no no thats not what were here for were just here to tell you what the observational outcomes are going to be but the other the other interpretations kind of think that the wave function is real yes thats right so thats an ontic interpretation of the wave function ontology being the study of what is real what exists as opposed to an epistemic interpretation of the wave function epistemology being the study of what we know that would actually just love to see that debate on stage there was a version of it on stage at the world science festival a few years ago that you can look up online on youtube yep its on youtube okay awesome ill link it and watch it who won i won i dont know there was no vote there was no vote but those theres brian green was the moderator and david albert stood up for a spontaneous collapse and shelley goldstein was there for hidden variables and rüdiger schock was there for epistemic approaches why do you i think you mentioned it but just to elaborate why do you find many worlds so compelling well theres two reasons actually one is like i said it is the simplest right its like the most bare bones austere pure version of quantum mechanics and i am someone who is very willing to put a lot of work into mapping the formalism onto reality im less willing to complicate the formalism itself but the other big reason is that theres something called modern physics with quantum fields', 'the following is a conversation with bjarne stroustrup he is the creator of c a programming language that after 40 years is still one of the most popular and powerful languages in the world its focus on fast stable robust code underlies many of the biggest systems in the world that we have come to rely on as a society if youre watching this on youtube for example many of the critical back end components of youtube are written in c the same goes for google facebook amazon twitter most microsoft applications adobe applications most database systems and most physical systems that operate in the real world like cars robots rockets that launch us into space and one day will land us on mars c also happens to be the language that i use more than any other in my life ive written several hundred thousand lines of c source code of course lines of source code dont mean much but they do give hints of my personal journey through the world of software ive enjoyed watching the development of c as a programming language leading up to the big update in the standard in 2011 and those that followed in 14 17 and toward the new c20 standard hopefully coming out next year title this is the artificial intelligence podcast if you enjoy it subscribe on youtube give it five stars on itunes support it on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now heres my conversation with björn stroustrup what was the first program youve ever written do you remember björn it was my second year in university first year of computer science and it was an alco 60 i calculated the shape of a super ellipse and then connected points on the perimeter creating star patterns it was with a wet ink on a paper printer title and that was in college university björn yeah yeah i learned to program the second year in university title and what was the first programming language if i may ask it this way that you fell in love with björn i think alco 60 and after that i remember snowball i remember fortran didnt fall in love with that i remember pascal didnt fall in love with that it all got in the way of me and then i discovered assembler and that was much more fun and from there i went to micro code title so you were drawn to the you found the low level stuff beautiful björn i went through a lot of languages and then i spent significant time in assembler and micro code that was sort of the first really profitable things that paid for my masters actually and then i discovered simula which was absolutely great title simula björn simula was the extension of alco 60 done primarily for simulation but basically they invented object oriented programming at inheritance and runtime polymorphism while they were doing it and that was the language that taught me that you could have the sort of the problems of a program grow with the size of the program rather than with the square of the size of the program that is you can actually modularize very nicely and that was a surprise to me it was also a surprise to me that a stricter type system than pascals was helpful whereas pascals type system got in my way all the time so you need a strong type system to organize your code well but it has to be extensible and flexible title lets get into the details a little bit if you remember what kind of type system did pascal have what type system typing system did alco 60 have björn basically pascal was sort of the simplest language that niklaus wirth could define that served the needs of niklaus wirth at the time and it has a sort of a highly moral tone to it that is if you can say it in pascal its good and if you cant its not so good whereas simula allowed you basically to build your own type system so instead of trying to fit yourself into niklaus wirths world christen nygaards language and johan dahls language allowed you to build your own so its sort of close to the original idea of you build a domain specific language as a matter of fact what you build is a set of types and relations among types that allows you to express something thats suitable for an application title so when you say types stuff youre saying has echoes of object oriented programming björn yes they invented it every language that uses the word class for type is a descendant of simula directly or indirectly christen nygaard and ole johan dahl were mathematicians and they didnt think in terms of types but they understood sets and classes of elements and so they called their types classes and basically in c as in simula classes are user defined type title so can you try the impossible task and give a brief history of programming languages from your perspective so we started with algol 60 simula pascal but thats just the 60s and 70s björn i can try the most sort of interesting and major improvement of programming languages was fortran the first fortran because before that all code was written for a specific machine and each specific machine had a language a simple language or a cross simpler or some extension of that idea but youre writing for a specific machine in the language of that machine and bacchus and his team at ibm built a language that would allow you to write what you really wanted that is you could write it in a language that was natural for people now these people happen to be engineers and physicists so the language that came out was somewhat unusual for the rest of the world but basically they said formula translation because they wanted to have the mathematical formulas translated into the machine and as a side effect they got portability because now theyre writing in the terms that the humans used and the way humans thought and then they had a program that translated it into the machines needs and that was new and that was great and its something to remember we want to raise the language to the human level but we dont want to lose the efficiency and that was the first step towards the human that was the first step and of course they were a very particular kind of humans business people were different so they got cobalt instead et cetera et cetera and simula came out no lets not go to simula yet lets go to algol fortran didnt have at the time the notions of not a precise notion of type not a precise notion of scope not a set of translation phases that was what we have today lexical syntax semantics it was sort of a bit of a model in the early days but hey theyve just done the biggest breakthrough in the history of programming right so you cant criticize them for not having gotten all the technical details right so we got algol that was very pretty and most people in commerce and science considered it useless because it was not flexible enough and it wasnt efficient enough and et cetera et cetera but that was a breakthrough from a technical point of view then simula came along to make that idea more flexible and you could define your own types and thats where i got very interested christen nygård was the main idea man behind simula that was late 60s this was late 60s well i was a visiting professor in aarhus and so i learned object oriented programming by sitting around and well in theory discussing with christen nygård but christen once you get started and in full flow its very hard to get a word in edgeways where you just listen so it was great i learned it from there not to romanticize the notion but it seems like a big leap to think about object oriented programming its really a leap of abstraction yes and was that as big and beautiful of a leap as it seems from now in retrospect or was it an obvious one at the time it was not obvious and many people have tried to do something like that and most people didnt come up with something as wonderful as simula lots of people got their phds and made their careers out of forgetting about simula or never knowing it for me the key idea was basically i could get my own types and thats the idea that goes further into c where i can get better types and more flexible types and more efficient types but its still the fundamental idea when i want to write a program i want to write it with my types that is appropriate to my problem and under the constraints that im under with hardware software environment et cetera and thats the key idea people picked up on the class hierarchies and the virtual functions and the inheritance and that was only part of it it was an interesting and major part and still a major part and a lot of graphic stuff but it was not the most fundamental it was when you wanted to relate one type to another you dont want them all to be independent the classical example is that you dont actually want to write a city simulation with vehicles where you say well if its a bicycle write the code for turning a bicycle to the left if its a normal car turn right the normal car way if its a fire engine turn right the fire engine way you get these big case statements and bunches of if statements and such instead you tell the base class that thats the vehicle saying turn left the way you want to and this is actually a real example they used it to simulate and optimize the emergency services for somewhere in norway back in the 60s so this was one of the early examples for why you needed inheritance and you needed a runtime polymorphism because you wanted to handle this set of vehicles in a manageable way you cant just rewrite your code each time a new kind of vehicle comes along yeah thats a beautiful powerful idea and of course it stretches through your work with c as well talk about but i think youve structured it nicely what other breakthroughs came along in the history of programming languages if we were to tell the history in that way obviously im better at telling the part of the history that is the path im on as opposed to all the paths yeah you skipped the hippie john mccarthy and lisp one of my favorite languages functional but lisp is not one of my favorite languages its obviously important its obviously interesting lots of people write code in it and then they rewrite it into c or c when they want to go to production its in the world im at which are constrained by performance reliability issues deployability cost of hardware i dont like things to be too dynamic it is really hard to write a piece of code thats perfectly flexible that you can also deploy on a small computer and that you can also put in say a telephone switch in bogota whats the chance if you get an error and you find yourself in the debugger that the telephone switch in bogota on late sunday night has a programmer around their chance is zero a lot of the things i think most about cant afford that flexibility im quite aware that maybe 70 80 of all code are not under the kind of constraints im interested in but somebody has to do the job im doing because you have to get from these high level flexible languages to the hardware the stuff that lasts for 10 20 30 years is robust operates under very constrained conditions yes absolutely thats right and its fascinating and beautiful in its own way c is one of my favorite languages and so is lisp so i can embody two for different reasons as a programmer i understand why lisp is popular and i can see the beauty of the ideas and similarly with smalltalk its just not as relevant in my world and by the way i distinguish between those and the functional languages where i go to things like ml and haskell different kind of languages they have a different kind of beauty and theyre very interesting and i think thats interesting and i actually try to learn from all the languages i encounter to see what is there that would make working on the kind of problems im interested in with the kind of constraints that im interested in what can actually be done better because we can surely do better than we do today youve said that its good for any professional programmer to know at least five languages as speaking about a variety of languages that youve taken inspiration from and youve listed yours as being at least at the time c obviously java python ruby script can you first of all update that list modify it you dont have to be constrained to just five but can you describe what you picked up also from each of these languages how do you see them as inspirations for you when youre working with c this is a very hard question to answer so about languages you should know languages i reckon i knew about 25 or thereabouts when i did c it was easier in those days because the languages were smaller and you didnt have to learn a whole programming environment and such to do it you could learn the language quite easily and its good to learn so many languages i imagine just like with natural language for communication theres different paradigms that emerge in all of them that theres commonalities and so on so i picked five out of a hat you picked five out of a hat obviously the important thing that the number is not one thats right its like i dont like i mean if youre a monoglot you are likely to think that your own culture is the only one superior to everybody elses a good learning of a foreign language and a foreign culture is important it helps you think and be a better person with programming languages you become a better programmer better designer with the second language now once youve got two the weight of five is not that long its the second one thats most important and then when i had to pick five i sort of thinking what kinds of languages are there well theres a really low level stuff its good its actually good to know machine code even still even today the c optimizers write better machine code than i do yes but i dont think i could appreciate them if i actually didnt understand machine code and machine architecture at least in my position i have to understand a bit of it because you mess up the cache and youre off in performance by a factor of 100 it shouldnt be that if you are interested in either performance or the size of the computer you have to deploy so i would go as a simpler i used to mention c but these days going low level is not actually what gives you the performance it is to express your ideas so cleanly that you can think about it and the optimizer can understand what youre up to my favorite way of optimizing these days is to throw express the commonality as the idea of a vector and the variations come through parameterization and so here we get the two fundamental ways of abstracting or of having similarities of types in c theres the inheritance and theres a parameterization theres the object oriented programming and theres the generic programming with the templates for the generic programming yep so youve presented it very nicely but now you have to make all that happen and make it efficient so generic programming with templates theres all kinds of magic going on especially recently that you can help catch up on but it feels to me like you can do way more than what you just said with templates you can start doing this kind of metaprogramming this kind of you can do metaprogramming also i didnt go there in that explanation were trying to be very basic but go back on to the implementation if you couldnt implement this efficiently if you couldnt use it so that it became efficient it has no place in c because it will violate the zero overhead principle so when i had to get object oriented programming inheritance i took the idea of virtual functions from simula virtual functions is a simula term class is a simula term if you ever use those words say thanks to christen nygaard and olli høndahl and i did the simplest implementation i knew of which was basically a jump table so you get the virtual function table the function goes in does an indirection through a table and get the right function thats how you pick the right thing there and i thought that was trivial its close to optimal and it was obvious it turned out the simula had a more complicated way of doing it and therefore was slower and it turns out that most languages have something thats a little bit more complicated sometimes more flexible but you pay for it and one of the strengths of c was that you could actually do this object oriented stuff and your overhead compared to ordinary functions theres no indirection its sort of in 5 10 25 just the call its down there its not two and that means you can afford to use it furthermore in c you have the distinction between a virtual function and a nonvirtual function if you dont want any overhead if you dont need the indirection that gives you the flexibility in object oriented programming just dont ask for it so the idea is that you only use virtual functions if you actually need the flexibility so its not zero overhead but its zero overhead compared to any other way of achieving the flexibility now auto parameterization basically the compiler looks at the template say the vector and it looks at the parameter and then combines the two and generates a piece of code that is exactly as if youve written a vector of that specific type so thats the minimal overhead if you have many template parameters you can actually combine code that the compiler couldnt usually see at the same time and therefore get code that is faster than if you had handwritten the stuff unless you are very very clever so the thing is parameterized code the compiler fills stuff in during the compilation process not during runtime thats right and furthermore it gives all the information its gotten which is the template the parameter and the context of use it combines the three and generates good code but it can generate now its a little outside of what im even comfortable thinking about but it can generate a lot of code yes and how do you i remember being both amazed at the power of that idea and how ugly the debugging looked yes debugging can be truly horrid come back to this because i have a solution anyway the debugging was ugly the code generated by c has always been ugly because theres these inherent optimizations a modern c compiler has front end middle end and back end even c front back in 83 had front end and back end optimizations i actually took the code generated an internal representation munched that representation to generate good code so people say its not a compiler it generates c the reason it generated c was i wanted to use cs code generator and i wanted to use cs code generator to generate good code c was i wanted to use cs code generators that was really good at back end optimizations but i needed front end optimizations and therefore the c i generated was optimized c the way a really good handcrafted optimizer human could generate it and it was not meant for humans it was the output of a program and its much worse today and with templates it gets much worse still so its hard to combine simple debugging with the optimal code because the idea is to drag in information from different parts of the code to generate good code machine code and thats not readable so what people often do for debugging is they turn the optimizer off and so you get code that when something in your source code looks like a function call it is a function call when the optimizer is turned on it may disappear the function call it may inline and so one of the things you can do is you can actually get code that is smaller than the function call because you eliminate the function preamble and return and theres just the operation there one of the key things when i did templates was i wanted to make sure that if you have say a sort algorithm and you give it a sorting criteria if that sorting criteria is simply comparing things with less than the code generated should be the less than not an indirect function call to a comparison object which is what it is in the source code but we really want down to the single instruction but anyway turn off the optimizer and you can debug the first level of debugging can be done and i always do without the optimization on because then i can see whats going on and then theres this idea of concepts that puts some now ive never even i dont know if it was ever available in any form but it puts some constraints on the stuff you can parameterize essentially let me try and explain this so yes it wasnt there 10 years ago we have had versions of it that actually work for the last four or five years it was a design by gabi dos reis drew sutton and me we were professors and postdocs in texas at the time and the implementation by andrew sutton has been available for that time and it is part of c20 and theres a standard library that uses it so this is becoming really very real its available in clang and gcc gcc for a couple of years and i believe microsoft is soon going to do it we expect all of c20 to be available in all the major compilers in 20 but this kind of stuff is available now im just saying that because otherwise people might think i was talking about science fiction and so what im going to say is concrete you can run it today and theres production uses of it so the basic idea is that when you have a generic component like a sort function the sort function will require at least two parameters one is the data structure with a given type and a comparison criteria and these things are related but obviously you cant compare things if you dont know what the type of things you compare and so you want to be able to say im going to sort something and it is to be sortable what does it mean to be sortable you look it up in the standard it has to have a it has to be a sequence with a beginning and an end there has to be random access to that sequence and there has to be the element types has to be comparable by default which means less than operator can operate on yes less than logical operator can operate basically what concepts are theyre compile time predicates theyre predicates you can ask are you a sequence yes i have a beginning and end are you a random access sequence yes i have a subscripting and plus is your element type something that has a less than yes i have a less than its and so basically thats the system and so instead of saying i will take a parameter of any type itll say ill take something thats sortable and its well defined and so we say okay you can sort with less than i dont want less than i want greater than or something i invent so you have two parameters the sortable thing and the comparison criteria and the comparison criteria will say well i can you can write it saying it should operate on the element type and then you can say well i can sort with less than and it has the comparison operations so thats just simply the fundamental thing its compile time predicates do you have the properties i need so it specifies the requirements of the code on the parameters that it gets its very similar to types actually but operating in the space of concepts concepts the word concept was used by alex stefanov who is sort of the father of generic programming in the context of c theres other places that use that word but the way we call it generic programming is alexs and he called them concepts because he said they are the sort of the fundamental concepts of an area so they should be called concepts and weve had concepts all the time if you look at the knr book about c c has arithmetic types and it has integral types it says so in the book and then it lists what they are and they have certain properties the difference today is that we can actually write a concept that will ask a type are you an integral type do you have the properties necessary to be an integral type do you have plus minus divide and such so maybe the story of concepts because i thought it might be part of c11 c o x or whatever it was at the time what was the why didnt it what like what well well talk a little bit about this fascinating process of standards because i think its really interesting for people its interesting for me but why did it take so long what shapes did the idea of concepts take what were the challenges back in 87 or thereabouts 1987 well 1987 or thereabouts when i was designing templates obviously i wanted to express the notion of what is required by a template of its arguments and so i looked at this and basically for templates i wanted three properties i wanted to be very flexible it had to be able to express things i couldnt imagine because i know i cant imagine everything and ive been suffering from languages that try to constrain you to only do what the designer thought good didnt want to do that secondly it had to run faster as fast or faster than handwritten code so basically if i have a vector of t and i take a vector of char it should run as fast as you built a vector of char yourself without parameterization and thirdly i wanted to be able to express the constraints of the arguments have proper type checking of the interfaces and neither i nor anybody else at the time knew how to get all three and i thought for c i must have the two first otherwise its not c and it bothered me for another couple of decades that i couldnt solve the third one i mean i was the one that put function argument type checking into c i know the value of good interfaces i didnt invent that idea its very common but i did it and i wanted to do the same for templates of course and i couldnt so it bothered me then we tried again 2002 2003 gaby desrays and i started analyzing the problem explained possible solutions it was not a complete design a group in university of indiana an old friend of mine they started a project at indiana and we thought we could get a good system of concepts in another two or three years that would have made c 11 to c 06 or 07 well it turns out that i think we got a lot of the fundamental ideas wrong they were too conventional they didnt quite fit c in my opinion didnt serve implicit conversions very well it didnt serve mixed type arithmetic mixed type computations very well a lot of stuff came out of the functional community and that community didnt deal with multiple types in the same way as c does had more constraints on what you could express and didnt have the draconian performance requirements and basically we tried we tried very hard we had some successes but it just in the end wasnt didnt compile fast enough was too hard to use and didnt run fast enough unless you had optimizers that was beyond the state of the art they still are so we had to do something else basically it was the idea that a set of parameters has defined a set of operations and you go through an interaction table just like for virtual functions and then you try to optimize the interaction away to get performance and we just couldnt do all of that but get back to the standardization we are standardizing c under iso rules which are very open process people come in theres no requirements for education or experience so you started to develop c and theres a whole when was the first standard established what is that like the iso standard is there a committee that youre referring to theres a group of people what was that like how often do you meet whats the discussion ill try and explain that so sometime in early 1989 two people one from ibm one from hp turned up in my office and told me i would like to standardize c this was a new idea to me and when i pointed out that it wasnt finished yet and it wasnt ready for formal standardization and such and they say no bjarne you havent gotten it you really want to do this our organizations depend on c we cannot depend on something thats owned by another corporation that might be a competitor of course we could rely on you but you might get run over by a boss we really need to get this out in the open it has to be standardized under formal rules and we are going to standardize it under iso rules and you really want to be part of it because basically otherwise well do it ourselves and we know you can do it better so through a combination of arm twisting and flattery it got started so in late 89 there was a meeting in dc at the actually no it was not iso then it was ansi the american national standard doing we met there we were lectured on the rules of how to do an ansi standard there was about 25 of us there which apparently was a new record for that kind of meeting and some of the old c guys that has been standardized in c was there so we got some expertise in so the way this works is that its an open process anybody can sign up if they pay the minimal fee which is about a thousand dollars less than a little bit more now and i think its 1280 its not going to kill you and we have three meetings a year this is fairly standard we tried two meetings a year for a couple of years that didnt work too well so three one week meetings a year and you meet and you have technical discussions and then you bring proposals forward for votes the votes are done one person per one vote per organization so you cant have say ibm come in with 10 people and dominate things thats not allowed and these are organizations that extensively uc plus plus yes or individuals or individuals i mean its a bunch of people in the room deciding the design of a language based on which a lot of the worlds systems run right well i think most people would agree its better than if i decided it or better than if a single organization like agt decides it i dont know if everyone agrees to that by the way bureaucracies have their critics too yes look standardization is not pleasant its horrifying its like democracy exactly as churchill says democracy is the worst way except for the others right and its i would say the same with formal standardization but anyway so we meet and we have these votes and that determines what the standard is a couple of years later we extended this so it became worldwide we have standard organizations that are active in currently 15 to 20 countries and another 15 to 20 are sort of looking and voting based on the rest of the work on it and we meet three times a year next week ill be in cologne germany spending a week doing standardization and well vote out the committee draft of c20 which goes to the national standards committees for comments and requests for changes and improvements then we do that and theres a second set of votes where hopefully everybody votes in favor this has happened several times the first time we finished we started in the first technical meeting was in 1990 the last was in 98 we voted it out that was the standard that people used until 11 or a little bit past 11 and it was an international standard all the countries voted in favor it took longer with 11 ill mention why but all the nations voted in favor and we work on the basis of consensus that is we do not want something that passes 6040 because then were going to get dialects and opponents and people complain too much they all complain too much but basically it has no real effect the standards has been obeyed they have been working to make it easier to use many compilers many computers and all of that kind of stuff it was traditional with iso standards to take 10 years we did the first one in eight brilliant and we thought we were going to do the next one in six because now we are good at it right it took 13 yeah it was named ox it was named ox hoping that you would at least get it within the single within the odds the single digits i thought we would get i thought wed get six seven or eight the confidence of youth thats right well the point is that this was sort of like a second system effect that is we now knew how to do it and so were going to do it much better and weve got more ambitious and it took longer furthermore there is this tendency because its a 10 year cycle or it doesnt matter just before youre about to ship somebody has a bright idea and so we really really must get that in we did that successfully with the stl we got the standard library that gives us all the stl stuff that basically i think it saved c it was beautiful and then people tried it with other things and it didnt work so well they got things in but it wasnt as dramatic and it took longer and longer and longer so after c 11 which was a huge improvement and what basically what most people are using today we decided never again and so how do you avoid those slips and the answer is that you ship more often so that if you have a slip on a 10 year cycle by the time you know its a slip theres 11 years till you get it now with a three year cycle there is about three or four years till you get it like the delay between feature freeze and shipping so you always get one or two years more and so we shipped 14 on time we shipped 17 on time and we ship we will ship 20 on time itll happen and furthermore this gives a predictability that allows the implementers the compiler implementers the library implementers they have a target and they deliver on it 11 took two years before most compilers were good enough 14 most compilers were actually getting pretty good in 14 17 everybody shipped in 17 we are going to have at least almost everybody ship almost everything in 20 and i know this and i know this because theyre shipping in 19 predictability is good delivery on time is good and so yeah thats great thats how it works theres a lot of features that came in in c 11 theres a lot of features at the birth of c that were amazing and ideas with concepts in 2020 what to you is the most just to you personally beautiful or just you sit back and think wow thats just nice and clean feature of c i have written two papers for the history of programming languages conference which basically asked me such questions and im writing a third one which i will deliver at the history of programming languages conference in london next year so ive been thinking about that and there is one clear answer constructors and destructors the way a constructor can establish the environment for the use of a type for an object and the destructor that cleans up any messes at the end of it that is key to c thats why we dont have to use garbage collection thats how we can get predictable performance thats how you can get the minimal overhead in many many cases and have really clean types its the idea of constructor destructor pairs sometimes it comes out under the name raii resource acquisition is initialization which is the idea that you grab resources in the constructor and release them in destructor its also the best example of why i shouldnt be in advertising i get the best idea and i call it resource acquisition is initialization not the greatest naming ive ever heard not the greatest naming ive ever heard so its types abstraction of types you said i want to create my own types so types is an essential part of c and making them efficient is the key part and to you this is almost getting philosophical but the construction and the destruction the creation of an instance of a type and the freeing of resources from that instance of a type is what defines the object its almost like birth and death is what defines human life thats right by the way philosophy is important you cant do good language design without philosophy because what you are determining is what people can express and how this is very important by the way constructors destructors came into c in 79 in about the second week of my work with what was then called c of the classes it is a fundamental idea next comes the fact that you need to control copying because once you control as you said birth and death you have to control taking copies which is another way of creating an object and finally you have to be able to move things around so you get the move operations and thats the set of key operations you can define on a c type and so to you those things are just just a beautiful part of c that is at the core of it all yes you mentioned that you hope there will be one unified set of guidelines in the future for how to construct a programming language so perhaps not one programming language but a unification of how we build programming languages if you remember such statements i have some trouble remembering it but i know the origin of that idea so maybe you can talk about sort of c has been improving theres been a lot of programming language do you where does the arc of history taking us do you hope that there is a unification about the languages with which we communicate in the digital space well i think that languages should be designed not by clobbering language features together and and doing slightly different versions of somebody elses ideas but through the creation of a set of principles rules of thumbs whatever you call them i made them for c and were trying to teach people in the standards committee about these rules because a lot of people come in and says ive got a great idea lets put it in the language and then you have to ask why does it fit in the language why does it fit in this language it may fit in another language and not here or it may fit here and not the other language so you have to work from a set of principles and you have to develop that set of principles and one example that i sometimes remember is i was sitting down with some of the designers of common lisp and we were talking about languages and language features and obviously we didnt agree about anything because well lisp is not c and vice versa its too many parentheses but suddenly we started making progress i said i had this problem and i developed it according to these ideas and they said why we had that problem different problem and we developed it with the same kind of principles and so we worked through large chunks of c and large chunks of common lisp and figured out we actually had similar sets of principles of how to do it but the constraints on our designs were very different and the aims for the usage was very different but there was commonality in the way you reason about language features and the fundamental principles you are trying to do so do you think thats possible so there just like there is perhaps a unified theory of physics of the fundamental forces of physics that im sure there is commonalities among the languages but theres also people involved that help drive the development of these languages do you have a hope or an optimism that there will be a unification if you think about physics and einstein towards a simplified language do you think thats possible lets remember sort of modern physics i think started with galileo in the 1300s so theyve had 700 years to get going modern computing started in about 49 weve got what is it 70 years they have 10 times furthermore they are not as bothered with people using physics the way we are worried about programming is done by humans so each have problems and constraints the others have but we are very immature compared to physics so i would look at sort of the philosophical level and look for fundamental principles like you dont leak resources you shouldnt you dont take errors at runtime that you dont need to you dont violate some kind of type system theres many kinds of type systems but when you have one you dont break it etc etc there will be quite a few and it will not be the same for all languages but i think if we step back at some kind of philosophical level we would be able to agree on sets of principles that applied to sets of problem areas and within an area of use like in cs case what used to be called systems programming the area between the hardware and the fluffier parts of the system you might very well see a convergence so these days you see rust having adopted raii and sometimes accuse me for having borrowed it 20 years before they discovered it but were seeing some kind of convergence here instead of relying on garbage collection all the time the garbage collection languages are doing things like the dispose patterns and such that imitate some of the construction destruction stuff and theyre trying not to use the garbage collection all the time and things like that so theres a conversion but i think we have to step back to the philosophical level agree on principles and then well see some conversions convergences and it will be application domain specific so a crazy question but i work a lot with machine learning with deep learning im not sure if you touch that world that much but you could think of programming as a thing that takes some input a programming is the task of creating a program and a program takes some input and produces some output so machine learning systems train on data in order to be able to take an input and produce output but theyre messy fuzzy things much like we as children grow up we take some input we make some output but were noisy we mess up a lot were definitely not reliable biological system are a giant mess so theres a sense in which machine learning is a kind of way of programming but just fuzzy its very very very different than c because c is just like you said its extremely reliable its efficient you can measure it you can test it in a bunch of different ways with biological systems or machine learning systems you cant say much except sort of empirically saying that 998 of the time it seems to work what do you think about this fuzzy kind of programming do you even see it as programming is it totally another kind of world i think its a different kind of world and it is fuzzy and in my domain i dont like fuzziness that is people say things like they want everybody to be able to program but i dont want everybody to program my airplane controls or the car controls i want that to be done by engineers i want that to be done with people that are specifically educated and trained for doing building things and it is not for everybody similarly a language like c is not for everybody it is generated to be a sharp and effective tool for professionals basically and definitely for people who aim at some kind of precision you dont have people doing calculations without understanding math counting on your fingers is not going to cut it if you want to fly to the moon and so there are areas where an 84 accuracy rate 16 false positive rate is perfectly acceptable and where people will probably get no more than 70 you said 98 what i have seen is more like 84 and by really a lot of blood sweat and tears you can get up to 925 so this is fine if it is say prescreening stuff before the human look at it it is not good enough for life threatening situations and so theres lots of areas where the fuzziness is perfectly acceptable and good and better than humans cheaper than humans cheaper than humans but its not the kind of engineering stuff im mostly interested in i worry a bit about machine learning in the context of cars you know much more about this than i do i worry too but im sort of an amateur here ive read some of the papers but ive not ever done it and the idea that scares me the most is the one i have heard and i dont know how common it is that you have this ai system machine learning all of these trained neural nets and when theres something thats too complicated they ask the human for help but the human is reading a book or asleep and he has 30 seconds or three seconds to figure out what the problem was that the ai system couldnt handle and do the right thing this is scary i mean how do you do the cutting work between the machine and the human its very very difficult and for the designer of one of the most reliable efficient and powerful programming languages c i can understand why that world is actually unappealing it is for most engineers to me its extremely appealing because we dont know how to get that interaction right but i think its possible but its very very hard it is and i was stating a problem not a solution that is impossible i mean i would much rather never rely on the human if youre driving a nuclear reactor if youre or an autonomous vehicle its much better to design systems written in c than never ask human for help lets just get one fact in yeah all of this ai stuff is on top of c so thats one reason i have to keep a weather eye out on whats going on in that field but i will never become an expert in that area but its a good example of how you separate different areas of applications and you have to have different tools different principles and then they interact no major system today is written in one language and there are good reasons for that when you look back at your life work what is a moment what is a event creation that youre really proud of they say damn i did pretty good there is it as obvious as the creation of c its obvious ive spent a lot of time with c and theres a combination of a few good ideas a lot of hard work and a bit of work that ive done and ive tried to get away from it a few times but i get dragged in again partly because im most effective in this area and partly because what i do has much more impact if i do it in the context of c i have four and a half million people that pick it up tomorrow if i get something right if i did it in another field i would have to start learning then i have to build it and then well see if anybody wants to use it one of the things that has kept me going for all of these years is one the good things that people do with it and the interesting things they do with it and also i get to see a lot of interesting stuff and talk to a lot of interesting people i mean if it has just been statements on paper on a screen i dont think i could have kept going but i get to see the telescopes up on mauna kea and i actually went and see how ford built cars and i got to jpl and see how they do the mars rovers theres so much cool stuff going on and most of the cool stuff is done by pretty nice people and sometimes in very nice places cambridge sophia silicon valley theres more to it than just code but code is central on top of the code are the people in very nice places well i think i speak for millions of people yaron in saying thank you for creating this language that so many systems are built on top of that make a better world so thank you and thank you for talking today yeah thanks and well make it even better good away out the clever bits and see if it still runs fast and sometimes it runs faster so i need the abstraction mechanisms or something like c to write compact high performance code there was a beautiful keynote by jason turner at the cppcon a couple of years ago where he decided he was going to program pong on motorola 6800 i think it was and he says well this is relevant because it looks like a microcontroller it has specialized hardware it has not very much memory and its relatively slow and so he shows in real time how he writes pong starting with fairly straightforward low level stuff improving his abstractions and what hes doing hes writing c and it translates into 86 assembler which you can do with clang and you can see it in real time its the compiler explorer which you can use on the web and then he wrote a little program that translated 86 assembler into motorola assembler and so he types and you can see this thing in real time wow you can see it in real time and even if you cant read the assembly code you can just see it his code gets better the code the assembler gets smaller he increases the abstraction level uses c 11 as it were better this code gets cleaner it gets easier maintainable the code shrinks and it keeps shrinking and i could not in any reasonable amount of time write that assembler as good as the compiler generated from really quite nice modern c and ill go as far as to say the thing that looked like c was significantly uglier and smaller and larger when it became machine code so the abstractions that can be optimized are important i would love to see that kind of visualization in larger code bases yeah that might be beautiful but you cant show a larger code base in a one hour talk and have it fit on screen right so thats c and c so my two languages would be machine code and c and then i think you can learn a lot from the functional languages so pic has gloy ml i dont care which i think actually you learn the same lessons of expressing especially mathematical notions really clearly and having a type system thats really strict and then you should probably have a language for sort of quickly churning out something you could pick javascript you could pick python you could pick ruby what do you make of javascript in general so youre talking in the platonic sense about languages about what theyre good at what their philosophy of design is but theres also a large user base behind each of these languages and they use it in the way sometimes maybe it wasnt really designed for thats right javascript is used way beyond probably what it was designed for let me say it this way when you build a tool you do not know how its going to be used you try to improve the tool by looking at how its being used and when people cut their fingers off and try and stop that from happening but really you have no control over how something is used so im very happy and proud of some of the things c is being used at and some of the things i wish people wouldnt do bitcoin mining being my favorite example uses as much energy as switzerland and mostly serves criminals but back to the languages i actually think that having javascript run in the browser was an enabling thing for a lot of things yes you could have done it better but people were trying to do it better and they were using more principles language designs but they just couldnt do it right and the nonprofessional programmers that write lots of that code just couldnt understand them so it did an amazing job for what it was its not the prettiest language and i dont think it ever will be the prettiest language but lets not be bigots here so what was the origin story of c yeah you basically gave a few perspectives of your inspiration of object oriented programming thats you had a connection with c and performance efficiency was an important thing you were drawn to efficiency and reliability reliability you have to get both whats reliability i really want my telephone calls to get through and i want the quality of what i am talking coming out at the other end the other end might be in london or wherever and you dont want the system to be crashing if youre doing a bank you mustnt crash it might be your bank account that is in trouble theres different constraints like in games it doesnt matter too much if theres a crash nobody dies and nobody gets ruined but i am interested in the combination of performance partly because of sort of speed of things being done part of being able to do things that is necessary to have reliability of larger systems if you spend all your time interpreting a simple function call a simple function call you are not going to have enough time to do proper signal processing to get the telephone calls to sound right either that or you have to have ten times as many computers and you cant afford your phone anymore its a ridiculous idea in the modern world because we have solved all of those problems i mean they keep popping up in different ways because we tackle bigger and bigger problems so efficiency remains always an important aspect but you have to think about efficiency not just as speed but as an enabler to important things and one of the things it enables is reliability is dependability when i press the pedal the brake pedal of a car it is not actually connected directly to anything but a computer that computer better work lets talk about reliability just a little bit so modern cars have ecus have millions of lines of code today so this is certainly especially true of autonomous vehicles where some of the aspects of the control or driver assistance systems that steer the car that keep it in the lane and so on so how do you think you know i talked to regulators people in government who are very nervous about testing the safety of these systems of software ultimately software that makes decisions that could lead to fatalities so how do we test software systems like these first of all safety like performance and like security is the systems property people tend to look at one part of a system at a time and saying something like this is secure thats all right i dont need to do that yeah that piece of code is secure ill buy your operator if you want to have reliability if you want to have performance if you want to have security you have to look at the whole system i did not expect you to say that but thats very true yes im dealing with one part of the system and i want my part to be really good but i know its not the whole system furthermore if making an individual part perfect may actually not be the best way of getting the highest degree of reliability and performance and such theres people that say c is not type safe you can break it sure i can break anything that runs on a computer i may not go through your type system if i wanted to break into your computer ill probably try sql injection and its very true if you think about safety or even reliability at the system level especially when a human being is involved it starts becoming hopeless pretty quickly in terms of proving that something is safe to a certain level yeah because theres so many variables its so complex well lets get back to something we can talk about and actually talk about it yeah talk about and actually make some progress on yes we can look at c programs and we can try and make sure they crash this often the way you do that is largely by simplification the first step is to simplify the code have less code have code that are less likely to go wrong its not by runtime testing everything it is not by big test frameworks that you are using yes we do that also but the first step is actually to make sure that when you want to express something you can express it directly in code rather than going through endless loops and convolutions in your head before it gets down the code the way you are thinking about a problem is not in the code there is a missing piece thats just in your head and the code you can see what it does but it cannot see what you thought about it unless you have expressed things directly when you express things directly you can maintain it its easier to find errors its easier to make modifications its actually easier to test it and lo and behold it runs faster and therefore you can use a smaller number of computers which means theres less hardware that could possibly break so i think the key here is simplification but it has to be to use the einstein quote as simple as possible and no simpler not simpler there are other areas with under constraints where you can be simpler than you can be in c but in the domain im dealing with thats the simplification im after so how do you inspire or ensure that the einstein level of simplification is reached so can you do code review can you look at code if i gave you the code for the ford f150 and said here is this a mess or is this okay is it possible to tell is it possible to regulate an experienced developer can look at code and see if it smells mixed metaphors deliberately yes the point is that it is hard to generate something that is really obviously clean and can be appreciated but you can usually recognize when you havent reached that point and so ive never looked at the f150 code so i wouldnt know but i know what i ought to be looking for ill be looking for some tricks that correlate with bugs and elsewhere and i have tried to formulate rules for what good code looks like and the current version of that is called the c core guidelines one thing people should remember is theres what you can do in a language and what you should do in a language you have lots of things that is necessary in some context but not in others theres things that exist just because theres 30 year old code out there and you cant get rid of it but you cant have rules that says when you create it try and follow these rules this does not create good programs by themselves but it limits the damage from mistakes it limits the possibilities of mistakes and basically we are trying to say what is it that a good programmer does at the fairly simple level of where you use the language and how you use it now i can put all the rules for chiseling in marble it doesnt mean that somebody who follows all of those rules can do a masterpiece by michelangelo that is theres something else to write a good program just is there something else to create an important work of art that is theres some kind of inspiration understanding gift but we can approach the sort of technical the craftsmanship level of it the famous painters the famous sculptures was among other things superb craftsmen they could express their ideas using their tools very well and so these days i think what im doing what a lot of people are doing we are still trying to figure out how it is to use our tools very well for a really good piece of code you need a spark of inspiration and you cant i think regulate that you cannot say that ill take a picture only ill buy your picture only if youre at least van gogh there are other things you can regulate but not the inspiration i think thats quite beautifully put it is true that there is as an experienced programmer when you see code thats inspired thats like michelangelo you know it when you see it and the opposite of that is code that is messy code that smells you know when you see it and im not sure you can describe it in words except vaguely through guidelines and so on yes its easier to recognize ugly than to recognize beauty in code and for the reason is that sometimes beauty comes from something thats innovative and unusual and you have to sometimes think reasonably hard to appreciate that on the other hand the messes have things that are in common and you can have static checkers and dynamic checkers that find a large number of the most common mistakes you can catch a lot of sloppiness mechanically im a great fan of static analysis in particular because you can check for not just the language rules but for the usage of language rules and i think we will see much more static analysis in the coming decade can you describe what static analysis is you represent a piece of code so that you can write a program that goes over that representation and look for things that are are right and not right so for instance you can analyze a program to see if resources are leaked thats one of my favorite problems its not actually all that hard and modern c but you can do it if you are writing in the c level you have to have a malloc and a free and they have to match if you have them in a single function you can usually do it very easily if theres a malloc here there should be a free there on the other hand in between can be showing complete code and then it becomes impossible if you pass that pointer to the memory out of a function and then want to make sure that the free is done somewhere else now it gets really difficult and so for static analysis you can run through a program and you can try and figure out if theres any leaks and what you will probably find is that you will find some leaks and youll find quite a few places where your analysis cant be complete it might depend on runtime it might depend on the cleverness of your analyzer and it might take a long time some of these programs run for a long time but if you combine such analysis with a set of rules that says how people could use it you can actually see why the rules are violated and that stops you from getting into the impossible complexities you dont want to solve the halting problem so static analysis is looking at the code without running the code yes and thereby its almost not a production code but its almost like an education tool of how the language should be used it guides you like it at its best right it would guide you in how you write future code as well and you learn together yes so basically you need a set of rules for how you use the language then you need a static analysis that catches your mistakes when you violate the rules or when your code ends up doing things that it shouldnt despite the rules because there is the language rules we can go further and again its back to my idea that id much rather find errors before i start running the code if nothing else once the code runs if it catches an error at run times i have to have an error handler and one of the hardest things to write in code is error handling code because you know something went wrong do you know really exactly what went wrong usually not how can you recover when you dont know what the problem was you cant be 100 sure what the problem was in many many cases and this is part of it so yes we need good languages we need good type systems we need rules for how to use them we need static analysis and the ultimate for static analysis is of course program proof but that still doesnt scale to the kind of systems we deploy then we start needing testing and the rest of the stuff so c is an object oriented programming language that creates especially with its newer versions as well talk about higher and higher levels of abstraction so how do you design lets even go back to the origin of c how do you design something with so much abstraction thats still efficient and is still something that you can manage do static analysis on you can have constraints on they can be reliable all those things weve talked about to me theres a slight tension between high level abstraction and efficiency thats a good question i could probably have a years course just trying to answer it yes theres a tension between efficiency and abstraction but you also get the interesting situation that you get the best efficiency out of the best abstraction and my main tool for efficiency for performance actually is abstraction so lets go back to how c was got there you said it was object oriented programming language i actually never said that its always quoted but i never did i said c supports object oriented programming and other techniques and thats important because i think that the best solution to most complex interesting problems require ideas and techniques from things that has been called object oriented data abstraction functional traditional c style code all of the above and so when i was designing c i soon realized i couldnt just add features if you just add what looks pretty or what people ask for or what you think is good one by one youre not going to get a coherent whole what you need is a set of guidelines that that guides your decisions should this feature be in or should this feature be out how should a feature be modified before it can go in and such and in the book i wrote about that the design evolution of c theres a whole bunch of rules like that most of them are not language technical theyre things like dont violate static type system because i like static type system for the obvious reason that i like things to be reliable on reasonable amounts of hardware but one of these rules is the zero overhead principle the what kind of principle the zero overhead principle it basically says that if you have an abstraction it should not cost anything compared to write the equivalent code at a lower level so if i have say a matrix multiply it should be written in such a way that you could not drop to the c level of abstraction and use arrays and pointers and such and run faster and so people have written such matrix multiplications and theyve actually gotten code that ran faster than fortran because once you had the right abstraction you can eliminate temporaries and you can do loop fusion and other good stuff like that thats quite hard to do by hand and in a lower level language and theres some really nice examples of that and the key here is that that matrix multiplication the matrix abstraction allows you to write code thats simple and easy you can do that in any language but with c it has the features so that you can also have this thing run faster than if you hand coded it now people have given that lecture many times i and others and a very common question after the talk where you have demonstrated that you can outperform fortran for dense matrix multiplication people come up and says yeah but that was c if i rewrote your code in c how much faster would it run the answer is much slower this happened the first time actually back in the 80s with a friend of mine called doug mcelroy who demonstrated exactly this effect and so the principle is you should give programmers the tools so that the abstractions can follow the zero void principle furthermore when you put in a language feature in c or a standard library feature you try to meet this it doesnt mean its absolutely optimal but it means if you hand code it with the usual facilities in the language in c in c you should not be able to better it usually you can do better if you use embedded assembler for machine code for some of the details to utilize part of a computer that the compiler doesnt know about but you should get to that point before you beat to the abstraction so thats a beautiful ideal to reach for and we meet it quite often quite often so wheres the magic of that coming from theres some of it is the compilation process so the implementation of c some of it is the design of the feature itself the guidelines so i think its important that you think about the guidelines so ive recently and often talked to chris latner so clang what just out of curiosity is your relationship in general with the different implementations of c as you think about you and committee and other people in c think about the design of features or design of previous features in trying to reach the ideal of zero overhead does the magic come from the design the guidelines or from the implementations and not all you go for programming technique programming language features and implementation techniques you need all three and how can you think about all three at the same time it takes some experience takes some practice and sometimes you get it wrong but after a while you sort of get it right i dont write compilers anymore but brian kernighan pointed out that one of the reasons c succeeded was some of the craftsmanship i put into the early compilers and of course i did the language assign of course i wrote a fair amount of code using this kind of stuff and i think most of the successes involve progress in all three areas together a small group of people can do that two three people can work together to do something like that its ideal if its one person that has all the skills necessary but nobody has all the skills necessary in all the fields where c is used so if you want to approach my ideal in say concurrent programming you need to know about algorithms from current programming you need to know the trigger of lock free programming you need to know something about compiler techniques and then you have to know some of the application areas where this is like some forms of graphics or some forms of what we call web server kind of stuff and thats very hard to get into a single head but small groups can do it too so is there differences in your view not saying which is better or so on but differences in the different implementations of c why are there several sort of maybe naive questions for me gcc clang so on this is a very reasonable question when i designed c most languages had multiple implementations because if you run on an ibm if you run on a sun if you run on a motorola there was just many many companies and they each have their own compilation structure and their own compilers it was just fairly common that there was many of them and i wrote c front assuming that other people would write compilers with c if successful and furthermore i wanted to utilize all the backend infrastructures that were available i soon realized that my users were using 25 different linkers i couldnt write my own linker yes i could but i couldnt write 25 linkers and also get any work done on the language and so it came from a world where there was many linkers many optimizers many compiler front ends not to start but many operating systems the whole world was not an 86 and a linux box or something whatever is the standard today in the old days they set a vax so basically i assumed there would be lots of compilers it was not a decision that there should be many compilers it was just a fact thats the way the world is and yes many compilers emerged and today theres at least four front ends clang gcc microsoft and edg it is design group they supply a lot of the independent organizations and the embedded systems industry and theres lots and lots of backends we have to think about how many dozen backends there are because different machines have different things especially in the embedded world the machines are very different the architectures are very different and so having a single implementation was never an option now i also happen to dislike monocultures monocultures they are dangerous because whoever owns the monoculture can go stale and theres no competition and theres no incentive to innovate theres a lot of incentive to put barriers in the way of change because hey we own the world and its a very comfortable world for us and who are you to mess with that so i really am very happy that theres four front ends for c clangs great but gcc was great but then it got somewhat stale clang came along and gcc is much better now microsoft is much better now so at least a low number of front ends puts a lot of pressure on standards compliance and also on performance and error messages and compile time speed all this good stuff that we want do you think crazy question there might come along do you hope there might come along implementation of c written given all its history written from scratch so written today from scratch well clang and the llvm is more or less written from scratch but theres been c 11 14 17 20 you know theres been a lot of i think sooner or later somebodys going to try again there has been attempts to write new c compilers and some of them has been used and some of them has been absorbed into others and such yeah itll happen so what are the key features of c and lets use that as a way to sort of talk about the evolution of c the new features so at the highest level what are the features that were there in the beginning what features got added lets first get a principle or an aim in place c is for people who want to use hardware really well and then manage the complexity of doing that through abstraction and so the first facility you have is a way of manipulating the machines at a fairly low level that looks very much like c it has loops it has variables it has pointers like machine addresses it can access memory directly it can allocate stuff in the absolute minimum of space needed on the machine theres a machine facing part of c which is roughly equivalent to c i said c could beat c and it can it doesnt mean i dislike c if i disliked c i wouldnt have built on it furthermore after dennis ritchie im probably the major contributor to modern c i had lunch with dennis most days for 16 years and we never had a harsh word between us so these c versus c fights are for people who dont quite understand whats going on then the other part is the abstraction the key is the class there the key is the class which is a user defined type my idea for the class is that you should be able to build a type thats just like the building types in the way you use them in the way you declare them in the way you get the memory and you can do just as well so in c theres an int as in c you should be able to build an abstraction a class which we can call capital int that you can use exactly like an integer and run just as fast as an integer theres the idea right there and of course you probably dont want to use the int itself but it has happened people have wanted integers that were range checked so that you couldnt overflow and such especially for very safety critical applications like the fuel injection for a marine diesel engine for the largest ships this is a real example by the way this has been done they built themselves an integer that was just like integer except that couldnt overflow if there was an overflow you went into the error handling and then you built more interesting types you can build a matrix which you need to do graphics or you could build a gnome for a video game and all these are classes and they appear just like the built in types exactly in terms of efficiency and so on so what else is there and flexibility so i dont know for people who are not familiar with object oriented programming theres inheritance theres a hierarchy of classes you can just like you said create a generic vehicle that can turn left so what people found was that you dont actually know how do i say this a lot of types are related that is the vehicles all vehicles are related bicycles cars fire engines tanks they have some things in common and some things that differ and you would like to have the common things common and having the differences specific and when you didnt want to know about the differences just turn left you dont have to worry about it thats how you get the traditional object oriented programming coming out of simula adopted by smalltalk and c and all the other languages the other kind of obvious similarity between types comes when you have something like a vector fortran gave us the vector as called array of doubles but the minute you have a vector of doubles you want a vector of double precision doubles and for short doubles for graphics and why should you not have a vector of integers while youre added or a vector of vectors and a vector of vectors of chess pieces now you have a board right so this is you', 'the following is a conversation with elon musk part 2 the second time we spoke on the podcast with parallels if not in quality than an outfit to the objectively speaking greatest sequel of all time godfather part 2 as many people know elon musk is a leader of tesla spacex neuralink and the boring company what may be less known is that hes a world class engineer and designer constantly emphasizing first principles thinking and taking on big engineering problems that many before him will consider impossible as scientists and engineers most of us dont question the way things are done we simply follow the momentum of the crowd but revolutionary ideas that change the world on the small and large scales happen when you return to the fundamentals and ask is there a better way this conversation focuses on the incredible engineering and innovation done in brain computer interfaces at neuralink this work promises to help treat neurobiological diseases to help us further understand the connection between the individual neuron to the high level function of the human brain and finally to one day expand the capacity of the brain through two way communication with computational devices the internet and artificial intelligence systems this is the artificial intelligence podcast if you enjoy it subscribe by youtube apple podcasts spotify support on patreon or simply connect with me on twitter at lex friedman spelled f r i d m a n and now as an anonymous youtube commenter referred to our previous conversation as the quote historical first video of two robots conversing without supervision heres the second time the second conversation with elon musk lets start with an easy question about consciousness in your view is consciousness something thats unique to humans or is it something that permeates all matter almost like a fundamental force of physics i dont think consciousness permeates all matter panpsychists believe that yeah theres a philosophical how would you tell thats true thats a good point i believe in scientific methods i dont know about your mind or anything but the scientific method is like if you cannot test the hypothesis then you cannot reach meaningful conclusion that it is true do you think consciousness understanding consciousness is within the reach of science of the scientific method we can dramatically improve our understanding of consciousness you know hot press to say that we understand anything with complete accuracy but can we dramatically improve our understanding of consciousness i believe the answer is yes does an ai system in your view have to have consciousness in order to achieve human level or superhuman level intelligence does it need to have some of these human qualities that consciousness maybe a body maybe a fear of mortality capacity to love those kinds of silly human things theres a different you know theres this theres the scientific method which i very much believe in where something is true to the degree that it is testably so and otherwise youre really just talking about you know preferences or untestable beliefs or that you know that kind of thing so it ends up being somewhat of a semantic question where we were conflating a lot of things with the word intelligence if we parse them out and say you know are we headed towards the future where an ai will be able to outthink us in every way then the answer is unequivocally yes in order for an ai system that needs to outthink us in every way it also needs to have a capacity to have consciousness self awareness and understanding it will be self aware yes thats different from consciousness i mean to me in terms of what what consciousness feels like it feels like consciousness is in a different dimension but this is this could be just an illusion you know if you damage your brain in some way physically you get you you damage your consciousness which implies that consciousness is a physical phenomenon and in my view the thing is that that i think are really quite quite likely is that digital intelligence will be able to outthink us in every way and it will simply be able to simulate what we consider consciousness so to the degree that you would not be able to tell the difference and from the from the aspect of the scientific method its might as well be consciousness if we can simulate it perfectly if you cant tell the difference when this is sort of the turing test but think of a more sort of advanced version of the turing test if youre if youre talking to a digital super intelligence and cant tell if that is a computer or a human like lets say youre just having conversation over a phone or a video conference or something where youre you think youre talking looks like a person makes all of the right inflections and movements and all the small subtleties that constitute a human and talks like human makes mistakes like a human like and you literally just cant tell is this are you video conferencing with a person or or an ai might as well might as well be human so on a darker topic youve expressed serious concern about existential threats of ai its perhaps one of the greatest challenges our civilization faces but since i would say were kind of an optimistic descendants of apes perhaps we can find several paths of escaping the harm of ai so if i can give you an example of an example of an example of escaping the harm of ai so if i can give you three options maybe you can comment which do you think is the most promising so one is scaling up efforts on ai safety and beneficial ai research in hope of finding an algorithmic or maybe a policy solution two is becoming a multi planetary species as quickly as possible and three is merging with ai and riding the wave of that increasing intelligence as it continuously improves what do you think is most promising most interesting as a civilization that we should invest in i think theres a lot of tremendous amount of investment going on in ai where theres a lack of investment is in ai safety and there should be in my view a government agency that oversees anything related to ai to confirm that it is does not represent a public safety risk just as there is a regulatory authority for the food and drug administration is thats for automotive safety theres the faa for aircraft safety which i really come to the conclusion that it is important to have a government referee or referee that is serving the public interest in ensuring that things are safe when when theres a potential danger to the public i would argue that ai is unequivocally something that has potential to be dangerous to the public and therefore should have a regulatory agency just as other things that are dangerous to the public have a regulatory agency but let me tell you the problem with this is that the government moves very slowly and the rate of the rate the usually way a regulatory agency comes into being is that something terrible happens theres a huge public outcry and years after that theres a regulatory agency or a rule put in place take something like like seatbelts it was known for a decade or more that seatbelts would have a massive impact on safety and save so many lives in serious injuries and the car industry fought the requirement to put seatbelts in tooth and nail thats crazy yeah and hundreds of 1000s of people probably died because of that and they said people wouldnt buy cars if they had seatbelts which is obviously absurd yeah or look at the tobacco industry and how long they fought any thing about smoking thats part of why i helped make that movie thank you for smoking you can sort of see just how pernicious it can be when you have these companies effectively achieve regulatory capture of government the bad people in the community refer to the advent of digital super intelligence as a singularity that is not to say that it is good or bad but that it is very difficult to predict what will happen after that point and then theres some probability it will be bad some probably itll be it will be good we obviously want to affect that probability and have it be more good than bad well let me on the merger with ai question and the incredible work thats being done at neuralink theres a lot of fascinating innovation here across different disciplines going on so the flexible wires the robotic sewing machine that responsive brain movement everything around ensuring safety and so on so we currently understand very little about the human brain do you also hope that the work at neuralink will help us understand more about our about our human brain yeah i think the work in neuralink will definitely shed a lot of insight into how the brain the mind works right now just the data we have regarding how the brain works is very limited you know weve got fmri which is that thats kind of like putting us you know stethoscope on the outside of a factory wall and then putting it like all over the factory wall and you can sort of hear the sounds but you dont know what the machines are doing really its hard you can infer a few things but its very broad brushstroke in order to really know whats going on in the brain you really need you have to have high precision sensors and then you want to have stimulus and response like if you trigger a neuron what how do you feel what do you see how does it change your perception of the world youre speaking to physically just getting close to the brain being able to measure signals how do you know whats going on in the brain physically just getting close to the brain being able to measure signals from the brain will give us sort of open the door inside the factory yes exactly being able to have high precision sensors that tell you what individual neurons are doing and then being able to trigger a neuron and see what the response is in the brain so you can see the consequences of if you fire this neuron what happens how do you feel what does it change itll be really profound to have this in people because people can articulate their change like if theres a change in mood or if they can tell you if they can see better or hear better or be able to form sentences better or worse or their memories are jogged or that kind of thing so on the human side theres this incredible general malleability plasticity of the human brain the human brain adapts adjusts and so on so thats not that plastic to be totally frank so theres a firm structure but nevertheless theres some plasticity and the open question is sort of if i could ask a broad question is how much that plasticity can be utilized sort of on the human side theres some plasticity in the human brain and on the machine side we have neural networks machine learning artificial intelligence its able to adjust and figure out signals so theres a mysterious language that we dont perfectly understand thats within the human brain and then were trying to understand that language to communicate both directions so the brain is adjusting a little bit we dont know how much and the machine is adjusting where do you see as they try to sort of reach together almost like with an alien species try to find a protocol communication protocol that works where do you see the biggest the biggest benefit arriving from on the machine side or the human side do you see both of them working together i think the machine side is far more malleable than the biological side by a huge amount so itll be the machine that adapts to the brain thats the only thing thats possible the brain cant adapt that well to the machine you cant have neurons start to regard an electrode as another neuron because neurons just theres like the pulse and so something else is pulsing so there is that elasticity in the interface which we believe is something that can happen but the vast majority of the malleability will have to be on the machine side but its interesting when you look at that synaptic plasticity at the interface side there might be like an emergent plasticity because its a whole nother its not like in the brain its a whole nother extension of the brain you know we might have to redefine what it means to be malleable for the brain so maybe the brain is able to adjust to external interfaces there will be some adjustments to the brain because theres going to be something reading and simulating the brain and so it will adjust to that thing but most the vast majority of the adjustment will be on the machine side this is just this is just it has to be that otherwise it will not work ultimately like we currently operate on two layers we have sort of a limbic like prime primitive brain layer which is where all of our kind of impulses are coming from its sort of like weve got weve got like a monkey brain with a computer stuck on it thats thats the human brain and a lot of our impulses and everything are driven by the monkey brain and the computer the cortex is constantly trying to make the monkey brain happy its not the cortex thats steering the monkey brains the monkey brain steering the cortex you know the cortex is the part that tells the story of the whole thing so we convince ourselves its its more interesting than just the monkey brain the cortex is like what we call like human intelligence you know its just like thats like the advanced computer relative to other creatures the other creatures do not have either really they dont they dont have the computer or they have a very weak computer relative to humans but its its like it sort of seems like surely the really smart thing should control the dumb thing but actually the dumb thing controls the smart thing so do you think some of the same kind of machine learning methods whether thats natural language processing applications are going to be applied for the communication between the machine and the brain to learn how to do certain things like movement of the body how to process visual stimuli and so on do you see the value of using machine learning to understand the language of the two way communication with the brain sure yeah absolutely i mean were neural net and that you know ai is basically neural net so its like digital neural net will interface with biological neural net and hopefully bring us along for the ride yeah but the vast majority of our intelligence will be digital like so like think of like the difference in intelligence between your cortex and your limbic system is gigantic your limbic system really has no comprehension of what the hell the cortex is doing its just literally hungry you know or tired or angry or sexy or something you know thats just and then that communicates that that impulse to the cortex and tells the cortex to go satisfy that then love a great deal of like a massive amount of thinking like truly stupendous amount of thinking has gone into sex without purpose without procreation without procreation which is actually quite a silly action in the absence of procreation its a bit silly why are you doing it because it makes the limbic system happy thats why thats why but its pretty absurd really well the whole of existence is pretty absurd in some kind of sense yeah but i mean this is a lot of computation has gone into how can i do more of that with procreation not even being a factor this is i think a very important area of research by nsfw an agency that should receive a lot of funding especially after this conversation i propose the formation of a new agency oh boy what is the most exciting or some of the most exciting things that you see in the future impact of neuralink both in the science the engineering and societal broad impact neuralink i think at first will solve a lot of brain related diseases so it could be anything from like autism schizophrenia memory loss like everyone experiences memory loss at certain points in age parents cant remember their kids names and that kind of thing so it could be anything from like autism schizophrenia memory loss like everyone experiences memory loss at certain points in age parents cant remember their kids names and that kind of thing so theres a tremendous amount of good that neuralink can do in solving critical damage to the brain or the spinal cord theres a lot that can be done to improve quality of life of individuals and those will be steps to address the existential risk associated with digital superintelligence like we will not be able to be smarter than a digital supercomputer so therefore if you cannot beat them join them and at least we wont have that option so you have hope that neuralink will be able to be a kind of connection to allow us to merge the wave of the improving ai systems i think the chance is above zero percent so its non zero theres a chance and thats what ive seen dumb and dumber yes so im saying theres a chance hes saying one in a billion or one in a million whatever it was a dumb and dumber you know it went from maybe one in a million to improving maybe itll be one in a thousand and then one in a hundred then one in ten depends on the rate of improvement of neuralink and how fast were able to do make progress well ive talked to a few folks here that are quite brilliant engineers so im excited yeah i think its like fundamentally good you know giving somebody back full motor control after theyve had a spinal cord injury you know restoring brain functionality after a stroke solving debilitating genetically oriented brain diseases these are all incredibly great i think and in order to do these you have to be able to interface with neurons at a detailed level and you need to be able to fire the right neurons read the right neurons and and then effectively you can create a circuit replace whats broken with with silicon and essentially fill in the missing functionality and then over time we can develop a tertiary layer so if like the limbic system is the primary layer then the cortex is like the second layer and as i said obviously the cortex is vastly more intelligent than the limbic system but people generally like the fact that they have a limbic system and a cortex i havent met anyone who wants to delete either one of them theyre like okay ill keep them both thats cool the limbic system is kind of fun thats where the fun is absolutely and then people generally dont want to lose their cortex either theyre like having the cortex and the limbic system and then theres a tertiary layer which will be digital superintelligence and i think theres room for optimism given that the cortex the cortex is very intelligent and limbic system is not and yet they work together well perhaps there can be a tertiary layer where digital superintelligence lies and that will be vastly more intelligent than the cortex but still coexist peacefully and in a benign manner with the cortex and limbic system thats a super exciting future both in low level engineering that i saw as being done here and the actual possibility in the next few decades its important that neuralink solve this problem sooner rather than later because the point at which we have digital superintelligence thats when we pass the singularity and things become just very uncertain it doesnt mean that theyre necessarily bad or good for the point at which we pass singularity things become extremely unstable so we want to have a human brain interface before the singularity or at least not long after it to minimize existential risk for humanity and consciousness as we know it so theres a lot of fascinating actual engineering low level problems here at neuralink that are quite exciting the problems that we face in neuralink are material science electrical engineering software mechanical engineering microfabrication its a bunch of engineering disciplines essentially thats what it comes down to is you have to have a tiny electrode so small it doesnt hurt neurons but its got to last for as long as a person so its going to last for decades and then youve got to take that signal youve got to process that signal locally at low power so we need a lot of chip design engineers because were going to do signal processing and do so in a very power efficient way so that we dont heat your brain up because the brain is very heat sensitive and then weve got to take those signals and were going to do something with them and then weve got to stimulate the back to bidirectional communication so somebodys good at material science software and weve got to do a lot of that so somebodys good at material science software mechanical engineering electrical engineering chip design microfabrication those are the things we need to work on we need to be good at material science so that we can have tiny electrodes that last a long time and its a tough thing with the material science problem its a tough one because youre trying to read and simulate electrically in an electrically active area your brain is very electrically active and electrochemically active so how do you have a coating on the electrode that doesnt dissolve over time and is safe in the brain this is a very hard problem and then how do you collect those signals in a way that is most efficient because you really just have very tiny amounts of power to process those signals and then we need to automate the whole thing so its like lasik if this is done by neurosurgeons theres no way it can scale to a large number of people and it needs to scale to a large number of people because i think ultimately we want the future to be determined by a large number of humans do you think that this has a chance to revolutionize surgery period so neurosurgery and surgery all across yeah for sure its got to be like lasik if lasik had to be done by hand by a person that wouldnt be great its done by a robot and the ophthalmologist kind of just needs to make sure your heads in the right position and then they just press a button and go smartsummon and soon autopark takes on the full beautiful mess of parking lots and their human to human nonverbal communication i think it has actually the potential to have a profound impact in changing how our civilization looks at ai and robotics because this is the first time human beings people that dont own a tesla may have never seen a tesla or heard about a tesla get to watch hundreds of thousands of cars without a driver do you see it this way almost like an education tool for the world about ai do you feel the burden of that the excitement of that or do you just think its a smart parking feature i do think you are getting at something important which is most people have never really seen a robot and what is the car that is autonomous its a four wheeled robot yeah it communicates a certain sort of message with everything from safety to the possibility of what ai could bring to its current limitations its current challenges its whats possible do you feel the burden of that almost like a communicator educator to the world about ai we were just really trying to make peoples lives easier with autonomy but now that you mentioned it i think it will be an eye opener to people about robotics because theyve really never seen most people never seen a robot and there are hundreds of thousands of teslas wont be long before theres a million of them that have autonomous capability and the drive without a person in it and you can see the kind of evolution of the cars personality and and thinking with each iteration of autopilot you can see its its uncertain about this or it gets it but now its more certain now its moving in a slightly different way like i can tell immediately if a car is on tesla autopilot because its got just little nuances of movement it just moves in a slightly different way cars on tesla autopilot for example on the highway are far more precise about being in the center of the lane than a person if you drive down the highway and look at how at where cars are the human driven cars are within their lane theyre like bumper cars theyre like moving all over the place the car in autopilot dead center yeah so the incredible work thats going into that neural network its learning fast autonomy is still very very hard we dont actually know how hard it is fully of course you look at the most problems you tackle this one included with an exponential lens but even with an exponential improvement things can take longer than expected sometimes so where does tesla currently stand on its quest for full autonomy whats your sense when can we see successful deployment of full autonomy well on the highway already the the probability of intervention is extremely low yes so for highway autonomy with the latest release especially the probability of needing to intervene is really quite low in fact id say for stop and go traffic its far safer than a person right now the probability of an injury or impact is much much lower for autopilot than a person and then with navigating autopilot you can change lanes take highway interchanges and then were coming at it from the other direction which is low speed full autonomy and in a way this is like how does a person learn to drive you learn to drive in the parking lot you know the first time you learn to drive probably wasnt jumping on august street in san francisco thatd be crazy you learn to drive in the parking lot get things get things right at low speed and then the missing piece that were working on is traffic lights and stop streets stop streets i would say actually also relatively easy because you know you kind of know where the stop street is worst case in geocoders and then use visualization to see where the line is and stop at the line to eliminate the gps error so actually id say its probably complex traffic lights and very windy roads are the two things that need to get solved whats harder perception or control for these problems so being able to perfectly perceive everything or figuring out a plan once you perceive everything how to interact with all the agents in the environment in your sense from a learning perspective is perception or action harder and that giant beautiful multitask learning neural network the hottest thing is having accurate representation of the physical objects in vector space so transfer taking the visual input primarily visual input some sonar and radar and and then creating the an accurate vector space representation of the objects around you once you have an accurate vector space representation the planning and control is relatively easier that is relatively easy basically once you have accurate vector space representation then youre kind of like a video game like cars and like grand theft auto or something like they work pretty well they drive down the road they dont crash you know pretty much unless you crash into them thats because theyve theyve got an accurate vector space representation of where the cars are and theyre just and then theyre rendering that as the as the output do you have a sense high level that teslas on track on being able to achieve full autonomy so on the highway yeah absolutely and still no driver state driver sensing and we have driver sensing with torque on the wheel thats right yeah by the way just a quick comment on karaoke most people think its fun but i also think it is a driving feature ive been saying for a long time singing in the car is really good for attention management and vigilance management thats right tesla karaoke is great its one of the most fun features of the car do you think of a connection between fun and safety sometimes yeah you can do both at the same time thats great i just met with andrew and wife of carl sagan directed cosmos im generally a big fan of carl sagan hes super cool and had a great way of putting things all of our consciousness all civilization everything weve ever known and done is on this tiny blue dot people also get they get too trapped in there this is like squabbles amongst humans lets not think of the big picture they take civilization and our continued existence for granted i shouldnt do that look at the history of civilizations they rise and they fall and now civilization is all its globalized and so civilization i think now rises and falls together theres no theres not geographic isolation this is a big risk things dont always go up that should be thats an important lesson of history in 1990 at the request of carl sagan the voyager one spacecraft which is a spacecraft thats reaching out farther than anything human made into space turned around to take a picture of earth from 36 billion years ago and thats a picture of earth from 37 billion miles away and as youre talking about the pale blue dot that picture there takes up less than a single pixel in that image yes appearing as a tiny blue dot as a pale blue dot as carl sagan called it so he spoke about this dot of ours in 1994 and if you could humor me i was wondering if in the last two minutes you could read the words that he wrote describing this pale blue dot sure yes its funny the universe appears to be 138 billion years old earth is like four and a half billion years old in another half billion years or so the sun will expand and probably evaporate the oceans and make life impossible on earth which means that if it had taken consciousness 10 longer to evolve it would never have evolved at all its 10 longer and i wonder how many dead one planet civilizations there are out there in the cosmos that never made it to the other planet and ultimately extinguished themselves or were destroyed by external factors probably a few its only just possible to travel to mars just barely if g was 10 more it wouldnt work really if g was 10 lower it would be easy like you can go single stage from the surface of mars all the way to the surface of the earth because mars is 37 earths gravity we need a giant booster to get off the earth channeling carl sagan look again at that dot thats here thats home thats us on it everyone you love everyone you know everyone youve ever heard of every human being who ever was lived out their lives the aggregate of our joy and suffering thousands of confident religions ideologies and economic doctrines every hunter and farger every hero and coward every creator and destroyer of civilization every king and peasant every young couple in love every mother and father hopeful child inventor and explorer every teacher of morals every corrupt politician every superstar every supreme leader every saint and sinner in the history of our species lived there on a mode of dust suspended in a sunbeam our planet is a lonely speck in the great enveloping cosmic dark in our obscurity in all this vastness there is no hint that help will come from elsewhere to save us from ourselves the earth is the only world known so far to harbor life there is nowhere else at least in the near future to which our species could migrate this is not true this is false mars and i think carl sagan would agree with that he couldnt even imagine it at that time so thank you for making the world dream and thank you for talking today i really appreciate it thank you']\n"
          ]
        }
      ],
      "source": [
        "print(corpus_nopunct[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yxZ0MA02vUN6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxZ0MA02vUN6",
        "outputId": "0df26740-a50f-470b-a6ee-1826212a2bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id            guest                    title  \\\n",
            "0   1      Max Tegmark                 Life 3.0   \n",
            "1   2    Christof Koch            Consciousness   \n",
            "2   3    Steven Pinker  AI in the Age of Reason   \n",
            "3   4    Yoshua Bengio            Deep Learning   \n",
            "4   5  Vladimir Vapnik     Statistical Learning   \n",
            "\n",
            "                                                text  \\\n",
            "0  As part of MIT course 6S099, Artificial Genera...   \n",
            "1  As part of MIT course 6S099 on artificial gene...   \n",
            "2  You've studied the human mind, cognition, lang...   \n",
            "3  What difference between biological neural netw...   \n",
            "4  The following is a conversation with Vladimir ...   \n",
            "\n",
            "                                        text_nopunct  \n",
            "0  as part of mit course 6s099 artificial general...  \n",
            "1  as part of mit course 6s099 on artificial gene...  \n",
            "2  youve studied the human mind cognition languag...  \n",
            "3  what difference between biological neural netw...  \n",
            "4  the following is a conversation with vladimir ...  \n"
          ]
        }
      ],
      "source": [
        "# Crear una lista vacía para almacenar los documentos procesados\n",
        "df['text_nopunct'] = corpus_nopunct\n",
        "#muestra los docuemntos procesados una ves que se ha realizado el preprocesamiento\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WDAwBDJ0gL5M",
      "metadata": {
        "id": "WDAwBDJ0gL5M"
      },
      "source": [
        "# Cargamos los stopwords para proceder a eliminarlos de nuestro corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ndICLRKEvULQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndICLRKEvULQ",
        "outputId": "6b5c467b-f0d6-4828-fad5-d9b4fdad7290"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the stopwords corpus\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#muestra los docuemntos procesados una ves que se ha realizado el preprocesamiento\n",
        "stopw = set(stopwords.words('english'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wgMU5brwwG7Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgMU5brwwG7Z",
        "outputId": "a50f62e8-b005-4da0-a5a8-c79d651cd3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'itself', \"aren't\", 'its', 'myself', 'don', 'while', \"couldn't\", 'on', 'is', \"hadn't\", 'for', 'you', 'doing', 'her', 'how', 'our', 'are', 'about', 'where', 'such', 'himself', 'at', 'only', \"doesn't\", 'i', 'shan', 'isn', 'here', 'needn', 'any', 'some', \"should've\", \"she's\", 'when', 'these', 'few', 'a', 'being', 'again', 'y', 'both', 'aren', \"won't\", 'same', 'than', 'all', 'it', 'below', 'we', 'under', 'his', 'and', 'was', 'now', 'from', 'over', 'to', 'ours', 'who', 'hadn', 'won', 'the', 'll', 'nor', 'very', 'do', \"wasn't\", 'am', \"you're\", 'just', 'theirs', 'through', 'ma', \"that'll\", 'in', 'weren', 'out', 'why', \"you've\", 've', \"wouldn't\", 'doesn', 'after', \"it's\", 'once', 'if', 'so', 'they', 'd', 'into', \"haven't\", 'by', 'most', 'have', 'she', 'this', 'but', \"don't\", 'own', 'couldn', 'wasn', 'didn', 'or', \"you'd\", 'ourselves', \"weren't\", 'had', \"hasn't\", \"shouldn't\", 'what', 'whom', 'further', 'herself', \"didn't\", 'haven', 'wouldn', 'o', 'm', 'hasn', 'mustn', 'has', 'until', \"mustn't\", 'he', 'been', 'yourself', 's', 'between', 'that', \"mightn't\", 'because', 't', 'mightn', 'other', 'did', 'yours', 'each', \"needn't\", 'more', 'an', 'no', \"shan't\", 'with', 'their', 'should', 'having', 'me', 'hers', \"isn't\", 'be', 'then', 'shouldn', 'there', 'those', 'off', 'which', 'yourselves', 'not', 'ain', 'before', 'my', 'will', 'can', 'your', 'above', 'themselves', 'them', \"you'll\", 'were', 'too', 'as', 'of', 'against', 'down', 'during', 'him', 're', 'up', 'does'}\n",
            "179\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Mostrar los stopwords\n",
        "print(stopw)\n",
        "#Mostar el tamano del arreglo de stopwords\n",
        "print(len(stopw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tib9rUVN6Jw-",
      "metadata": {
        "id": "tib9rUVN6Jw-"
      },
      "outputs": [],
      "source": [
        "# Inicializa una lista vacía para almacenar los documentos sin stopwords\n",
        "corpus_nostopw = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nSH7ytrsvUIw",
      "metadata": {
        "id": "nSH7ytrsvUIw"
      },
      "outputs": [],
      "source": [
        " # Itera sobre todos los documentos\n",
        "for doc in corpus_nopunct:\n",
        "    # Inicializa una lista vacía para almacenar las palabras sin stopwords\n",
        "    clean_doc = []\n",
        "    # Tokenizar el documento en palabras\n",
        "    doc_array = doc.split(' ')\n",
        "    # Iterar sobre cada palabra en la lista\n",
        "    for word in doc_array:\n",
        "       # Verifica si la palabra no está en la lista de stopwords\n",
        "        if word not in stopw:\n",
        "        # Si la palabra no está en la lista de stopwords, la agrega a la lista de palabras sin stopwords\n",
        "           clean_doc.append(word)\n",
        "      # Une las palabras en clean_doc con un espacio y agrega el documento procesado a corpus_nostopw\n",
        "    corpus_nostopw.append(' '.join(clean_doc))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1jMjKbxMipoP",
      "metadata": {
        "id": "1jMjKbxMipoP"
      },
      "source": [
        "### Datos limpios mostrados en un DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Mes0xwI1dQH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mes0xwI1dQH",
        "outputId": "4e691c9e-98b3-4386-82f9-7460dd6a9ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id            guest                    title  \\\n",
            "0   1      Max Tegmark                 Life 3.0   \n",
            "1   2    Christof Koch            Consciousness   \n",
            "2   3    Steven Pinker  AI in the Age of Reason   \n",
            "3   4    Yoshua Bengio            Deep Learning   \n",
            "4   5  Vladimir Vapnik     Statistical Learning   \n",
            "\n",
            "                                                text  \\\n",
            "0  As part of MIT course 6S099, Artificial Genera...   \n",
            "1  As part of MIT course 6S099 on artificial gene...   \n",
            "2  You've studied the human mind, cognition, lang...   \n",
            "3  What difference between biological neural netw...   \n",
            "4  The following is a conversation with Vladimir ...   \n",
            "\n",
            "                                        text_nopunct  \\\n",
            "0  as part of mit course 6s099 artificial general...   \n",
            "1  as part of mit course 6s099 on artificial gene...   \n",
            "2  youve studied the human mind cognition languag...   \n",
            "3  what difference between biological neural netw...   \n",
            "4  the following is a conversation with vladimir ...   \n",
            "\n",
            "                                        text_nostopw  \n",
            "0  part mit course 6s099 artificial general intel...  \n",
            "1  part mit course 6s099 artificial general intel...  \n",
            "2  youve studied human mind cognition language vi...  \n",
            "3  difference biological neural networks artifici...  \n",
            "4  following conversation vladimir vapnik hes co ...  \n"
          ]
        }
      ],
      "source": [
        "# Crear una lista vacía para almacenar los documentos procesados\n",
        "df['text_nostopw'] = corpus_nostopw\n",
        "#Impresion de las primeras filas\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pHyfQuYJvUF7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHyfQuYJvUF7",
        "outputId": "628cf7cb-0e60-4fd2-b41c-525d41421dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44733\n"
          ]
        }
      ],
      "source": [
        "#Muestra el tamaño del corpus procesados\n",
        "print(len(corpus_nostopw[0]))\n",
        "#rint(len(df['text'][0].split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vDdo3fE9vUBq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDdo3fE9vUBq",
        "outputId": "97681084-3b84-4531-b066-54d90990b286"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13424"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df['text'].iloc[0].split(' '))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CNo2TkcD3_BG",
      "metadata": {
        "id": "CNo2TkcD3_BG"
      },
      "source": [
        "# Step 4 : Vector Space Representation - TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xlAGnb_94Joa",
      "metadata": {
        "id": "xlAGnb_94Joa"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#Impresion de las primeras filas\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Aplica el vectorizador para ajustar y transformar los documentos limpios en una matriz TF-IDF\n",
        "tfidf_mtx = vectorizer.fit_transform(df['text_nostopw'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qyVDsxF_9ttJ",
      "metadata": {
        "id": "qyVDsxF_9ttJ"
      },
      "source": [
        "# Step 5: Vector Space Representation  BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imZeI_Mq9tK9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imZeI_Mq9tK9",
        "outputId": "e0281264-0ae6-4f74-8f59-3c9b8deee820"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Cargar el tokenizador y el modelo BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GHTO_Z97mJn2",
      "metadata": {
        "id": "GHTO_Z97mJn2"
      },
      "source": [
        "### Funcion generador de embeddings BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bqgDYhN-IjO",
      "metadata": {
        "id": "4bqgDYhN-IjO"
      },
      "outputs": [],
      "source": [
        "def generate_bert_embeddings(texts):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "      # Tokenizar el texto y convertirlo en tensores usando TensorFlow\n",
        "        inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
        "      #Pasar los inputs al modelo BERT para obtener las representaciones\n",
        "        outputs = model(**inputs)\n",
        "        # Usar la representación de la [CLS] token o la media de todas las representaciones\n",
        "        embeddings.append(outputs.last_hidden_state[:, 0, :])\n",
        " # Convertir la lista de embeddings en un numpy array y transponer las dimensiones\n",
        "    return np.array(embeddings).transpose(0,2,1)\n",
        "# Generar embeddings BERT para el corpus de textos\n",
        "corpus_bert = generate_bert_embeddings(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2_x3dAyBz93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2_x3dAyBz93",
        "outputId": "6995b4c0-b3d5-4d78-c4e5-b9d5407cedec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(319, 768, 1)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Devuelve la forma del array corpus_bert\n",
        "corpus_bert.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "kHI39Bzy-tP_",
      "metadata": {
        "id": "kHI39Bzy-tP_"
      },
      "outputs": [],
      "source": [
        "# Define una lista con la consulta 'Computer Science'\n",
        "query = ['Artificial General']\n",
        "# Genera embeddings BERT para la consulta\n",
        "query_bert = generate_bert_embeddings(query)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "T_-0cpcQB72d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_-0cpcQB72d",
        "outputId": "39b35124-cddd-4577-815d-11c71011b186"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 768, 1)"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Devuelve la forma del array query_bert\n",
        "query_bert.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "mh9F5r1m_iO7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh9F5r1m_iO7",
        "outputId": "464b64d1-6ceb-460a-f2f3-af35dfe67885"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.66573834],\n",
              "       [0.68808705],\n",
              "       [0.6628542 ],\n",
              "       [0.5722449 ],\n",
              "       [0.6859926 ],\n",
              "       [0.71603954],\n",
              "       [0.6740874 ],\n",
              "       [0.6259572 ],\n",
              "       [0.63718104],\n",
              "       [0.6339799 ],\n",
              "       [0.6250173 ],\n",
              "       [0.66667867],\n",
              "       [0.6957108 ],\n",
              "       [0.64849   ],\n",
              "       [0.64849   ],\n",
              "       [0.6591395 ],\n",
              "       [0.7493383 ],\n",
              "       [0.6533493 ],\n",
              "       [0.47185946],\n",
              "       [0.6283725 ],\n",
              "       [0.70002836],\n",
              "       [0.5759804 ],\n",
              "       [0.5983999 ],\n",
              "       [0.6757225 ],\n",
              "       [0.5966219 ],\n",
              "       [0.63746464],\n",
              "       [0.68690896],\n",
              "       [0.6173605 ],\n",
              "       [0.5717934 ],\n",
              "       [0.6350664 ],\n",
              "       [0.6329876 ],\n",
              "       [0.6906017 ],\n",
              "       [0.6739389 ],\n",
              "       [0.6484343 ],\n",
              "       [0.67641956],\n",
              "       [0.69708866],\n",
              "       [0.6202234 ],\n",
              "       [0.69530123],\n",
              "       [0.6773106 ],\n",
              "       [0.68360865],\n",
              "       [0.64828914],\n",
              "       [0.61575466],\n",
              "       [0.6287988 ],\n",
              "       [0.6648556 ],\n",
              "       [0.69731116],\n",
              "       [0.62786067],\n",
              "       [0.6176902 ],\n",
              "       [0.5987702 ],\n",
              "       [0.69495296],\n",
              "       [0.63917404],\n",
              "       [0.62777424],\n",
              "       [0.6247306 ],\n",
              "       [0.7101145 ],\n",
              "       [0.6651702 ],\n",
              "       [0.65136707],\n",
              "       [0.63153684],\n",
              "       [0.6097708 ],\n",
              "       [0.5921366 ],\n",
              "       [0.5935069 ],\n",
              "       [0.57846844],\n",
              "       [0.5708726 ],\n",
              "       [0.60035026],\n",
              "       [0.6664817 ],\n",
              "       [0.5475467 ],\n",
              "       [0.5429728 ],\n",
              "       [0.5262343 ],\n",
              "       [0.6142604 ],\n",
              "       [0.49373144],\n",
              "       [0.61615217],\n",
              "       [0.5802715 ],\n",
              "       [0.6216183 ],\n",
              "       [0.6084441 ],\n",
              "       [0.66399014],\n",
              "       [0.62246037],\n",
              "       [0.6084896 ],\n",
              "       [0.5496608 ],\n",
              "       [0.59355336],\n",
              "       [0.6301904 ],\n",
              "       [0.5922042 ],\n",
              "       [0.67008495],\n",
              "       [0.5446838 ],\n",
              "       [0.61567336],\n",
              "       [0.6188056 ],\n",
              "       [0.5799978 ],\n",
              "       [0.57890505],\n",
              "       [0.63647854],\n",
              "       [0.6314473 ],\n",
              "       [0.5010631 ],\n",
              "       [0.65946805],\n",
              "       [0.6506573 ],\n",
              "       [0.47208685],\n",
              "       [0.61787224],\n",
              "       [0.65560913],\n",
              "       [0.61564267],\n",
              "       [0.61478835],\n",
              "       [0.6297027 ],\n",
              "       [0.7079358 ],\n",
              "       [0.61071074],\n",
              "       [0.6269009 ],\n",
              "       [0.6692755 ],\n",
              "       [0.56037223],\n",
              "       [0.6276444 ],\n",
              "       [0.5680911 ],\n",
              "       [0.5608659 ],\n",
              "       [0.56627715],\n",
              "       [0.6167163 ],\n",
              "       [0.636587  ],\n",
              "       [0.5607398 ],\n",
              "       [0.60439557],\n",
              "       [0.612442  ],\n",
              "       [0.6225896 ],\n",
              "       [0.631815  ],\n",
              "       [0.6443731 ],\n",
              "       [0.559207  ],\n",
              "       [0.68143564],\n",
              "       [0.6360524 ],\n",
              "       [0.61082226],\n",
              "       [0.6334967 ],\n",
              "       [0.60145676],\n",
              "       [0.6733229 ],\n",
              "       [0.6529634 ],\n",
              "       [0.63707423],\n",
              "       [0.57453334],\n",
              "       [0.61173034],\n",
              "       [0.55982673],\n",
              "       [0.59633243],\n",
              "       [0.5980059 ],\n",
              "       [0.667003  ],\n",
              "       [0.63848436],\n",
              "       [0.7148348 ],\n",
              "       [0.5634457 ],\n",
              "       [0.57675934],\n",
              "       [0.68340504],\n",
              "       [0.7233645 ],\n",
              "       [0.6696424 ],\n",
              "       [0.674607  ],\n",
              "       [0.64987147],\n",
              "       [0.6532767 ],\n",
              "       [0.6474549 ],\n",
              "       [0.68296444],\n",
              "       [0.69291955],\n",
              "       [0.6282674 ],\n",
              "       [0.65997064],\n",
              "       [0.6617546 ],\n",
              "       [0.68688846],\n",
              "       [0.7051398 ],\n",
              "       [0.62352514],\n",
              "       [0.6679151 ],\n",
              "       [0.699492  ],\n",
              "       [0.6781773 ],\n",
              "       [0.6106576 ],\n",
              "       [0.58439404],\n",
              "       [0.69209814],\n",
              "       [0.6707057 ],\n",
              "       [0.6421605 ],\n",
              "       [0.711987  ],\n",
              "       [0.71423143],\n",
              "       [0.7042304 ],\n",
              "       [0.65104926],\n",
              "       [0.7029996 ],\n",
              "       [0.6311651 ],\n",
              "       [0.72338283],\n",
              "       [0.65435934],\n",
              "       [0.7037899 ],\n",
              "       [0.71670836],\n",
              "       [0.7190948 ],\n",
              "       [0.6007632 ],\n",
              "       [0.6520143 ],\n",
              "       [0.6727535 ],\n",
              "       [0.55653405],\n",
              "       [0.6591917 ],\n",
              "       [0.52716035],\n",
              "       [0.5416035 ],\n",
              "       [0.65723157],\n",
              "       [0.61886513],\n",
              "       [0.58605224],\n",
              "       [0.66872156],\n",
              "       [0.666278  ],\n",
              "       [0.5442149 ],\n",
              "       [0.61289376],\n",
              "       [0.63285244],\n",
              "       [0.65945244],\n",
              "       [0.6434135 ],\n",
              "       [0.5886638 ],\n",
              "       [0.6311461 ],\n",
              "       [0.6965134 ],\n",
              "       [0.58823836],\n",
              "       [0.58932936],\n",
              "       [0.61241364],\n",
              "       [0.6884757 ],\n",
              "       [0.7004658 ],\n",
              "       [0.7014442 ],\n",
              "       [0.6276001 ],\n",
              "       [0.6556617 ],\n",
              "       [0.65023404],\n",
              "       [0.5907401 ],\n",
              "       [0.6417322 ],\n",
              "       [0.6442414 ],\n",
              "       [0.60575444],\n",
              "       [0.7412368 ],\n",
              "       [0.6684311 ],\n",
              "       [0.6575674 ],\n",
              "       [0.6840917 ],\n",
              "       [0.594388  ],\n",
              "       [0.64322937],\n",
              "       [0.6216664 ],\n",
              "       [0.7055822 ],\n",
              "       [0.5825942 ],\n",
              "       [0.5719667 ],\n",
              "       [0.61646205],\n",
              "       [0.7211634 ],\n",
              "       [0.5934608 ],\n",
              "       [0.5138732 ],\n",
              "       [0.6424247 ],\n",
              "       [0.6552705 ],\n",
              "       [0.65383255],\n",
              "       [0.6659593 ],\n",
              "       [0.556414  ],\n",
              "       [0.5459101 ],\n",
              "       [0.6332474 ],\n",
              "       [0.6042002 ],\n",
              "       [0.5473953 ],\n",
              "       [0.68845725],\n",
              "       [0.560443  ],\n",
              "       [0.5607374 ],\n",
              "       [0.6363841 ],\n",
              "       [0.6203762 ],\n",
              "       [0.6186434 ],\n",
              "       [0.61411333],\n",
              "       [0.623204  ],\n",
              "       [0.56159735],\n",
              "       [0.59318435],\n",
              "       [0.6439739 ],\n",
              "       [0.58252263],\n",
              "       [0.634726  ],\n",
              "       [0.51509255],\n",
              "       [0.633871  ],\n",
              "       [0.6264521 ],\n",
              "       [0.6019037 ],\n",
              "       [0.6485095 ],\n",
              "       [0.6459262 ],\n",
              "       [0.62968355],\n",
              "       [0.58121127],\n",
              "       [0.60438603],\n",
              "       [0.62544006],\n",
              "       [0.6017611 ],\n",
              "       [0.6457346 ],\n",
              "       [0.5888922 ],\n",
              "       [0.6585815 ],\n",
              "       [0.52348775],\n",
              "       [0.6971184 ],\n",
              "       [0.6997295 ],\n",
              "       [0.55474746],\n",
              "       [0.64357895],\n",
              "       [0.4483206 ],\n",
              "       [0.64890015],\n",
              "       [0.6102581 ],\n",
              "       [0.5390788 ],\n",
              "       [0.5642598 ],\n",
              "       [0.6908378 ],\n",
              "       [0.6458435 ],\n",
              "       [0.58097726],\n",
              "       [0.61987376],\n",
              "       [0.57799554],\n",
              "       [0.5623927 ],\n",
              "       [0.672243  ],\n",
              "       [0.58270776],\n",
              "       [0.5643382 ],\n",
              "       [0.6464619 ],\n",
              "       [0.6668567 ],\n",
              "       [0.6717338 ],\n",
              "       [0.62026125],\n",
              "       [0.6814616 ],\n",
              "       [0.7297316 ],\n",
              "       [0.6216591 ],\n",
              "       [0.5933792 ],\n",
              "       [0.63352764],\n",
              "       [0.6328498 ],\n",
              "       [0.6295608 ],\n",
              "       [0.6597614 ],\n",
              "       [0.6072072 ],\n",
              "       [0.52892494],\n",
              "       [0.6900575 ],\n",
              "       [0.5691989 ],\n",
              "       [0.6103448 ],\n",
              "       [0.689453  ],\n",
              "       [0.63249743],\n",
              "       [0.72496426],\n",
              "       [0.6501269 ],\n",
              "       [0.5691569 ],\n",
              "       [0.64395523],\n",
              "       [0.62549746],\n",
              "       [0.7201496 ],\n",
              "       [0.68188506],\n",
              "       [0.6666619 ],\n",
              "       [0.70717585],\n",
              "       [0.5790349 ],\n",
              "       [0.64949894],\n",
              "       [0.6537028 ],\n",
              "       [0.63184404],\n",
              "       [0.69827056],\n",
              "       [0.6448592 ],\n",
              "       [0.6370392 ],\n",
              "       [0.6809606 ],\n",
              "       [0.57491356],\n",
              "       [0.62488854],\n",
              "       [0.7155966 ],\n",
              "       [0.67645955],\n",
              "       [0.5876165 ],\n",
              "       [0.5528586 ],\n",
              "       [0.6588849 ],\n",
              "       [0.699935  ],\n",
              "       [0.57664335],\n",
              "       [0.6046312 ],\n",
              "       [0.608068  ],\n",
              "       [0.62208724],\n",
              "       [0.67705   ],\n",
              "       [0.6724013 ],\n",
              "       [0.6780514 ]], dtype=float32)"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calcula la similitud coseno entre corpus_bert y query_bert\n",
        "similarities = cosine_similarity(corpus_bert.reshape(319,768),query_bert.reshape(1,768))\n",
        "# Muestra las similitudes calculadas\n",
        "similarities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UWHBIjfq9Ehf",
      "metadata": {
        "id": "UWHBIjfq9Ehf"
      },
      "source": [
        "#Step 6: Query processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xBko1mv5mZLm",
      "metadata": {
        "id": "xBko1mv5mZLm"
      },
      "source": [
        "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iFRUZ04TmcnU",
      "metadata": {
        "id": "iFRUZ04TmcnU"
      },
      "source": [
        "### Funcion retrieve TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CwtN4VwI71lI",
      "metadata": {
        "id": "CwtN4VwI71lI"
      },
      "outputs": [],
      "source": [
        "def retrieve_tfidf(query):\n",
        "  # Transforma la consulta usando vectorizer (TF-IDF)\n",
        "  query_vector = vectorizer.transform([query])\n",
        "\n",
        "  # Calcula la similitud coseno entre tfidf_mtx y la consulta\n",
        "  similarities = cosine_similarity(tfidf_mtx, query_vector)\n",
        "\n",
        "  # Crea un DataFrame con las similitudes\n",
        "  similarities_df = pd.DataFrame(similarities, columns=['similarity'])\n",
        "\n",
        "  # Agrega los títulos de los documentos al DataFrame\n",
        "  similarities_df['document'] = df['title']\n",
        "\n",
        "  # Devuelve el DataFrame con las similitudes calculadas\n",
        "  return similarities_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "AWETFOKF71ie",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AWETFOKF71ie",
        "outputId": "5bf93edc-4352-45c7-b955-14305f7b81b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"retrieve_tfidf('Artificial General')\",\n  \"rows\": 319,\n  \"fields\": [\n    {\n      \"column\": \"similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014651214965682113,\n        \"min\": 0.0,\n        \"max\": 0.13137856337847947,\n        \"num_unique_values\": 315,\n        \"samples\": [\n          0.0021037729924243843,\n          0.04275490239747699,\n          0.007042707155588823\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 317,\n        \"samples\": [\n          \"Deep Learning, Education, and Real-World AI\",\n          \"Bad Vegan\",\n          \"Thousand Brains Theory of Intelligence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-37c2ef84-48fe-4641-802e-46660ebef183\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.033378</td>\n",
              "      <td>Life 3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.052715</td>\n",
              "      <td>Consciousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.131379</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.069172</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.041889</td>\n",
              "      <td>Statistical Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>0.003836</td>\n",
              "      <td>Singularity, Superintelligence, and Immortality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>0.013679</td>\n",
              "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>0.002737</td>\n",
              "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>0.003851</td>\n",
              "      <td>Poker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>0.007999</td>\n",
              "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37c2ef84-48fe-4641-802e-46660ebef183')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37c2ef84-48fe-4641-802e-46660ebef183 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37c2ef84-48fe-4641-802e-46660ebef183');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18a67604-a801-488d-ba7c-b672f23d122f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18a67604-a801-488d-ba7c-b672f23d122f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18a67604-a801-488d-ba7c-b672f23d122f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     similarity                                           document\n",
              "0      0.033378                                           Life 3.0\n",
              "1      0.052715                                      Consciousness\n",
              "2      0.131379                            AI in the Age of Reason\n",
              "3      0.069172                                      Deep Learning\n",
              "4      0.041889                               Statistical Learning\n",
              "..          ...                                                ...\n",
              "314    0.003836    Singularity, Superintelligence, and Immortality\n",
              "315    0.013679   Emotion AI, Social Robots, and Self-Driving Cars\n",
              "316    0.002737  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
              "317    0.003851                                              Poker\n",
              "318    0.007999  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
              "\n",
              "[319 rows x 2 columns]"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejecuta la función retrieve_tfidf con la consulta 'image'\n",
        "retrieve_tfidf('Artificial General')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dUXbOYXmmiAW",
      "metadata": {
        "id": "dUXbOYXmmiAW"
      },
      "source": [
        "### Funcion retrieve BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EZSu76FL-tMm",
      "metadata": {
        "id": "EZSu76FL-tMm"
      },
      "outputs": [],
      "source": [
        "def retrieve_bert(query):\n",
        "  # Genera embeddings BERT para la consulta\n",
        "  query_bert = generate_bert_embeddings(query)\n",
        "\n",
        "  # Calcula la similitud coseno entre corpus_bert y la consulta BERT\n",
        "  similarities = cosine_similarity(corpus_bert.reshape(319 ,768),query_bert.reshape(1,768))\n",
        "\n",
        "# Crea un DataFrame con las similitudes\n",
        "  similarities_df = pd.DataFrame(similarities, columns=['similarity'])\n",
        "\n",
        "  # Agrega los títulos de los episodios al DataFrame\n",
        "  similarities_df['document'] = df['title']\n",
        "\n",
        "  # Devuelve el DataFrame con las similitudes calculadas\n",
        "  return similarities_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "LUhUK_pd_Zt1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LUhUK_pd_Zt1",
        "outputId": "4ca587d8-77f2-4890-fe8d-6867e86cb1a1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"retrieve_bert(['Artificial General'])\",\n  \"rows\": 319,\n  \"fields\": [\n    {\n      \"column\": \"similarity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 318,\n        \"samples\": [\n          0.6084895730018616,\n          0.6295608282089233,\n          0.6869089603424072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 317,\n        \"samples\": [\n          \"Deep Learning, Education, and Real-World AI\",\n          \"Bad Vegan\",\n          \"Thousand Brains Theory of Intelligence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-38fa277c-f7b9-4fe2-9ef8-955377b5dc9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.665738</td>\n",
              "      <td>Life 3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.688087</td>\n",
              "      <td>Consciousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.662854</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.572245</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.685993</td>\n",
              "      <td>Statistical Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>0.608068</td>\n",
              "      <td>Singularity, Superintelligence, and Immortality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>0.622087</td>\n",
              "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>0.677050</td>\n",
              "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>0.672401</td>\n",
              "      <td>Poker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>0.678051</td>\n",
              "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38fa277c-f7b9-4fe2-9ef8-955377b5dc9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38fa277c-f7b9-4fe2-9ef8-955377b5dc9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38fa277c-f7b9-4fe2-9ef8-955377b5dc9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-057f4651-7792-45a0-baab-78c6849544b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-057f4651-7792-45a0-baab-78c6849544b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-057f4651-7792-45a0-baab-78c6849544b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     similarity                                           document\n",
              "0      0.665738                                           Life 3.0\n",
              "1      0.688087                                      Consciousness\n",
              "2      0.662854                            AI in the Age of Reason\n",
              "3      0.572245                                      Deep Learning\n",
              "4      0.685993                               Statistical Learning\n",
              "..          ...                                                ...\n",
              "314    0.608068    Singularity, Superintelligence, and Immortality\n",
              "315    0.622087   Emotion AI, Social Robots, and Self-Driving Cars\n",
              "316    0.677050  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
              "317    0.672401                                              Poker\n",
              "318    0.678051  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
              "\n",
              "[319 rows x 2 columns]"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejecuta la función retrieve_bert con la consulta ['Computer Science']\n",
        "retrieve_bert(['Artificial General'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FFQbESVPmpgK",
      "metadata": {
        "id": "FFQbESVPmpgK"
      },
      "source": [
        "# Step 7: Retrieve and Compare Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uONFxgi6mtUV",
      "metadata": {
        "id": "uONFxgi6mtUV"
      },
      "source": [
        "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K-nhZIVkv-Xt",
      "metadata": {
        "id": "K-nhZIVkv-Xt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def process_query(query, tfidf_vectorizer, tfidf_matrix, bert_embeddings, tokenizer, model):\n",
        "\n",
        "    # TF-IDF\n",
        "    # Transforma la consulta usando el vectorizador TF-IDF\n",
        "    query_vector = tfidf_vectorizer.transform([query])\n",
        "\n",
        "    # Calcula la similitud coseno entre tfidf_matrix y la consulta transformada\n",
        "    tfidf_similarity = cosine_similarity(tfidf_matrix, query_vector)\n",
        "\n",
        "    # BERT\n",
        "    # Genera embeddings BERT para la consulta\n",
        "    query_embedding = generate_bert_embeddings([query])\n",
        "\n",
        "     # Calcula la similitud coseno entre los embeddings BERT y la consulta BERT\n",
        "    bert_similarity = cosine_similarity(bert_embeddings.reshape(len(bert_embeddings), -1), query_embedding.reshape(1, -1))\n",
        "\n",
        "\n",
        "   # Devuelve las similitudes calculadas para TF-IDF y BERT\n",
        "    return tfidf_similarity, bert_similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B0stZQp_m1xY",
      "metadata": {
        "id": "B0stZQp_m1xY"
      },
      "source": [
        "#Step 8: Test the IR System"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q47TdIovm4fP",
      "metadata": {
        "id": "Q47TdIovm4fP"
      },
      "source": [
        "Test the system with a sample query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DBuuZSnoq6Wv",
      "metadata": {
        "id": "DBuuZSnoq6Wv"
      },
      "outputs": [],
      "source": [
        "def retrieve_top_results(similarity_scores, top_n=5):\n",
        "\n",
        "   # Obtiene los índices de los documentos con las mayores similitudes\n",
        "    top_indices = similarity_scores.argsort()[0][-top_n:][::-1]\n",
        "\n",
        "    # Devuelve los índices de los documentos más similares\n",
        "    return top_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KN8sJyEjq6Up",
      "metadata": {
        "id": "KN8sJyEjq6Up"
      },
      "outputs": [],
      "source": [
        "def display_results(indices, df, similarities):\n",
        "    for index in indices:\n",
        "\n",
        "      # Imprime el título del episodio\n",
        "        print(f\"Episode: {df.iloc[index]['title']}\")\n",
        "\n",
        "        # Imprime la similitud del episodio\n",
        "        print(f\"Similarity: {similarities[0][index]:.4f}\")\n",
        "\n",
        "         # Imprime los primeros 200 caracteres del texto del episodio\n",
        "        print(f\"Transcript: {df.iloc[index]['text'][:200]}...\")  # Display the first 200 characters\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "qVxhgE0kq6Q_",
      "metadata": {
        "id": "qVxhgE0kq6Q_"
      },
      "outputs": [],
      "source": [
        "#Definiendo la query\n",
        "query = \"So the army of the good in terms of the development of technology is large\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "pTk6xkJptsy6",
      "metadata": {
        "id": "pTk6xkJptsy6"
      },
      "outputs": [],
      "source": [
        "# Procesando la query con TF-IDF y BERT\n",
        "tfidf_similarity, bert_similarity = process_query(query, vectorizer, tfidf_mtx, corpus_bert, tokenizer, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "kO6rTyXfnGgf",
      "metadata": {
        "id": "kO6rTyXfnGgf"
      },
      "outputs": [],
      "source": [
        "# Recuperar los resultados principales\n",
        "tfidf_top_indices = retrieve_top_results(tfidf_similarity)\n",
        "bert_top_indices = retrieve_top_results(bert_similarity)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "k8BXh1ELwZcU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BXh1ELwZcU",
        "outputId": "0b555a69-bf54-4027-f70a-4ba2c39c2556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Results:\n",
            "Episode: Life 3.0\n",
            "Similarity: 0.0044\n",
            "Transcript: As part of MIT course 6S099, Artificial General Intelligence, I've gotten the chance to sit down with Max Tegmark. He is a professor here at MIT. He's a physicist, spent a large part of his career stu...\n",
            "\n",
            "\n",
            "BERT Results:\n",
            "Episode: Life 3.0\n",
            "Similarity: 0.7204\n",
            "Transcript: As part of MIT course 6S099, Artificial General Intelligence, I've gotten the chance to sit down with Max Tegmark. He is a professor here at MIT. He's a physicist, spent a large part of his career stu...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostrar los resultados\n",
        "print(\"TF-IDF Results:\")\n",
        "display_results(tfidf_top_indices, df, tfidf_similarity)\n",
        "\n",
        "print(\"BERT Results:\")\n",
        "display_results(bert_top_indices, df, bert_similarity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07HoZliBnJND",
      "metadata": {
        "id": "07HoZliBnJND"
      },
      "source": [
        "Retrieve and display the top results using both TF-IDF and BERT representations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wMM0kvDLnLYC",
      "metadata": {
        "id": "wMM0kvDLnLYC"
      },
      "source": [
        "#Step 9: Compare Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hTCDWWQznNL1",
      "metadata": {
        "id": "hTCDWWQznNL1"
      },
      "source": [
        "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
        "\n",
        "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ajovkzku0yhP",
      "metadata": {
        "id": "ajovkzku0yhP"
      },
      "source": [
        "- Resultados del analisis y comparacion\n",
        "  - TFIDF\n",
        "    - Similitud: 0.0044\n",
        "    - Transcripción: Episodio \"Life 3.0\"\n",
        "    - Observación: La similitud obtenida es bastante baja. Esto se debe a que TF-IDF se basa en la coincidencia exacta de palabras clave, lo que no captura adecuadamente el contexto o el significado semántico de la consulta en relación con el texto del episodio.\n",
        "\n",
        "  - BERT\n",
        "    - Similitud: 0.7204\n",
        "    - Transcripción: Episodio \"Life 3.0\"\n",
        "    - Observación: La similitud es significativamente mayor. Esto indica que BERT puede capturar mejor el contexto y las relaciones semánticas entre las palabras, proporcionando una mayor precisión en la recuperación de información.\n",
        "\n",
        "En conclusión, BERT es  mejor que TF-IDF para recuperar la información relevante. Mientras TF-IDF tiene una similitud muy baja (0.0044) porque solo busca coincidencias exactas de palabras, BERT, con una similitud mucho mayor (0.7204), entiende mejor el contexto y el significado, haciendo que los resultados sean  más precisos\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

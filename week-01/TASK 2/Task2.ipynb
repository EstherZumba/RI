{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9ef1e8-718c-434d-85fd-eb542423fd10",
   "metadata": {},
   "source": [
    "### RAQUEL ZUMBA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ea1ed-9e37-481c-812c-f54eba194127",
   "metadata": {},
   "source": [
    "### 01 Basic Boolean Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36b0d1-73af-4504-84be-cc80887cfc94",
   "metadata": {},
   "source": [
    "### Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911876f-3c38-4c98-8cf5-d9ef4d15b614",
   "metadata": {},
   "source": [
    " Amplíe la funcionalidad de búsqueda de términos simples para incluir capacidades de búsqueda booleana. Esto permitirá a los usuarios realizar consultas más complejas combinando múltiples términos de búsqueda utilizando operadores booleanos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b2600-eb85-4b64-acbe-86ea4a6375b3",
   "metadata": {},
   "source": [
    "### Descripcion del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21725bd-96f4-4cb1-9222-34ee96d95e8e",
   "metadata": {},
   "source": [
    "Debe mejorar el motor de búsqueda existente del ejercicio anterior para que admita operadores booleanos: Y, O y NO. Esto permitirá la recuperación de documentos basándose en las relaciones lógicas entre múltiples términos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaba3d-94f6-4267-80e5-d6b1d60879d0",
   "metadata": {},
   "source": [
    "### Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50412617-a44b-4931-b64d-ee7972f0b64e",
   "metadata": {},
   "source": [
    "### Paso 1: actualizar la preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e0db1-6eac-4638-a98c-1750d81f6981",
   "metadata": {},
   "source": [
    "Asegúrese de que los documentos todavía estén cargados y preprocesados ​​desde la tarea anterior. Los datos deben estar limpios y listos para consultas avanzadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a4a0d9-a82c-4620-ad0d-de3c3a7cd3e1",
   "metadata": {},
   "source": [
    "Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9840c5-f938-44ae-8f05-fb04c6bdd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86717ad5-73be-4df5-bde5-e505473fa5dc",
   "metadata": {},
   "source": [
    "Funcion para abrir y cargar el archivo de texto desde la ruta especificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27c9abd-a522-4707-a8b5-6dbb5f21b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_archivo(ruta_archivo):\n",
    "    with open(ruta_archivo, \"r\", encoding=\"utf-8\") as archivo:\n",
    "        contenido = archivo.read()\n",
    "    return contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f0386-ac05-45a6-8eff-fbf83d81dccf",
   "metadata": {},
   "source": [
    "Funcion tokenizar_texto realiza la tokenización de un texto.\n",
    "Divide un texto en unidades más pequeñas, llamadas tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645ec50d-adaa-4a90-943d-b3fd8246424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar_texto(texto):\n",
    "    palabras = re.findall(r'\\b\\d{2,}\\b|\\b\\w+\\b', texto)\n",
    "    return palabras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08167502-b9f2-4e93-8861-a3df20b39456",
   "metadata": {},
   "source": [
    "Funcion impiar_texto realiza una limpieza básica de una lista de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c031ab0e-cdf6-40f8-9366-92178f3255d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(palabras):\n",
    "    palabras_limpias = [palabra.lower() for palabra in palabras if palabra.isalpha()]\n",
    "    return palabras_limpias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29088fc0-0c62-4b27-ae16-c541b104b5a0",
   "metadata": {},
   "source": [
    "Combina las tres funciones anteriores para cargar un archivo, tokenizar su contenido y limpiar las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "106b5ee8-9875-4aab-a36e-21a5623794c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_archivo(ruta_archivo):\n",
    "    contenido = cargar_archivo(ruta_archivo)\n",
    "    palabras_tokenizadas = tokenizar_texto(contenido)\n",
    "    palabras_limpias = limpiar_texto(palabras_tokenizadas)\n",
    "    return palabras_limpias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ede13-ef78-45eb-bf73-6b353a977dea",
   "metadata": {},
   "source": [
    "### PASO 2: Preparacion de archivos tokenizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a645849-0438-4b05-ac4e-0a2806da70ed",
   "metadata": {},
   "source": [
    "Recorre todos los archivos en un directorio, procesa cada archivo y almacena las palabras limpias en un diccionario:\n",
    "\n",
    "    - claves: nombres de los archivos\n",
    "    - valores: las listas de palabras limpias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d62d48f-a9c8-48a1-8f46-93d0d15e9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_archivos_tokenizados(directorio):\n",
    "    archivos_tokenizados = {}\n",
    "    for nombre_archivo in os.listdir(directorio):\n",
    "        if nombre_archivo.endswith(\".txt\"):\n",
    "            ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "            palabras_procesadas = procesar_archivo(ruta_archivo)\n",
    "            archivos_tokenizados[nombre_archivo] = palabras_procesadas\n",
    "    return archivos_tokenizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8327e1e-106a-4578-9c8e-e701cd012d90",
   "metadata": {},
   "source": [
    "### PASO 3: Creacion de un indice invertido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e75513-7763-42f7-8662-1d4eb423d3d5",
   "metadata": {},
   "source": [
    "Se crea un índice invertido a partir de un diccionario de archivos tokenizados.\n",
    "Recorre cada archivo y su lista de palabras, y construye un diccionario donde las claves son las palabras y los valores son conjuntos de nombres de archivos donde aparece cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7a08d4-5201-409e-a88e-111ba7e41512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_indice_invertido(archivos_tokenizados):\n",
    "    indice_invertido = {}\n",
    "    for nombre_archivo, palabras in archivos_tokenizados.items():\n",
    "        for palabra in palabras:\n",
    "            if palabra in indice_invertido:\n",
    "                indice_invertido[palabra].add(nombre_archivo)\n",
    "            else:\n",
    "                indice_invertido[palabra] = {nombre_archivo}\n",
    "    return indice_invertido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a35a8d-bdfa-44ab-9e81-9253220c54ce",
   "metadata": {},
   "source": [
    "### PASO 4: Implementación de busqueda  boleana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b360d-713d-4d79-a540-2efa078d574b",
   "metadata": {},
   "source": [
    "- Analizar la consulta: implemente una función para analizar la consulta de entrada para identificar los términos y operadores.\n",
    "- Buscar documentos: según la consulta analizada, implemente la lógica para recuperar y clasificar los documentos según las expresiones booleanas.\n",
    "- Manejo de distinción entre mayúsculas y minúsculas y coincidencias parciales: opcionalmente, puede manejar casos y coincidencias parciales para refinar los resultados de la búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b5511-5f2a-4c50-b4f2-f5607bef7796",
   "metadata": {},
   "source": [
    "Divide la consulta en términos individuales y separa los operadores booleanos (\"AND\", \"OR\", \"NOT\") en una lista aparte. \n",
    "\n",
    "Devuelve dos listas: una lista de términos y una lista de operadores booleanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76bc1e2c-a5d2-44a5-88af-3e9795f8ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_consulta(consulta):\n",
    "    terminos = consulta.split()\n",
    "    operadores_booleanos = [term for term in terminos if term in [\"AND\", \"OR\", \"NOT\"]]\n",
    "    terminos = [term for term in terminos if term not in [\"AND\", \"OR\", \"NOT\"]]\n",
    "    return terminos, operadores_booleanos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7e4e7-3cc8-446e-a19e-09c52e2d4266",
   "metadata": {},
   "source": [
    "En esta funcion, utilizamos:\n",
    "\n",
    "- los términos de búsqueda\n",
    "- los operadores booleanos\n",
    "- El índice invertido \n",
    "\n",
    "para encontrar los documentos relevantes que coinciden con la consulta de busqueda. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc54ab49-b070-454b-90f2-31703723d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_documentos(terminos, operadores_booleanos, indice_invertido):\n",
    "    documentos_coincidentes = None\n",
    "    for i, termino in enumerate(terminos):\n",
    "        documentos_termino = indice_invertido.get(termino, set())\n",
    "        if operadores_booleanos and i < len(operadores_booleanos):\n",
    "            operador = operadores_booleanos[i]\n",
    "            if operador == \"AND\":\n",
    "                documentos_coincidentes = documentos_termino if documentos_coincidentes is None else documentos_coincidentes & documentos_termino\n",
    "            elif operador == \"OR\":\n",
    "                documentos_coincidentes = documentos_termino if documentos_coincidentes is None else documentos_coincidentes | documentos_termino\n",
    "            elif operador == \"NOT\":\n",
    "                documentos_coincidentes -= documentos_termino\n",
    "        else:\n",
    "            documentos_coincidentes = documentos_termino if documentos_coincidentes is None else documentos_coincidentes & documentos_termino\n",
    "    return documentos_coincidentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ef2e5-d3da-426f-9653-a45f63b7f4f9",
   "metadata": {},
   "source": [
    "### PASO 5: Desplegar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff8b45-4f87-4f6b-a90e-4a0f9861ef25",
   "metadata": {},
   "source": [
    "Esta función muestra los nombres de los documentos que coinciden con la consulta que se ha hecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638dd388-6da4-451a-92c0-f2b79ea13ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_resultados(documentos_coincidentes):\n",
    "    if documentos_coincidentes:\n",
    "        print(\"\\nDocumentos que coinciden con la consulta:\")\n",
    "        for documento in documentos_coincidentes:\n",
    "            print(\"- \", documento)\n",
    "    else:\n",
    "        print(\"No se encontraron documentos que coincidan con la consulta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e18198-86e6-4173-9071-e3b3338f81f7",
   "metadata": {},
   "source": [
    "Se toma el directorio de archivos de texto a ser tokenizados, para luego construir los indices invertidos(mediante ED diccionario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea0c6ae-5aa1-4b59-94e4-a99b167ea03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_consulta_usuario():\n",
    "    consulta = input(\"Ingrese la consulta de búsqueda: \")\n",
    "    return consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a05e7b76-4cea-4e81-b676-8bf5ec6c0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = r\"C:\\Users\\Dell\\OneDrive - Escuela Politécnica Nacional\\7 SEMESTRE 2023B\\RI\\RI\\week-01\\TASK 2\\data49\"\n",
    "archivos_tokenizados = preparar_archivos_tokenizados(directorio)\n",
    "indice_invertido = crear_indice_invertido(archivos_tokenizados)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f7140-3a7d-4ccb-9d53-3e620ede4c24",
   "metadata": {},
   "source": [
    "Solicita y analiza la consulta para identificar el termino de busqueda utilizando el indice invertido para encontrar los docuemntos que coinciden con la consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be8855-a9b0-4d00-9539-00d710ced126",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta_usuario = obtener_consulta_usuario()\n",
    "terminos, operadores_booleanos = analizar_consulta(consulta_usuario)\n",
    "documentos_coincidentes = buscar_documentos(terminos, operadores_booleanos, indice_invertido)\n",
    "mostrar_resultados(documentos_coincidentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144c2b7-ce00-4a7e-8a83-020d2a40d6f7",
   "metadata": {},
   "source": [
    "Genera una matriz que representa las palabras en los archivos tokenizados. \n",
    "\n",
    "Cada fila de la matriz corresponde a una palabra, y cada columna corresponde a un archivo. Si una palabra está presente en un archivo, se marca con un 1 en la matriz; de lo contrario, se marca con un 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eabeff-7f92-47de-931a-b61a918b5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_matriz_indices(archivos_tokenizados):\n",
    "    matriz_indices = {}\n",
    "    for nombre_archivo, palabras in archivos_tokenizados.items():\n",
    "        for palabra in palabras:\n",
    "            if palabra in matriz_indices:\n",
    "                matriz_indices[palabra][nombre_archivo] = 1\n",
    "            else:\n",
    "                matriz_indices[palabra] = {archivo: 0 for archivo in archivos_tokenizados}\n",
    "                matriz_indices[palabra][nombre_archivo] = 1\n",
    "    return matriz_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdc75d-33a4-438f-93b2-970b3ed64cef",
   "metadata": {},
   "source": [
    "Muestra las palabras en las filas y los nombres de los archivos en las columnas. Cada celda de la matriz contiene un 1 si la palabra está presente en el archivo correspondiente, y un 0 si no lo está. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d71542-e857-4a83-bda6-4123f7b1ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_matriz_indices(matriz_indices):\n",
    "    print(\"\\nMatriz de índices:\")\n",
    "    print(\"{: <15}\".format(\"Palabra\"), end=\"\")\n",
    "    for nombre_archivo in matriz_indices[next(iter(matriz_indices))]:\n",
    "        print(\"{: <10}\".format(nombre_archivo), end=\"\")\n",
    "    print()\n",
    "    for palabra, presencias in matriz_indices.items():\n",
    "        print(\"{: <15}\".format(palabra), end=\"\")\n",
    "        for nombre_archivo in matriz_indices[next(iter(matriz_indices))]:\n",
    "            print(\"{: <10}\".format(presencias.get(nombre_archivo, 0)), end=\"\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325662b-3bae-44e8-943f-dc8b8b94498f",
   "metadata": {},
   "source": [
    "### PASO 6: Matriz de indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7a265-658e-4a4f-80aa-b25b16940165",
   "metadata": {},
   "source": [
    "Imprime la matriz de índices en la consola. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6715d28-ca36-4ff9-a763-8c30f689a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego de obtener la consulta y los documentos coincidentes\n",
    "\n",
    "# Preparar la matriz de índices\n",
    "matriz_indices = crear_matriz_indices(archivos_tokenizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b856a-1af5-40bb-99a9-c610dec2dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la matriz de índices\n",
    "mostrar_matriz_indices(matriz_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
